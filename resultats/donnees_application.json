[
  {
    "Model Name": "0-hero/Matter-0.2-7B-DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.219174164123715,
    "Overall Score": 8.90636130175029,
    "MMLU Score": 1.8173758865248213,
    "BBH Score": 10.055525080241036,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.305241173767623
  },
  {
    "Model Name": "01-ai/Yi-1.5-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 22.7033978747449,
    "Overall Score": 25.64649419429311,
    "MMLU Score": 40.732121749408975,
    "BBH Score": 42.74936268839652,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.1296324160720492
  },
  {
    "Model Name": "01-ai/Yi-1.5-34B-32K",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 23.15462857509891,
    "Overall Score": 26.72791290850813,
    "MMLU Score": 41.21232269503546,
    "BBH Score": 43.38184666762572,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.154322679883193
  },
  {
    "Model Name": "01-ai/Yi-1.5-34B-Chat",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 22.423843867327744,
    "Overall Score": 33.35799367075618,
    "MMLU Score": 39.11606087470449,
    "BBH Score": 44.262825981005655,
    "Math Score": 27.7190332326284,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.487612644296005
  },
  {
    "Model Name": "01-ai/Yi-1.5-34B-Chat-16K",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.774022458148835,
    "Overall Score": 29.403554842710225,
    "MMLU Score": 39.38386524822696,
    "BBH Score": 44.53615654671034,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-07-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.340634390330241
  },
  {
    "Model Name": "01-ai/Yi-1.5-6B",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.8442095716487763,
    "Overall Score": 16.745698054972127,
    "MMLU Score": 23.823507683215126,
    "BBH Score": 22.027904536694773,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.080149193673792
  },
  {
    "Model Name": "01-ai/Yi-1.5-6B-Chat",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4447911071090622,
    "Overall Score": 22.784006289829847,
    "MMLU Score": 24.368351063829788,
    "BBH Score": 23.67872313235784,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.769758117780249
  },
  {
    "Model Name": "01-ai/Yi-1.5-9B",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.4688920320817076,
    "Overall Score": 22.153901514184795,
    "MMLU Score": 32.402482269503544,
    "BBH Score": 30.50071699492122,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.082048939150674
  },
  {
    "Model Name": "01-ai/Yi-1.5-9B-32K",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5680734132696938,
    "Overall Score": 19.809786285875365,
    "MMLU Score": 30.72177895981088,
    "BBH Score": 28.937011582169664,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.633200791644484
  },
  {
    "Model Name": "01-ai/Yi-1.5-9B-Chat",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.453543490910605,
    "Overall Score": 29.53087222026097,
    "MMLU Score": 33.05814125295508,
    "BBH Score": 36.95293138417893,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 20.316469651527722
  },
  {
    "Model Name": "01-ai/Yi-1.5-9B-Chat-16K",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.584745013401753,
    "Overall Score": 23.76539234993476,
    "MMLU Score": 33.261303191489354,
    "BBH Score": 31.49760894701832,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.99635092646285
  },
  {
    "Model Name": "01-ai/Yi-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 25.657483288779545,
    "Overall Score": 22.373127018936653,
    "MMLU Score": 37.90632387706855,
    "BBH Score": 35.542431259008794,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.8719922670171163
  },
  {
    "Model Name": "01-ai/Yi-34B-200K",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 25.50385584712952,
    "Overall Score": 20.01347533597433,
    "MMLU Score": 39.27304964539008,
    "BBH Score": 36.02211028900003,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7847235122381255
  },
  {
    "Model Name": "01-ai/Yi-34B-Chat",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.12569568998157,
    "Overall Score": 24.226662652803373,
    "MMLU Score": 34.369459219858165,
    "BBH Score": 37.623987597243485,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.964218581317266
  },
  {
    "Model Name": "01-ai/Yi-6B",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.0985492537000408,
    "Overall Score": 13.611617485376058,
    "MMLU Score": 22.12433510638298,
    "BBH Score": 19.408504737915056,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.390539103759398
  },
  {
    "Model Name": "01-ai/Yi-6B-200K",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1264239806184515,
    "Overall Score": 11.99609829883284,
    "MMLU Score": 20.489804964539008,
    "BBH Score": 20.148020103768047,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.649718494315529
  },
  {
    "Model Name": "01-ai/Yi-6B-Chat",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1106656722436012,
    "Overall Score": 14.11765000523676,
    "MMLU Score": 22.90004432624113,
    "BBH Score": 17.00016656742376,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.710980773105545
  },
  {
    "Model Name": "01-ai/Yi-9B",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.530663961417017,
    "Overall Score": 17.811867367746064,
    "MMLU Score": 28.59781323877068,
    "BBH Score": 27.62695611207793,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.636693498197129
  },
  {
    "Model Name": "01-ai/Yi-9B-200K",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5489823437933046,
    "Overall Score": 17.72955178611439,
    "MMLU Score": 29.1334219858156,
    "BBH Score": 26.49249509714754,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.445935363405415
  },
  {
    "Model Name": "01-ai/Yi-Coder-9B-Chat",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.819532229592168,
    "Overall Score": 16.985989314863886,
    "MMLU Score": 15.83554964539007,
    "BBH Score": 25.94315294491389,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.33536050563454
  },
  {
    "Model Name": "1-800-LLMs/Qwen-2.5-14B-Hindi",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.866074287346813,
    "Overall Score": 36.2661770066689,
    "MMLU Score": 47.362588652482266,
    "BBH Score": 49.32988995210337,
    "Math Score": 33.30815709969788,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.38062083425651
  },
  {
    "Model Name": "1-800-LLMs/Qwen-2.5-14B-Hindi-Custom-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.400465469071647,
    "Overall Score": 31.020777275634742,
    "MMLU Score": 46.26366725768322,
    "BBH Score": 46.54015554088327,
    "Math Score": 31.1178247734139,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.744093255162928
  },
  {
    "Model Name": "1024m/PHI-4-Hindi",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.65964205977959,
    "Overall Score": 27.48785095027712,
    "MMLU Score": 47.10401891252955,
    "BBH Score": 52.46181381023763,
    "Math Score": 23.338368580060425,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.562517675605104
  },
  {
    "Model Name": "1024m/QWEN-14B-B100",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.370181942335884,
    "Overall Score": 41.91906679224076,
    "MMLU Score": 46.429890661938536,
    "BBH Score": 49.77664782103219,
    "Math Score": 54.38066465256798,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.438220698312366
  },
  {
    "Model Name": "152334H/miqu-1-70b-sf",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 12.19797195382831,
    "Overall Score": 29.097407726236643,
    "MMLU Score": 35.865469858156025,
    "BBH Score": 43.807147003691966,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.3854299580599116
  },
  {
    "Model Name": "1TuanPham/T-VisStar-7B-v0.1",
    "Parameters (B)": 7.294,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9052644538640493,
    "Overall Score": 19.14480861089536,
    "MMLU Score": 24.562278368794324,
    "BBH Score": 30.24383447882599,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.048373375185765
  },
  {
    "Model Name": "1TuanPham/T-VisStar-v0.1",
    "Parameters (B)": 7.294,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2487688271364052,
    "Overall Score": 19.14480861089536,
    "MMLU Score": 24.562278368794324,
    "BBH Score": 30.24383447882599,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.330946925378479
  },
  {
    "Model Name": "3rd-Degree-Burn/L-3.1-Science-Writer-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4193565486098367,
    "Overall Score": 21.09120798437004,
    "MMLU Score": 29.43816489361702,
    "BBH Score": 29.19930078641656,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.859696814748517
  },
  {
    "Model Name": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.974099722258276,
    "Overall Score": 11.223740793316349,
    "MMLU Score": 8.32779255319149,
    "BBH Score": 8.618063681935197,
    "Math Score": 26.586102719033235,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.685498390363444
  },
  {
    "Model Name": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5454985447919645,
    "Overall Score": 8.037946007988568,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 6.515144725982737,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2024-11-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.20087581775791
  },
  {
    "Model Name": "3rd-Degree-Burn/Llama-Squared-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.022223049482849,
    "Overall Score": 12.434954194134717,
    "MMLU Score": 15.179890661938533,
    "BBH Score": 21.277103190106818,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.149150657398924
  },
  {
    "Model Name": "4season/final_model_test_v2",
    "Parameters (B)": 21.421,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1620767196814024,
    "Overall Score": 23.086235043644056,
    "MMLU Score": 28.08990839243498,
    "BBH Score": 47.410670136906425,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.677805664105193
  },
  {
    "Model Name": "AALF/FuseChat-Llama-3.1-8B-Instruct-preview",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3772382561660794,
    "Overall Score": 28.56857495894073,
    "MMLU Score": 30.361628250591018,
    "BBH Score": 30.84806521622957,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.743378882365057
  },
  {
    "Model Name": "AALF/FuseChat-Llama-3.1-8B-SFT-preview",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.368615076760581,
    "Overall Score": 29.225292099823264,
    "MMLU Score": 30.48167848699764,
    "BBH Score": 32.53678156315301,
    "Math Score": 22.507552870090635,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.353916521946804
  },
  {
    "Model Name": "AALF/gemma-2-27b-it-SimPO-37K",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 19.995443250824795,
    "Overall Score": 9.512077380763676,
    "MMLU Score": 10.793439716312056,
    "BBH Score": 15.307880971954305,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.47571225410926116
  },
  {
    "Model Name": "AALF/gemma-2-27b-it-SimPO-37K-100steps",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 19.7134709493991,
    "Overall Score": 10.246803363324457,
    "MMLU Score": 12.501846926713949,
    "BBH Score": 15.261078322847055,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.5197868700862542
  },
  {
    "Model Name": "AELLM/gemma-2-aeria-infinity-9b",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.007578688357264,
    "Overall Score": 31.919053815912523,
    "MMLU Score": 31.80223108747045,
    "BBH Score": 42.0902142313775,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.313131208380492
  },
  {
    "Model Name": "AELLM/gemma-2-lyco-infinity-9b",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.957040134565551,
    "Overall Score": 30.04985134020671,
    "MMLU Score": 30.961879432624112,
    "BBH Score": 39.78753882674737,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.044426537575822
  },
  {
    "Model Name": "AGI-0/Art-v0-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3615763771653406,
    "Overall Score": 12.132145545921874,
    "MMLU Score": 1.9835992907801416,
    "BBH Score": 8.029776912286984,
    "Math Score": 24.62235649546828,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.137308140117997
  },
  {
    "Model Name": "AGI-0/Artificium-llama3.1-8B-001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.797402632571756,
    "Overall Score": 19.491817924739056,
    "MMLU Score": 24.23906619385342,
    "BBH Score": 19.34889807323965,
    "Math Score": 13.595166163141997,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.967827118550863
  },
  {
    "Model Name": "AGI-0/smartllama3.1-8B-001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4376684950180103,
    "Overall Score": 20.42455207766212,
    "MMLU Score": 27.628176713947987,
    "BBH Score": 24.8577369132814,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.206718828742403
  },
  {
    "Model Name": "AI-MO/NuminaMath-7B-CoT",
    "Parameters (B)": 6.91,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4919779154384425,
    "Overall Score": 16.118457218023075,
    "MMLU Score": 20.75760933806146,
    "BBH Score": 19.152364282090307,
    "Math Score": 26.96374622356496,
    "Date Submitted": "2024-09-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.803415420050905
  },
  {
    "Model Name": "AI-MO/NuminaMath-7B-TIR",
    "Parameters (B)": 6.91,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.148219574988251,
    "Overall Score": 14.182289143173431,
    "MMLU Score": 19.25236406619385,
    "BBH Score": 16.87354725795866,
    "Math Score": 16.08761329305136,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.601880603034258
  },
  {
    "Model Name": "AI-Sweden-Models/Llama-3-8B-instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3322217617350347,
    "Overall Score": 14.343669671742774,
    "MMLU Score": 17.747118794326237,
    "BBH Score": 18.388095615027524,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.150216890640766
  },
  {
    "Model Name": "AI-Sweden-Models/gpt-sw3-40b",
    "Parameters (B)": 39.927,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.919638730114153,
    "Overall Score": 4.872902485288683,
    "MMLU Score": 3.064051418439715,
    "BBH Score": 6.894934050796576,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.8231756543688122
  },
  {
    "Model Name": "AI4free/Dhanishtha",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.1626300441273092,
    "Overall Score": 11.247711953182252,
    "MMLU Score": 7.145759456264774,
    "BBH Score": 7.93648440557281,
    "Math Score": 25.604229607250755,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.674368910382825
  },
  {
    "Model Name": "AI4free/t2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7121244370774158,
    "Overall Score": 11.33461581083953,
    "MMLU Score": 1.595744680851063,
    "BBH Score": 2.133152068631521,
    "Math Score": 18.95770392749245,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.916622461879275
  },
  {
    "Model Name": "AIDC-AI/Marco-o1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.572870574451556,
    "Overall Score": 27.639223265636087,
    "MMLU Score": 34.62802895981088,
    "BBH Score": 34.84254498655976,
    "Math Score": 37.46223564954683,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.572471450979748
  },
  {
    "Model Name": "Aashraf995/Creative-7B-nerd",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.297734001048624,
    "Overall Score": 29.97819251596781,
    "MMLU Score": 38.802083333333336,
    "BBH Score": 37.0801538173552,
    "Math Score": 31.64652567975831,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.100413868900837
  },
  {
    "Model Name": "Aashraf995/Gemma-Evo-10B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.596031436815906,
    "Overall Score": 34.32632733409121,
    "MMLU Score": 36.3918439716312,
    "BBH Score": 43.42455936867185,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.468688542712018
  },
  {
    "Model Name": "Aashraf995/Qwen-Evo-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.268015219938996,
    "Overall Score": 30.275058582706105,
    "MMLU Score": 38.46963652482269,
    "BBH Score": 38.585326990506125,
    "Math Score": 31.41993957703928,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.87594258069129
  },
  {
    "Model Name": "Aashraf995/QwenStock-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.74989130587265,
    "Overall Score": 37.13002133952593,
    "MMLU Score": 48.69237588652482,
    "BBH Score": 50.43389870716874,
    "Math Score": 35.725075528700906,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.90162602350024
  },
  {
    "Model Name": "AbacusResearch/Jallabi-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.572984679569464,
    "Overall Score": 26.18608192071653,
    "MMLU Score": 40.90757978723404,
    "BBH Score": 43.61576498719506,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.9838951705014076
  },
  {
    "Model Name": "Ahdoot/StructuredThinker-v0.3-MoreStructure",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4898812996305322,
    "Overall Score": 23.924082152035727,
    "MMLU Score": 29.00413711583924,
    "BBH Score": 27.258541777802407,
    "Math Score": 29.0785498489426,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.05771020682556
  },
  {
    "Model Name": "Ahdoot/Test_StealthThinker",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5976047229935322,
    "Overall Score": 22.06904758264274,
    "MMLU Score": 28.856382978723406,
    "BBH Score": 25.366571749083093,
    "Math Score": 17.900302114803626,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.813834714566054
  },
  {
    "Model Name": "AicoresSecurity/Cybernet-Sec-3B-R1-V0",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5825486726169312,
    "Overall Score": 20.584200054790823,
    "MMLU Score": 22.336731678486995,
    "BBH Score": 22.32210586978715,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.33472999315622
  },
  {
    "Model Name": "AicoresSecurity/Cybernet-Sec-3B-R1-V0-Coder",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5676457690031012,
    "Overall Score": 22.930540293017284,
    "MMLU Score": 24.202127659574465,
    "BBH Score": 22.65149321038919,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.39586225277055
  },
  {
    "Model Name": "AicoresSecurity/Cybernet-Sec-3B-R1-V1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5874449879343348,
    "Overall Score": 19.9979903395144,
    "MMLU Score": 20.849955673758867,
    "BBH Score": 19.125071594281845,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 34.04232013253605
  },
  {
    "Model Name": "AicoresSecurity/Cybernet-Sec-3B-R1-V1.1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6141912522744508,
    "Overall Score": 22.6434068109946,
    "MMLU Score": 23.204787234042552,
    "BBH Score": 20.43056853928926,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 36.867029165821485
  },
  {
    "Model Name": "Alepach/notHumpback-M0",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.507090986732091,
    "Overall Score": 5.137220097878128,
    "MMLU Score": 1.3187056737588652,
    "BBH Score": 1.2773603683897798,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.4648094723841174
  },
  {
    "Model Name": "Alepach/notHumpback-M1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.594455192144196,
    "Overall Score": 4.779297887614574,
    "MMLU Score": 1.0139627659574466,
    "BBH Score": 1.922946094565394,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.3296306761758756
  },
  {
    "Model Name": "Alepach/notHumpback-M1-v2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.170536546043483,
    "Overall Score": 5.206724746715221,
    "MMLU Score": 1.3187056737588652,
    "BBH Score": 1.2676708259061196,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.448152229261368
  },
  {
    "Model Name": "Alibaba-NLP/gte-Qwen2-7B-instruct",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.344226697159869,
    "Overall Score": 13.834176058521932,
    "MMLU Score": 25.790484633569736,
    "BBH Score": 21.92548248566236,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.184496809884788
  },
  {
    "Model Name": "Alsebay/Qwen2.5-7B-test-novelist",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.334385652370072,
    "Overall Score": 27.172849099811742,
    "MMLU Score": 31.839169621749413,
    "BBH Score": 30.417500036353,
    "Math Score": 23.48942598187311,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.363565099451293
  },
  {
    "Model Name": "Amaorynho/BBAI2006",
    "Parameters (B)": 1.09,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.0885101147748754,
    "Overall Score": 3.4638352160730896,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.6776683167876156,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.13490819533248
  },
  {
    "Model Name": "Amaorynho/BBAI270V4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6849635831653293,
    "Overall Score": 4.549298117195413,
    "MMLU Score": 1.263297872340425,
    "BBH Score": 3.006785000149223,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.6416642125298955
  },
  {
    "Model Name": "Amaorynho/BBAIIFEV1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6822098163443253,
    "Overall Score": 30.577013862416408,
    "MMLU Score": 31.746823286052013,
    "BBH Score": 32.97465792285014,
    "Math Score": 19.335347432024168,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.8205421995622
  },
  {
    "Model Name": "Amaorynho/BBAI_375",
    "Parameters (B)": 1.09,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.0862765934283882,
    "Overall Score": 3.4638352160730896,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.6776683167876156,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.14802947624679
  },
  {
    "Model Name": "Amu/t1-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6206258731095564,
    "Overall Score": 12.141383312461109,
    "MMLU Score": 17.405437352245865,
    "BBH Score": 15.17286027788074,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.56312786579209
  },
  {
    "Model Name": "Amu/t1-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8009694476236229,
    "Overall Score": 11.160895171582572,
    "MMLU Score": 3.1563977541371155,
    "BBH Score": 15.248848632790676,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.934233327744979
  },
  {
    "Model Name": "ArliAI/ArliAI-RPMax-12B-v1.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.66680461065589,
    "Overall Score": 20.9763399120862,
    "MMLU Score": 26.492316784869978,
    "BBH Score": 24.80906331793277,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.720604760648567
  },
  {
    "Model Name": "ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7854895170769118,
    "Overall Score": 23.942143268323218,
    "MMLU Score": 28.34847813238771,
    "BBH Score": 28.787014099442825,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.40928806320843
  },
  {
    "Model Name": "Arthur-LAGACHERIE/Precis-1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7923436680964789,
    "Overall Score": 8.848710962428209,
    "MMLU Score": 4.735520094562647,
    "BBH Score": 6.06909792285563,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.167768884537555
  },
  {
    "Model Name": "Artples/L-MChat-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1844523714047013,
    "Overall Score": 21.238493444242582,
    "MMLU Score": 25.54114952718676,
    "BBH Score": 24.20155738881327,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2024-07-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.931065830071994
  },
  {
    "Model Name": "Artples/L-MChat-Small",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9310211903677648,
    "Overall Score": 15.23132798262929,
    "MMLU Score": 16.269577423167846,
    "BBH Score": 26.85651550003136,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-07-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.359808069043765
  },
  {
    "Model Name": "Aryanne/QwentileSwap",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 34.397309465760216,
    "Overall Score": 43.91650770857709,
    "MMLU Score": 54.95345744680851,
    "BBH Score": 57.67565555333628,
    "Math Score": 42.220543806646525,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.2767425240713226
  },
  {
    "Model Name": "Aryanne/SHBA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5300866770671715,
    "Overall Score": 29.875548231649606,
    "MMLU Score": 32.134677895981085,
    "BBH Score": 32.47770265291174,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.525395965746362
  },
  {
    "Model Name": "Aryanne/SuperHeart",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.807918553647338,
    "Overall Score": 25.55719928277682,
    "MMLU Score": 32.35630910165484,
    "BBH Score": 31.893554212659296,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.136255879014637
  },
  {
    "Model Name": "AtAndDev/Qwen2.5-1.5B-continuous-learnt",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.673034773667099,
    "Overall Score": 16.518524239214223,
    "MMLU Score": 20.12965425531915,
    "BBH Score": 19.53766599736009,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 24.543344393947656
  },
  {
    "Model Name": "AtAndDev/Qwen2.5-1.5B-continuous-learnt",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3771692115967815,
    "Overall Score": 17.483555890459094,
    "MMLU Score": 20.06501182033097,
    "BBH Score": 19.76640880407865,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.695285185897742
  },
  {
    "Model Name": "Ateron/Glowing-Forest-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8972694159256903,
    "Overall Score": 22.612024614962053,
    "MMLU Score": 30.1954048463357,
    "BBH Score": 35.52548240518279,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 25.200930973038677
  },
  {
    "Model Name": "Ateron/Lotus-Magpic",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8675250939281365,
    "Overall Score": 25.49856357813722,
    "MMLU Score": 27.67434988179669,
    "BBH Score": 32.65772737584173,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.39230663943129
  },
  {
    "Model Name": "Ateron/Way_of_MagPicaro",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8622054716791998,
    "Overall Score": 20.630569141650984,
    "MMLU Score": 28.173020094562645,
    "BBH Score": 34.315941121704846,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.927671325805488
  },
  {
    "Model Name": "AuraIndustries/Aura-4B",
    "Parameters (B)": 4.513,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1599834197817671,
    "Overall Score": 16.063480369846303,
    "MMLU Score": 18.95685579196217,
    "BBH Score": 22.64085672774061,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.84802583891104
  },
  {
    "Model Name": "AuraIndustries/Aura-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.279427720279719,
    "Overall Score": 27.363297533889394,
    "MMLU Score": 31.93151595744681,
    "BBH Score": 30.98134841070972,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.387138249519094
  },
  {
    "Model Name": "AuraIndustries/Aura-MoE-2x4B",
    "Parameters (B)": 7.231,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.994775253625848,
    "Overall Score": 16.79797839924053,
    "MMLU Score": 18.32890070921986,
    "BBH Score": 20.61384808360901,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.42098796278293
  },
  {
    "Model Name": "AuraIndustries/Aura-MoE-2x4B-v2",
    "Parameters (B)": 7.231,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8490265375303527,
    "Overall Score": 17.515881576703762,
    "MMLU Score": 17.88563829787234,
    "BBH Score": 20.801181076748463,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.473028764691934
  },
  {
    "Model Name": "Aurel9/testmerge-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9529287302081578,
    "Overall Score": 20.96930213435916,
    "MMLU Score": 22.807697990543733,
    "BBH Score": 32.79279332763635,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.0051106338022
  },
  {
    "Model Name": "Ayush-Singh/Llama1B-sft-2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7669701604841612,
    "Overall Score": 3.169322945076769,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 1.2375708061002186,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.132263689471422
  },
  {
    "Model Name": "Azure99/Blossom-V6-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.503315116093226,
    "Overall Score": 32.80581546858162,
    "MMLU Score": 39.3746306146572,
    "BBH Score": 30.3528011952772,
    "Math Score": 52.567975830815705,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.2848145472533
  },
  {
    "Model Name": "Azure99/Blossom-V6-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8136679248856464,
    "Overall Score": 31.04565038906736,
    "MMLU Score": 34.932771867612296,
    "BBH Score": 29.447521285247884,
    "Math Score": 45.84592145015105,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.117604586310815
  },
  {
    "Model Name": "Azure99/blossom-v5-32b",
    "Parameters (B)": 32.512,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 11.3760006618128,
    "Overall Score": 27.724659940062114,
    "MMLU Score": 35.93934692671394,
    "BBH Score": 42.883055884713976,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.4371183480261953
  },
  {
    "Model Name": "Azure99/blossom-v5-llama3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7443057854894946,
    "Overall Score": 14.598962808998438,
    "MMLU Score": 13.397606382978722,
    "BBH Score": 18.306535405618444,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.369497441586262
  },
  {
    "Model Name": "Azure99/blossom-v5.1-34b",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 12.700997469006204,
    "Overall Score": 30.29868169090017,
    "MMLU Score": 39.53161938534279,
    "BBH Score": 44.14770458838461,
    "Math Score": 25.90634441087613,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.385535605753562
  },
  {
    "Model Name": "Azure99/blossom-v5.1-9b",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.227728401062798,
    "Overall Score": 26.470194407631528,
    "MMLU Score": 33.10431442080379,
    "BBH Score": 34.20124449031171,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2024-07-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.200874150041761
  },
  {
    "Model Name": "BAAI/Gemma2-9B-IT-Simpo-Infinity-Preference",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.800296921754853,
    "Overall Score": 22.607935619579848,
    "MMLU Score": 31.876108156028373,
    "BBH Score": 42.19084405906616,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.568996912330503
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0613-Llama3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 21.053813934815626,
    "Overall Score": 35.578242909223654,
    "MMLU Score": 41.44318853427896,
    "BBH Score": 51.32716098252212,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.6898716317802027
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0613-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.898749257491813,
    "Overall Score": 22.29353000800769,
    "MMLU Score": 24.00820035460993,
    "BBH Score": 28.992936470320583,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.741165885935212
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0625-Llama3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 20.86191028123878,
    "Overall Score": 36.91009196843762,
    "MMLU Score": 39.84559692671394,
    "BBH Score": 52.02816164280523,
    "Math Score": 22.507552870090635,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.7692575354247901
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0625-Llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7160075623568083,
    "Overall Score": 22.06253195877917,
    "MMLU Score": 25.02401004728132,
    "BBH Score": 28.9882222457564,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2024-07-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.856896696001694
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0625-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5715943827465826,
    "Overall Score": 22.843425216048672,
    "MMLU Score": 24.774674940898343,
    "BBH Score": 28.82328942958971,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.535191437962872
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0625-Qwen2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.660155948960905,
    "Overall Score": 26.199808011295485,
    "MMLU Score": 32.89191784869976,
    "BBH Score": 34.65682860864863,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.848974463895436
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.233602481106533,
    "Overall Score": 28.14496041142372,
    "MMLU Score": 34.64649822695036,
    "BBH Score": 35.37870748220464,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.60070251958201
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7336102063619132,
    "Overall Score": 23.447423677135685,
    "MMLU Score": 24.710032505910167,
    "BBH Score": 30.88880460756557,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.525199373590176
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-7M-0729-mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.598522434021865,
    "Overall Score": 23.21644934658775,
    "MMLU Score": 25.26411052009456,
    "BBH Score": 28.697915491520025,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.523693163426815
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 22.138242550850272,
    "Overall Score": 37.48445364047765,
    "MMLU Score": 40.07646276595744,
    "BBH Score": 52.49894685232329,
    "Math Score": 25.22658610271904,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.693199157718957
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8342796170800315,
    "Overall Score": 23.447423677135685,
    "MMLU Score": 24.710032505910167,
    "BBH Score": 30.88880460756557,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.782905866043132
  },
  {
    "Model Name": "BAAI/Infinity-Instruct-7M-Gen-mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.64927044522619,
    "Overall Score": 23.191053766563783,
    "MMLU Score": 25.26411052009456,
    "BBH Score": 28.697915491520025,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.06140141156973
  },
  {
    "Model Name": "BAAI/OPI-Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.343313618854893,
    "Overall Score": 8.531604396997649,
    "MMLU Score": 12.492612293144209,
    "BBH Score": 9.76871171424153,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.351163479061881
  },
  {
    "Model Name": "BEE-spoke-data/Meta-Llama-3-8Bee",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6607598585562942,
    "Overall Score": 14.657811877680324,
    "MMLU Score": 24.66385933806146,
    "BBH Score": 24.19903269979749,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.825967103047892
  },
  {
    "Model Name": "BEE-spoke-data/smol_llama-101M-GQA",
    "Parameters (B)": 0.101,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2392113053171906,
    "Overall Score": 4.019599868138451,
    "MMLU Score": 1.1894208037825047,
    "BBH Score": 3.1980040943527936,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-07-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.803553087963472
  },
  {
    "Model Name": "BEE-spoke-data/smol_llama-220M-GQA",
    "Parameters (B)": 0.218,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3272265469372181,
    "Overall Score": 6.577800964187134,
    "MMLU Score": 1.6603871158392434,
    "BBH Score": 3.03784275772053,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 20.101672757770338
  },
  {
    "Model Name": "BEE-spoke-data/smol_llama-220M-GQA-fineweb_edu",
    "Parameters (B)": 0.218,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.3237520083234144,
    "Overall Score": 6.629850832257909,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.314902449149024,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 20.478176696389703
  },
  {
    "Model Name": "BEE-spoke-data/smol_llama-220M-openhermes",
    "Parameters (B)": 0.218,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.3088517951911614,
    "Overall Score": 4.938005238605682,
    "MMLU Score": 1.337174940898345,
    "BBH Score": 3.107692077087363,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.988267886056295
  },
  {
    "Model Name": "BEE-spoke-data/tFINE-900m-e16-d32-flan",
    "Parameters (B)": 0.887,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.912012576744369,
    "Overall Score": 4.597533011984676,
    "MMLU Score": 3.4149674940898342,
    "BBH Score": 4.411893932611097,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.9359774512287329
  },
  {
    "Model Name": "BEE-spoke-data/tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024",
    "Parameters (B)": 0.887,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.201215896234896,
    "Overall Score": 5.999886320692095,
    "MMLU Score": 2.6300236406619386,
    "BBH Score": 4.737018282627999,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1535545611623905
  },
  {
    "Model Name": "BEE-spoke-data/tFINE-900m-e16-d32-instruct_2e",
    "Parameters (B)": 0.887,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.033237360715477,
    "Overall Score": 5.908138429401099,
    "MMLU Score": 2.6300236406619386,
    "BBH Score": 5.013070335904381,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1738247187613768
  },
  {
    "Model Name": "BEE-spoke-data/tFINE-900m-instruct-orpo",
    "Parameters (B)": 0.887,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.149923864058659,
    "Overall Score": 3.69630792495429,
    "MMLU Score": 1.6880910165484628,
    "BBH Score": 3.267300577931774,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.7177403050073884
  },
  {
    "Model Name": "BSC-LT/salamandra-7b",
    "Parameters (B)": 7.768,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3785773282820378,
    "Overall Score": 5.704911444345451,
    "MMLU Score": 5.474290780141842,
    "BBH Score": 10.157421990520298,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.06934255739511
  },
  {
    "Model Name": "BSC-LT/salamandra-7b-instruct",
    "Parameters (B)": 7.768,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.2950081726740126,
    "Overall Score": 10.181243697003833,
    "MMLU Score": 8.946513002364064,
    "BBH Score": 14.688128545731288,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.436255965546836
  },
  {
    "Model Name": "Ba2han/Llama-Phi-3_DoRA",
    "Parameters (B)": 3.821,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0662727000384584,
    "Overall Score": 25.4698950011544,
    "MMLU Score": 32.393247635933804,
    "BBH Score": 37.24916418079274,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 23.886849021114156
  },
  {
    "Model Name": "Baptiste-HUVELLE-10/LeTriomphant2.2_ECE_iLAB",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 33.66266319511599,
    "Overall Score": 41.30426754456703,
    "MMLU Score": 53.90070921985816,
    "BBH Score": 61.61232489960707,
    "Math Score": 44.48640483383686,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.2270053413527822
  },
  {
    "Model Name": "BenevolenceMessiah/Qwen2.5-72B-2x-Instruct-TIES-v1.0",
    "Parameters (B)": 72.7,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 34.70178370637048,
    "Overall Score": 42.26732013588396,
    "MMLU Score": 51.425827423167846,
    "BBH Score": 61.91149453060484,
    "Math Score": 57.85498489425982,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.2180157796362676
  },
  {
    "Model Name": "BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0",
    "Parameters (B)": 28.309,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.669594250051597,
    "Overall Score": 15.07109165755061,
    "MMLU Score": 18.67058215130024,
    "BBH Score": 26.877991478721707,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.2596714421471766
  },
  {
    "Model Name": "BlackBeenie/Bloslain-8B-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3835257027469932,
    "Overall Score": 23.803914231544336,
    "MMLU Score": 29.484338061465724,
    "BBH Score": 30.66290179734065,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.205256240835727
  },
  {
    "Model Name": "BlackBeenie/Llama-3.1-8B-OpenO1-SFT-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.462855656236873,
    "Overall Score": 21.4004099666704,
    "MMLU Score": 27.683584515366427,
    "BBH Score": 26.034289552808826,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.629201367496462
  },
  {
    "Model Name": "BlackBeenie/Llama-3.1-8B-pythonic-passthrough-merge",
    "Parameters (B)": 20.245,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.166580943068515,
    "Overall Score": 7.3995789368526035,
    "MMLU Score": 3.692006501182032,
    "BBH Score": 9.359904687487282,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.0325117368568122
  },
  {
    "Model Name": "BlackBeenie/Neos-Gemma-2-9b",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.358184238723577,
    "Overall Score": 25.475663495967385,
    "MMLU Score": 33.12278368794326,
    "BBH Score": 35.638851313766615,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.754532946413985
  },
  {
    "Model Name": "BlackBeenie/Neos-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5877339071002958,
    "Overall Score": 19.51217705998031,
    "MMLU Score": 25.1348256501182,
    "BBH Score": 21.080122945815933,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.289324409287017
  },
  {
    "Model Name": "BlackBeenie/Neos-Llama-3.1-base",
    "Parameters (B)": 4.65,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.818569405998589,
    "Overall Score": 3.968794754491314,
    "MMLU Score": 1.2448286052009452,
    "BBH Score": 2.2214471263806472,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.4080883536324387
  },
  {
    "Model Name": "BlackBeenie/Neos-Phi-3-14B-v0.1",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8192521859467727,
    "Overall Score": 27.03230678365464,
    "MMLU Score": 39.596261820330966,
    "BBH Score": 46.63138689861978,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.859021191493868
  },
  {
    "Model Name": "BlackBeenie/llama-3-luminous-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.527707129075998,
    "Overall Score": 21.618577268829103,
    "MMLU Score": 30.81412529550828,
    "BBH Score": 30.64368722878725,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.150995866534085
  },
  {
    "Model Name": "BlackBeenie/llama-3.1-8B-Galore-openassistant-guanaco",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7136395964032798,
    "Overall Score": 18.37421537036845,
    "MMLU Score": 24.516105200945624,
    "BBH Score": 31.444704759068383,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-10-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.72233356940029
  },
  {
    "Model Name": "Bllossom/llama-3.2-Korean-Bllossom-AICA-5B",
    "Parameters (B)": 5.199,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2202363351953194,
    "Overall Score": 19.01285199149148,
    "MMLU Score": 19.00302895981088,
    "BBH Score": 18.65022251208589,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.58128654515779
  },
  {
    "Model Name": "BoltMonkey/DreadMix",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.4194278361687624,
    "Overall Score": 28.76173172145654,
    "MMLU Score": 30.99881796690307,
    "BBH Score": 34.84501521605123,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.887823762084848
  },
  {
    "Model Name": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.486203373854456,
    "Overall Score": 27.776634015071924,
    "MMLU Score": 30.37086288416076,
    "BBH Score": 30.75990006920939,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.17230967795235
  },
  {
    "Model Name": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7743185740676325,
    "Overall Score": 21.345510590269537,
    "MMLU Score": 29.235002955082745,
    "BBH Score": 30.79378475265928,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 27.56683270315704
  },
  {
    "Model Name": "BoltMonkey/SuperNeuralDreadDevil-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.281416103439857,
    "Overall Score": 27.11105496878025,
    "MMLU Score": 29.76137706855792,
    "BBH Score": 32.61215762394777,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.261998513495486
  },
  {
    "Model Name": "BrainWave-ML/llama3.2-3B-maths-orpo",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4144381166479545,
    "Overall Score": 5.07608283209792,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.5887627548723136
  },
  {
    "Model Name": "BramVanroy/GEITje-7B-ultra",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2390464419973757,
    "Overall Score": 11.02289881921654,
    "MMLU Score": 11.236702127659573,
    "BBH Score": 12.879913010035898,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.896275753350563
  },
  {
    "Model Name": "BramVanroy/fietje-2",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.6250772888227508,
    "Overall Score": 9.140300477810824,
    "MMLU Score": 10.950428486997636,
    "BBH Score": 15.603676192567876,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.622672493869283
  },
  {
    "Model Name": "BramVanroy/fietje-2-chat",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7980654163418115,
    "Overall Score": 10.615455210257904,
    "MMLU Score": 11.71690307328605,
    "BBH Score": 17.718965848323496,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.301485057349364
  },
  {
    "Model Name": "BramVanroy/fietje-2-instruct",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6487901858353973,
    "Overall Score": 10.48571837435655,
    "MMLU Score": 12.26174645390071,
    "BBH Score": 17.57247980884759,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.161955903902733
  },
  {
    "Model Name": "CYFRAGOVPL/Llama-PLLuM-8B-base",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.723931594223454,
    "Overall Score": 14.51887667865397,
    "MMLU Score": 19.52016843971631,
    "BBH Score": 20.21873797779148,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.055591984803563
  },
  {
    "Model Name": "CYFRAGOVPL/Llama-PLLuM-8B-chat",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6247553846649435,
    "Overall Score": 14.61481701543444,
    "MMLU Score": 19.104609929078016,
    "BBH Score": 16.279056764258215,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.39286282946144
  },
  {
    "Model Name": "CYFRAGOVPL/PLLuM-12B-base",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.8935730836523827,
    "Overall Score": 14.667469455106152,
    "MMLU Score": 19.335475768321512,
    "BBH Score": 21.240801542833136,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.414403839420125
  },
  {
    "Model Name": "CYFRAGOVPL/PLLuM-12B-chat",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7807010086114211,
    "Overall Score": 15.34838688249824,
    "MMLU Score": 20.803782505910167,
    "BBH Score": 21.319737721095155,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.65975029262144
  },
  {
    "Model Name": "CYFRAGOVPL/PLLuM-12B-nc-base",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9262126633435942,
    "Overall Score": 11.421222164941392,
    "MMLU Score": 17.322325650118206,
    "BBH Score": 19.387664951963902,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.331101286945477
  },
  {
    "Model Name": "CYFRAGOVPL/PLLuM-12B-nc-chat",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8350715162365853,
    "Overall Score": 14.598342751082509,
    "MMLU Score": 17.747118794326237,
    "BBH Score": 23.008553823293614,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.481547947980342
  },
  {
    "Model Name": "CarrotAI/Llama-3.2-Rabbit-Ko-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1359074637893565,
    "Overall Score": 23.50945092474288,
    "MMLU Score": 20.249704491725765,
    "BBH Score": 21.49731033280348,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.69662509859385
  },
  {
    "Model Name": "CarrotAI/Llama-3.2-Rabbit-Ko-3B-Instruct-2412",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2871786673601686,
    "Overall Score": 20.301755342918195,
    "MMLU Score": 23.712692080378247,
    "BBH Score": 20.17567961421505,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.772290092838768
  },
  {
    "Model Name": "Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.976769816253202,
    "Overall Score": 25.899338809216697,
    "MMLU Score": 30.26004728132387,
    "BBH Score": 32.48627762381486,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.101848579571433
  },
  {
    "Model Name": "CausalLM/14B",
    "Parameters (B)": 14.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.992828927210416,
    "Overall Score": 17.235580154596317,
    "MMLU Score": 24.682328605200944,
    "BBH Score": 24.780942674518663,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.648800666860488
  },
  {
    "Model Name": "CausalLM/34b-beta",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.853192681528399,
    "Overall Score": 23.29783304542188,
    "MMLU Score": 48.05518617021277,
    "BBH Score": 36.677226262739055,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.980363250119129
  },
  {
    "Model Name": "CausalLM/preview-1-hf",
    "Parameters (B)": 9.543,
    "Architecture": "GlmForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5574978825517047,
    "Overall Score": 16.706753161023286,
    "MMLU Score": 28.856382978723406,
    "BBH Score": 10.100940706274752,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.532460212383198
  },
  {
    "Model Name": "Changgil/K2S3-14b-v0.2",
    "Parameters (B)": 14.352,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2492605048590075,
    "Overall Score": 15.275784761251336,
    "MMLU Score": 18.26425827423168,
    "BBH Score": 24.283946726650168,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.701311187086302
  },
  {
    "Model Name": "Changgil/K2S3-v0.1",
    "Parameters (B)": 14.352,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4997646880101265,
    "Overall Score": 14.839283995827836,
    "MMLU Score": 17.359264184397162,
    "BBH Score": 24.559557672503782,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.936272348754661
  },
  {
    "Model Name": "ClaudioItaly/Albacus",
    "Parameters (B)": 8.987,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5078778727070576,
    "Overall Score": 20.505574062384014,
    "MMLU Score": 24.054373522458626,
    "BBH Score": 31.63886474402479,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.598962113271707
  },
  {
    "Model Name": "ClaudioItaly/Book-Gut12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9044964466390915,
    "Overall Score": 23.39409811229197,
    "MMLU Score": 29.669030732860524,
    "BBH Score": 34.63219258973313,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.054441980592614
  },
  {
    "Model Name": "ClaudioItaly/Evolutionstory-7B-v2.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.120463976671076,
    "Overall Score": 20.810835332574907,
    "MMLU Score": 23.98973108747045,
    "BBH Score": 31.62386474402479,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-09-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.573408664510904
  },
  {
    "Model Name": "ClaudioItaly/intelligence-cod-rag-7b-v3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3209446661048176,
    "Overall Score": 31.836966345244434,
    "MMLU Score": 35.50531914893617,
    "BBH Score": 34.776158539494425,
    "Math Score": 38.06646525679759,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.101665393089338
  },
  {
    "Model Name": "CohereForAI/aya-23-35B",
    "Parameters (B)": 34.981,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 33.97063403896728,
    "Overall Score": 24.75540844693965,
    "MMLU Score": 26.17833924349881,
    "BBH Score": 34.85836046775463,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7287296556944753
  },
  {
    "Model Name": "CohereForAI/aya-23-8B",
    "Parameters (B)": 8.028,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.390344162641917,
    "Overall Score": 16.010983148168723,
    "MMLU Score": 14.2010195035461,
    "BBH Score": 20.20376064673937,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.698191581948875
  },
  {
    "Model Name": "CohereForAI/aya-expanse-32b",
    "Parameters (B)": 32.296,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 11.035470199820203,
    "Overall Score": 29.71851012657705,
    "MMLU Score": 34.77578309692671,
    "BBH Score": 38.70961143301418,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.692998992200735
  },
  {
    "Model Name": "CohereForAI/aya-expanse-8b",
    "Parameters (B)": 8.028,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.3393781377514093,
    "Overall Score": 22.406573697993498,
    "MMLU Score": 22.26285460992908,
    "BBH Score": 28.52348250428851,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.578004229590052
  },
  {
    "Model Name": "CohereForAI/c4ai-command-r-plus",
    "Parameters (B)": 103.811,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 57.26306342334156,
    "Overall Score": 30.936070612618508,
    "MMLU Score": 33.242833924349874,
    "BBH Score": 39.91995423143177,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5402447714665637
  },
  {
    "Model Name": "CohereForAI/c4ai-command-r-plus-08-2024",
    "Parameters (B)": 103.811,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 44.63775333534616,
    "Overall Score": 33.647474595578004,
    "MMLU Score": 38.0079048463357,
    "BBH Score": 42.83686540770696,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.7537896081551765
  },
  {
    "Model Name": "CohereForAI/c4ai-command-r-v01",
    "Parameters (B)": 34.981,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.79087453397965,
    "Overall Score": 25.929031834951832,
    "MMLU Score": 26.32609338061465,
    "BBH Score": 34.556659257058264,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.9678307366213552
  },
  {
    "Model Name": "CohereForAI/c4ai-command-r7b-12-2024",
    "Parameters (B)": 8.028,
    "Architecture": "Cohere2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.909613871990747,
    "Overall Score": 31.61752928799648,
    "MMLU Score": 28.5793439716312,
    "BBH Score": 36.0245641700103,
    "Math Score": 29.909365558912388,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.439921776409724
  },
  {
    "Model Name": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9796484742504704,
    "Overall Score": 11.483994762243412,
    "MMLU Score": 7.395094562647753,
    "BBH Score": 14.585976093815775,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.722566884034421
  },
  {
    "Model Name": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9891382403495008,
    "Overall Score": 11.26209259662469,
    "MMLU Score": 7.385859929078014,
    "BBH Score": 14.243045647726928,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.661794825605428
  },
  {
    "Model Name": "Columbia-NLP/LION-Gemma-2b-odpo-v1.0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.924136196677034,
    "Overall Score": 11.897378852943028,
    "MMLU Score": 7.690602836879433,
    "BBH Score": 14.02392166541634,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-07-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.183231142104023
  },
  {
    "Model Name": "Columbia-NLP/LION-Gemma-2b-sft-v1.0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.921617625954828,
    "Overall Score": 12.60325045021582,
    "MMLU Score": 8.687943262411347,
    "BBH Score": 14.11717086360044,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.558667177063085
  },
  {
    "Model Name": "Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3936984403045485,
    "Overall Score": 21.78540431507501,
    "MMLU Score": 24.654624704491724,
    "BBH Score": 30.356398875749075,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.631361623906605
  },
  {
    "Model Name": "Columbia-NLP/LION-LLaMA-3-8b-odpo-v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4373937651386457,
    "Overall Score": 19.85320809199725,
    "MMLU Score": 23.91585401891253,
    "BBH Score": 30.457173008350704,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.811948106009964
  },
  {
    "Model Name": "Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5072262758006536,
    "Overall Score": 20.74886229970928,
    "MMLU Score": 24.857786643026003,
    "BBH Score": 30.88426036029,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.766255692886775
  },
  {
    "Model Name": "CombinHorizon/Josiefied-abliteratedV4-Qwen2.5-14B-Inst-BaseMerge-TIES",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3307043527297373,
    "Overall Score": 41.765081012881176,
    "MMLU Score": 44.213578605200944,
    "BBH Score": 48.19594986631396,
    "Math Score": 53.17220543806647,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.539414066772954
  },
  {
    "Model Name": "CombinHorizon/Rombos-Qwen2.5-7B-Inst-BaseMerge-TIES",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.091121739266506,
    "Overall Score": 35.36673047341537,
    "MMLU Score": 37.1306146572104,
    "BBH Score": 34.954070231174235,
    "Math Score": 49.320241691842895,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.91280321432688
  },
  {
    "Model Name": "CombinHorizon/YiSM-blossom5.1-34B-SLERP",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.141628447926251,
    "Overall Score": 31.37993020523676,
    "MMLU Score": 41.56323877068557,
    "BBH Score": 46.39761279639615,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.109382710351412
  },
  {
    "Model Name": "CombinHorizon/huihui-ai-abliterated-Qwen2.5-32B-Inst-BaseMerge-TIES",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 26.000843124030272,
    "Overall Score": 45.6578470977455,
    "MMLU Score": 52.45087174940899,
    "BBH Score": 56.04478184089901,
    "Math Score": 59.44108761329305,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.7560140984639074
  },
  {
    "Model Name": "CombinHorizon/huihui-ai-abliteratedV2-Qwen2.5-14B-Inst-BaseMerge-TIES",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3342592235028725,
    "Overall Score": 41.46621085774212,
    "MMLU Score": 43.44710401891253,
    "BBH Score": 47.767346005909815,
    "Math Score": 54.7583081570997,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.436408832717861
  },
  {
    "Model Name": "CombinHorizon/zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.366635145725348,
    "Overall Score": 46.76362120574333,
    "MMLU Score": 52.05378250591017,
    "BBH Score": 56.82740697772572,
    "Math Score": 58.53474320241692,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.34803004094467
  },
  {
    "Model Name": "ContactDoctor/Bio-Medical-3B-CoT-012025",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5996892891616017,
    "Overall Score": 18.73071055946323,
    "MMLU Score": 21.48714539007092,
    "BBH Score": 22.26352810389536,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.708967914187891
  },
  {
    "Model Name": "ContactDoctor/Bio-Medical-Llama-3-8B",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2351165102170476,
    "Overall Score": 19.91745266981443,
    "MMLU Score": 29.419695626477544,
    "BBH Score": 26.195811296028182,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.12597071211875
  },
  {
    "Model Name": "CoolSpring/Qwen2-0.5B-Abyme",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.355594617085158,
    "Overall Score": 4.999994251217356,
    "MMLU Score": 3.701241134751772,
    "BBH Score": 2.2764835705971893,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.122603870357121
  },
  {
    "Model Name": "CoolSpring/Qwen2-0.5B-Abyme-merge2",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2193908884207358,
    "Overall Score": 6.320258162859158,
    "MMLU Score": 5.437352245862883,
    "BBH Score": 3.709041394335512,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.183127266962512
  },
  {
    "Model Name": "CoolSpring/Qwen2-0.5B-Abyme-merge3",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2203426634256125,
    "Overall Score": 6.8201960830112,
    "MMLU Score": 5.557402482269504,
    "BBH Score": 4.301149162861492,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.5887549353279935
  },
  {
    "Model Name": "Corianas/Neural-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.923426566639272,
    "Overall Score": 18.2004385677184,
    "MMLU Score": 19.30777186761229,
    "BBH Score": 22.431162626805257,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.709676140201662
  },
  {
    "Model Name": "Corianas/Quokka_2.7b",
    "Parameters (B)": 2.786,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5873825038450923,
    "Overall Score": 4.995249580966088,
    "MMLU Score": 1.6142139479905429,
    "BBH Score": 3.1652676176883503,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.504253273235838
  },
  {
    "Model Name": "Corianas/llama-3-reactor",
    "Parameters (B)": -1.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6423296412642534,
    "Overall Score": 13.99546972704566,
    "MMLU Score": 20.00960401891253,
    "BBH Score": 21.88855981925079,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.521717793677553
  },
  {
    "Model Name": "CortexLM/btlm-7b-base-v0.2",
    "Parameters (B)": 6.885,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.422716700807614,
    "Overall Score": 8.920254930681883,
    "MMLU Score": 14.995197990543732,
    "BBH Score": 16.19327709708517,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.269874336625306
  },
  {
    "Model Name": "Cran-May/SCE-2-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7042352510701058,
    "Overall Score": 31.951539780759408,
    "MMLU Score": 40.13187056737589,
    "BBH Score": 46.32574571477496,
    "Math Score": 18.95770392749245,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.815369897317813
  },
  {
    "Model Name": "Cran-May/SCE-3-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.3631698036966537,
    "Overall Score": 30.620429636223,
    "MMLU Score": 40.51972517730496,
    "BBH Score": 42.278564800296486,
    "Math Score": 18.80664652567976,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.957354815690412
  },
  {
    "Model Name": "Cran-May/T.E-8.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.181265600716749,
    "Overall Score": 35.699515240521414,
    "MMLU Score": 38.13718971631205,
    "BBH Score": 37.02437662584371,
    "Math Score": 44.5619335347432,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.366422882564507
  },
  {
    "Model Name": "Cran-May/merge_model_20250308_2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.021194536877009,
    "Overall Score": 40.25753367174487,
    "MMLU Score": 49.10793439716312,
    "BBH Score": 50.99569841983836,
    "Math Score": 43.80664652567976,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.91769368917237
  },
  {
    "Model Name": "Cran-May/merge_model_20250308_3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.025239989867329,
    "Overall Score": 33.22959855955027,
    "MMLU Score": 44.0196513002364,
    "BBH Score": 46.56854499584235,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 16.407733762815486
  },
  {
    "Model Name": "Cran-May/merge_model_20250308_4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9787744084472945,
    "Overall Score": 37.569693940140574,
    "MMLU Score": 48.51691784869976,
    "BBH Score": 52.02370667184541,
    "Math Score": 41.99395770392749,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.98634517394066
  },
  {
    "Model Name": "Cran-May/tempmotacilla-cinerea-0308",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.6420107969216495,
    "Overall Score": 43.6405549503723,
    "MMLU Score": 47.224069148936174,
    "BBH Score": 50.59894860885105,
    "Math Score": 55.51359516616314,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 11.982544090000713
  },
  {
    "Model Name": "CreitinGameplays/Llama-3.1-8B-R1-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.745944048401834,
    "Overall Score": 10.034841772545372,
    "MMLU Score": 2.7962470449172567,
    "BBH Score": 3.2159805820764724,
    "Math Score": 18.12688821752266,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.45253949548195
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Broca",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.154002933010168,
    "Overall Score": 37.92450077102951,
    "MMLU Score": 48.48921394799055,
    "BBH Score": 50.034411781701095,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.129627827091541
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-BrocaV9",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.548005606974808,
    "Overall Score": 39.25874716685152,
    "MMLU Score": 48.119828605200944,
    "BBH Score": 48.05322494738571,
    "Math Score": 38.14199395770393,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.065018355572816
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Brocav3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.633477979894391,
    "Overall Score": 39.84683205575066,
    "MMLU Score": 47.972074468085104,
    "BBH Score": 49.04911178348141,
    "Math Score": 38.74622356495468,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.966581406641366
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Brocav6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5828022711198058,
    "Overall Score": 39.840730335689976,
    "MMLU Score": 47.99054373522459,
    "BBH Score": 47.81922480607394,
    "Math Score": 38.74622356495468,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.1199913701176
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Brocav7",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.402698845183717,
    "Overall Score": 39.61737991043984,
    "MMLU Score": 47.30718085106383,
    "BBH Score": 48.90536078331687,
    "Math Score": 38.4441087613293,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.642928661322902
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Emerged",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.614720335241756,
    "Overall Score": 37.95214334488745,
    "MMLU Score": 46.51300236406619,
    "BBH Score": 45.932419368684656,
    "Math Score": 32.477341389728096,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.499330466833799
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Emergedv3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.837856552994495,
    "Overall Score": 38.65629185173199,
    "MMLU Score": 46.3744828605201,
    "BBH Score": 44.731608242608615,
    "Math Score": 43.58006042296073,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.072364956311446
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-FinalMerge",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.887882991880861,
    "Overall Score": 32.23626965408581,
    "MMLU Score": 39.71631205673759,
    "BBH Score": 38.16247948342354,
    "Math Score": 38.14199395770393,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.291471148027195
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Hyper",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.678342043702582,
    "Overall Score": 37.76193504060264,
    "MMLU Score": 48.60002955082743,
    "BBH Score": 49.75987937749839,
    "Math Score": 34.3655589123867,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.917980317322958
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-HyperMarck-dl",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.968582586414336,
    "Overall Score": 39.89416756441815,
    "MMLU Score": 45.4510195035461,
    "BBH Score": 43.78585928068085,
    "Math Score": 52.87009063444109,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.265427439893777
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Hyperionv3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.965710751391208,
    "Overall Score": 39.76212059640138,
    "MMLU Score": 48.22140957446809,
    "BBH Score": 49.95005488379496,
    "Math Score": 37.00906344410876,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.026480267743295
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Hyperionv4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.073613730173503,
    "Overall Score": 37.67001853618524,
    "MMLU Score": 48.48921394799055,
    "BBH Score": 49.07652018118392,
    "Math Score": 34.74320241691843,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.247322164387148
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Hyperionv5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.973468255735361,
    "Overall Score": 39.72496970046036,
    "MMLU Score": 47.796616430260045,
    "BBH Score": 48.948279827370094,
    "Math Score": 38.21752265861027,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.997555572042327
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-MegaMerge-pt2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.500867569666822,
    "Overall Score": 38.79652976123104,
    "MMLU Score": 49.11716903073285,
    "BBH Score": 50.9079030473653,
    "Math Score": 39.95468277945619,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.619789220793042
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-MergeStock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.645908481708354,
    "Overall Score": 38.74423639967271,
    "MMLU Score": 48.84013002364066,
    "BBH Score": 51.00939101332111,
    "Math Score": 41.46525679758308,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.8297878320637615
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-ReasoningMerge",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.625354688150173,
    "Overall Score": 40.64588590091172,
    "MMLU Score": 48.27681737588653,
    "BBH Score": 50.867897804151305,
    "Math Score": 52.0392749244713,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.211561184279923
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Ultimav2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.907627333688703,
    "Overall Score": 38.835600416037856,
    "MMLU Score": 49.0802304964539,
    "BBH Score": 50.44105269414074,
    "Math Score": 38.4441087613293,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.573806745488977
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Unity",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8273777920130327,
    "Overall Score": 38.29922923584618,
    "MMLU Score": 45.28479609929077,
    "BBH Score": 42.25861689291335,
    "Math Score": 43.126888217522655,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.006649804931449
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Wernicke",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.444468975984375,
    "Overall Score": 37.94335063991926,
    "MMLU Score": 49.15410756501182,
    "BBH Score": 50.64287609242263,
    "Math Score": 38.14199395770393,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.537206772045348
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Wernicke-SFT",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.786025404587684,
    "Overall Score": 33.549511791224056,
    "MMLU Score": 45.2201536643026,
    "BBH Score": 49.33057176327372,
    "Math Score": 35.95166163141994,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.04206958629266
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Wernicke-SLERP",
    "Parameters (B)": 14.491,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.311975384763283,
    "Overall Score": 36.5436519453458,
    "MMLU Score": 45.48795803782507,
    "BBH Score": 49.372327095724025,
    "Math Score": 44.864048338368576,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.47492127957775
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-Wernickev3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.831268500614135,
    "Overall Score": 38.38114202702078,
    "MMLU Score": 46.12514775413712,
    "BBH Score": 44.57627490618109,
    "Math Score": 35.422960725075534,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.017867977895168
  },
  {
    "Model Name": "CultriX/Qwen2.5-14B-partialmergept1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.018672278551488,
    "Overall Score": 39.10871735916122,
    "MMLU Score": 46.75310283687944,
    "BBH Score": 44.5944042928325,
    "Math Score": 45.392749244713,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.731750849128154
  },
  {
    "Model Name": "CultriX/Qwenfinity-2.5-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9541332272834326,
    "Overall Score": 32.322008098684286,
    "MMLU Score": 38.86672576832151,
    "BBH Score": 37.259942422120695,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.174233451635654
  },
  {
    "Model Name": "CultriX/Qwestion-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.707642084016007,
    "Overall Score": 38.54922603408469,
    "MMLU Score": 49.13563829787233,
    "BBH Score": 48.75703449690036,
    "Math Score": 37.235649546827794,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.397234997486414
  },
  {
    "Model Name": "CultriX/SeQwence-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.592765105556317,
    "Overall Score": 36.886272868734814,
    "MMLU Score": 49.09869976359338,
    "BBH Score": 50.16357763465521,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.266820063379347
  },
  {
    "Model Name": "CultriX/SeQwence-14B-EvolMerge",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.901652091511035,
    "Overall Score": 38.018640895247245,
    "MMLU Score": 49.09869976359338,
    "BBH Score": 50.780351477179785,
    "Math Score": 36.70694864048338,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.744241670846504
  },
  {
    "Model Name": "CultriX/SeQwence-14B-EvolMergev1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9157920215613617,
    "Overall Score": 38.4634621004166,
    "MMLU Score": 48.81242612293145,
    "BBH Score": 50.30225894842213,
    "Math Score": 42.14501510574018,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.822651940814744
  },
  {
    "Model Name": "CultriX/SeQwence-14B-v5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.730320092147557,
    "Overall Score": 37.60854208566567,
    "MMLU Score": 49.05252659574468,
    "BBH Score": 49.99573116031767,
    "Math Score": 33.081570996978854,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.08185387758891
  },
  {
    "Model Name": "CultriX/SeQwence-14Bv1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.660382222401487,
    "Overall Score": 38.625628460880606,
    "MMLU Score": 47.99977836879433,
    "BBH Score": 47.19089791628922,
    "Math Score": 36.102719033232624,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.552348392605644
  },
  {
    "Model Name": "CultriX/SeQwence-14Bv2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9497873720789447,
    "Overall Score": 38.74007503457753,
    "MMLU Score": 48.1567671394799,
    "BBH Score": 46.52922387651957,
    "Math Score": 47.583081570996974,
    "Date Submitted": "2024-12-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.808141903645549
  },
  {
    "Model Name": "CultriX/SeQwence-14Bv3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.930149292746144,
    "Overall Score": 38.665815540663296,
    "MMLU Score": 48.16600177304965,
    "BBH Score": 46.38536750450479,
    "Math Score": 47.65861027190332,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.838256173125176
  },
  {
    "Model Name": "DRXD1000/Atlas-7B",
    "Parameters (B)": 7.768,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.513516751999117,
    "Overall Score": 8.78657746420255,
    "MMLU Score": 4.4584810874704495,
    "BBH Score": 7.540207541436388,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.4957306161632604
  },
  {
    "Model Name": "DRXD1000/Phoenix-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9417448383956702,
    "Overall Score": 12.420154178714036,
    "MMLU Score": 14.921320921985814,
    "BBH Score": 15.620179664331877,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.188449431666285
  },
  {
    "Model Name": "DUAL-GPO/zephyr-7b-ipo-0k-15k-i1",
    "Parameters (B)": 14.483,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9428467642746567,
    "Overall Score": 15.492947659683166,
    "MMLU Score": 23.66651891252955,
    "BBH Score": 22.65864266009636,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.974353893765425
  },
  {
    "Model Name": "DZgas/GIGABATEMAN-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2606746542398035,
    "Overall Score": 20.47146897335566,
    "MMLU Score": 24.183658392434985,
    "BBH Score": 29.827516654014,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.238502855996668
  },
  {
    "Model Name": "Daemontatox/AetherDrake-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.196693873194594,
    "Overall Score": 22.91796073644076,
    "MMLU Score": 27.76669621749409,
    "BBH Score": 27.13925232163005,
    "Math Score": 15.105740181268882,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.43293333499937
  },
  {
    "Model Name": "Daemontatox/AetherSett",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9646454629488488,
    "Overall Score": 31.420122512312307,
    "MMLU Score": 36.42878250591017,
    "BBH Score": 34.7441456018993,
    "Math Score": 39.72809667673716,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.992769741341549
  },
  {
    "Model Name": "Daemontatox/AetherTOT",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.39784689077682,
    "Overall Score": 23.178825097337903,
    "MMLU Score": 31.15580673758865,
    "BBH Score": 29.43639149563461,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.581805382459894
  },
  {
    "Model Name": "Daemontatox/AetherTOT",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 0.708698329429445,
    "Overall Score": 22.874708418571885,
    "MMLU Score": 30.86953309692671,
    "BBH Score": 29.03185731417456,
    "Math Score": 14.425981873111782,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 32.27707399421659
  },
  {
    "Model Name": "Daemontatox/AetherUncensored",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4785060672358763,
    "Overall Score": 18.37486391721989,
    "MMLU Score": 19.00302895981088,
    "BBH Score": 21.678618361970496,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.427993583802062
  },
  {
    "Model Name": "Daemontatox/Cogito-MIS",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.765363845157954,
    "Overall Score": 11.081961864729385,
    "MMLU Score": 4.837101063829785,
    "BBH Score": 29.075970117521223,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.277437874988222
  },
  {
    "Model Name": "Daemontatox/CogitoDistil",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.629079371188348,
    "Overall Score": 17.180474194347855,
    "MMLU Score": 18.0610963356974,
    "BBH Score": 11.94875947902338,
    "Math Score": 39.27492447129909,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.546124699753204
  },
  {
    "Model Name": "Daemontatox/CogitoZ",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.863382417868953,
    "Overall Score": 39.383291042826805,
    "MMLU Score": 51.02873817966904,
    "BBH Score": 53.889571248021504,
    "Math Score": 52.41691842900303,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.443370395869237
  },
  {
    "Model Name": "Daemontatox/CogitoZ14",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.193449652876317,
    "Overall Score": 34.383430079600444,
    "MMLU Score": 33.32594562647754,
    "BBH Score": 46.47935186892328,
    "Math Score": 42.220543806646525,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.620537865531762
  },
  {
    "Model Name": "Daemontatox/DocumentCogito",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 1.4133165870289686,
    "Overall Score": 24.220439046588428,
    "MMLU Score": 31.13733747044917,
    "BBH Score": 29.79360859597188,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.137306155518846
  },
  {
    "Model Name": "Daemontatox/DocumentCogito",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 0.7117566552956288,
    "Overall Score": 29.10815605844729,
    "MMLU Score": 30.41703605200945,
    "BBH Score": 31.184823044232704,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.89621901232127
  },
  {
    "Model Name": "Daemontatox/Llama3.3-70B-CogniLink",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 32.37823644138559,
    "Overall Score": 42.77471354959223,
    "MMLU Score": 46.36524822695035,
    "BBH Score": 52.12466257626164,
    "Math Score": 41.389728096676734,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 1.3210946070836012
  },
  {
    "Model Name": "Daemontatox/Llama_cot",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 0.7507026467642424,
    "Overall Score": 27.115741618463783,
    "MMLU Score": 27.979092789598106,
    "BBH Score": 26.866582717626454,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 36.120482237995176
  },
  {
    "Model Name": "Daemontatox/MawaredT1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.276958262253007,
    "Overall Score": 29.23129822157277,
    "MMLU Score": 41.3139036643026,
    "BBH Score": 31.900788297617016,
    "Math Score": 30.211480362537763,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.89134976894108
  },
  {
    "Model Name": "Daemontatox/Mini_QwQ",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.317404163373526,
    "Overall Score": 30.832499483820992,
    "MMLU Score": 37.47229609929077,
    "BBH Score": 36.21028479375264,
    "Math Score": 41.918429003021146,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.40397908328076
  },
  {
    "Model Name": "Daemontatox/NemoR",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.261325280400474,
    "Overall Score": 18.07399800099431,
    "MMLU Score": 25.44880319148936,
    "BBH Score": 31.605520137148783,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.992657295987713
  },
  {
    "Model Name": "Daemontatox/PathFinderAI2.0",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 14.003082210470806,
    "Overall Score": 36.25665231066442,
    "MMLU Score": 50.520833333333336,
    "BBH Score": 52.95651298557802,
    "Math Score": 50.75528700906344,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.5891908485371533
  },
  {
    "Model Name": "Daemontatox/PathFinderAi3.0",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.094724327094367,
    "Overall Score": 40.45869427281298,
    "MMLU Score": 52.85719562647754,
    "BBH Score": 55.53835541644173,
    "Math Score": 50.45317220543807,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.998155914635796
  },
  {
    "Model Name": "Daemontatox/PathfinderAI",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.540918227975272,
    "Overall Score": 38.13131352504058,
    "MMLU Score": 51.03797281323877,
    "BBH Score": 52.64654733435329,
    "Math Score": 47.583081570996974,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.39726936506469
  },
  {
    "Model Name": "Daemontatox/PathfinderAI",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 9.451440999099956,
    "Overall Score": 36.54876805856116,
    "MMLU Score": 50.465425531914896,
    "BBH Score": 52.32216296509384,
    "Math Score": 48.413897280966765,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.86700483683299
  },
  {
    "Model Name": "Daemontatox/Phi-4-COT",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.715153253727952,
    "Overall Score": 26.128818323637788,
    "MMLU Score": 44.49985224586289,
    "BBH Score": 45.34299043065811,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.234101248297078
  },
  {
    "Model Name": "Daemontatox/PixelParse_AI",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 1.4002193288085218,
    "Overall Score": 22.92506088584278,
    "MMLU Score": 30.86953309692671,
    "BBH Score": 29.03185731417456,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.372478521168702
  },
  {
    "Model Name": "Daemontatox/RA2.0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.327376435124672,
    "Overall Score": 23.232562711526068,
    "MMLU Score": 17.95951536643026,
    "BBH Score": 28.471838145021334,
    "Math Score": 38.36858006042296,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.502618019088143
  },
  {
    "Model Name": "Daemontatox/RA_Reasoner",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5581467334671502,
    "Overall Score": 29.20800259079704,
    "MMLU Score": 36.6688829787234,
    "BBH Score": 43.07300777347365,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.74534789531927
  },
  {
    "Model Name": "Daemontatox/RA_Reasoner2.0",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.573512786211919,
    "Overall Score": 29.039667218867848,
    "MMLU Score": 37.259899527186754,
    "BBH Score": 43.07006895743249,
    "Math Score": 23.11178247734139,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.4553106103307
  },
  {
    "Model Name": "Daemontatox/ReasonTest",
    "Parameters (B)": 3.808,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3406293497661246,
    "Overall Score": 25.858232794071,
    "MMLU Score": 36.35490543735224,
    "BBH Score": 35.37503681384339,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.28812971205055
  },
  {
    "Model Name": "Daemontatox/Research_PathfinderAI",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6188413544397473,
    "Overall Score": 9.365878628802648,
    "MMLU Score": 1.4479905437352243,
    "BBH Score": 1.4263456550462994,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.134539024596723
  },
  {
    "Model Name": "Daemontatox/SphinX",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3043167149586126,
    "Overall Score": 29.87478015820759,
    "MMLU Score": 37.39841903073286,
    "BBH Score": 34.71245082713039,
    "Math Score": 30.81570996978852,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.90454443739575
  },
  {
    "Model Name": "Daemontatox/Sphinx2.0",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.592650364309399,
    "Overall Score": 37.69418546772203,
    "MMLU Score": 46.485298463356976,
    "BBH Score": 49.39675153748764,
    "Math Score": 40.181268882175225,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.492027234876176
  },
  {
    "Model Name": "Daemontatox/TinySphinx",
    "Parameters (B)": 0.247,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0072558813543913,
    "Overall Score": 8.167167127412911,
    "MMLU Score": 7.7552452718676115,
    "BBH Score": 6.54657571552213,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.108334017797995
  },
  {
    "Model Name": "Daemontatox/TinySphinx2.0",
    "Parameters (B)": 0.247,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0041719918661665,
    "Overall Score": 7.583926718324835,
    "MMLU Score": 8.12463061465721,
    "BBH Score": 5.004028710418718,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.552418091477303
  },
  {
    "Model Name": "Daemontatox/Zirel-7B-Math",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.538753219597133,
    "Overall Score": 30.97662500003112,
    "MMLU Score": 35.96705082742317,
    "BBH Score": 34.93944104913604,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 57.49687217311614
  },
  {
    "Model Name": "Daemontatox/Zirel_1.5",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5795306020738551,
    "Overall Score": 14.243506396749902,
    "MMLU Score": 12.705008865248226,
    "BBH Score": 15.082126333167832,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 24.577660516596357
  },
  {
    "Model Name": "Daemontatox/mini-Cogito-R1",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6109876520487433,
    "Overall Score": 11.629717650498437,
    "MMLU Score": 5.354240543735224,
    "BBH Score": 6.038995128638223,
    "Math Score": 27.492447129909365,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.034292446831056
  },
  {
    "Model Name": "Daemontatox/mini_Pathfinder",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5482629089653008,
    "Overall Score": 19.87259516246408,
    "MMLU Score": 20.10195035460993,
    "BBH Score": 16.03002789836758,
    "Math Score": 47.50755287009064,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.83541383533167
  },
  {
    "Model Name": "Dampfinchen/Llama-3.1-8B-Ultra-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6729573304154113,
    "Overall Score": 30.15927702188916,
    "MMLU Score": 31.395907210401887,
    "BBH Score": 32.49458680420566,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 18.027523161275322
  },
  {
    "Model Name": "Danielbrdz/Barcenas-10b",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6193104184932727,
    "Overall Score": 31.87097059768785,
    "MMLU Score": 37.34301122931442,
    "BBH Score": 43.769694605609374,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2025-01-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.68181655209937
  },
  {
    "Model Name": "Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO",
    "Parameters (B)": 13.96,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.3541541178541143,
    "Overall Score": 31.88950498581046,
    "MMLU Score": 41.36931146572104,
    "BBH Score": 51.029418403280296,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2024-08-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.546056625586923
  },
  {
    "Model Name": "Danielbrdz/Barcenas-14b-phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7478531452063368,
    "Overall Score": 28.746056207730017,
    "MMLU Score": 46.38371749408983,
    "BBH Score": 53.25769202541582,
    "Math Score": 25.83081570996979,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.446493966938224
  },
  {
    "Model Name": "Danielbrdz/Barcenas-14b-phi-4-v2",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.988565362638172,
    "Overall Score": 31.447866315089907,
    "MMLU Score": 47.150192080378254,
    "BBH Score": 50.20692953827006,
    "Math Score": 32.17522658610272,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.814348829534541
  },
  {
    "Model Name": "Danielbrdz/Barcenas-3b-GRPO",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6176673631419419,
    "Overall Score": 20.5654768779582,
    "MMLU Score": 22.63223995271868,
    "BBH Score": 21.13661740394343,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 33.295391832500286
  },
  {
    "Model Name": "Danielbrdz/Barcenas-Llama3-8b-ORPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5483183713957436,
    "Overall Score": 26.51900505359198,
    "MMLU Score": 31.44208037825059,
    "BBH Score": 28.600623499981847,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.127617642155997
  },
  {
    "Model Name": "Danielbrdz/Barcenas-R1-Qwen-1.5b",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2225069482677418,
    "Overall Score": 15.138858570183295,
    "MMLU Score": 10.10084219858156,
    "BBH Score": 10.491260075913582,
    "Math Score": 34.96978851963746,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.383454009512695
  },
  {
    "Model Name": "Dans-DiscountModels/12b-mn-dans-reasoning-test-2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9447289025847284,
    "Overall Score": 15.564777531713789,
    "MMLU Score": 16.749778368794324,
    "BBH Score": 26.108938446170427,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 16.475390441775815
  },
  {
    "Model Name": "Dans-DiscountModels/12b-mn-dans-reasoning-test-3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8696611878200479,
    "Overall Score": 19.13127211265294,
    "MMLU Score": 16.842124704491724,
    "BBH Score": 25.84864126816548,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.998535039385505
  },
  {
    "Model Name": "Dans-DiscountModels/Dans-Instruct-CoreCurriculum-12b-ChatML",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.636903883938605,
    "Overall Score": 13.542857676063695,
    "MMLU Score": 20.05577718676123,
    "BBH Score": 26.046417064819565,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.920668190465129
  },
  {
    "Model Name": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5971383963665835,
    "Overall Score": 13.521356471467334,
    "MMLU Score": 25.42109929078014,
    "BBH Score": 26.33639354405325,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.465989235640317
  },
  {
    "Model Name": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6293978013302186,
    "Overall Score": 13.074906766382025,
    "MMLU Score": 25.37492612293144,
    "BBH Score": 26.737651950701505,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.024379777429333
  },
  {
    "Model Name": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5811774914426833,
    "Overall Score": 13.349347006636378,
    "MMLU Score": 25.319518321513,
    "BBH Score": 26.412550636134668,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.442661926875958
  },
  {
    "Model Name": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.2.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6874331691059232,
    "Overall Score": 19.08185593143887,
    "MMLU Score": 22.21668144208038,
    "BBH Score": 24.73477061224504,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.308214322674054
  },
  {
    "Model Name": "Dans-DiscountModels/Mistral-7b-v0.3-Test-E0.7",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.875771180221206,
    "Overall Score": 19.169864255303853,
    "MMLU Score": 19.38164893617021,
    "BBH Score": 26.82076225675772,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.88912433777719
  },
  {
    "Model Name": "Dans-DiscountModels/mistral-7b-test-merged",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.336846263016353,
    "Overall Score": 22.07333933109492,
    "MMLU Score": 21.976580969267136,
    "BBH Score": 28.94100499482477,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.445781556294213
  },
  {
    "Model Name": "Darkknight535/OpenCrystal-12B-L3",
    "Parameters (B)": 11.52,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.024570033760275,
    "Overall Score": 20.68547638312264,
    "MMLU Score": 29.33658392434988,
    "BBH Score": 31.84449091545611,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.139797844142766
  },
  {
    "Model Name": "DavidAU/DeepHermes-3-Llama-3-8B-Preview-16.5B-Brainstorm",
    "Parameters (B)": 16.537,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5248284998228248,
    "Overall Score": 18.4525815482333,
    "MMLU Score": 24.543809101654844,
    "BBH Score": 24.9087539518445,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.308449484599915
  },
  {
    "Model Name": "DavidAU/DeepSeek-BlackRoot-R1-Distill-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.717378353005959,
    "Overall Score": 19.075555358413183,
    "MMLU Score": 21.95811170212766,
    "BBH Score": 27.61664414777965,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.59064812658869
  },
  {
    "Model Name": "DavidAU/DeepSeek-Grand-Horror-SMB-R1-Distill-Llama-3.1-16B",
    "Parameters (B)": 15.664,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6307445591975105,
    "Overall Score": 14.762746148661485,
    "MMLU Score": 18.99379432624113,
    "BBH Score": 22.777139438535443,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.611622799731173
  },
  {
    "Model Name": "DavidAU/DeepSeek-MOE-4X8B-R1-Distill-Llama-3.1-Deep-Thinker-Uncensored-24B",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3816831290269125,
    "Overall Score": 20.033732738998072,
    "MMLU Score": 22.49372044917257,
    "BBH Score": 27.77355005218521,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.411586115229058
  },
  {
    "Model Name": "DavidAU/DeepSeek-MOE-4X8B-R1-Distill-Llama-3.1-Mad-Scientist-24B",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6746962812464536,
    "Overall Score": 18.80531524670597,
    "MMLU Score": 21.884234633569736,
    "BBH Score": 25.61443384964336,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.030822668935844
  },
  {
    "Model Name": "DavidAU/DeepSeek-R1-Distill-Qwen-25.5B-Brainstorm",
    "Parameters (B)": 25.506,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.562346505649761,
    "Overall Score": 35.28187768500508,
    "MMLU Score": 40.26115543735224,
    "BBH Score": 38.54849081746308,
    "Math Score": 55.36253776435045,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.342984502883582
  },
  {
    "Model Name": "DavidAU/DeepSeek-V2-Grand-Horror-SMB-R1-Distill-Llama-3.1-Uncensored-16.5B",
    "Parameters (B)": 16.537,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.791403414085212,
    "Overall Score": 15.169195541253533,
    "MMLU Score": 19.751034278959807,
    "BBH Score": 22.87842410217944,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.434254133498193
  },
  {
    "Model Name": "DavidAU/DeepThought-MOE-8X3B-R1-Llama-3.2-Reasoning-18B",
    "Parameters (B)": 18.405,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.524036957049664,
    "Overall Score": 16.128174383829172,
    "MMLU Score": 19.11384456264776,
    "BBH Score": 18.81085739291652,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.5766189686420695
  },
  {
    "Model Name": "DavidAU/Gemma-The-Writer-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.968036805179416,
    "Overall Score": 20.57119536629256,
    "MMLU Score": 33.10431442080379,
    "BBH Score": 41.272318662592205,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.1842249395069375
  },
  {
    "Model Name": "DavidAU/Gemma-The-Writer-DEADLINE-10B",
    "Parameters (B)": 10.952,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.197589797990433,
    "Overall Score": 21.6766411356942,
    "MMLU Score": 32.73492907801418,
    "BBH Score": 41.01919903629973,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.17051787043201
  },
  {
    "Model Name": "DavidAU/Gemma-The-Writer-J.GutenBerg-10B",
    "Parameters (B)": 10.034,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.037345351027912,
    "Overall Score": 22.350742726448782,
    "MMLU Score": 32.74416371158392,
    "BBH Score": 41.15599097529756,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.437008219396339
  },
  {
    "Model Name": "DavidAU/Gemma-The-Writer-Mighty-Sword-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.842982875986834,
    "Overall Score": 32.033823768599724,
    "MMLU Score": 32.97502955082743,
    "BBH Score": 41.392610073884825,
    "Math Score": 19.10876132930513,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.267680871092265
  },
  {
    "Model Name": "DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored",
    "Parameters (B)": 10.034,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4933973013928696,
    "Overall Score": 31.67934579653929,
    "MMLU Score": 32.95656028368795,
    "BBH Score": 40.85009081777402,
    "Math Score": 22.9607250755287,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.068348963316673
  },
  {
    "Model Name": "DavidAU/L3-DARKEST-PLANET-16.5B",
    "Parameters (B)": 16.537,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.225040735611014,
    "Overall Score": 24.265056044870743,
    "MMLU Score": 29.225768321512994,
    "BBH Score": 31.776241491685315,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.743153158347383
  },
  {
    "Model Name": "DavidAU/L3-Dark-Planet-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8782814138679609,
    "Overall Score": 20.46918405625605,
    "MMLU Score": 30.40780141843972,
    "BBH Score": 29.78962694499553,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.897826015380563
  },
  {
    "Model Name": "DavidAU/L3-Jamet-12.2B-MK.V-Blackroot-Instruct",
    "Parameters (B)": 12.174,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4375216123892207,
    "Overall Score": 17.857043217965458,
    "MMLU Score": 25.458037825059098,
    "BBH Score": 25.86979314469773,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.422104171558374
  },
  {
    "Model Name": "DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct",
    "Parameters (B)": 12.174,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8494143473815945,
    "Overall Score": 17.831555665481403,
    "MMLU Score": 23.795803782505907,
    "BBH Score": 24.5048155831814,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.257972162548881
  },
  {
    "Model Name": "DavidAU/L3-SMB-Instruct-12.2B-F32",
    "Parameters (B)": 12.174,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.764794372875263,
    "Overall Score": 18.90163889043809,
    "MMLU Score": 25.6889036643026,
    "BBH Score": 26.130957088441544,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.83654418421766
  },
  {
    "Model Name": "DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B",
    "Parameters (B)": 16.537,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.845597193164506,
    "Overall Score": 17.197491298716887,
    "MMLU Score": 28.56087470449172,
    "BBH Score": 26.692021341537863,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.9419562673299846
  },
  {
    "Model Name": "DavidAU/L3-Stheno-v3.2-12.2B-Instruct",
    "Parameters (B)": 12.174,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.795399201725276,
    "Overall Score": 18.73968028525321,
    "MMLU Score": 26.0582890070922,
    "BBH Score": 27.36962320894452,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.703758187269775
  },
  {
    "Model Name": "DavidAU/L3.1-Dark-Planet-SpinFire-Uncensored-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2605639032263736,
    "Overall Score": 24.710302269160096,
    "MMLU Score": 29.669030732860524,
    "BBH Score": 32.46178300050608,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.60257802552878
  },
  {
    "Model Name": "DavidAU/L3.1-MOE-2X8B-Deepseek-DeepHermes-e32-uncensored-abliterated-13.7B",
    "Parameters (B)": 13.668,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4035730196826506,
    "Overall Score": 19.615401464984767,
    "MMLU Score": 21.025413711583923,
    "BBH Score": 21.1978292731234,
    "Math Score": 26.057401812688823,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.975333801600028
  },
  {
    "Model Name": "DavidAU/Qwen2.5-MOE-2X1.5B-DeepSeek-Uncensored-Censored-4B",
    "Parameters (B)": 4.089,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1268767305406775,
    "Overall Score": 5.120376565217631,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 3.023581212338263,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.543865736548544
  },
  {
    "Model Name": "DavidAU/Qwen2.5-MOE-2X7B-DeepSeek-Abliterated-Censored-19B",
    "Parameters (B)": 19.022,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2596681212071084,
    "Overall Score": 13.021728019791546,
    "MMLU Score": 7.071882387706856,
    "BBH Score": 10.870199077362608,
    "Math Score": 24.169184290030213,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.762672800302806
  },
  {
    "Model Name": "DavidAU/Qwen2.5-MOE-6x1.5B-DeepSeek-Reasoning-e32",
    "Parameters (B)": 8.714,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2526985444884104,
    "Overall Score": 6.418592963200898,
    "MMLU Score": 1.3556442080378246,
    "BBH Score": 6.218964782807416,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 2.849290678020376
  },
  {
    "Model Name": "Davidsv/SUONG-1",
    "Parameters (B)": 2.879,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.2206802990394573,
    "Overall Score": 5.32234226282347,
    "MMLU Score": 0.9493203309692664,
    "BBH Score": 1.827242482574876,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.11788585564606
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter0",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3696496824722615,
    "Overall Score": 3.6238167467938993,
    "MMLU Score": 1.392582742316784,
    "BBH Score": 2.1008283750749497,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.803381197455325
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter0",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7089527374016119,
    "Overall Score": 3.985688359677067,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 2.330668557723352,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.621938035368964
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter1",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7217203551845318,
    "Overall Score": 3.7519748574168585,
    "MMLU Score": 1.309471040189124,
    "BBH Score": 2.433772217660189,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.198654618044604
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7070763736913788,
    "Overall Score": 3.658145708347315,
    "MMLU Score": 1.4295212765957446,
    "BBH Score": 3.1573429783229785,
    "Math Score": 0.5287009063444108,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.173621753544836
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter3",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0930826432847425,
    "Overall Score": 3.593140598286666,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 3.1395015434855087,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.287162796299814
  },
  {
    "Model Name": "DavieLion/Llama-3.2-1B-SPIN-iter3",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3632299840264858,
    "Overall Score": 3.6136899611836006,
    "MMLU Score": 1.4295212765957446,
    "BBH Score": 3.02851385306557,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.948765575806924
  },
  {
    "Model Name": "DavieLion/Lllma-3.2-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7337502581357204,
    "Overall Score": 3.932331961262434,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 2.438122895622896,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.359223956191206
  },
  {
    "Model Name": "DebateLabKIT/Llama-3.1-Argunaut-1-8B-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4339566351371729,
    "Overall Score": 24.113556306971883,
    "MMLU Score": 27.47118794326241,
    "BBH Score": 27.187826826803345,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.816098699292375
  },
  {
    "Model Name": "Deci/DeciLM-7B",
    "Parameters (B)": 7.044,
    "Architecture": "DeciLMForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.2842746949253772,
    "Overall Score": 15.023477940437225,
    "MMLU Score": 18.7998670212766,
    "BBH Score": 21.252729791067395,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.698025352208754
  },
  {
    "Model Name": "Deci/DeciLM-7B-instruct",
    "Parameters (B)": 7.044,
    "Architecture": "DeciLMForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.277298664672314,
    "Overall Score": 17.470092220993035,
    "MMLU Score": 17.86716903073286,
    "BBH Score": 23.8871490441846,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.677374528121753
  },
  {
    "Model Name": "DeepAutoAI/Explore_Llama-3.1-8B-Inst",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.639464971642932,
    "Overall Score": 28.926700693431915,
    "MMLU Score": 31.017287234042552,
    "BBH Score": 30.393262902042363,
    "Math Score": 20.09063444108761,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.959304633403232
  },
  {
    "Model Name": "DeepAutoAI/Explore_Llama-3.2-1B-Inst",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3254123091945325,
    "Overall Score": 13.897376870733368,
    "MMLU Score": 8.983451536643026,
    "BBH Score": 8.292273657131942,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.485323528630088
  },
  {
    "Model Name": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.93437873881675,
    "Overall Score": 13.359085066778022,
    "MMLU Score": 8.928043735224584,
    "BBH Score": 7.042771972349901,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.297291357137782
  },
  {
    "Model Name": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9399318977538752,
    "Overall Score": 10.921433609301348,
    "MMLU Score": 2.990174349881796,
    "BBH Score": 4.257780193079653,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.61938820823077
  },
  {
    "Model Name": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3605236173599355,
    "Overall Score": 14.311829325717667,
    "MMLU Score": 9.094267139479904,
    "BBH Score": 8.818154144791238,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.519353830468184
  },
  {
    "Model Name": "DeepAutoAI/causal_gpt2",
    "Parameters (B)": 0.124,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.2517304194831908,
    "Overall Score": 6.032059300937514,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 2.6333438399574587,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 23.962377345262805
  },
  {
    "Model Name": "DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7123559936882888,
    "Overall Score": 29.33896549450444,
    "MMLU Score": 31.96845449172577,
    "BBH Score": 30.51007603826353,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2024-09-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.133683417844946
  },
  {
    "Model Name": "DeepAutoAI/d2nwg_causal_gpt2",
    "Parameters (B)": 0.124,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.2598146183920366,
    "Overall Score": 6.305441322097188,
    "MMLU Score": 1.6788563829787229,
    "BBH Score": 2.850573557678692,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 24.26900134072845
  },
  {
    "Model Name": "DeepAutoAI/d2nwg_causal_gpt2_v1",
    "Parameters (B)": 0.124,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3430067286083757,
    "Overall Score": 6.419565742614277,
    "MMLU Score": 1.5033983451536632,
    "BBH Score": 2.3872783507070148,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-10-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.715567967600276
  },
  {
    "Model Name": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.570061196406768,
    "Overall Score": 29.85905810866196,
    "MMLU Score": 32.070035460992905,
    "BBH Score": 31.101628224178786,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.618033901452716
  },
  {
    "Model Name": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.72090943948751,
    "Overall Score": 29.73524433069372,
    "MMLU Score": 32.171616430260045,
    "BBH Score": 31.162649496607862,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.278796692258794
  },
  {
    "Model Name": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.656891613064036,
    "Overall Score": 29.73524433069372,
    "MMLU Score": 32.171616430260045,
    "BBH Score": 31.162649496607862,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.946402828188198
  },
  {
    "Model Name": "DeepMount00/Lexora-Lite-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.161923130387553,
    "Overall Score": 24.888387400166817,
    "MMLU Score": 28.911790780141843,
    "BBH Score": 28.43627869001684,
    "Math Score": 23.036253776435046,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.871281613704593
  },
  {
    "Model Name": "DeepMount00/Lexora-Lite-3B_v2",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7749346127852547,
    "Overall Score": 22.690213091300453,
    "MMLU Score": 28.26536643026005,
    "BBH Score": 27.16845176322372,
    "Math Score": 22.80966767371601,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.280164696409336
  },
  {
    "Model Name": "DeepMount00/Lexora-Medium-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4698222000444563,
    "Overall Score": 25.83719802694387,
    "MMLU Score": 36.9459219858156,
    "BBH Score": 32.6953311808552,
    "Math Score": 22.20543806646526,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.44625993418707
  },
  {
    "Model Name": "DeepMount00/Llama-3-8b-Ita",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.556516897300023,
    "Overall Score": 26.7968164089867,
    "MMLU Score": 31.691415484633573,
    "BBH Score": 28.077745566893725,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.215885324129275
  },
  {
    "Model Name": "DeepMount00/Llama-3.1-8b-ITA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5075735912307806,
    "Overall Score": 28.228097653849485,
    "MMLU Score": 31.959219858156025,
    "BBH Score": 30.933181176860177,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.257136282087904
  },
  {
    "Model Name": "DeepMount00/Llama-3.1-8b-Ita",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 0.9062470550284772,
    "Overall Score": 26.26573192518462,
    "MMLU Score": 32.89191784869976,
    "BBH Score": 31.333639113507697,
    "Math Score": 17.069486404833835,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 28.982970790850477
  },
  {
    "Model Name": "DeepMount00/Llama-3.1-Distilled",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6780001093726986,
    "Overall Score": 29.631398468956544,
    "MMLU Score": 30.906471631205672,
    "BBH Score": 30.84142128641545,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.65875836565583
  },
  {
    "Model Name": "DeepMount00/Qwen2-1.5B-Ita",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5125510916273373,
    "Overall Score": 16.83176132950784,
    "MMLU Score": 19.686391843971627,
    "BBH Score": 15.42299613137108,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.8391873599711
  },
  {
    "Model Name": "DeepMount00/Qwen2-1.5B-Ita_v2",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5546789113986239,
    "Overall Score": 17.07000871129109,
    "MMLU Score": 22.57683215130024,
    "BBH Score": 15.106125348603843,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 30.77457671547136
  },
  {
    "Model Name": "DeepMount00/Qwen2-1.5B-Ita_v3",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5846262308283405,
    "Overall Score": 16.948513223691304,
    "MMLU Score": 22.41984338061465,
    "BBH Score": 15.22652186012814,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 28.99034003260071
  },
  {
    "Model Name": "DeepMount00/Qwen2-1.5B-Ita_v5",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5321054999622403,
    "Overall Score": 17.023240512569227,
    "MMLU Score": 21.588726359338057,
    "BBH Score": 16.487037607634196,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 31.992228070894292
  },
  {
    "Model Name": "DeepMount00/Qwen2-1.5B-Ita_v6",
    "Parameters (B)": 1.497,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6074762902125238,
    "Overall Score": 14.577672072316156,
    "MMLU Score": 20.794547872340427,
    "BBH Score": 19.093803548070223,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.997104590232155
  },
  {
    "Model Name": "DeepMount00/Qwen2.5-7B-Instruct-MathCoder",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5853591543493346,
    "Overall Score": 4.39690970265251,
    "MMLU Score": 1.309471040189124,
    "BBH Score": 2.636670587150039,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7006958956768599
  },
  {
    "Model Name": "DeepMount00/mergekit-ties-okvgjfz",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.577642692775661,
    "Overall Score": 4.39690970265251,
    "MMLU Score": 1.309471040189124,
    "BBH Score": 2.636670587150039,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7057871189733531
  },
  {
    "Model Name": "Delta-Vector/Baldur-8B",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.060930655450191,
    "Overall Score": 24.191735720120548,
    "MMLU Score": 29.493572695035457,
    "BBH Score": 32.54183409581636,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.9033922826855125
  },
  {
    "Model Name": "Delta-Vector/Control-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3549719696219258,
    "Overall Score": 25.058025917312307,
    "MMLU Score": 30.352393617021285,
    "BBH Score": 29.15507782169402,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.493390622910216
  },
  {
    "Model Name": "Delta-Vector/Control-8B-V1.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.281195193166664,
    "Overall Score": 24.632508988415825,
    "MMLU Score": 30.50014775413712,
    "BBH Score": 28.725850265520112,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.22619528998772
  },
  {
    "Model Name": "Delta-Vector/Darkens-8B",
    "Parameters (B)": 8.414,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.399486158167288,
    "Overall Score": 18.93741540437432,
    "MMLU Score": 30.39856678486997,
    "BBH Score": 32.88379503743108,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.89227949488927
  },
  {
    "Model Name": "Delta-Vector/Henbane-7b-attempt2",
    "Parameters (B)": 7.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2676763161131808,
    "Overall Score": 23.81394998002872,
    "MMLU Score": 33.63992316784869,
    "BBH Score": 30.86584945112165,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.501476692602258
  },
  {
    "Model Name": "Delta-Vector/Odin-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.416323354381718,
    "Overall Score": 24.977112692219293,
    "MMLU Score": 33.85231973995272,
    "BBH Score": 34.83242280758616,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.611451543418879
  },
  {
    "Model Name": "Delta-Vector/Tor-8B",
    "Parameters (B)": 8.414,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.504106680356207,
    "Overall Score": 18.406879108800087,
    "MMLU Score": 30.33392434988179,
    "BBH Score": 31.73822449849867,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.350676891362202
  },
  {
    "Model Name": "DevQuasar/DevQuasar-R1-Uncensored-Llama-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7195218960856864,
    "Overall Score": 26.432648640760963,
    "MMLU Score": 29.050310283687946,
    "BBH Score": 30.22023823479265,
    "Math Score": 33.081570996978854,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.73640619494525
  },
  {
    "Model Name": "Dongwei/DeepSeek-R1-Distill-Qwen-7B-GRPO",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3446612624924523,
    "Overall Score": 14.996461674248115,
    "MMLU Score": 14.690455082742314,
    "BBH Score": 7.882702983365756,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.152594406156094
  },
  {
    "Model Name": "DoppelReflEx/L3-8B-R1-WolfCore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.660438890438418,
    "Overall Score": 23.481232873269377,
    "MMLU Score": 30.18617021276595,
    "BBH Score": 33.760104762918594,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.55398268215531
  },
  {
    "Model Name": "DoppelReflEx/L3-8B-R1-WolfCore-V1.5-test",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.654732953184737,
    "Overall Score": 22.363618284395272,
    "MMLU Score": 30.30622044917257,
    "BBH Score": 33.45949833611522,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 34.15685460097078
  },
  {
    "Model Name": "DoppelReflEx/L3-8B-WolfCore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6531067502572314,
    "Overall Score": 21.170086506168307,
    "MMLU Score": 30.056885342789595,
    "BBH Score": 31.290072076092343,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.414435309128706
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-FoxFrame-test",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5525658386176966,
    "Overall Score": 23.221061750775235,
    "MMLU Score": 27.812869385342783,
    "BBH Score": 34.55981394889724,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.956571356387537
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-FoxFrame2-test",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7505194111203773,
    "Overall Score": 23.639728527998752,
    "MMLU Score": 28.54240543735224,
    "BBH Score": 34.99669953906846,
    "Math Score": 14.04833836858006,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.497824277068734
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-FoxFrame3-test",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.697196284743319,
    "Overall Score": 23.94718793396009,
    "MMLU Score": 28.09914302600473,
    "BBH Score": 34.041185744792614,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 34.34784214717457
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Kakigori",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5956599074145044,
    "Overall Score": 21.69773317205639,
    "MMLU Score": 28.680924940898343,
    "BBH Score": 34.3313471973429,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.597968508974999
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-LilithFrame",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8565068435824488,
    "Overall Score": 21.321059817195124,
    "MMLU Score": 25.070183215130022,
    "BBH Score": 27.49206445527077,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.484503755479015
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-LilithFrame",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.928004753006219,
    "Overall Score": 20.022540131471107,
    "MMLU Score": 24.857786643026003,
    "BBH Score": 27.65349780577308,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.575902565810377
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-LilithFrame-Experiment-2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.839135306107101,
    "Overall Score": 21.00209029579248,
    "MMLU Score": 25.29181442080378,
    "BBH Score": 28.11118297022868,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.419546036690264
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-LilithFrame-Experiment-3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.362722818955918,
    "Overall Score": 23.13928263244864,
    "MMLU Score": 28.93026004728133,
    "BBH Score": 34.998286324114495,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.793481675803951
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-LilithFrame-Experiment-4",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6437133049727632,
    "Overall Score": 23.52862068050267,
    "MMLU Score": 29.42893026004728,
    "BBH Score": 35.77765007970374,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.314309319831505
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-GreenSnake",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6886018245229184,
    "Overall Score": 25.0150134402288,
    "MMLU Score": 29.4566341607565,
    "BBH Score": 35.390600609410264,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.814039092547057
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-Nocturne",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8795798612287349,
    "Overall Score": 24.06630184974314,
    "MMLU Score": 29.26270685579196,
    "BBH Score": 38.39866772323549,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.361133321224024
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-Orochi",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5209626837047343,
    "Overall Score": 24.65222284950452,
    "MMLU Score": 27.184914302600472,
    "BBH Score": 35.28322975535459,
    "Math Score": 13.595166163141997,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.20830222438927
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-Orochi-v2-Experiment",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1022812062861855,
    "Overall Score": 19.804010674590824,
    "MMLU Score": 26.92634456264776,
    "BBH Score": 32.77471060618407,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.96638694522848
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-Orochi-v3-Experiment",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.334928752887779,
    "Overall Score": 22.641023288108883,
    "MMLU Score": 26.621601654846334,
    "BBH Score": 34.569479663100296,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.960473163178772
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-Orochi-v4-Experiment",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8864542031174687,
    "Overall Score": 23.57577520136853,
    "MMLU Score": 27.997562056737586,
    "BBH Score": 35.29906847464648,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.497401295196179
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.598793921384112,
    "Overall Score": 25.05856000855185,
    "MMLU Score": 29.53051122931442,
    "BBH Score": 36.89971047715762,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.67341461172062
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake-v2-Experiment-1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.876918435447324,
    "Overall Score": 18.86667946331972,
    "MMLU Score": 23.49106087470449,
    "BBH Score": 27.07796440244996,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.05194424382285
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake-v2-Experiment-2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.634526312899575,
    "Overall Score": 19.42254252989416,
    "MMLU Score": 25.70737293144208,
    "BBH Score": 30.66571959351228,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.372309183170616
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake-v2-Experiment-3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.814317659192325,
    "Overall Score": 19.601520651982582,
    "MMLU Score": 24.423758865248228,
    "BBH Score": 26.321395450260827,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.803797533838997
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake-v2-Experiment-4",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7271200547540042,
    "Overall Score": 21.794341198490542,
    "MMLU Score": 26.021350472813243,
    "BBH Score": 31.42294702518673,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.61889185902293
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-Unleashed-Twilight",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8143144766567885,
    "Overall Score": 22.56427237998545,
    "MMLU Score": 29.752142434988176,
    "BBH Score": 35.97610662338389,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.709531178451197
  },
  {
    "Model Name": "DoppelReflEx/MN-12B-WolFrame",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6813747793154408,
    "Overall Score": 22.07871968405737,
    "MMLU Score": 26.59389775413712,
    "BBH Score": 29.991929835267143,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.13134939079231
  },
  {
    "Model Name": "DoppelReflEx/MiniusLight-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4403396216495052,
    "Overall Score": 26.210340083042343,
    "MMLU Score": 45.46025413711584,
    "BBH Score": 46.002968874248914,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.19733324632544
  },
  {
    "Model Name": "DoppelReflEx/MiniusLight-24B-test",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5780434517444448,
    "Overall Score": 20.83721280671412,
    "MMLU Score": 46.466829196217496,
    "BBH Score": 46.95696642451458,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 36.04783125529866
  },
  {
    "Model Name": "DoppelReflEx/MiniusLight-24B-v1b-test",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.37466461037625,
    "Overall Score": 32.3748943419153,
    "MMLU Score": 48.49844858156028,
    "BBH Score": 50.63814760323434,
    "Math Score": 23.94259818731118,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.551122286514808
  },
  {
    "Model Name": "DoppelReflEx/MiniusLight-24B-v1c-test",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.322544674351261,
    "Overall Score": 34.40831757695809,
    "MMLU Score": 49.85593971631205,
    "BBH Score": 52.84065809537824,
    "Math Score": 29.68277945619335,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.960199412426474
  },
  {
    "Model Name": "DoppelReflEx/MiniusLight-24B-v1d-test",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.497396987337705,
    "Overall Score": 34.681949426054764,
    "MMLU Score": 49.87440898345154,
    "BBH Score": 52.35844104160633,
    "Math Score": 29.45619335347432,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.161492723260707
  },
  {
    "Model Name": "DreadPoor/Again-8B-Model_Stock",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3606541886058623,
    "Overall Score": 26.00238758465348,
    "MMLU Score": 27.979092789598106,
    "BBH Score": 33.2594612268752,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-12-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.110210222698644
  },
  {
    "Model Name": "DreadPoor/Alita99-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.317244660000561,
    "Overall Score": 29.392264436250034,
    "MMLU Score": 31.21121453900709,
    "BBH Score": 35.00891825379863,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.313443606017366
  },
  {
    "Model Name": "DreadPoor/AnotherTest",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5180190760115888,
    "Overall Score": 19.50517112101721,
    "MMLU Score": 20.831486406619387,
    "BBH Score": 25.197137506034824,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.849094869258614
  },
  {
    "Model Name": "DreadPoor/Aspire-8B-model_stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6862557790299026,
    "Overall Score": 28.611281691142512,
    "MMLU Score": 30.7033096926714,
    "BBH Score": 32.534270073092834,
    "Math Score": 14.954682779456194,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.96734389109254
  },
  {
    "Model Name": "DreadPoor/Aspire_1.3-8B_model-stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.431562779750175,
    "Overall Score": 28.38880221155723,
    "MMLU Score": 30.17693557919622,
    "BBH Score": 32.66185070730422,
    "Math Score": 16.91842900302115,
    "Date Submitted": "2024-11-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.83063726797327
  },
  {
    "Model Name": "DreadPoor/Aspire_V2-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3396128096032138,
    "Overall Score": 29.023157905941588,
    "MMLU Score": 29.9645390070922,
    "BBH Score": 33.327406017534244,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.66533322008028
  },
  {
    "Model Name": "DreadPoor/Aspire_V2.1-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.350700850251785,
    "Overall Score": 28.738387280035045,
    "MMLU Score": 31.11886820330969,
    "BBH Score": 32.18794456865431,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.27664854484833
  },
  {
    "Model Name": "DreadPoor/Aspire_V2_ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3203141655524284,
    "Overall Score": 29.05989321843224,
    "MMLU Score": 30.296985815602827,
    "BBH Score": 32.44516856104618,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.009832187381996
  },
  {
    "Model Name": "DreadPoor/Aspire_V2_ALT_ROW-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.290022700649708,
    "Overall Score": 29.05989321843224,
    "MMLU Score": 30.296985815602827,
    "BBH Score": 32.44516856104618,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.526652595955476
  },
  {
    "Model Name": "DreadPoor/Aspire_V3-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3138646967471743,
    "Overall Score": 25.135023019694938,
    "MMLU Score": 29.35505319148936,
    "BBH Score": 32.68368177507647,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.13060232299677
  },
  {
    "Model Name": "DreadPoor/Aspire_V4-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3502461987292993,
    "Overall Score": 29.36906658031589,
    "MMLU Score": 30.093823877068555,
    "BBH Score": 33.20598944793845,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.750897434819496
  },
  {
    "Model Name": "DreadPoor/Aspire_V4_ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3543781518936209,
    "Overall Score": 29.003526021452984,
    "MMLU Score": 29.79831560283688,
    "BBH Score": 32.63543581177509,
    "Math Score": 18.12688821752266,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.414644042287428
  },
  {
    "Model Name": "DreadPoor/Asymmetric_Linearity-8B-Model_Stock",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2785390621096806,
    "Overall Score": 29.34813164491316,
    "MMLU Score": 31.599069148936167,
    "BBH Score": 35.4412470409656,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.9544270602782
  },
  {
    "Model Name": "DreadPoor/Aurora_faustus-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5347539539225346,
    "Overall Score": 29.619908170064097,
    "MMLU Score": 31.580599881796683,
    "BBH Score": 36.26348248348271,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.29945063465146
  },
  {
    "Model Name": "DreadPoor/Aurora_faustus-8B-LORABLATED",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6017002655807937,
    "Overall Score": 29.127203730886404,
    "MMLU Score": 29.696734633569736,
    "BBH Score": 34.19993531370101,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.185177562123066
  },
  {
    "Model Name": "DreadPoor/Aurora_faustus-8B-LORABLATED_ALT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5902321956738188,
    "Overall Score": 29.00968134721205,
    "MMLU Score": 29.93683510638298,
    "BBH Score": 34.21152011815682,
    "Math Score": 15.861027190332328,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.242418576439377
  },
  {
    "Model Name": "DreadPoor/Autumn_Dawn-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.402496876361008,
    "Overall Score": 29.605469000443268,
    "MMLU Score": 32.97502955082743,
    "BBH Score": 35.845555124121006,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.10911582010733
  },
  {
    "Model Name": "DreadPoor/BaeZel-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.330137640213943,
    "Overall Score": 30.34681191186813,
    "MMLU Score": 31.792996453900702,
    "BBH Score": 35.53537606986396,
    "Math Score": 18.12688821752266,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.814790736233178
  },
  {
    "Model Name": "DreadPoor/BaeZel-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3246060112910538,
    "Overall Score": 30.021263046626203,
    "MMLU Score": 32.00539302600473,
    "BBH Score": 34.643632940053415,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.664296244107618
  },
  {
    "Model Name": "DreadPoor/BaeZel_V2-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.428644701659184,
    "Overall Score": 30.020772741913536,
    "MMLU Score": 32.74416371158392,
    "BBH Score": 34.4487493680143,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.013463114410698
  },
  {
    "Model Name": "DreadPoor/BaeZel_V2_ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4263812233952076,
    "Overall Score": 30.020772741913536,
    "MMLU Score": 32.74416371158392,
    "BBH Score": 34.4487493680143,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.046808699889677
  },
  {
    "Model Name": "DreadPoor/BaeZel_V3-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3245907715556766,
    "Overall Score": 30.71919480994485,
    "MMLU Score": 32.08850472813239,
    "BBH Score": 34.408658796480346,
    "Math Score": 18.95770392749245,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.191460690811272
  },
  {
    "Model Name": "DreadPoor/Blunt_Edge-8B-SLERP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.295227329313974,
    "Overall Score": 29.67747863443424,
    "MMLU Score": 30.74024822695036,
    "BBH Score": 34.14138253488904,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.912949690579122
  },
  {
    "Model Name": "DreadPoor/BulkUp",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5267189091550464,
    "Overall Score": 3.7903724081838015,
    "MMLU Score": 1.2171247044917255,
    "BBH Score": 1.6612873090290492,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.482691728945416
  },
  {
    "Model Name": "DreadPoor/Cadence-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6703182483240965,
    "Overall Score": 29.577499098320445,
    "MMLU Score": 31.146572104018905,
    "BBH Score": 34.914380348862515,
    "Math Score": 16.76737160120846,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.12456198569702
  },
  {
    "Model Name": "DreadPoor/Caelid-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2312977459174457,
    "Overall Score": 28.396110525383506,
    "MMLU Score": 31.29432624113476,
    "BBH Score": 35.23706805025389,
    "Math Score": 15.105740181268882,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.061936578325685
  },
  {
    "Model Name": "DreadPoor/Casuar-9B-Model_Stock",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3008564505336286,
    "Overall Score": 33.631173922201846,
    "MMLU Score": 35.07129137115839,
    "BBH Score": 43.92726768312374,
    "Math Score": 21.299093655589125,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.188620567478754
  },
  {
    "Model Name": "DreadPoor/Condensed_Milk-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3093283812844896,
    "Overall Score": 30.083171334394155,
    "MMLU Score": 31.959219858156025,
    "BBH Score": 35.12062025244797,
    "Math Score": 17.447129909365557,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.976032418148364
  },
  {
    "Model Name": "DreadPoor/CoolerCoder-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.165600817763367,
    "Overall Score": 19.437537566560177,
    "MMLU Score": 23.98973108747045,
    "BBH Score": 26.365382993394,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.975586547217537
  },
  {
    "Model Name": "DreadPoor/Damasteel-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3493181419987623,
    "Overall Score": 28.97747867481607,
    "MMLU Score": 30.87876773049646,
    "BBH Score": 34.10613777622061,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-11-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.475645937652153
  },
  {
    "Model Name": "DreadPoor/Dearly_Beloved-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.430481044772098,
    "Overall Score": 26.286760418026628,
    "MMLU Score": 20.295877659574465,
    "BBH Score": 16.671812993247975,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.37616829254427
  },
  {
    "Model Name": "DreadPoor/Decayed-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6464955314560469,
    "Overall Score": 29.71154213470467,
    "MMLU Score": 30.7033096926714,
    "BBH Score": 34.490500759556504,
    "Math Score": 17.14501510574018,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.957846093364154
  },
  {
    "Model Name": "DreadPoor/Derivative-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.279546685554034,
    "Overall Score": 30.10114939087056,
    "MMLU Score": 31.229683806146568,
    "BBH Score": 34.248821021284016,
    "Math Score": 17.900302114803626,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.524854333733817
  },
  {
    "Model Name": "DreadPoor/Derivative_V2-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2734998344522872,
    "Overall Score": 29.613500365543217,
    "MMLU Score": 31.73758865248227,
    "BBH Score": 34.49028104908971,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.253635033474136
  },
  {
    "Model Name": "DreadPoor/Derivative_V2_ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3019899546090274,
    "Overall Score": 30.17823315705989,
    "MMLU Score": 32.023862293144205,
    "BBH Score": 34.09335381950132,
    "Math Score": 18.80664652567976,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.178545310760146
  },
  {
    "Model Name": "DreadPoor/Derivative_V3-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3470456912363171,
    "Overall Score": 26.93055889710345,
    "MMLU Score": 27.803634751773053,
    "BBH Score": 32.42070195179438,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.992312860884926
  },
  {
    "Model Name": "DreadPoor/Elusive_Dragon_Heart-8B-LINEAR",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2727870512490191,
    "Overall Score": 28.65682513548015,
    "MMLU Score": 31.26662234042553,
    "BBH Score": 35.31017141761393,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.515019387853183
  },
  {
    "Model Name": "DreadPoor/Emu_Eggs-9B-Model_Stock",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.176699167352184,
    "Overall Score": 32.68321529929168,
    "MMLU Score": 35.85623522458629,
    "BBH Score": 42.783674159620205,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.291372367953977
  },
  {
    "Model Name": "DreadPoor/Eunoia_Vespera-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.626520093949101,
    "Overall Score": 28.956332369127026,
    "MMLU Score": 31.543661347517727,
    "BBH Score": 34.21610348917685,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.802628124207583
  },
  {
    "Model Name": "DreadPoor/Fu_sion_HA-8B-SLERP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2951105435024746,
    "Overall Score": 29.95901160445741,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 34.05290214273217,
    "Math Score": 17.522658610271904,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.132397272773932
  },
  {
    "Model Name": "DreadPoor/HOT_STINKING_GARBAGE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4737654914835887,
    "Overall Score": 21.5845732424896,
    "MMLU Score": 22.410608747044915,
    "BBH Score": 27.851418136508787,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.645866908419165
  },
  {
    "Model Name": "DreadPoor/H_the_eighth-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6574557527465881,
    "Overall Score": 30.18954140441448,
    "MMLU Score": 31.37743794326241,
    "BBH Score": 34.15424498998624,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.91874248311709
  },
  {
    "Model Name": "DreadPoor/Happy_New_Year-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.281487412969691,
    "Overall Score": 29.722378273097977,
    "MMLU Score": 31.98692375886525,
    "BBH Score": 34.00006494069371,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.193656037728836
  },
  {
    "Model Name": "DreadPoor/Heart_Stolen-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4986020927170227,
    "Overall Score": 29.41103592529093,
    "MMLU Score": 31.044991134751776,
    "BBH Score": 34.44482164620488,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2024-09-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.62564717360537
  },
  {
    "Model Name": "DreadPoor/Heart_Stolen-ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.471254548591098,
    "Overall Score": 27.8678381845889,
    "MMLU Score": 30.80489066193854,
    "BBH Score": 32.354424456472486,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2024-09-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.941547682062012
  },
  {
    "Model Name": "DreadPoor/Here_We_Go_Again-8B-SLERP",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.225435569157672,
    "Overall Score": 30.129656228309155,
    "MMLU Score": 31.922281323877066,
    "BBH Score": 35.53148620432186,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.586895457114395
  },
  {
    "Model Name": "DreadPoor/Howdy-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3063248770741902,
    "Overall Score": 29.644826479517462,
    "MMLU Score": 31.183510638297868,
    "BBH Score": 34.22706196535763,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.693303174256126
  },
  {
    "Model Name": "DreadPoor/Incidental-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2634223164614282,
    "Overall Score": 29.5682894801915,
    "MMLU Score": 31.922281323877066,
    "BBH Score": 35.15766080254052,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.403330062275504
  },
  {
    "Model Name": "DreadPoor/Irina-8B-model_stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.491172890181649,
    "Overall Score": 25.34985665112922,
    "MMLU Score": 28.59781323877068,
    "BBH Score": 32.08833034979686,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.999944686522028
  },
  {
    "Model Name": "DreadPoor/Kindling-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2885656354328203,
    "Overall Score": 29.66229791748307,
    "MMLU Score": 31.44208037825059,
    "BBH Score": 35.77883534009465,
    "Math Score": 17.522658610271904,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.019625156711328
  },
  {
    "Model Name": "DreadPoor/L3.1-BaeZel-8B-Della",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3179894823741092,
    "Overall Score": 26.25567172776485,
    "MMLU Score": 32.245493498817964,
    "BBH Score": 35.15745504522053,
    "Math Score": 17.447129909365557,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.92100246541438
  },
  {
    "Model Name": "DreadPoor/Laughing_Stock-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2966608065773144,
    "Overall Score": 28.21250433678697,
    "MMLU Score": 30.71254432624113,
    "BBH Score": 34.93824337423678,
    "Math Score": 15.78549848942598,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.757813757984348
  },
  {
    "Model Name": "DreadPoor/Lava_Lamp-8B-SLERP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.264561277760501,
    "Overall Score": 29.15489302019657,
    "MMLU Score": 30.55555555555556,
    "BBH Score": 33.802734199229576,
    "Math Score": 17.371601208459214,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.05534222258409
  },
  {
    "Model Name": "DreadPoor/LemonP-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3972866396390922,
    "Overall Score": 30.052497237216315,
    "MMLU Score": 33.38135342789598,
    "BBH Score": 35.371476735853804,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.50775394587515
  },
  {
    "Model Name": "DreadPoor/Lydia_of_Whiterun-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6539682055402704,
    "Overall Score": 30.10503527354818,
    "MMLU Score": 31.11886820330969,
    "BBH Score": 33.86908733681889,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 46.03440200686386
  },
  {
    "Model Name": "DreadPoor/Matryoshka-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3246274294755,
    "Overall Score": 29.825025523646488,
    "MMLU Score": 31.839169621749413,
    "BBH Score": 35.110911704209016,
    "Math Score": 17.522658610271904,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.51578433299997
  },
  {
    "Model Name": "DreadPoor/Mercury_In_Retrograde-8b-Model-Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.347093322001088,
    "Overall Score": 29.2612899751994,
    "MMLU Score": 31.432845744680847,
    "BBH Score": 34.38486477258895,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.721798703398047
  },
  {
    "Model Name": "DreadPoor/Minthy-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3610815072271032,
    "Overall Score": 30.05298886932508,
    "MMLU Score": 33.25206855791962,
    "BBH Score": 34.17002969063864,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.080227164757584
  },
  {
    "Model Name": "DreadPoor/Minthy_ALT-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3178485106532778,
    "Overall Score": 28.422530280387416,
    "MMLU Score": 29.70596926713948,
    "BBH Score": 34.16825686462601,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.567372919287916
  },
  {
    "Model Name": "DreadPoor/Minthy_V2-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3756823635961437,
    "Overall Score": 28.428890431570498,
    "MMLU Score": 30.40780141843972,
    "BBH Score": 35.82274773153525,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.66530122349981
  },
  {
    "Model Name": "DreadPoor/Minus_Penus-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6067024859198201,
    "Overall Score": 29.14247782385972,
    "MMLU Score": 30.57402482269504,
    "BBH Score": 33.57084078325773,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.03421528704779
  },
  {
    "Model Name": "DreadPoor/Morphing-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3703618658259002,
    "Overall Score": 29.281274084097088,
    "MMLU Score": 31.691415484633573,
    "BBH Score": 34.452420920507734,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.367548830943004
  },
  {
    "Model Name": "DreadPoor/Not_Even_My_Final_Form-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3929903739376703,
    "Overall Score": 29.473061853716462,
    "MMLU Score": 31.55289598108747,
    "BBH Score": 33.71901446820086,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.15812313218127
  },
  {
    "Model Name": "DreadPoor/Nother_One-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.262117274440706,
    "Overall Score": 26.07727131376096,
    "MMLU Score": 28.82867907801418,
    "BBH Score": 31.92112823138842,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.66152792759835
  },
  {
    "Model Name": "DreadPoor/Noxis-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.632762720740592,
    "Overall Score": 29.287317950959928,
    "MMLU Score": 29.558215130023648,
    "BBH Score": 34.8222565522494,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 46.28483472711817
  },
  {
    "Model Name": "DreadPoor/Nullsworn-12B-LINEAR",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8642260980352026,
    "Overall Score": 23.778140361939588,
    "MMLU Score": 29.39199172576832,
    "BBH Score": 35.51240857664764,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.513795771729903
  },
  {
    "Model Name": "DreadPoor/Nwah-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6453176169467952,
    "Overall Score": 29.720182729588192,
    "MMLU Score": 31.19274527186761,
    "BBH Score": 34.11306781436337,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 46.055123785716425
  },
  {
    "Model Name": "DreadPoor/ONeil-model_stock-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5288975332798018,
    "Overall Score": 26.935908369361425,
    "MMLU Score": 28.874852245862886,
    "BBH Score": 36.4126125295027,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-07-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.617863710969775
  },
  {
    "Model Name": "DreadPoor/Oh_Boy-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.335458516352382,
    "Overall Score": 29.675174242254258,
    "MMLU Score": 31.654476950354614,
    "BBH Score": 34.14329045372282,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.220962971809744
  },
  {
    "Model Name": "DreadPoor/OrangeJ-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.414155066210815,
    "Overall Score": 30.2188791324389,
    "MMLU Score": 32.98426418439716,
    "BBH Score": 35.15080738484264,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.368858235193017
  },
  {
    "Model Name": "DreadPoor/Promissum_Mane-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6572930442289775,
    "Overall Score": 29.099649072440133,
    "MMLU Score": 31.672946217494097,
    "BBH Score": 35.253190231117536,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.558541727892283
  },
  {
    "Model Name": "DreadPoor/Promissum_Mane-8B-LINEAR-lorablated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5846849960800864,
    "Overall Score": 28.82332716689665,
    "MMLU Score": 30.43550531914893,
    "BBH Score": 34.60910725048443,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.188679288435683
  },
  {
    "Model Name": "DreadPoor/RPMash-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3049476110310343,
    "Overall Score": 21.700898440005755,
    "MMLU Score": 28.93026004728133,
    "BBH Score": 31.11259163110552,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.62970854658292
  },
  {
    "Model Name": "DreadPoor/RPMash_V3-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2215115599421278,
    "Overall Score": 25.785089599589032,
    "MMLU Score": 29.0410756501182,
    "BBH Score": 31.99104716376097,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.109165435004698
  },
  {
    "Model Name": "DreadPoor/Rusted_Gold-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5831037946767536,
    "Overall Score": 29.31884390292816,
    "MMLU Score": 30.888002364066192,
    "BBH Score": 34.12086145705898,
    "Math Score": 19.335347432024168,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 50.28066044259102
  },
  {
    "Model Name": "DreadPoor/Rusted_Platinum-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6016343137475283,
    "Overall Score": 27.83034980109748,
    "MMLU Score": 30.33392434988179,
    "BBH Score": 34.78573450204923,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 46.257916420598804
  },
  {
    "Model Name": "DreadPoor/Rusted_Platinum-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6156083073986824,
    "Overall Score": 20.303818181145747,
    "MMLU Score": 28.29307033096927,
    "BBH Score": 32.36931288487491,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 32.98171570643948
  },
  {
    "Model Name": "DreadPoor/Sellen-8B-model_stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.614941045520685,
    "Overall Score": 26.387643367541383,
    "MMLU Score": 28.551640070921984,
    "BBH Score": 31.3609793143707,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.339694529860406
  },
  {
    "Model Name": "DreadPoor/Something-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5553240142927571,
    "Overall Score": 25.93310010934314,
    "MMLU Score": 32.06080082742317,
    "BBH Score": 34.539896807500135,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.673760496866976
  },
  {
    "Model Name": "DreadPoor/Spring_Dusk-8B-SCE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4256880940800347,
    "Overall Score": 26.661455778534272,
    "MMLU Score": 27.06486406619385,
    "BBH Score": 37.76481840522523,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.700763434331915
  },
  {
    "Model Name": "DreadPoor/Summer_Dawn-8B-SCE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.281365469197718,
    "Overall Score": 27.707526796543544,
    "MMLU Score": 30.59249408983452,
    "BBH Score": 34.62851818112923,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.623438014052024
  },
  {
    "Model Name": "DreadPoor/Summer_Dusk-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3505131314656516,
    "Overall Score": 25.70113735165475,
    "MMLU Score": 31.728354018912537,
    "BBH Score": 33.83081371910365,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.030646021014586
  },
  {
    "Model Name": "DreadPoor/Summer_Rain-8B-SCE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.417925622177407,
    "Overall Score": 25.516588284918253,
    "MMLU Score": 28.33924349881796,
    "BBH Score": 40.61854240395792,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.995717043136757
  },
  {
    "Model Name": "DreadPoor/Summer_Rain-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4687409513265564,
    "Overall Score": 25.49119270489429,
    "MMLU Score": 28.33924349881796,
    "BBH Score": 40.61854240395792,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.355812597089244
  },
  {
    "Model Name": "DreadPoor/Sun-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3758434175655363,
    "Overall Score": 30.08071455068633,
    "MMLU Score": 31.49748817966903,
    "BBH Score": 32.954595045665,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.86347237384917
  },
  {
    "Model Name": "DreadPoor/Sweetened_Condensed_Milk-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3313386343071156,
    "Overall Score": 29.56115847933121,
    "MMLU Score": 31.645242316784863,
    "BBH Score": 34.670888066076664,
    "Math Score": 18.731117824773413,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.204086712105426
  },
  {
    "Model Name": "DreadPoor/TEST02-Ignore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.445361409314325,
    "Overall Score": 24.97786899148115,
    "MMLU Score": 27.425014775413715,
    "BBH Score": 37.13218783602701,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.28140023008541
  },
  {
    "Model Name": "DreadPoor/TEST03-ignore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.905766682553736,
    "Overall Score": 28.440777656618568,
    "MMLU Score": 30.989583333333336,
    "BBH Score": 34.38735467240193,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.923535980022379
  },
  {
    "Model Name": "DreadPoor/TEST06-ignore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1041045761762494,
    "Overall Score": 27.721454908565875,
    "MMLU Score": 29.05954491725768,
    "BBH Score": 35.92411184894727,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.174941598645997
  },
  {
    "Model Name": "DreadPoor/TEST07-ignore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3740561440519077,
    "Overall Score": 29.498717642655507,
    "MMLU Score": 31.99615839243498,
    "BBH Score": 36.88142926288663,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.468349579710576
  },
  {
    "Model Name": "DreadPoor/TEST08-ignore",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.37025617734741,
    "Overall Score": 29.66477204531803,
    "MMLU Score": 31.700650118203303,
    "BBH Score": 35.35061865878467,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.649070105083663
  },
  {
    "Model Name": "DreadPoor/Trinas_Nectar-8B-model_stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.733447793388806,
    "Overall Score": 27.522454161375844,
    "MMLU Score": 29.08724881796691,
    "BBH Score": 31.97509368554489,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.877290487976444
  },
  {
    "Model Name": "DreadPoor/UNTESTED-VENN_1.2-8B-Model_Stock",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2984347569797885,
    "Overall Score": 25.47474271610336,
    "MMLU Score": 30.961879432624112,
    "BBH Score": 35.427098756489926,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.619578557307445
  },
  {
    "Model Name": "DreadPoor/VENN_1.2-8B-Model_Stock",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2817874457469578,
    "Overall Score": 28.85327338885053,
    "MMLU Score": 30.23234338061465,
    "BBH Score": 35.12536864211717,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.51018566657623
  },
  {
    "Model Name": "DreadPoor/WIP-Acacia-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3259010853742466,
    "Overall Score": 26.72381960950896,
    "MMLU Score": 30.40780141843972,
    "BBH Score": 31.162352922428383,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.155213616079017
  },
  {
    "Model Name": "DreadPoor/WIP_Damascus-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6362246106711529,
    "Overall Score": 24.97055556390754,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 34.52230581565854,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.261080539342958
  },
  {
    "Model Name": "DreadPoor/Wannabe-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1807024438715077,
    "Overall Score": 29.111295234622,
    "MMLU Score": 31.451315011820324,
    "BBH Score": 34.278852846231906,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.65591172926385
  },
  {
    "Model Name": "DreadPoor/What_A_Thrill-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2363391557136492,
    "Overall Score": 28.00959961323061,
    "MMLU Score": 29.05954491725768,
    "BBH Score": 32.94877726470522,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.65527180287572
  },
  {
    "Model Name": "DreadPoor/Winter-8B-SCE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3285695722275177,
    "Overall Score": 29.224572446583664,
    "MMLU Score": 31.543661347517727,
    "BBH Score": 32.53825480363242,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.997020748853153
  },
  {
    "Model Name": "DreadPoor/Winter_Dawn-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4492919129493278,
    "Overall Score": 26.79784991005577,
    "MMLU Score": 32.337839834515364,
    "BBH Score": 33.71410059102799,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.490305279853388
  },
  {
    "Model Name": "DreadPoor/Winter_Dusk-8B-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3938008057333435,
    "Overall Score": 24.11123263157222,
    "MMLU Score": 27.53583037825059,
    "BBH Score": 28.22781538216536,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.2989085186288
  },
  {
    "Model Name": "DreadPoor/Winter_Night-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6128445606478136,
    "Overall Score": 27.21635948101721,
    "MMLU Score": 29.622857565011817,
    "BBH Score": 31.604274148057367,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.40988992746853
  },
  {
    "Model Name": "DreadPoor/Yafune-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8160167821079294,
    "Overall Score": 30.104766282389747,
    "MMLU Score": 31.672946217494097,
    "BBH Score": 35.2912300982616,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.892337195104375
  },
  {
    "Model Name": "DreadPoor/Yearn_V3-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3757086381451888,
    "Overall Score": 28.95670005151148,
    "MMLU Score": 31.128102836879428,
    "BBH Score": 33.41239643429133,
    "Math Score": 18.95770392749245,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.04857035029787
  },
  {
    "Model Name": "DreadPoor/ZEUS-8B-V17-Abliterated_ALT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3636809735215685,
    "Overall Score": 26.25054546511405,
    "MMLU Score": 32.116208628841605,
    "BBH Score": 32.2576119397764,
    "Math Score": 19.033232628398792,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.24977027238612
  },
  {
    "Model Name": "DreadPoor/Zelus-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3257089020449857,
    "Overall Score": 29.7413869053032,
    "MMLU Score": 31.57136524822695,
    "BBH Score": 33.05816146454601,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.43432691703686
  },
  {
    "Model Name": "DreadPoor/Zelus_V2-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3413598010523688,
    "Overall Score": 30.16449183127745,
    "MMLU Score": 31.47901891252955,
    "BBH Score": 33.66407644966964,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.487994502005936
  },
  {
    "Model Name": "DreadPoor/felix_dies-mistral-7B-model_stock",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3231433347271495,
    "Overall Score": 18.13959245219531,
    "MMLU Score": 23.43565307328605,
    "BBH Score": 28.890798050964488,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.70946894119823
  },
  {
    "Model Name": "DreadPoor/hakuchido-8B-MODEL_STOCK",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6512636744112785,
    "Overall Score": 29.346239826870143,
    "MMLU Score": 30.906471631205672,
    "BBH Score": 34.575610505807134,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.060458582152926
  },
  {
    "Model Name": "DreadPoor/ichor-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8754344347697692,
    "Overall Score": 23.325804130424327,
    "MMLU Score": 23.89738475177305,
    "BBH Score": 29.92236880007357,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.644832787002247
  },
  {
    "Model Name": "DreadPoor/ichor_1.1-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6235860749127251,
    "Overall Score": 30.01706630636859,
    "MMLU Score": 31.728354018912537,
    "BBH Score": 32.6207492618971,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.136203667744944
  },
  {
    "Model Name": "DreadPoor/inexpertus-8B-Model_Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.665457340724185,
    "Overall Score": 29.70787002354444,
    "MMLU Score": 31.00805260047281,
    "BBH Score": 32.4633736795138,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.64278655520548
  },
  {
    "Model Name": "DreadPoor/inexpertus_1.1-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6597645235646241,
    "Overall Score": 29.60954761227837,
    "MMLU Score": 31.414376477541367,
    "BBH Score": 36.1991911954092,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.87896295530068
  },
  {
    "Model Name": "DreadPoor/inexpertus_1.2-8B-LINEAR",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6493941807487916,
    "Overall Score": 28.786491464394853,
    "MMLU Score": 30.98034869976359,
    "BBH Score": 36.05652346278443,
    "Math Score": 15.861027190332324,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.3282251639555
  },
  {
    "Model Name": "DreadPoor/mergekit-nuslerp-nqzkedi",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4374317529670209,
    "Overall Score": 30.29630220229005,
    "MMLU Score": 32.430186170212764,
    "BBH Score": 34.09522783768477,
    "Math Score": 18.80664652567976,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.07668912959177
  },
  {
    "Model Name": "DreadPoor/remember_to_breathe-8b-Model-Stock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3270803241537383,
    "Overall Score": 28.25652417725776,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 34.67899076231628,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.29224860241717
  },
  {
    "Model Name": "DreadPoor/test",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.207847051540963,
    "Overall Score": 24.9529907016386,
    "MMLU Score": 29.4104609929078,
    "BBH Score": 34.28751436834826,
    "Math Score": 19.335347432024168,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.301956213055023
  },
  {
    "Model Name": "DreadPoor/test_ALT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5629934211563457,
    "Overall Score": 24.26567020016676,
    "MMLU Score": 27.692819148936167,
    "BBH Score": 33.986912493518574,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.52512625562707
  },
  {
    "Model Name": "DreadPoor/tests_pending-do_not_use_yet",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2634870441411763,
    "Overall Score": 29.64145994849537,
    "MMLU Score": 31.414376477541367,
    "BBH Score": 34.6745089445582,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.46004265413217
  },
  {
    "Model Name": "ECE-ILAB-PRYMMAL/ILAB-Merging-3B-V2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4245496438848985,
    "Overall Score": 24.06556562824206,
    "MMLU Score": 31.783761820330973,
    "BBH Score": 36.00403694105599,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 56.684927133672446
  },
  {
    "Model Name": "EVA-UNIT-01/EVA-Qwen2.5-14B-v0.2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.665346050968798,
    "Overall Score": 33.81260628765727,
    "MMLU Score": 45.94968971631205,
    "BBH Score": 43.60784925797068,
    "Math Score": 34.06344410876133,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.247609484538837
  },
  {
    "Model Name": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 45.910196932620046,
    "Overall Score": 44.22159602545703,
    "MMLU Score": 53.47591607565011,
    "BBH Score": 59.0667326828602,
    "Math Score": 43.126888217522655,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.9632194802030302
  },
  {
    "Model Name": "Edgerunners/meta-llama-3-8b-instruct-hf-ortho-baukit-34fail-3000total-bf16",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.311560065165848,
    "Overall Score": 23.44886681186292,
    "MMLU Score": 29.290410756501185,
    "BBH Score": 28.25639185977421,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.878606885531994
  },
  {
    "Model Name": "EleutherAI/gpt-j-6b",
    "Parameters (B)": 6.0,
    "Architecture": "GPTJForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5348643127710762,
    "Overall Score": 6.570411768928537,
    "MMLU Score": 2.6761968085106376,
    "BBH Score": 4.912818068323685,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-08-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.280776948332441
  },
  {
    "Model Name": "EleutherAI/gpt-neo-1.3B",
    "Parameters (B)": 1.366,
    "Architecture": "GPTNeoForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7188481230380952,
    "Overall Score": 5.391090848825532,
    "MMLU Score": 1.8173758865248213,
    "BBH Score": 3.024569180930987,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.499624296215672
  },
  {
    "Model Name": "EleutherAI/gpt-neo-125m",
    "Parameters (B)": 0.15,
    "Architecture": "GPTNeoForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4058049731865188,
    "Overall Score": 4.407321907614049,
    "MMLU Score": 0.2844267139479898,
    "BBH Score": 3.436738951426704,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.860689737255454
  },
  {
    "Model Name": "EleutherAI/gpt-neo-2.7B",
    "Parameters (B)": 2.718,
    "Architecture": "GPTNeoForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.0167628032465814,
    "Overall Score": 6.431047800987447,
    "MMLU Score": 1.8081412529550824,
    "BBH Score": 4.178602667081014,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.325022690103086
  },
  {
    "Model Name": "EleutherAI/gpt-neox-20b",
    "Parameters (B)": 20.739,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 6.293472747230082,
    "Overall Score": 6.1165221524743325,
    "MMLU Score": 1.725029550827422,
    "BBH Score": 4.929114201526899,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.9718834732646408
  },
  {
    "Model Name": "EleutherAI/pythia-1.4b",
    "Parameters (B)": 1.515,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3872326488039495,
    "Overall Score": 6.008531439497028,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 3.878989478987103,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.516593081847972
  },
  {
    "Model Name": "EleutherAI/pythia-12b",
    "Parameters (B)": 12.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.2360143063327462,
    "Overall Score": 6.059841492942702,
    "MMLU Score": 1.2078900709219855,
    "BBH Score": 4.987531038290507,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.7101085515330885
  },
  {
    "Model Name": "EleutherAI/pythia-160m",
    "Parameters (B)": 0.213,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4706770826081154,
    "Overall Score": 5.730394616916023,
    "MMLU Score": 1.3279403073286051,
    "BBH Score": 2.198832279508135,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.174789954001511
  },
  {
    "Model Name": "EleutherAI/pythia-1b",
    "Parameters (B)": 1.079,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3122948049784091,
    "Overall Score": 5.07026822083096,
    "MMLU Score": 1.512632978723403,
    "BBH Score": 2.2939863995762866,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.23551893916871
  },
  {
    "Model Name": "EleutherAI/pythia-2.8b",
    "Parameters (B)": 2.909,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.507804003243129,
    "Overall Score": 5.554946281603011,
    "MMLU Score": 1.521867612293143,
    "BBH Score": 5.077786161905462,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.6841302116554284
  },
  {
    "Model Name": "EleutherAI/pythia-410m",
    "Parameters (B)": 0.506,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7541636544345159,
    "Overall Score": 5.227072311484412,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 2.715428120335748,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.930952294968066
  },
  {
    "Model Name": "EleutherAI/pythia-6.9b",
    "Parameters (B)": 6.9,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.7377338289158395,
    "Overall Score": 5.966546774741993,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 5.88163197981621,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.433521679476357
  },
  {
    "Model Name": "Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.018255930617328,
    "Overall Score": 15.68446940398294,
    "MMLU Score": 18.162677304964536,
    "BBH Score": 16.875928374989595,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.771298558347603
  },
  {
    "Model Name": "Enno-Ai/EnnoAi-Pro-Llama-3-8B",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.368674679609323,
    "Overall Score": 12.51454591188142,
    "MMLU Score": 12.788120567375886,
    "BBH Score": 17.507545086854382,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-07-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.28335360681337
  },
  {
    "Model Name": "Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.941671164165739,
    "Overall Score": 18.128287498482543,
    "MMLU Score": 22.11510047281324,
    "BBH Score": 16.668385554519382,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.162581229103404
  },
  {
    "Model Name": "Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8651424904010885,
    "Overall Score": 15.575099921155848,
    "MMLU Score": 17.728649527186757,
    "BBH Score": 17.49829637438283,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.350622004116431
  },
  {
    "Model Name": "EnnoAi/EnnoAi-7B-French-Instruct-202502",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6896437531248036,
    "Overall Score": 31.28743755248046,
    "MMLU Score": 33.48293439716312,
    "BBH Score": 36.92413092542704,
    "Math Score": 37.235649546827794,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.36753564534706
  },
  {
    "Model Name": "EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.89128318456398,
    "Overall Score": 15.600495501179813,
    "MMLU Score": 17.728649527186757,
    "BBH Score": 17.49829637438283,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.248630151479077
  },
  {
    "Model Name": "Epiculous/Azure_Dusk-v0.2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.98282278279691,
    "Overall Score": 14.239648971826766,
    "MMLU Score": 22.604536052009458,
    "BBH Score": 17.396414392379338,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.575265521060184
  },
  {
    "Model Name": "Epiculous/Crimson_Dawn-v0.2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.253400057014685,
    "Overall Score": 15.085950749805088,
    "MMLU Score": 19.123079196217496,
    "BBH Score": 21.68824851395527,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.8716546590928926
  },
  {
    "Model Name": "Epiculous/NovaSpark",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6363700494168842,
    "Overall Score": 25.253737990368,
    "MMLU Score": 29.42893026004728,
    "BBH Score": 29.52691068844395,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.43277940058063
  },
  {
    "Model Name": "Epiculous/Violet_Twilight-v0.2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7704359904032256,
    "Overall Score": 18.55277348742638,
    "MMLU Score": 23.45412234042553,
    "BBH Score": 23.94053725590186,
    "Math Score": 2.870090634441088,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.479211667630464
  },
  {
    "Model Name": "EpistemeAI/Alpaca-Llama3.1-8B",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8417051746542896,
    "Overall Score": 13.985046352420849,
    "MMLU Score": 24.959367612293143,
    "BBH Score": 25.93522655511771,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-08-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.593531551566613
  },
  {
    "Model Name": "EpistemeAI/Athena-gemma-2-2b-it",
    "Parameters (B)": 2.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.0277164101834417,
    "Overall Score": 14.54609172912029,
    "MMLU Score": 15.79861111111111,
    "BBH Score": 19.41781767446152,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.804311156816361
  },
  {
    "Model Name": "EpistemeAI/Athena-gemma-2-2b-it-Philos",
    "Parameters (B)": 2.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2571856348609125,
    "Overall Score": 15.663946300399497,
    "MMLU Score": 13.86857269503546,
    "BBH Score": 13.212088152695856,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.9395915242765165
  },
  {
    "Model Name": "EpistemeAI/Athene-codegemma-2-7b-it-alpaca-v1.3",
    "Parameters (B)": 7.0,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9439560175879884,
    "Overall Score": 17.314021588433324,
    "MMLU Score": 17.636303191489358,
    "BBH Score": 20.87379456667128,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.906591214916542
  },
  {
    "Model Name": "EpistemeAI/DeepPhi-3.5-mini-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.423737744033451,
    "Overall Score": 3.46432918593773,
    "MMLU Score": 1.1432476359338055,
    "BBH Score": 1.667358455856632,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.175644569590776
  },
  {
    "Model Name": "EpistemeAI/DeepThinkers-Phi4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9143025960276636,
    "Overall Score": 39.40710857221479,
    "MMLU Score": 47.30718085106383,
    "BBH Score": 53.786668719353166,
    "Math Score": 45.84592145015105,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.10072917152963
  },
  {
    "Model Name": "EpistemeAI/FineLlama3.1-8B-Instruct",
    "Parameters (B)": 14.483,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.709921965614319,
    "Overall Score": 11.239255981586004,
    "MMLU Score": 23.47259160756501,
    "BBH Score": 23.506618815003453,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.3862934595605467
  },
  {
    "Model Name": "EpistemeAI/Fireball-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2370416419749457,
    "Overall Score": 15.534531353358348,
    "MMLU Score": 26.03981973995272,
    "BBH Score": 30.66671150263205,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.798990273069395
  },
  {
    "Model Name": "EpistemeAI/Fireball-12B-v1.13a-philosophers",
    "Parameters (B)": 12.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.325326791263037,
    "Overall Score": 14.466040850876617,
    "MMLU Score": 26.29838947990544,
    "BBH Score": 30.33623264030357,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.3502614205872
  },
  {
    "Model Name": "EpistemeAI/Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8447622495689264,
    "Overall Score": 21.12991448262953,
    "MMLU Score": 28.69939420803782,
    "BBH Score": 26.377774027551386,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.45400416100614
  },
  {
    "Model Name": "EpistemeAI/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.771289856542313,
    "Overall Score": 25.242227896928764,
    "MMLU Score": 28.25613179669031,
    "BBH Score": 26.897964171299805,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.25076071185968
  },
  {
    "Model Name": "EpistemeAI/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6234862691629817,
    "Overall Score": 22.550476627240737,
    "MMLU Score": 26.13216607565012,
    "BBH Score": 28.24700927539328,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.890155436218782
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-0.001-128K-auto",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3899885588128729,
    "Overall Score": 21.567361907712467,
    "MMLU Score": 27.95138888888889,
    "BBH Score": 26.832966985874886,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.51621541844358
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6295729321675876,
    "Overall Score": 20.62716790652169,
    "MMLU Score": 28.25613179669031,
    "BBH Score": 28.02516078188715,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.658020699376936
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.708635561809437,
    "Overall Score": 23.934713958118284,
    "MMLU Score": 26.917109929078016,
    "BBH Score": 28.17188778217276,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.00808603841274
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.593826046770673,
    "Overall Score": 23.14416546279052,
    "MMLU Score": 26.547724586288417,
    "BBH Score": 24.46265416899608,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-10-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.922790135292662
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2853056830713743,
    "Overall Score": 23.74994070118673,
    "MMLU Score": 27.554299645390067,
    "BBH Score": 24.58673708035273,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.392456850353431
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3441355413277185,
    "Overall Score": 23.627287074905905,
    "MMLU Score": 26.150635342789595,
    "BBH Score": 23.544253406580115,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.578053959920737
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.678073131069293,
    "Overall Score": 20.857427405175983,
    "MMLU Score": 27.45271867612293,
    "BBH Score": 25.82086537586569,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.429391198156736
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-ds-auto",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4902619095486798,
    "Overall Score": 23.874258540372427,
    "MMLU Score": 28.311539598108748,
    "BBH Score": 26.45205960447092,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.02017631088931
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Math",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.820543196181828,
    "Overall Score": 20.55792899003061,
    "MMLU Score": 25.901300236406616,
    "BBH Score": 28.95934409387967,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.29219511690036
  },
  {
    "Model Name": "EpistemeAI/Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.667151564837414,
    "Overall Score": 21.29356141520376,
    "MMLU Score": 28.00679669030733,
    "BBH Score": 26.31787775764873,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.772420855017089
  },
  {
    "Model Name": "EpistemeAI/Fireball-Mistral-Nemo-Base-2407-v1-DPO2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.5425381988690936,
    "Overall Score": 15.339340300308171,
    "MMLU Score": 26.14140070921986,
    "BBH Score": 28.56782489270228,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-08-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.330042314068778
  },
  {
    "Model Name": "EpistemeAI/Fireball-R1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7517107170434107,
    "Overall Score": 14.729862999540122,
    "MMLU Score": 1.2817671394799046,
    "BBH Score": 10.273656027098816,
    "Math Score": 31.1178247734139,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.595121721125448
  },
  {
    "Model Name": "EpistemeAI/Fireball-R1-Llama-3.1-8B-Medical-COT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.747615825519124,
    "Overall Score": 14.486213316641551,
    "MMLU Score": 4.467715721040189,
    "BBH Score": 12.153438929855737,
    "Math Score": 32.703927492447136,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.376547181278195
  },
  {
    "Model Name": "EpistemeAI/Fireball-R1.1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8073899540313522,
    "Overall Score": 10.130881566678475,
    "MMLU Score": 1.2817671394799046,
    "BBH Score": 6.28685605104149,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.547693361917998
  },
  {
    "Model Name": "EpistemeAI/Llama-3.2-3B-Agent007-Coder",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4216313423297888,
    "Overall Score": 18.91456180890705,
    "MMLU Score": 20.572916666666664,
    "BBH Score": 19.02580948500905,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.30482892837014
  },
  {
    "Model Name": "EpistemeAI/Mistral-Nemo-Instruct-12B-Philosophy-Math",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7272149280286,
    "Overall Score": 16.60399677564458,
    "MMLU Score": 25.513445626477537,
    "BBH Score": 33.835810999564586,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.088261179930903
  },
  {
    "Model Name": "EpistemeAI/OpenReasoner-Llama-3.2-3B-rs1.0",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5924359491094815,
    "Overall Score": 22.93957882205128,
    "MMLU Score": 23.712692080378247,
    "BBH Score": 22.80780815942809,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2025-02-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.720774552139936
  },
  {
    "Model Name": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-Empathy",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3356626948818016,
    "Overall Score": 23.321646038971995,
    "MMLU Score": 25.67966903073286,
    "BBH Score": 24.419414132832703,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.460730263965203
  },
  {
    "Model Name": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-Logic",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.368995863321704,
    "Overall Score": 23.204900560269166,
    "MMLU Score": 26.11369680851064,
    "BBH Score": 23.576450573055748,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.950307288705215
  },
  {
    "Model Name": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-divergent",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3958844451637349,
    "Overall Score": 23.02725584049078,
    "MMLU Score": 25.44880319148936,
    "BBH Score": 22.89036811976203,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.496534451882745
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.1-CoT-RE1-NMT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.447840402014464,
    "Overall Score": 19.208175433660585,
    "MMLU Score": 26.03058510638298,
    "BBH Score": 25.54405444475448,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.266776784882603
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.1-CoT-RE1-NMT-V2-ORPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4427844314051856,
    "Overall Score": 21.331579969605,
    "MMLU Score": 28.865617612293136,
    "BBH Score": 25.89560083857891,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.785008422103166
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.2-1B-Instruct-v1.2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9031677511029814,
    "Overall Score": 9.508931658156024,
    "MMLU Score": 1.9835992907801416,
    "BBH Score": 6.5772148357059725,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.528422484686118
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.2-1B-Instruct-v1.3",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7538632079758366,
    "Overall Score": 8.170098865797046,
    "MMLU Score": 1.9189568557919607,
    "BBH Score": 6.111150533529301,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.837641072488736
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.2-3B-Math-Instruct-RE1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2263268803331018,
    "Overall Score": 17.78003203358188,
    "MMLU Score": 19.880319148936167,
    "BBH Score": 20.728881523559497,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.498607442048703
  },
  {
    "Model Name": "EpistemeAI/Reasoning-Llama-3.2-3B-Math-Instruct-RE1-ORPO",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3505097740284058,
    "Overall Score": 23.430640115437427,
    "MMLU Score": 23.33407210401891,
    "BBH Score": 23.00465031166173,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.349478371820062
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-1.0-3B-Instruct-r01-Reflect-Math",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5962760270217874,
    "Overall Score": 19.475016650589627,
    "MMLU Score": 20.258939125295505,
    "BBH Score": 19.82126931574648,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 32.66107602524498
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-0",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5853917932437854,
    "Overall Score": 23.526303672038257,
    "MMLU Score": 24.137485224586285,
    "BBH Score": 22.166822802153792,
    "Math Score": 15.861027190332324,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.188987860034395
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-Instruct-r01-Reflect",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5679692340468294,
    "Overall Score": 23.51162994918955,
    "MMLU Score": 23.823507683215126,
    "BBH Score": 22.265678862081568,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.39595692827792
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-R01",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6070635739248887,
    "Overall Score": 14.035244688635869,
    "MMLU Score": 17.682476359338057,
    "BBH Score": 20.62436739279366,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.119892695740024
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-RE1-V2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5824159628332604,
    "Overall Score": 23.57087320558054,
    "MMLU Score": 24.229831560283685,
    "BBH Score": 22.47288380169552,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.4708571017114
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-RE1-V2A",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5854265795489074,
    "Overall Score": 18.398292233746385,
    "MMLU Score": 19.28930260047281,
    "BBH Score": 18.05942921696145,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.427155644219198
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-RE1-V2B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6061262394745162,
    "Overall Score": 16.80359555586663,
    "MMLU Score": 18.58747044917257,
    "BBH Score": 17.62918970867094,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.722930408745512
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-RE1-V2C",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5980412814196955,
    "Overall Score": 16.648061999116766,
    "MMLU Score": 18.790632387706854,
    "BBH Score": 17.793270992983555,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.837646858751597
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-T1-V1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5761983025195495,
    "Overall Score": 23.243643018070443,
    "MMLU Score": 23.55570330969267,
    "BBH Score": 23.06533291680579,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.33965896191064
  },
  {
    "Model Name": "EpistemeAI/ReasoningCore-3B-T1_1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1654658615572893,
    "Overall Score": 23.49247452002092,
    "MMLU Score": 23.51876477541371,
    "BBH Score": 23.09499879387329,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.157153714164053
  },
  {
    "Model Name": "EpistemeAI2/Athene-codegemma-2-7b-it-alpaca-v1.2",
    "Parameters (B)": 7.0,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.939269685082392,
    "Overall Score": 15.718390848250491,
    "MMLU Score": 14.413416075650115,
    "BBH Score": 18.971369774912947,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.10531457752493
  },
  {
    "Model Name": "EpistemeAI2/Fireball-12B-v1.2",
    "Parameters (B)": 12.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.745129376454524,
    "Overall Score": 15.200286583835773,
    "MMLU Score": 25.965942671394792,
    "BBH Score": 29.776014226579218,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.058681304683185
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1-8B-Philos",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6966642760929416,
    "Overall Score": 22.551673578610224,
    "MMLU Score": 26.73241725768321,
    "BBH Score": 29.259226071264724,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.291771328233509
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.01-8B-Philos",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7411433753603245,
    "Overall Score": 21.567143968773337,
    "MMLU Score": 26.48308215130024,
    "BBH Score": 28.628475325906475,
    "Math Score": 13.595166163141997,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.38677082770974
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.03-8B-Philos",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5950461475759945,
    "Overall Score": 20.274573357917856,
    "MMLU Score": 26.16910460992908,
    "BBH Score": 27.99254879661235,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.710963497030667
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.04-8B-Philos",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5304958366458974,
    "Overall Score": 21.094517497325704,
    "MMLU Score": 26.695478723404253,
    "BBH Score": 27.963797525362725,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.782799660242544
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8695479199902147,
    "Overall Score": 21.86763175289908,
    "MMLU Score": 29.050310283687946,
    "BBH Score": 27.207176615070413,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.6967484593888
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8040592656869945,
    "Overall Score": 21.97087003498899,
    "MMLU Score": 28.117612293144205,
    "BBH Score": 26.901201452028392,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-09-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.178574425393046
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7679480184248195,
    "Overall Score": 20.89462493481088,
    "MMLU Score": 28.8102098108747,
    "BBH Score": 27.571611204577167,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.818574255043577
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8195181295523024,
    "Overall Score": 22.51118824548196,
    "MMLU Score": 28.034500591016545,
    "BBH Score": 26.76368521382555,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.372060426251924
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Llama-3.1-8B-Philos-Reflection",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.78988673075239,
    "Overall Score": 20.37672090429901,
    "MMLU Score": 28.33924349881796,
    "BBH Score": 27.76979570236311,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.384363353391379
  },
  {
    "Model Name": "EpistemeAI2/Fireball-MathMistral-Nemo-Base-2407-v2dpo",
    "Parameters (B)": 11.58,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.762851272980899,
    "Overall Score": 11.369982746356044,
    "MMLU Score": 1.6419178486997636,
    "BBH Score": 21.145528378150857,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.0216402194787886
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-math",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5833654691318215,
    "Overall Score": 22.72795730229104,
    "MMLU Score": 26.8894060283688,
    "BBH Score": 26.74376716558517,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.354208011592581
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6016352294968983,
    "Overall Score": 21.037758831912942,
    "MMLU Score": 28.496232269503547,
    "BBH Score": 26.400991557555106,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.135174879064861
  },
  {
    "Model Name": "EpistemeAI2/Fireball-Phi-3-medium-4k-inst-Philos",
    "Parameters (B)": 13.96,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5436275349185773,
    "Overall Score": 29.67636693004503,
    "MMLU Score": 39.984116430260045,
    "BBH Score": 46.20887281141656,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.225082643793595
  },
  {
    "Model Name": "Eric111/CatunaMayo",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.101649256054395,
    "Overall Score": 21.27397881040676,
    "MMLU Score": 24.202127659574465,
    "BBH Score": 33.299425909067885,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 19.31102725617085
  },
  {
    "Model Name": "Eric111/CatunaMayo-DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1080452807347074,
    "Overall Score": 21.292884967568227,
    "MMLU Score": 24.109781323877066,
    "BBH Score": 33.08995159999345,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.216619878069995
  },
  {
    "Model Name": "Etherll/Chocolatine-3B-Instruct-DPO-Revised-Ties",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2709938613196208,
    "Overall Score": 24.98182072995224,
    "MMLU Score": 33.08584515366431,
    "BBH Score": 35.58334267696659,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 19.655343342110747
  },
  {
    "Model Name": "Etherll/Chocolatine-3B-Instruct-DPO-Revised-Ties-v2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2625910778696097,
    "Overall Score": 25.0072163099762,
    "MMLU Score": 33.08584515366431,
    "BBH Score": 35.58334267696659,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 19.80626724542619
  },
  {
    "Model Name": "Etherll/Herplete-LLM-Llama-3.1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9736847295609784,
    "Overall Score": 19.58870802333299,
    "MMLU Score": 27.57276891252955,
    "BBH Score": 28.952590926070883,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 20.118121840285287
  },
  {
    "Model Name": "Etherll/Herplete-LLM-Llama-3.1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.709613282616363,
    "Overall Score": 26.260139418825688,
    "MMLU Score": 30.583259456264773,
    "BBH Score": 33.206608363709044,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.360280413028622
  },
  {
    "Model Name": "Etherll/Herplete-LLM-Llama-3.1-8b-Ties",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7244029419033515,
    "Overall Score": 26.53329128692283,
    "MMLU Score": 30.583259456264773,
    "BBH Score": 33.07089034564546,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.386943876143047
  },
  {
    "Model Name": "Etherll/Qwen2.5-7B-della-test",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.084641406728251,
    "Overall Score": 35.81656745139639,
    "MMLU Score": 37.34301122931442,
    "BBH Score": 35.54689390845198,
    "Math Score": 48.94259818731118,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.181164748909428
  },
  {
    "Model Name": "Etherll/Qwen2.5-Coder-7B-Instruct-Ties",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.394362523519261,
    "Overall Score": 26.513720070911543,
    "MMLU Score": 27.812869385342783,
    "BBH Score": 28.008294264156472,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.073394195938791
  },
  {
    "Model Name": "Etherll/Replete-LLM-V3-Llama-3.1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5786586422846098,
    "Overall Score": 21.70431724543067,
    "MMLU Score": 27.44348404255319,
    "BBH Score": 22.902455222412783,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.748581652852149
  },
  {
    "Model Name": "Etherll/SuperHermes",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.500030829605098,
    "Overall Score": 26.91930524281158,
    "MMLU Score": 32.7626329787234,
    "BBH Score": 32.84031674117277,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.94583465321071
  },
  {
    "Model Name": "Eurdem/Defne-llama3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6645961851911526,
    "Overall Score": 25.12060541103021,
    "MMLU Score": 31.839169621749413,
    "BBH Score": 32.822381370434904,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2024-08-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.427546864564812
  },
  {
    "Model Name": "FINGU-AI/Chocolatine-Fusion-14B",
    "Parameters (B)": 8.367,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.778182731900417,
    "Overall Score": 40.36155927006158,
    "MMLU Score": 47.35335401891253,
    "BBH Score": 48.600901490542746,
    "Math Score": 38.51963746223565,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.682797030772468
  },
  {
    "Model Name": "FINGU-AI/L3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4241896674664711,
    "Overall Score": 28.91453457774598,
    "MMLU Score": 29.32734929078014,
    "BBH Score": 28.805821240438444,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.302446533812322
  },
  {
    "Model Name": "FINGU-AI/Phi-4-RRStock",
    "Parameters (B)": 6.652,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.73031594302183,
    "Overall Score": 26.41539412271864,
    "MMLU Score": 43.14236111111111,
    "BBH Score": 48.68220452265962,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.674848872428623
  },
  {
    "Model Name": "FINGU-AI/Q-Small-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4546580986103823,
    "Overall Score": 16.89041454501282,
    "MMLU Score": 19.889553782505907,
    "BBH Score": 21.386476977673595,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.611260791211373
  },
  {
    "Model Name": "FINGU-AI/QwQ-Buddy-32B-Alpha",
    "Parameters (B)": 19.662,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 11.118192684812248,
    "Overall Score": 35.1782720586928,
    "MMLU Score": 47.71350472813239,
    "BBH Score": 48.730953196766194,
    "Math Score": 38.51963746223565,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.1640279185615543
  },
  {
    "Model Name": "FINGU-AI/RomboUltima-32B",
    "Parameters (B)": 17.645,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.804714974681665,
    "Overall Score": 44.731545333278405,
    "MMLU Score": 53.20811170212767,
    "BBH Score": 56.67376969863417,
    "Math Score": 53.85196374622356,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.731348995880903
  },
  {
    "Model Name": "FINGU-AI/Ultimos-32B",
    "Parameters (B)": 9.604,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.703313123882228,
    "Overall Score": 3.640726542069556,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 2.277935201319207,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.137438202655031
  },
  {
    "Model Name": "FallenMerick/Chewy-Lemon-Cookie-11B",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.714547555272019,
    "Overall Score": 22.0437256537836,
    "MMLU Score": 25.19023345153664,
    "BBH Score": 33.01430008846961,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.85687619803948
  },
  {
    "Model Name": "Felladrin/Llama-160M-Chat-v1",
    "Parameters (B)": 0.162,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.3631612182790685,
    "Overall Score": 4.201766115349323,
    "MMLU Score": 1.512632978723403,
    "BBH Score": 3.166755569392556,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.569974721586345
  },
  {
    "Model Name": "Felladrin/Minueza-32M-UltraChat",
    "Parameters (B)": 0.033,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.3361337790341132,
    "Overall Score": 3.924255988180698,
    "MMLU Score": 1.4756944444444438,
    "BBH Score": 2.4372895622895623,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.674685000291023
  },
  {
    "Model Name": "FlofloB/100k_fineweb_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.967387192446507,
    "Overall Score": 8.550830451075553,
    "MMLU Score": 5.529698581560284,
    "BBH Score": 7.347825006715015,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.839098261628457
  },
  {
    "Model Name": "FlofloB/10k_continued_pretraining_Phi-3-mini-4k-instruct_Unsloth_merged_16bit",
    "Parameters (B)": 16.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9750895997519636,
    "Overall Score": 24.04356389387962,
    "MMLU Score": 30.76795212765957,
    "BBH Score": 32.60779983085876,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.657799549903572
  },
  {
    "Model Name": "FlofloB/10k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.0167301564092104,
    "Overall Score": 8.363924265648496,
    "MMLU Score": 6.009899527186761,
    "BBH Score": 7.530228683558659,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.226297029673436
  },
  {
    "Model Name": "FlofloB/40k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9631341659191968,
    "Overall Score": 8.381580312764262,
    "MMLU Score": 5.391179078014184,
    "BBH Score": 7.532089563374818,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.702401606493778
  },
  {
    "Model Name": "FlofloB/83k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9843727823413428,
    "Overall Score": 8.427461121141809,
    "MMLU Score": 6.166888297872341,
    "BBH Score": 8.132273330945772,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.561249632580239
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1000k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6758171455944094,
    "Overall Score": 4.20780841481479,
    "MMLU Score": 1.8173758865248213,
    "BBH Score": 2.708743994249611,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.226252829252869
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1000k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6782092114841033,
    "Overall Score": 4.06134991308063,
    "MMLU Score": 1.5865100472813234,
    "BBH Score": 3.2742669103063946,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.988343779927892
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1000k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.669616488744322,
    "Overall Score": 5.055842764583344,
    "MMLU Score": 1.7434988179669018,
    "BBH Score": 2.113413506540018,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.550355837360218
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1200k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6707608185610174,
    "Overall Score": 4.188312239003598,
    "MMLU Score": 0.8477393617021267,
    "BBH Score": 2.2372961213751537,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.244121783959863
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1200k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6721534238637444,
    "Overall Score": 4.280291147523802,
    "MMLU Score": 1.549571513002364,
    "BBH Score": 2.849419191919192,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.36802699437187
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1200k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6705899568677858,
    "Overall Score": 4.03050468089069,
    "MMLU Score": 1.8266105200945613,
    "BBH Score": 2.206545314818884,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.010386286899535
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1400k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.688092511805587,
    "Overall Score": 4.992957353487976,
    "MMLU Score": 0.8846778959810875,
    "BBH Score": 2.1601002436397274,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.25622974792477
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1400k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6882452217267977,
    "Overall Score": 5.063032045008573,
    "MMLU Score": 1.1617169030732852,
    "BBH Score": 2.630029274903698,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.356436173004581
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_1400k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.675417141898889,
    "Overall Score": 4.624639622707802,
    "MMLU Score": 1.521867612293143,
    "BBH Score": 2.631616005839404,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.847086542260305
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_200k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6664092675100278,
    "Overall Score": 3.8819679158721776,
    "MMLU Score": 1.3279403073286051,
    "BBH Score": 2.8225402293478967,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.825200976536185
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_200k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6822896325237215,
    "Overall Score": 3.4920262751647098,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 2.3223515642593,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.118099570483069
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_400k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6912568660729026,
    "Overall Score": 4.224944649553536,
    "MMLU Score": 1.8081412529550824,
    "BBH Score": 1.889766073379756,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.111974950145316
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_400k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6793362286993389,
    "Overall Score": 4.710926533341115,
    "MMLU Score": 1.5311022458628842,
    "BBH Score": 3.575492461700485,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.934602240131786
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_400k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.671529895073909,
    "Overall Score": 4.38733089603933,
    "MMLU Score": 1.7527334515366433,
    "BBH Score": 2.073466032877798,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.533336681245528
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_600k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6741543448317168,
    "Overall Score": 4.886739290130319,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 3.4240529327139213,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.248695091255628
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_600k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6677341935122562,
    "Overall Score": 4.644401741390064,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 2.418749257278669,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.955464893838505
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_600k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6755758340530301,
    "Overall Score": 4.657606376854525,
    "MMLU Score": 1.798906619385342,
    "BBH Score": 2.165156425929996,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.894276174610652
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_800k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6726619081749295,
    "Overall Score": 4.17450578103981,
    "MMLU Score": 1.6880910165484628,
    "BBH Score": 2.348388410325006,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.205949423189585
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_800k_fineweb_uncovai_human_removed",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.668405275912299,
    "Overall Score": 5.03254333671229,
    "MMLU Score": 1.5311022458628842,
    "BBH Score": 3.210703163941808,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.529179553293361
  },
  {
    "Model Name": "FlofloB/smollm2-135M_pretrained_800k_fineweb_uncovai_selected",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6702372444523718,
    "Overall Score": 4.118739390912178,
    "MMLU Score": 1.4479905437352243,
    "BBH Score": 1.9228579509844617,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.145196234622056
  },
  {
    "Model Name": "FlofloB/smollm2_pretrained_200k_fineweb",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6594641244107149,
    "Overall Score": 4.00559929596115,
    "MMLU Score": 1.7712027186761226,
    "BBH Score": 2.872523000621309,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.074021539140556
  },
  {
    "Model Name": "FlofloB/test_continued_pretraining_Phi-3-mini-4k-instruct_Unsloth_merged_16bit",
    "Parameters (B)": 16.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.5153220268770875,
    "Overall Score": 24.48570245546706,
    "MMLU Score": 30.23234338061465,
    "BBH Score": 32.882433170322564,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.158745151965753
  },
  {
    "Model Name": "FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs",
    "Parameters (B)": 14.483,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.004096435504555,
    "Overall Score": 20.395988185954646,
    "MMLU Score": 21.736480496453904,
    "BBH Score": 26.59686097043189,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.177149075573158
  },
  {
    "Model Name": "FuJhen/mistral-instruct-7B-DPO",
    "Parameters (B)": 14.496,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.019293470108344,
    "Overall Score": 19.02953078213065,
    "MMLU Score": 22.59530141843972,
    "BBH Score": 24.92582719493644,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.42385594953151
  },
  {
    "Model Name": "FuJhen/mistral_7b_v0.1_structedData_e2e",
    "Parameters (B)": 7.0,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1604922772920125,
    "Overall Score": 10.909311048443838,
    "MMLU Score": 20.12041962174941,
    "BBH Score": 18.06242392393546,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.049456164739317
  },
  {
    "Model Name": "FuJhen/mistral_7b_v0.1_structedData_viggo",
    "Parameters (B)": 14.483,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1522273022121814,
    "Overall Score": 12.440582510781873,
    "MMLU Score": 21.57949172576832,
    "BBH Score": 23.960171694414896,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.780329288637281
  },
  {
    "Model Name": "FuseAI/FuseChat-7B-v2.0",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8866122219783815,
    "Overall Score": 20.14636743747765,
    "MMLU Score": 24.02666962174941,
    "BBH Score": 29.341638180782923,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.722862304473043
  },
  {
    "Model Name": "FuseAI/FuseChat-Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3404290644370094,
    "Overall Score": 28.59550964455965,
    "MMLU Score": 30.37086288416076,
    "BBH Score": 30.84806521622957,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.33310176810437
  },
  {
    "Model Name": "FuseAI/FuseChat-Llama-3.2-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5067297106978743,
    "Overall Score": 25.746913825686644,
    "MMLU Score": 23.684988179669027,
    "BBH Score": 24.2199004496583,
    "Math Score": 24.24471299093656,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 50.809955055186485
  },
  {
    "Model Name": "FuseAI/FuseChat-Qwen-2.5-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.309118142780276,
    "Overall Score": 31.40771569311038,
    "MMLU Score": 34.64649822695036,
    "BBH Score": 36.25134763068275,
    "Math Score": 45.61933534743202,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.99150593574952
  },
  {
    "Model Name": "GalrionSoftworks/MN-LooseCannon-12B-v1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.05803936508976,
    "Overall Score": 22.12442725339166,
    "MMLU Score": 24.396054964539008,
    "BBH Score": 29.97606209295129,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.234840566789845
  },
  {
    "Model Name": "GalrionSoftworks/MagnusIntellectus-12B-v1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.248527617657325,
    "Overall Score": 21.773295532025813,
    "MMLU Score": 26.898640661938533,
    "BBH Score": 33.26225439614359,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.702512059210265
  },
  {
    "Model Name": "GenVRadmin/AryaBhatta-GemmaOrca-2-Merged",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8188650858383464,
    "Overall Score": 14.006450277637631,
    "MMLU Score": 15.383052600472812,
    "BBH Score": 13.66159169666284,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.700653768490924
  },
  {
    "Model Name": "GenVRadmin/AryaBhatta-GemmaOrca-Merged",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9810632012201568,
    "Overall Score": 11.99472750549792,
    "MMLU Score": 13.6469414893617,
    "BBH Score": 17.68358820544961,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.054691994738102
  },
  {
    "Model Name": "GenVRadmin/AryaBhatta-GemmaUltra-Merged",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0074310732975738,
    "Overall Score": 13.28281509458921,
    "MMLU Score": 14.0625,
    "BBH Score": 17.96825031857262,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.616822500794386
  },
  {
    "Model Name": "GenVRadmin/llama38bGenZ_Vikas-Merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4353168101343383,
    "Overall Score": 16.09338316937527,
    "MMLU Score": 18.02415780141844,
    "BBH Score": 23.13191042200777,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.212425755585633
  },
  {
    "Model Name": "GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.8621893014690505,
    "Overall Score": 32.46826016178984,
    "MMLU Score": 36.26255910165484,
    "BBH Score": 41.86650373118869,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.406698281060429
  },
  {
    "Model Name": "GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3468218426289178,
    "Overall Score": 23.05939902243402,
    "MMLU Score": 27.258791371158388,
    "BBH Score": 28.53952939391592,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.1213432189542
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.975284803465032,
    "Overall Score": 9.768236092545305,
    "MMLU Score": 7.127290189125294,
    "BBH Score": 6.845785955173547,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.015778014627433
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4980036188524055,
    "Overall Score": 8.415919404386559,
    "MMLU Score": 7.090351654846336,
    "BBH Score": 7.2211690840719855,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.899313751534812
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5667617401508371,
    "Overall Score": 18.44117473256343,
    "MMLU Score": 19.806442080378247,
    "BBH Score": 18.30601328940368,
    "Math Score": 20.84592145015106,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.770248315348853
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4384858224632824,
    "Overall Score": 15.56674922027016,
    "MMLU Score": 17.350029550827426,
    "BBH Score": 16.499503211302823,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.821621580957572
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4124015158696626,
    "Overall Score": 15.592787360948462,
    "MMLU Score": 17.28538711583924,
    "BBH Score": 16.439711885397813,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.03991123327807
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-14B-Instruct-abliterated-v4",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4942336302425923,
    "Overall Score": 42.550065874753976,
    "MMLU Score": 44.64760638297872,
    "BBH Score": 48.05226992969286,
    "Math Score": 54.229607250755286,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.177224071820257
  },
  {
    "Model Name": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.4030128559486643,
    "Overall Score": 35.31663337889917,
    "MMLU Score": 34.66496749408983,
    "BBH Score": 33.33398601463088,
    "Math Score": 45.31722054380665,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.696814164548789
  },
  {
    "Model Name": "Goekdeniz-Guelmez/j.o.s.i.e.v4o-1.5b-dpo-stage1-v1",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5823051977207447,
    "Overall Score": 15.07804770111701,
    "MMLU Score": 17.2761524822695,
    "BBH Score": 17.748016873381815,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.529165247536575
  },
  {
    "Model Name": "Goekdeniz-Guelmez/josie-3b-v6.0",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.491912040011956,
    "Overall Score": 24.746540779866937,
    "MMLU Score": 24.66385933806146,
    "BBH Score": 22.87108835512943,
    "Math Score": 29.38066465256798,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.58713122233977
  },
  {
    "Model Name": "Goekdeniz-Guelmez/josie-7b-v6.0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3509256308404545,
    "Overall Score": 32.374168071296964,
    "MMLU Score": 31.183510638297868,
    "BBH Score": 30.44475330982171,
    "Math Score": 43.58006042296073,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.964433964552104
  },
  {
    "Model Name": "Goekdeniz-Guelmez/josie-7b-v6.0-step2000",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3788389441043891,
    "Overall Score": 26.97043751712353,
    "MMLU Score": 33.69533096926713,
    "BBH Score": 30.081094189593973,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.560252219770238
  },
  {
    "Model Name": "Goekdeniz-Guelmez/josie-7b-v6.0-step2000",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.383397861475809,
    "Overall Score": 33.83292639490552,
    "MMLU Score": 33.46446513002365,
    "BBH Score": 30.39581290531489,
    "Math Score": 42.37160120845921,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.45639633909261
  },
  {
    "Model Name": "GreenNode/GreenNode-small-9B-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 5.291887986432054,
    "Overall Score": 31.194506347689323,
    "MMLU Score": 32.52253250591017,
    "BBH Score": 41.899925635193455,
    "Math Score": 17.447129909365557,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.894778277179969
  },
  {
    "Model Name": "GritLM/GritLM-7B-KTO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2797271864870114,
    "Overall Score": 19.2358949114183,
    "MMLU Score": 18.67058215130024,
    "BBH Score": 27.904317623033844,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.031246592660812
  },
  {
    "Model Name": "GritLM/GritLM-8x7B-KTO",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.208926459712533,
    "Overall Score": 26.2413047085506,
    "MMLU Score": 29.419695626477544,
    "BBH Score": 40.8261615594601,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.8495509029583186
  },
  {
    "Model Name": "Groq/Llama-3-Groq-8B-Tool-Use",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0086565382541746,
    "Overall Score": 21.44560137489326,
    "MMLU Score": 26.658540189125297,
    "BBH Score": 27.254234386573227,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.261549954370214
  },
  {
    "Model Name": "Gryphe/Pantheon-RP-1.0-8b-Llama-3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4416729891301094,
    "Overall Score": 16.87312240356046,
    "MMLU Score": 22.96468676122932,
    "BBH Score": 23.631914688111305,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.703848605599198
  },
  {
    "Model Name": "Gryphe/Pantheon-RP-1.5-12b-Nemo",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.371166401118355,
    "Overall Score": 21.32374664039768,
    "MMLU Score": 25.57808806146572,
    "BBH Score": 31.750144021634004,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.3253319780725485
  },
  {
    "Model Name": "Gryphe/Pantheon-RP-1.6-12b-Nemo",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4745060547622137,
    "Overall Score": 20.56659922855925,
    "MMLU Score": 25.67966903073286,
    "BBH Score": 31.68734382617837,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-08-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.919287203535116
  },
  {
    "Model Name": "Gryphe/Pantheon-RP-1.6-12b-Nemo-KTO",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.3640528836556807,
    "Overall Score": 21.558598525492474,
    "MMLU Score": 26.46461288416076,
    "BBH Score": 33.032200369425645,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-08-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.408519506407097
  },
  {
    "Model Name": "Gryphe/Pantheon-RP-Pure-1.6.2-22b-Small",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.906640148295222,
    "Overall Score": 28.13863519609944,
    "MMLU Score": 32.68875591016548,
    "BBH Score": 31.68316320987065,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2024-10-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.680811438802657
  },
  {
    "Model Name": "GuilhermeNaturaUmana/Nature-Reason-1.2-reallysmall",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6894452515867744,
    "Overall Score": 28.68902218654482,
    "MMLU Score": 38.1002511820331,
    "BBH Score": 37.752975371907866,
    "Math Score": 25.755287009063444,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 41.611748170745045
  },
  {
    "Model Name": "GuilhermeNaturaUmana/Nature-Reason-1.2-reallysmall",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6936433748469978,
    "Overall Score": 28.37476976386807,
    "MMLU Score": 37.8693853427896,
    "BBH Score": 37.812775827443616,
    "Math Score": 25.0,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.90685616384199
  },
  {
    "Model Name": "Gunulhona/Gemma-Ko-Merge",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.274495075785254,
    "Overall Score": 29.04465836961312,
    "MMLU Score": 31.98692375886525,
    "BBH Score": 38.78719707326869,
    "Math Score": 18.80664652567976,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.629003293301363
  },
  {
    "Model Name": "Gunulhona/Gemma-Ko-Merge-PEFT",
    "Parameters (B)": 20.318,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.876476720258237,
    "Overall Score": 18.16949453226467,
    "MMLU Score": 31.303560874704488,
    "BBH Score": 30.18627333134207,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.0919027500999317
  },
  {
    "Model Name": "Gunulhona/Gemma-Ko-Merge-PEFT",
    "Parameters (B)": 20.318,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 18.78866710415633,
    "Overall Score": 18.06624017039761,
    "MMLU Score": 23.30636820330969,
    "BBH Score": 26.015069295888747,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.9615498571690109
  },
  {
    "Model Name": "HPAI-BSC/Llama3-Aloe-8B-Alpha",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5904895773762358,
    "Overall Score": 20.23044725696465,
    "MMLU Score": 25.5042109929078,
    "BBH Score": 27.14597757758177,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.719635227247432
  },
  {
    "Model Name": "HPAI-BSC/Llama3.1-Aloe-Beta-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0813801340892315,
    "Overall Score": 26.52419518267397,
    "MMLU Score": 28.671690307328607,
    "BBH Score": 30.36962478134476,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.743561230481527
  },
  {
    "Model Name": "HPAI-BSC/Qwen2.5-Aloe-Beta-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.216719947943519,
    "Overall Score": 27.826720985708487,
    "MMLU Score": 37.2691341607565,
    "BBH Score": 30.33160459968833,
    "Math Score": 35.422960725075534,
    "Date Submitted": "2024-12-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.870275968385968
  },
  {
    "Model Name": "HarbingerX/Zeitgeist-3b-V1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5911335287258164,
    "Overall Score": 21.70541406485785,
    "MMLU Score": 22.32749704491725,
    "BBH Score": 21.647559636357908,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.71829292384024
  },
  {
    "Model Name": "HarbingerX/Zeitgeist-3b-V1.2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6026767345231062,
    "Overall Score": 21.62222005411458,
    "MMLU Score": 22.844636524822693,
    "BBH Score": 21.6297148573501,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.87697818005881
  },
  {
    "Model Name": "Hastagaras/L3.2-JametMini-3B-MK.III",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5696355012646784,
    "Overall Score": 21.75038505136374,
    "MMLU Score": 22.031988770685576,
    "BBH Score": 22.362058620348964,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.18298719632912
  },
  {
    "Model Name": "Hastagaras/Llama-3.1-Jamet-8B-MK.I",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4374797961123538,
    "Overall Score": 25.42380601749484,
    "MMLU Score": 27.582003546099287,
    "BBH Score": 29.503904748319474,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.686374505056147
  },
  {
    "Model Name": "Hastagaras/Zabuza-8B-Llama-3.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3505746169086037,
    "Overall Score": 19.92582695678787,
    "MMLU Score": 21.3670951536643,
    "BBH Score": 23.220320849670458,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.753592069127635
  },
  {
    "Model Name": "HelpingAI/Cipher-20B",
    "Parameters (B)": 20.551,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.068230413560843,
    "Overall Score": 26.97600761673777,
    "MMLU Score": 30.49091312056737,
    "BBH Score": 43.43973598811683,
    "Math Score": 19.939577039274926,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.6308947317283815
  },
  {
    "Model Name": "HelpingAI/Dhanishtha-Large",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6810018739499718,
    "Overall Score": 19.889172686673326,
    "MMLU Score": 19.501699172576835,
    "BBH Score": 24.0022140693209,
    "Math Score": 38.51963746223565,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.205753240165734
  },
  {
    "Model Name": "HelpingAI/Priya-10B",
    "Parameters (B)": 10.211,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.8156790123754447,
    "Overall Score": 14.14328407509064,
    "MMLU Score": 16.583554964539008,
    "BBH Score": 19.96679684299346,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.789528864238534
  },
  {
    "Model Name": "HelpingAI/Priya-3B",
    "Parameters (B)": 2.81,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.2826597442200018,
    "Overall Score": 13.429592166190526,
    "MMLU Score": 14.875147754137116,
    "BBH Score": 14.335273409626751,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.47011276896134
  },
  {
    "Model Name": "HeraiHench/DeepSeek-R1-Qwen-Coder-8B",
    "Parameters (B)": 8.164,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6427932957296756,
    "Overall Score": 4.563387722893334,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 2.147966883446335,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.099308211846146
  },
  {
    "Model Name": "HeraiHench/Double-Down-Qwen-Math-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.399766890062088,
    "Overall Score": 4.309785575689419,
    "MMLU Score": 1.2448286052009452,
    "BBH Score": 1.9548697694104624,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.078930932205614
  },
  {
    "Model Name": "HeraiHench/Marge-Qwen-Math-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.373742012462644,
    "Overall Score": 4.083812323812456,
    "MMLU Score": 0.616873522458628,
    "BBH Score": 3.363509103932151,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.9727651092883107
  },
  {
    "Model Name": "HeraiHench/Phi-4-slerp-ReasoningRP-14B",
    "Parameters (B)": 9.207,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3111993722915891,
    "Overall Score": 8.51238737192275,
    "MMLU Score": 9.99926122931442,
    "BBH Score": 18.8853764817121,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.4920618113518564
  },
  {
    "Model Name": "HiroseKoichi/Llama-Salad-4x8B-V3",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.275390404302961,
    "Overall Score": 24.922701724199342,
    "MMLU Score": 27.979092789598106,
    "BBH Score": 31.92884881074505,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.829339397664345
  },
  {
    "Model Name": "HoangHa/Pensez-Llama3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2326767237191776,
    "Overall Score": 19.04804643436893,
    "MMLU Score": 23.620345744680847,
    "BBH Score": 24.84515798598393,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.531484308502499
  },
  {
    "Model Name": "HuggingFaceH4/zephyr-7b-alpha",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9030544872725952,
    "Overall Score": 18.598795237504422,
    "MMLU Score": 19.94496158392435,
    "BBH Score": 23.890291427068444,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 20.595429732791093
  },
  {
    "Model Name": "HuggingFaceH4/zephyr-7b-beta",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.110046181738907,
    "Overall Score": 17.792237227370464,
    "MMLU Score": 19.78797281323877,
    "BBH Score": 21.48754218280673,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.02837568388246
  },
  {
    "Model Name": "HuggingFaceH4/zephyr-7b-gemma-v0.1",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.860947822540511,
    "Overall Score": 16.030043342251584,
    "MMLU Score": 20.526743498817968,
    "BBH Score": 23.751162749201274,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.603053371318378
  },
  {
    "Model Name": "HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1",
    "Parameters (B)": 140.621,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 84.13557284613555,
    "Overall Score": 34.125963384670946,
    "MMLU Score": 39.84559692671394,
    "BBH Score": 47.5037962865412,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.4056068346629008
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-1.7B",
    "Parameters (B)": 1.71,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6486145130353238,
    "Overall Score": 5.576455936269043,
    "MMLU Score": 1.6419178486997636,
    "BBH Score": 4.4111278515492005,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.597488684261597
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-1.7B-Instruct",
    "Parameters (B)": 1.71,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6340453268534886,
    "Overall Score": 5.490688803655309,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 2.0803742908537424,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.659773317632329
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-135M",
    "Parameters (B)": 0.13,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6867550151153348,
    "Overall Score": 6.951489892134872,
    "MMLU Score": 1.3556442080378246,
    "BBH Score": 3.2853998220852616,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.122226615217986
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5972598335396585,
    "Overall Score": 3.652287650202965,
    "MMLU Score": 1.9558953900709208,
    "BBH Score": 2.69295800470458,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.115073281519191
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-360M",
    "Parameters (B)": 0.36,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7305190643342521,
    "Overall Score": 6.260888857386585,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 3.284915303246592,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.570466074136416
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM-360M-Instruct",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7330020485979701,
    "Overall Score": 5.0088989557053685,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 2.0803742908537424,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-08-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.833403760993581
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-1.7B",
    "Parameters (B)": 1.71,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6500519822806164,
    "Overall Score": 9.5836210417532,
    "MMLU Score": 12.640366430260045,
    "BBH Score": 9.301788459551682,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.742853345559238
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-1.7B-Instruct",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9397207100161584,
    "Overall Score": 15.02227766709556,
    "MMLU Score": 11.707668439716311,
    "BBH Score": 10.917989226208066,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.985896135924527
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-135M",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.677924434996086,
    "Overall Score": 5.695927392648112,
    "MMLU Score": 1.0509013002364058,
    "BBH Score": 3.70807758683998,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.402009278041435
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-135M-Instruct",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.338375628206877,
    "Overall Score": 6.467364720358819,
    "MMLU Score": 1.2725325059101646,
    "BBH Score": 4.720807660805284,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.112974402532277
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-135M-Instruct",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.697507687387014,
    "Overall Score": 3.2065969565576755,
    "MMLU Score": 1.0231973995271864,
    "BBH Score": 4.796275744662444,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.597220954754133
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-360M",
    "Parameters (B)": 0.36,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7733156187446921,
    "Overall Score": 6.251282350517303,
    "MMLU Score": 1.8820183215130024,
    "BBH Score": 5.543603155369513,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.083739936178821
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3923818692717623,
    "Overall Score": 3.1000195398620374,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 3.2990473293233173,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.900516773661056
  },
  {
    "Model Name": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "Parameters (B)": 0.36,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7516385415285941,
    "Overall Score": 8.139566424375877,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 4.173863636363637,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.82909666636118
  },
  {
    "Model Name": "HumanLLMs/Humanish-LLama3-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.496556281341137,
    "Overall Score": 22.678203747779094,
    "MMLU Score": 30.019946808510632,
    "BBH Score": 28.012476599572,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.15359230423065
  },
  {
    "Model Name": "HumanLLMs/Humanish-Mistral-Nemo-Instruct-2407",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.2405666128817936,
    "Overall Score": 23.888067848972184,
    "MMLU Score": 28.00679669030733,
    "BBH Score": 32.70961342122556,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.371571302997792
  },
  {
    "Model Name": "HumanLLMs/Humanish-Qwen2.5-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.3867854372664867,
    "Overall Score": 34.99870743015318,
    "MMLU Score": 37.75856973995272,
    "BBH Score": 34.47899758661866,
    "Math Score": 50.0,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.663533170470549
  },
  {
    "Model Name": "IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.216514860669184,
    "Overall Score": 3.9064248386004095,
    "MMLU Score": 1.124778368794326,
    "BBH Score": 1.4636170460989155,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.7624176169164179
  },
  {
    "Model Name": "INSAIT-Institute/BgGPT-Gemma-2-27B-IT-v1.0",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 20.72624365724348,
    "Overall Score": 1.6780628068086922,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.08096319017374078
  },
  {
    "Model Name": "IlyaGusev/gemma-2-2b-it-abliterated",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.68717312543207,
    "Overall Score": 16.705746365531194,
    "MMLU Score": 17.091459810874703,
    "BBH Score": 16.796334504661765,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.530773521401597
  },
  {
    "Model Name": "IlyaGusev/gemma-2-9b-it-abliterated",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.6226877064686693,
    "Overall Score": 31.294229585782904,
    "MMLU Score": 32.393247635933804,
    "BBH Score": 40.82468502686295,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.932121963510163
  },
  {
    "Model Name": "Infinirc/Infinirc-Llama3-8B-2G-Release-v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7162005063744825,
    "Overall Score": 13.16266165602399,
    "MMLU Score": 12.889701536643026,
    "BBH Score": 20.83116494676627,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.845983065364047
  },
  {
    "Model Name": "Intel/neural-chat-7b-v3",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9785806289666896,
    "Overall Score": 18.069527284193285,
    "MMLU Score": 18.87374408983452,
    "BBH Score": 30.205692320538088,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.465036757649084
  },
  {
    "Model Name": "Intel/neural-chat-7b-v3-1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1273840573130482,
    "Overall Score": 21.06792676095294,
    "MMLU Score": 18.642878250591018,
    "BBH Score": 29.7397523676162,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.687444286878776
  },
  {
    "Model Name": "Intel/neural-chat-7b-v3-2",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1208829689611992,
    "Overall Score": 21.4714111685822,
    "MMLU Score": 18.522828014184395,
    "BBH Score": 30.237457969159426,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.155801063228985
  },
  {
    "Model Name": "Intel/neural-chat-7b-v3-3",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1190477903556486,
    "Overall Score": 20.557585514141863,
    "MMLU Score": 18.05186170212766,
    "BBH Score": 27.753850886523697,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.370605519544775
  },
  {
    "Model Name": "IntervitensInc/internlm2_5-20b-llamafied",
    "Parameters (B)": 19.861,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.76225561886365,
    "Overall Score": 29.216880819026148,
    "MMLU Score": 33.89849290780142,
    "BBH Score": 63.47057952429436,
    "Math Score": 17.14501510574018,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.577182147626704
  },
  {
    "Model Name": "Invalid-Null/PeiYangMe-0.5",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5153573523009258,
    "Overall Score": 3.4273672940352,
    "MMLU Score": 1.2078900709219855,
    "BBH Score": 1.4745771439889088,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 2.2617551489297685
  },
  {
    "Model Name": "Invalid-Null/PeiYangMe-0.7",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.493280597282422,
    "Overall Score": 4.397279528582866,
    "MMLU Score": 1.124778368794326,
    "BBH Score": 3.600797717385781,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 2.9447108176355785
  },
  {
    "Model Name": "Isaak-Carter/JOSIEv4o-8b-stage1-v4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.781164210084582,
    "Overall Score": 15.66808216767364,
    "MMLU Score": 25.7350768321513,
    "BBH Score": 25.7872756997585,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.796539970298197
  },
  {
    "Model Name": "Isaak-Carter/JOSIEv4o-8b-stage1-v4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8798822262772638,
    "Overall Score": 15.419272249038904,
    "MMLU Score": 25.46727245862884,
    "BBH Score": 25.91957835941345,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.52424561895863
  },
  {
    "Model Name": "Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1535813501469194,
    "Overall Score": 35.06474762506518,
    "MMLU Score": 36.401078605200944,
    "BBH Score": 34.904315688323074,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.28206318868476
  },
  {
    "Model Name": "Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.261829293581302,
    "Overall Score": 35.685532582369234,
    "MMLU Score": 34.75731382978724,
    "BBH Score": 33.2945398202129,
    "Math Score": 47.205438066465256,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.777288181578902
  },
  {
    "Model Name": "J-LAB/Thynk_orpo",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.429528221432072,
    "Overall Score": 17.263933728919593,
    "MMLU Score": 24.793144208037827,
    "BBH Score": 22.062783944144368,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.105879065995563
  },
  {
    "Model Name": "JackFram/llama-160m",
    "Parameters (B)": 0.162,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.1869487883487398,
    "Overall Score": 4.738129846796396,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 2.033606152852728,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.344533594717657
  },
  {
    "Model Name": "JackFram/llama-68m",
    "Parameters (B)": 0.068,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.1211158078368217,
    "Overall Score": 4.963339700174584,
    "MMLU Score": 1.595744680851063,
    "BBH Score": 2.5910478068354776,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 40.980114725087326
  },
  {
    "Model Name": "Jacoby746/Casual-Magnum-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.85339428403758,
    "Overall Score": 23.79792072114355,
    "MMLU Score": 46.485298463356976,
    "BBH Score": 43.05156762846773,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.4724283668563927
  },
  {
    "Model Name": "Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.780861420852331,
    "Overall Score": 20.186181285193417,
    "MMLU Score": 25.236406619385345,
    "BBH Score": 32.38700420411291,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.258966999875303
  },
  {
    "Model Name": "Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.732529076638037,
    "Overall Score": 20.01822829916165,
    "MMLU Score": 25.24564125295508,
    "BBH Score": 32.259183510828905,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.554339011733592
  },
  {
    "Model Name": "Jacoby746/Proto-Athena-4x7B",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.353228735285469,
    "Overall Score": 19.77557762348212,
    "MMLU Score": 24.516105200945624,
    "BBH Score": 30.870822876627887,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.897473505277765
  },
  {
    "Model Name": "Jacoby746/Proto-Athena-v0.2-4x7B",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3027439043825804,
    "Overall Score": 19.345307494794017,
    "MMLU Score": 24.414524231678485,
    "BBH Score": 30.34084433030367,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.857344091718324
  },
  {
    "Model Name": "Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7636816551119412,
    "Overall Score": 22.48121361701981,
    "MMLU Score": 25.56885342789598,
    "BBH Score": 32.63252990159268,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.746752539983143
  },
  {
    "Model Name": "Jacoby746/Proto-Harpy-Spark-v0.1-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1916091917298846,
    "Overall Score": 19.84999990070571,
    "MMLU Score": 22.992390661938536,
    "BBH Score": 26.913110159424864,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.658146008331006
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-DPO-1epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.956513484116059,
    "Overall Score": 7.385732750247261,
    "MMLU Score": 6.19459219858156,
    "BBH Score": 5.543694750350672,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.721514513799693
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-DPO-5epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4107319976270312,
    "Overall Score": 7.198583184761694,
    "MMLU Score": 5.917553191489359,
    "BBH Score": 5.056692258334079,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.102729077436615
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-IRPO-1epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9908871168069724,
    "Overall Score": 7.031892544703613,
    "MMLU Score": 5.557402482269504,
    "BBH Score": 5.324351851851852,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.096562691584015
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-IRPO-5epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4630507773978825,
    "Overall Score": 6.9234686409529,
    "MMLU Score": 5.631279550827422,
    "BBH Score": 5.711334497269228,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.732213500659681
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-eDPO-1epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9731382094916656,
    "Overall Score": 7.280997177732158,
    "MMLU Score": 6.139184397163118,
    "BBH Score": 5.918400632703615,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.481976462043869
  },
  {
    "Model Name": "JayHyeon/Qwen-0.5B-eDPO-5epoch",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.446003944235028,
    "Overall Score": 6.72779460682018,
    "MMLU Score": 5.8067375886524815,
    "BBH Score": 5.197837690631808,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.652680674657046
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.009091526783928,
    "Overall Score": 8.158039000338244,
    "MMLU Score": 5.779033687943262,
    "BBH Score": 5.93241994210165,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.084538204714393
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-DPO-1epoch_v1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0041674574559156,
    "Overall Score": 8.15078478555964,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 6.12607291013818,
    "Math Score": 6.495468277945618,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.116957709633278
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-IRPO-1epoch_v1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0015027584440948,
    "Overall Score": 8.319017359475316,
    "MMLU Score": 6.951832151300234,
    "BBH Score": 6.622365326648162,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.306534644397281
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-MDPO-1epoch_v1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9959784337587836,
    "Overall Score": 7.896219502136105,
    "MMLU Score": 6.39775413711584,
    "BBH Score": 6.129987166860655,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.9281028930878366
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7276743059196251,
    "Overall Score": 6.611058734039895,
    "MMLU Score": 7.478206264775414,
    "BBH Score": 4.4344753335124,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.8265654072576427
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.714998944312747,
    "Overall Score": 5.941930910286053,
    "MMLU Score": 6.877955082742317,
    "BBH Score": 4.331493365022777,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.4646848792476477
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.580354599240864,
    "Overall Score": 6.345325435592133,
    "MMLU Score": 5.963726359338062,
    "BBH Score": 5.650884333531393,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.015127642011584
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4200189869366269,
    "Overall Score": 6.469032763498576,
    "MMLU Score": 5.908318557919619,
    "BBH Score": 4.797235096058625,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.55559596245545
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2679503095602949,
    "Overall Score": 5.890344422168456,
    "MMLU Score": 6.19459219858156,
    "BBH Score": 4.784241393250257,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.645564086979982
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.71611308822178,
    "Overall Score": 6.664256620538701,
    "MMLU Score": 7.7552452718676115,
    "BBH Score": 4.213683823190269,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.8833435082323975
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6947619269204228,
    "Overall Score": 7.003091729061743,
    "MMLU Score": 7.238105791962175,
    "BBH Score": 5.619297426317974,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.132197931651182
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.651995118215892,
    "Overall Score": 7.740340198303553,
    "MMLU Score": 7.65366430260047,
    "BBH Score": 6.246296486215907,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.685449801245721
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.641911210347618,
    "Overall Score": 7.8890047643086625,
    "MMLU Score": 7.644429669030731,
    "BBH Score": 6.5376144197820265,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.804769414198979
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7071369576852713,
    "Overall Score": 5.555176381236881,
    "MMLU Score": 4.587765957446806,
    "BBH Score": 3.114588111846371,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.2540894602675667
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.711045303670801,
    "Overall Score": 5.51830189312826,
    "MMLU Score": 5.381944444444444,
    "BBH Score": 3.1994992498175416,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.225105659849882
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5817230626386445,
    "Overall Score": 5.465283047679917,
    "MMLU Score": 4.62470449172577,
    "BBH Score": 4.420916097586122,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.4552717708766814
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.640625424134062,
    "Overall Score": 6.087118748270012,
    "MMLU Score": 3.7381796690307305,
    "BBH Score": 3.069330255279086,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.710242849298067
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6849158103513178,
    "Overall Score": 6.9691100972452,
    "MMLU Score": 7.533614066193853,
    "BBH Score": 4.981848012762598,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.136177044829372
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.741069582939448,
    "Overall Score": 7.69236788584868,
    "MMLU Score": 7.884530141843972,
    "BBH Score": 5.7648020969838045,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.418185212828573
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_3e-7-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6802691752300627,
    "Overall Score": 7.460129211594215,
    "MMLU Score": 6.249999999999999,
    "BBH Score": 6.702479854955681,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.439841735817581
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-1ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9629006772435992,
    "Overall Score": 7.89170131391145,
    "MMLU Score": 6.333111702127657,
    "BBH Score": 6.892109783030413,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.195758400027556
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-2ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.966450423771423,
    "Overall Score": 7.618464097122786,
    "MMLU Score": 6.009899527186761,
    "BBH Score": 7.351407019428777,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.8829331642205815
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6735105292159798,
    "Overall Score": 7.868642802061662,
    "MMLU Score": 6.166888297872341,
    "BBH Score": 6.453776300474527,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.701878276050064
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-1ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.949960446462803,
    "Overall Score": 7.430131653175725,
    "MMLU Score": 6.22229609929078,
    "BBH Score": 6.676263541946459,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.821516865088406
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-2ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9530341118411932,
    "Overall Score": 7.336426732183583,
    "MMLU Score": 6.083776595744679,
    "BBH Score": 6.449024830632406,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.697968667679834
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.619904502829789,
    "Overall Score": 7.648469593189115,
    "MMLU Score": 6.23153073286052,
    "BBH Score": 6.900838556122601,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.721555857044726
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9335881625277724,
    "Overall Score": 7.714071022336462,
    "MMLU Score": 6.443927304964539,
    "BBH Score": 6.330228534336109,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.262820087017742
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9826218900481372,
    "Overall Score": 7.634084055658554,
    "MMLU Score": 6.23153073286052,
    "BBH Score": 6.636386948995733,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.769096264774411
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.585209509005599,
    "Overall Score": 7.772250160016548,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 6.317309144357895,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.902979773879905
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-7-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9553102297737666,
    "Overall Score": 7.773024145558947,
    "MMLU Score": 6.406988770685579,
    "BBH Score": 6.435274271047841,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.136649125383833
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.730292283324373,
    "Overall Score": 7.5699062251194,
    "MMLU Score": 6.4808658392434975,
    "BBH Score": 6.3853505237711525,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.374929194376053
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9391865870283091,
    "Overall Score": 7.393492455729212,
    "MMLU Score": 6.453161938534278,
    "BBH Score": 6.402744874205392,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.872229605751765
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9538609155694656,
    "Overall Score": 7.844417926699584,
    "MMLU Score": 5.972960992907801,
    "BBH Score": 6.901808055033277,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.223859263608027
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6179762800252908,
    "Overall Score": 7.696682188954132,
    "MMLU Score": 5.991430260047281,
    "BBH Score": 7.002679365505716,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.7569808556364155
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9503727986258512,
    "Overall Score": 7.753028845132317,
    "MMLU Score": 6.37005023640662,
    "BBH Score": 6.620615393798311,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.157881682159317
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9838564283065736,
    "Overall Score": 7.5524251169059395,
    "MMLU Score": 5.732860520094564,
    "BBH Score": 6.780448413764288,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.676348804169803
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5996652304020564,
    "Overall Score": 7.645766396524414,
    "MMLU Score": 6.111480496453899,
    "BBH Score": 7.007125824454593,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.779604039154332
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.727522292956337,
    "Overall Score": 7.580039598446345,
    "MMLU Score": 6.37928486997636,
    "BBH Score": 6.671898931566538,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.387810003582935
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9244260639179844,
    "Overall Score": 7.682977767911112,
    "MMLU Score": 6.3608156028368805,
    "BBH Score": 6.428288118900529,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.311078698223236
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4388206268955834,
    "Overall Score": 7.668495371524835,
    "MMLU Score": 5.511229314420804,
    "BBH Score": 6.992686975855793,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.329709088248528
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.568426743270365,
    "Overall Score": 7.698046996488631,
    "MMLU Score": 5.538933215130023,
    "BBH Score": 7.221132822992211,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.908132961592612
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9560694003572412,
    "Overall Score": 7.824147748385339,
    "MMLU Score": 6.3608156028368805,
    "BBH Score": 6.537585206076343,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.183660878030192
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9856434837220436,
    "Overall Score": 7.706086604401125,
    "MMLU Score": 6.351580969267137,
    "BBH Score": 6.56672292356821,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.81833059485257
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_3ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.955982707001288,
    "Overall Score": 7.813940287125231,
    "MMLU Score": 6.296173167848698,
    "BBH Score": 6.932125973677143,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.17372555999039
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9937085506127672,
    "Overall Score": 7.842463015004548,
    "MMLU Score": 6.305407801418437,
    "BBH Score": 6.4262889097800455,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.892115862511718
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9328624737149236,
    "Overall Score": 7.58869267971069,
    "MMLU Score": 6.323877068557918,
    "BBH Score": 6.4779954188677,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.134846125271133
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_3ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9555559480929502,
    "Overall Score": 7.82811926779825,
    "MMLU Score": 6.286938534278959,
    "BBH Score": 6.25191698749515,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.1922144730732
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9798458957510294,
    "Overall Score": 7.958391854528215,
    "MMLU Score": 6.342346335697398,
    "BBH Score": 6.714916509982989,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.122085206499017
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-2ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9858942704409892,
    "Overall Score": 7.678680596214881,
    "MMLU Score": 6.5178043735224565,
    "BBH Score": 6.875548169039305,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.788543687123993
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6879119412493844,
    "Overall Score": 7.707475337922656,
    "MMLU Score": 6.176122931442081,
    "BBH Score": 7.08976945115946,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.5662781034759545
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_3e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5746445665887192,
    "Overall Score": 7.811415481732978,
    "MMLU Score": 6.508569739952717,
    "BBH Score": 6.706365162503357,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.9607483793345715
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.948448848961016,
    "Overall Score": 7.608040308738378,
    "MMLU Score": 6.083776595744679,
    "BBH Score": 6.3889454442355325,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.021561012038395
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-2ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9495726767487782,
    "Overall Score": 7.376023721057838,
    "MMLU Score": 5.788268321513002,
    "BBH Score": 7.489152117467992,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.7677295289418495
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.606487559792415,
    "Overall Score": 7.500614312695059,
    "MMLU Score": 6.305407801418437,
    "BBH Score": 8.34016877070463,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.668952627099249
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9237289026935196,
    "Overall Score": 7.830243972560936,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 6.5670715074462045,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.47677706059491
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-2ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.953572337055508,
    "Overall Score": 7.764548314144669,
    "MMLU Score": 6.39775413711584,
    "BBH Score": 6.6590467663473305,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.14258972541135
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6214702427172307,
    "Overall Score": 7.87411176143835,
    "MMLU Score": 6.296173167848698,
    "BBH Score": 6.800973005640612,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.8561555765852695
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9777035716539286,
    "Overall Score": 7.491580739378782,
    "MMLU Score": 6.249999999999999,
    "BBH Score": 6.560842435908914,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.662425459595772
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9748893197902356,
    "Overall Score": 7.496575969696766,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 6.524571656668756,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.689668783436652
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.595170776368906,
    "Overall Score": 7.758022627216668,
    "MMLU Score": 6.39775413711584,
    "BBH Score": 6.739192109111529,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.863443301585733
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5812332726991494,
    "Overall Score": 7.538763276089521,
    "MMLU Score": 6.18535756501182,
    "BBH Score": 6.42055719700361,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.76764776345803
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9418792589240153,
    "Overall Score": 7.900913542849916,
    "MMLU Score": 6.573212174940895,
    "BBH Score": 6.6874635150864,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.388456872779816
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.994687575413746,
    "Overall Score": 7.872419066693536,
    "MMLU Score": 6.23153073286052,
    "BBH Score": 6.553899558301251,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.91446406015372
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6287579769869538,
    "Overall Score": 7.662137140256275,
    "MMLU Score": 5.972960992907801,
    "BBH Score": 6.583344002745696,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.704282188339912
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9466656521995674,
    "Overall Score": 7.613408611706003,
    "MMLU Score": 6.471631205673758,
    "BBH Score": 6.560212045244278,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.042341658870088
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9649867208676276,
    "Overall Score": 7.688163880198053,
    "MMLU Score": 5.991430260047281,
    "BBH Score": 6.83074782881189,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.967118835879484
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9650369713069662,
    "Overall Score": 7.510368922283475,
    "MMLU Score": 6.536273640661936,
    "BBH Score": 6.204970976213926,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.782467558846013
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9756798711523568,
    "Overall Score": 7.696957299033557,
    "MMLU Score": 5.926787825059102,
    "BBH Score": 7.019682155967409,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.888814278747832
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6261828818601185,
    "Overall Score": 8.113734287630097,
    "MMLU Score": 5.89908392434988,
    "BBH Score": 7.0604011102157775,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.989435307761422
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9554874322349814,
    "Overall Score": 7.472755907553406,
    "MMLU Score": 6.314642434988178,
    "BBH Score": 6.715595621810369,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.8208835149970275
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9770739578099976,
    "Overall Score": 7.491778365975214,
    "MMLU Score": 5.557402482269504,
    "BBH Score": 6.98474035276211,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.66756529133905
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6191035921575376,
    "Overall Score": 7.931808376696927,
    "MMLU Score": 5.788268321513002,
    "BBH Score": 7.363649162861492,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.8988887524654245
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5672288780515016,
    "Overall Score": 7.664774636147854,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 6.726276300474528,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.890654290187204
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9606349545204644,
    "Overall Score": 7.6637155055011235,
    "MMLU Score": 6.610150709219859,
    "BBH Score": 6.708541946458948,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.97776040673717
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9716211474827172,
    "Overall Score": 7.759729017494784,
    "MMLU Score": 6.240765366430259,
    "BBH Score": 6.253469424299401,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.9863731224858
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.635012914673809,
    "Overall Score": 7.566871862822331,
    "MMLU Score": 6.176122931442081,
    "BBH Score": 6.443718103679828,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.628019629026569
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7_1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4377628452926612,
    "Overall Score": 7.522450873561554,
    "MMLU Score": 6.296173167848698,
    "BBH Score": 6.39987465305757,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.2320526282833075
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7_2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9673478289923536,
    "Overall Score": 7.658751981428238,
    "MMLU Score": 6.148419030732861,
    "BBH Score": 6.482712194466828,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.917267969067594
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4998281694187698,
    "Overall Score": 7.452521242968808,
    "MMLU Score": 8.290854018912528,
    "BBH Score": 6.085450245131953,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.968916703209336
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4430169200453364,
    "Overall Score": 7.715260794976504,
    "MMLU Score": 7.727541371158392,
    "BBH Score": 7.179764119844701,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.346618385274448
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_5e-7_3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5272056484708256,
    "Overall Score": 7.834821841142105,
    "MMLU Score": 6.37928486997636,
    "BBH Score": 6.757650565553466,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.130168192467744
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_5e-7_3ep_0alp_0lam_1ep",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.926214387243842,
    "Overall Score": 7.472893784749629,
    "MMLU Score": 6.628619976359339,
    "BBH Score": 5.959990748201868,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.068211731181261
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_5e-7_3ep_0alp_0lam_2ep",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.920317545171435,
    "Overall Score": 7.494108519452317,
    "MMLU Score": 6.240765366430259,
    "BBH Score": 6.1123436893783385,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.142959523885127
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_7e-7_3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4310927512750664,
    "Overall Score": 7.453297176972131,
    "MMLU Score": 6.259234633569739,
    "BBH Score": 6.240268525979645,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.208116084950775
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_7e-7_3ep_0alp_0lam_1ep",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.911805268810864,
    "Overall Score": 7.592452067439491,
    "MMLU Score": 6.573212174940895,
    "BBH Score": 6.292637807025397,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.326835045975585
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep-MDPO_7e-7_3ep_0alp_0lam_2ep",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9175874353422176,
    "Overall Score": 7.702241458661472,
    "MMLU Score": 6.176122931442081,
    "BBH Score": 6.357407183573582,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.394013651449894
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7130763775454447,
    "Overall Score": 6.609556986596828,
    "MMLU Score": 7.468971631205674,
    "BBH Score": 4.746972667855022,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.8582967305096054
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.615044419227721,
    "Overall Score": 6.850186995920002,
    "MMLU Score": 6.970301418439714,
    "BBH Score": 5.832625611473314,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.241485196546862
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4376652440986477,
    "Overall Score": 7.074425558693155,
    "MMLU Score": 7.238105791962175,
    "BBH Score": 7.669544389639071,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.920773864244389
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.361085858952767,
    "Overall Score": 7.440232615798167,
    "MMLU Score": 6.5178043735224565,
    "BBH Score": 7.191287458251598,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.466394766251378
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6818854605225897,
    "Overall Score": 6.761335194180454,
    "MMLU Score": 6.914893617021275,
    "BBH Score": 6.35784176033773,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.020092540712966
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-2ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4621946194053217,
    "Overall Score": 6.502777310751012,
    "MMLU Score": 6.305407801418437,
    "BBH Score": 5.463607645078233,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.4472720829705334
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-3ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.437731349494459,
    "Overall Score": 6.894032740125938,
    "MMLU Score": 5.7975029550827415,
    "BBH Score": 5.984021663044627,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.795077148835939
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-5ep",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4582645673428911,
    "Overall Score": 6.575560410304202,
    "MMLU Score": 6.979536052009454,
    "BBH Score": 5.343662111309169,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.50916833444397
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-DPO-1epoch_v1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.961642524321046,
    "Overall Score": 6.245597623653178,
    "MMLU Score": 3.664302600472812,
    "BBH Score": 6.136573850240249,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.4947186357662305
  },
  {
    "Model Name": "JayHyeon/Qwen2.5-0.5B-SFT-MDPO-1epoch_v1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9604210151237632,
    "Overall Score": 6.644463688191298,
    "MMLU Score": 3.747414302600472,
    "BBH Score": 6.524721998388398,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.918282277835277
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_1e-6-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.703989511017824,
    "Overall Score": 7.889615512040611,
    "MMLU Score": 6.286938534278959,
    "BBH Score": 6.140998671919301,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.630084552180136
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_1e-7-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.759286387006712,
    "Overall Score": 7.889282686740077,
    "MMLU Score": 6.249999999999999,
    "BBH Score": 6.642106052466649,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.484365220470485
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-6-1ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.944368121118752,
    "Overall Score": 7.503528444281592,
    "MMLU Score": 6.277703900709218,
    "BBH Score": 6.943810696272422,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.945554573985923
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-6-2ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9402523468511222,
    "Overall Score": 7.695125090795082,
    "MMLU Score": 5.594341016548462,
    "BBH Score": 7.149861894529503,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.18410623123232
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-6-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6105590892603854,
    "Overall Score": 7.64886621890572,
    "MMLU Score": 5.926787825059102,
    "BBH Score": 6.96901565344555,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.74919937424854
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-7-1ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.99787018486109,
    "Overall Score": 7.460153325587554,
    "MMLU Score": 6.277703900709218,
    "BBH Score": 6.629315516160802,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.476075985400902
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-7-2ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.478217700979221,
    "Overall Score": 7.630732587028278,
    "MMLU Score": 6.296173167848698,
    "BBH Score": 6.682421807383531,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.16211690739018
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_3e-7-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6883948898981882,
    "Overall Score": 7.691670985905742,
    "MMLU Score": 6.4808658392434975,
    "BBH Score": 6.35458053541051,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.555611386841829
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_5e-7-1ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9850000355205352,
    "Overall Score": 7.493393961856238,
    "MMLU Score": 6.314642434988178,
    "BBH Score": 6.505902199540394,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.60750628592238
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_5e-7-2ep_0alp_5lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9684952369307004,
    "Overall Score": 7.718986668912689,
    "MMLU Score": 6.37005023640662,
    "BBH Score": 6.769462425761781,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.970082220925793
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPOP_5e-7-3ep_0alp_5lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6480123216517315,
    "Overall Score": 7.865443795694458,
    "MMLU Score": 6.4808658392434975,
    "BBH Score": 6.7976270630017614,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.772685065734984
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_1e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4718979698729255,
    "Overall Score": 7.62746022008641,
    "MMLU Score": 6.443927304964539,
    "BBH Score": 6.865286941551371,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.1820577079435175
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_1e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6979621580424176,
    "Overall Score": 7.573179197494986,
    "MMLU Score": 6.619385342789598,
    "BBH Score": 7.100430208613126,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.46015782014018
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-6-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0017297185291754,
    "Overall Score": 6.91953175659681,
    "MMLU Score": 5.917553191489359,
    "BBH Score": 5.926862745098039,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.907583581284435
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-6-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.990338277414754,
    "Overall Score": 8.075905010851175,
    "MMLU Score": 6.277703900709218,
    "BBH Score": 7.35619576137537,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.154693396213123
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.60550287006388,
    "Overall Score": 7.64297366620885,
    "MMLU Score": 6.03760342789598,
    "BBH Score": 7.139829635632065,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.933396755775389
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0747653244281925,
    "Overall Score": 7.97015103471792,
    "MMLU Score": 6.628619976359339,
    "BBH Score": 6.931145581520281,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.415712857091179
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-7-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.008058398895298,
    "Overall Score": 7.9611230480624675,
    "MMLU Score": 6.656323877068558,
    "BBH Score": 7.127311158862328,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.897481987935254
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_3e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6343527793020924,
    "Overall Score": 7.740913588485586,
    "MMLU Score": 6.545508274231676,
    "BBH Score": 7.222719655594354,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.736378636557978
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_5e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.115253927209164,
    "Overall Score": 8.081986081140814,
    "MMLU Score": 6.591681442080379,
    "BBH Score": 6.663952457695408,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.82081128756209
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_5e-7-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9417871309922724,
    "Overall Score": 8.095071949326913,
    "MMLU Score": 6.684027777777778,
    "BBH Score": 7.732770540484078,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.595436997315835
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-DPO_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5068458858938178,
    "Overall Score": 7.974924607629624,
    "MMLU Score": 6.610150709219859,
    "BBH Score": 7.20213873220521,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.29246201106965
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IPO_5e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.61252824106982,
    "Overall Score": 8.328387378313979,
    "MMLU Score": 7.228871158392436,
    "BBH Score": 7.733923210075507,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.164800941897657
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IPO_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4504781313625783,
    "Overall Score": 8.595287891585235,
    "MMLU Score": 6.933362884160756,
    "BBH Score": 6.747260572417705,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.925830735214757
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_1e-6-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5367821997177236,
    "Overall Score": 7.800520466258392,
    "MMLU Score": 6.37928486997636,
    "BBH Score": 7.213578356761274,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.075878981218804
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_1e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5957421944206596,
    "Overall Score": 8.273392756694859,
    "MMLU Score": 6.508569739952717,
    "BBH Score": 6.900346643984839,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.184667539419515
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_3e-6-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.032004910729791,
    "Overall Score": 7.058958298337019,
    "MMLU Score": 6.794843380614658,
    "BBH Score": 7.306987942817919,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.840043322415216
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_3e-6-2ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9566755642062156,
    "Overall Score": 7.289618635016649,
    "MMLU Score": 5.908318557919619,
    "BBH Score": 7.390762452621842,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.619739552002752
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_3e-6-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.489902248473601,
    "Overall Score": 8.103245031991229,
    "MMLU Score": 6.23153073286052,
    "BBH Score": 8.111779105858478,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.438776295755625
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_3e-7-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5261960014175653,
    "Overall Score": 8.061310556795855,
    "MMLU Score": 6.545508274231676,
    "BBH Score": 7.0010276210941,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.281962833940285
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_3e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6548160816235464,
    "Overall Score": 8.09865538559358,
    "MMLU Score": 6.5178043735224565,
    "BBH Score": 7.133620064464142,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.893991226896923
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_5e-7-1ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9939143395959068,
    "Overall Score": 8.092380138165963,
    "MMLU Score": 6.499335106382978,
    "BBH Score": 7.061898931566539,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.141929154031585
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_5e-7-2ep_1alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9537584810036168,
    "Overall Score": 8.02099509740262,
    "MMLU Score": 6.157653664302601,
    "BBH Score": 7.42829155101919,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.409880758242194
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-IRPO_5e-7-3ep_1alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5479838953154563,
    "Overall Score": 7.856695293795835,
    "MMLU Score": 6.259234633569739,
    "BBH Score": 7.086835437371295,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.0754373592464
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.1_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6532249263422252,
    "Overall Score": 8.047077683691153,
    "MMLU Score": 5.7975029550827415,
    "BBH Score": 6.819112125824454,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.8675032389545345
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.1_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6946543424159073,
    "Overall Score": 7.30787971874518,
    "MMLU Score": 6.286938534278959,
    "BBH Score": 6.6221693974393405,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.312312862767655
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.3_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.635614455627846,
    "Overall Score": 7.891216810785522,
    "MMLU Score": 6.046838061465721,
    "BBH Score": 6.566535873101143,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.8246191415301505
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.3_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.353720692744416,
    "Overall Score": 7.408853983144998,
    "MMLU Score": 6.443927304964539,
    "BBH Score": 6.633772569910765,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.1477201207363072
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_1e-5-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6884974551073353,
    "Overall Score": 7.59126646499979,
    "MMLU Score": 6.02836879432624,
    "BBH Score": 7.674537111648312,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.495870835954102
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.182313887292226,
    "Overall Score": 7.390617436527434,
    "MMLU Score": 6.443927304964539,
    "BBH Score": 6.547597964604411,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.250977440054999
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-2ep_0alp_0lam",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9849166918543724,
    "Overall Score": 7.709276870890068,
    "MMLU Score": 6.342346335697398,
    "BBH Score": 6.797543498373474,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.827339037553792
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7511048688142228,
    "Overall Score": 7.48846250817605,
    "MMLU Score": 6.120715130023639,
    "BBH Score": 6.479625973677142,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.276421499100127
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_4e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.599250543749703,
    "Overall Score": 8.137448792080777,
    "MMLU Score": 5.991430260047281,
    "BBH Score": 7.112517981317336,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.130690425995494
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_6e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6748997032943111,
    "Overall Score": 7.452943905551304,
    "MMLU Score": 5.963726359338062,
    "BBH Score": 7.373346017250125,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.449785196625402
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_7e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7743450616304828,
    "Overall Score": 7.944784882371251,
    "MMLU Score": 5.89908392434988,
    "BBH Score": 7.574128764138837,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.477587282301573
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.5_7e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7628564670187925,
    "Overall Score": 7.688013559253314,
    "MMLU Score": 6.268469267139479,
    "BBH Score": 6.263411227504701,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.361111470552501
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.7_3e-6-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6180608379538362,
    "Overall Score": 7.816323890967756,
    "MMLU Score": 5.982195626477541,
    "BBH Score": 6.770439236577431,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.830673672846632
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.7_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.345510946531508,
    "Overall Score": 7.460108761190238,
    "MMLU Score": 6.3608156028368805,
    "BBH Score": 6.636595785955174,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.1805900425329883
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-MDPO_0.9_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8309944741150623,
    "Overall Score": 7.877893571937886,
    "MMLU Score": 6.37928486997636,
    "BBH Score": 6.534335437371297,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.302521762522167
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_3e-6-1ep_3vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8767476863718147,
    "Overall Score": 7.151029068055777,
    "MMLU Score": 6.2038268321513,
    "BBH Score": 6.10466259440003,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.156313588517575
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6170922607453528,
    "Overall Score": 8.018805167387615,
    "MMLU Score": 6.610150709219859,
    "BBH Score": 6.86099852269675,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.958780251469125
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_10vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7989427864939285,
    "Overall Score": 8.070117533212565,
    "MMLU Score": 6.628619976359339,
    "BBH Score": 7.109440788491956,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.10099555266952
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_1vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8346728545974762,
    "Overall Score": 8.079611266480615,
    "MMLU Score": 6.5178043735224565,
    "BBH Score": 6.97515616139911,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.679973683074952
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_3vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8344717513563957,
    "Overall Score": 7.784158197402131,
    "MMLU Score": 6.545508274231676,
    "BBH Score": 6.852004431909751,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.328246504149885
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6581914337571315,
    "Overall Score": 8.039735734618104,
    "MMLU Score": 6.5178043735224565,
    "BBH Score": 7.2279757961023074,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.848496724169937
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-3ep_1vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8056727355826008,
    "Overall Score": 8.004444649280561,
    "MMLU Score": 6.249999999999999,
    "BBH Score": 7.343317068075329,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.4329431859632775
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VDPO_5e-7-3ep_3vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9629762658816848,
    "Overall Score": 8.231694304691628,
    "MMLU Score": 6.443927304964539,
    "BBH Score": 7.24175202196556,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.548179842371116
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5718164174484692,
    "Overall Score": 8.71371672694166,
    "MMLU Score": 7.0441784869976365,
    "BBH Score": 7.834260900707316,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.5437242099090955
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_10vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8492316769292112,
    "Overall Score": 8.993052881905456,
    "MMLU Score": 7.053413120567376,
    "BBH Score": 7.692240203539559,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.589634284985678
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_1vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8293594279742648,
    "Overall Score": 8.292943161631719,
    "MMLU Score": 7.210401891252953,
    "BBH Score": 7.776385232936402,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.999214914440028
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_30vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8032189364040347,
    "Overall Score": 8.721617990921317,
    "MMLU Score": 7.0441784869976365,
    "BBH Score": 7.655186826633241,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.858332137894434
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_3vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8291183283913374,
    "Overall Score": 8.601146924480913,
    "MMLU Score": 7.238105791962175,
    "BBH Score": 7.67033388545677,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.373847290493424
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_0alp_0lam",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3846643617962733,
    "Overall Score": 8.579605529729827,
    "MMLU Score": 6.563977541371156,
    "BBH Score": 6.099203002357716,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.196162598277481
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_10vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.653186297134859,
    "Overall Score": 8.853042881324415,
    "MMLU Score": 6.4623965721040175,
    "BBH Score": 6.454270227116723,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.55362615559675
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_1vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6594938597017257,
    "Overall Score": 9.001725127164766,
    "MMLU Score": 6.767139479905436,
    "BBH Score": 6.08394171367177,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.649444941361615
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_30vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7392397993919483,
    "Overall Score": 8.944503538443925,
    "MMLU Score": 6.37928486997636,
    "BBH Score": 6.616879159578596,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.099596836914227
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_3vpo_const",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6903602932272771,
    "Overall Score": 8.730937881241061,
    "MMLU Score": 6.573212174940895,
    "BBH Score": 5.989063404661713,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.646929388748468
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-cDPO_5e-7-3ep_0vpo_const_0.1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7898335214086819,
    "Overall Score": 7.905104898093658,
    "MMLU Score": 6.37005023640662,
    "BBH Score": 7.201174679917629,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.008571026454746
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-cDPO_5e-7-3ep_0vpo_const_0.3",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8270344996930198,
    "Overall Score": 7.980367592203365,
    "MMLU Score": 6.296173167848698,
    "BBH Score": 6.9860820873250375,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.649376894392596
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-rDPO_3e-6-1ep_0vpo_const_0.1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7678363288986092,
    "Overall Score": 7.083621157947087,
    "MMLU Score": 5.511229314420804,
    "BBH Score": 6.90518932317681,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.225431112523541
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-rDPO_5e-7-3ep_0vpo_const_0.1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7945318466738231,
    "Overall Score": 8.149323958197453,
    "MMLU Score": 6.767139479905436,
    "BBH Score": 7.1964107499925385,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.256761880990997
  },
  {
    "Model Name": "JayHyeon/Qwen_0.5-rDPO_5e-7-3ep_0vpo_const_0.3",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7159497773067481,
    "Overall Score": 7.715290660055365,
    "MMLU Score": 6.628619976359339,
    "BBH Score": 6.775212492911929,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.776301501312926
  },
  {
    "Model Name": "Jimmy19991222/Llama-3-Instruct-8B-SimPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.026303449176492,
    "Overall Score": 24.59465136328484,
    "MMLU Score": 29.84448877068557,
    "BBH Score": 29.1238227637126,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 23.964307420987076
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9635818182639768,
    "Overall Score": 24.144995316075697,
    "MMLU Score": 29.26270685579196,
    "BBH Score": 27.755228582197063,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 25.05754556429487
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9570708276407988,
    "Overall Score": 24.09614909345055,
    "MMLU Score": 29.53051122931442,
    "BBH Score": 28.613596677525617,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 25.176975828265608
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0449703983820169,
    "Overall Score": 23.03715310569549,
    "MMLU Score": 29.01337174940898,
    "BBH Score": 27.666183558964235,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 22.045747077013033
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.960742202414242,
    "Overall Score": 23.393777045662542,
    "MMLU Score": 28.27460106382979,
    "BBH Score": 29.3297318748178,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 24.349692338773597
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5136981730468009,
    "Overall Score": 24.385612249734205,
    "MMLU Score": 29.53051122931442,
    "BBH Score": 28.390676236054286,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.10995684869618
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0039870513171805,
    "Overall Score": 24.210850058799164,
    "MMLU Score": 29.604388297872337,
    "BBH Score": 28.07503551511944,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 24.114703498452243
  },
  {
    "Model Name": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.973171896245862,
    "Overall Score": 24.056972059408523,
    "MMLU Score": 30.12152777777778,
    "BBH Score": 28.56256683836558,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 24.720167271795912
  },
  {
    "Model Name": "Joseph717171/Hermes-3-Llama-3.1-8B_TIES_with_Base_Embeds_Initialized_to_Special_Instruct_Toks_dtypeF32",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7075451204073241,
    "Overall Score": 23.25287703936368,
    "MMLU Score": 23.823507683215126,
    "BBH Score": 30.72409661414796,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 32.86416140638114
  },
  {
    "Model Name": "Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7494627877110125,
    "Overall Score": 30.245028049214653,
    "MMLU Score": 32.00539302600473,
    "BBH Score": 31.46581339489899,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.288180269777033
  },
  {
    "Model Name": "Josephgflowers/Cinder-Phi-2-V1-F16-gguf",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9428072189943586,
    "Overall Score": 11.258522615146036,
    "MMLU Score": 12.898936170212766,
    "BBH Score": 22.45340222827221,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.941489615612928
  },
  {
    "Model Name": "Josephgflowers/Differential-Attention-Liquid-Metal-Tinyllama",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3475871967533884,
    "Overall Score": 5.250959952944556,
    "MMLU Score": 2.3806885342789585,
    "BBH Score": 2.5522242028124382,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.10688541462616
  },
  {
    "Model Name": "Josephgflowers/TinyLlama-Cinder-Agent-v1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4756630252902916,
    "Overall Score": 6.332677189374276,
    "MMLU Score": 1.7896719858156025,
    "BBH Score": 3.804167155031377,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.313368609026352
  },
  {
    "Model Name": "Josephgflowers/TinyLlama-v1.1-Cinders-World",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5147665325802105,
    "Overall Score": 5.683002628938165,
    "MMLU Score": 2.2052304964539005,
    "BBH Score": 3.107714473502144,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.039961359672589
  },
  {
    "Model Name": "Josephgflowers/TinyLlama_v1.1_math_code-world-test-1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5458875585125622,
    "Overall Score": 2.0028112750677205,
    "MMLU Score": 1.466459810874704,
    "BBH Score": 4.164017098724634,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.668908081592834
  },
  {
    "Model Name": "Josephgflowers/Tinyllama-STEM-Cinder-Agent-v1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3267712803723987,
    "Overall Score": 5.683635033220809,
    "MMLU Score": 0.958554964539006,
    "BBH Score": 3.731312676862636,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.39331261530561
  },
  {
    "Model Name": "Josephgflowers/Tinyllama-r1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.2147723520179736,
    "Overall Score": 5.217266718069099,
    "MMLU Score": 1.4941637115839237,
    "BBH Score": 3.2046589179465896,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.292077956256133
  },
  {
    "Model Name": "JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 1.397413513183364,
    "Overall Score": 47.09154471380421,
    "MMLU Score": 54.27009456264776,
    "BBH Score": 65.46659667305961,
    "Math Score": 28.625377643504528,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 33.69907637899377
  },
  {
    "Model Name": "JungZoona/T3Q-qwen2.5-14b-v1.0-e3",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.561938476492499,
    "Overall Score": 47.09154471380421,
    "MMLU Score": 54.27009456264776,
    "BBH Score": 65.46659667305961,
    "Math Score": 28.625377643504528,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 30.1494235672799
  },
  {
    "Model Name": "Junhoee/Qwen-Megumin",
    "Parameters (B)": 15.231,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.8402978495698914,
    "Overall Score": 33.992180349901545,
    "MMLU Score": 35.54225768321512,
    "BBH Score": 33.64214368642437,
    "Math Score": 49.01812688821752,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.967822443357132
  },
  {
    "Model Name": "KSU-HW-SEC/Llama3-70b-SVA-FT-1415",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 19.20205773179167,
    "Overall Score": 36.11923272324064,
    "MMLU Score": 47.140957446808514,
    "BBH Score": 51.328741195678994,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.8810084433524146
  },
  {
    "Model Name": "KSU-HW-SEC/Llama3-70b-SVA-FT-500",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 18.947476483090963,
    "Overall Score": 35.953711985827894,
    "MMLU Score": 46.96549940898345,
    "BBH Score": 51.8870262488106,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.8975461992478826
  },
  {
    "Model Name": "KSU-HW-SEC/Llama3-70b-SVA-FT-final",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 19.312397977552983,
    "Overall Score": 36.09383714321667,
    "MMLU Score": 47.140957446808514,
    "BBH Score": 51.328741195678994,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.8689464242176936
  },
  {
    "Model Name": "KSU-HW-SEC/Llama3.1-70b-SVA-FT-1000step",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 25.108894169483907,
    "Overall Score": 40.75025867079505,
    "MMLU Score": 47.24253841607565,
    "BBH Score": 55.48536459580824,
    "Math Score": 32.09969788519638,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.6229411934963218
  },
  {
    "Model Name": "Khetterman/DarkAtom-12B-v3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1065675447310444,
    "Overall Score": 25.88038265945612,
    "MMLU Score": 28.29307033096927,
    "BBH Score": 31.6595419899606,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.285569823853141
  },
  {
    "Model Name": "Khetterman/Kosmos-8B-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2588972069970084,
    "Overall Score": 21.31847148009074,
    "MMLU Score": 29.659796099290777,
    "BBH Score": 31.75895920189927,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.93424321032861
  },
  {
    "Model Name": "Kimargin/GPT-NEO-1.3B-wiki",
    "Parameters (B)": 1.316,
    "Architecture": "GPTNeoForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.248672424714661,
    "Overall Score": 5.349183189126563,
    "MMLU Score": 1.0970744680851066,
    "BBH Score": 3.423611572649296,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.283896307191156
  },
  {
    "Model Name": "KingNish/Qwen2.5-0.5b-Test-ft",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3373808598428163,
    "Overall Score": 7.865415598812703,
    "MMLU Score": 7.65366430260047,
    "BBH Score": 6.058845092070314,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.881208438811614
  },
  {
    "Model Name": "KingNish/Reasoning-0.5b",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.51124066474765,
    "Overall Score": 7.163893227645488,
    "MMLU Score": 7.127290189125294,
    "BBH Score": 7.491210642552303,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 14.0127609590321
  },
  {
    "Model Name": "KingNish/Reasoning-Llama-3b-v0.1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3504700051621026,
    "Overall Score": 20.212379567792407,
    "MMLU Score": 22.549128250591018,
    "BBH Score": 19.86245115758441,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.966922249684643
  },
  {
    "Model Name": "KingNish/qwen-1b-continued",
    "Parameters (B)": 1.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.8910725804726569,
    "Overall Score": 4.792600271519794,
    "MMLU Score": 2.897828014184398,
    "BBH Score": 4.387464099020609,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.378462289769512
  },
  {
    "Model Name": "KingNish/qwen-1b-continued-v2",
    "Parameters (B)": 1.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9114872192218902,
    "Overall Score": 4.4416424249765365,
    "MMLU Score": 2.14058806146572,
    "BBH Score": 4.989232311632899,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.872961826901133
  },
  {
    "Model Name": "KingNish/qwen-1b-continued-v2.1",
    "Parameters (B)": 1.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.8904057809009366,
    "Overall Score": 5.461814579103264,
    "MMLU Score": 3.0917553191489344,
    "BBH Score": 4.197658352409889,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.134073583368757
  },
  {
    "Model Name": "KingNish/qwen-1b-continued-v2.2",
    "Parameters (B)": 1.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.9038140571785204,
    "Overall Score": 4.441641963318088,
    "MMLU Score": 2.916297281323877,
    "BBH Score": 4.956068589848116,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.914331579643466
  },
  {
    "Model Name": "Kquant03/CognitiveFusion2-4x7B-BF16",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3320706625435443,
    "Overall Score": 15.629054867362484,
    "MMLU Score": 19.917257683215126,
    "BBH Score": 17.689002759870313,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.690493224844159
  },
  {
    "Model Name": "Kquant03/L3-Pneuma-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6076220151511036,
    "Overall Score": 16.617570099377616,
    "MMLU Score": 24.26677009456265,
    "BBH Score": 28.82020171626968,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.336739571096068
  },
  {
    "Model Name": "Krystalan/DRT-o1-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.745980502612048,
    "Overall Score": 36.16608563724584,
    "MMLU Score": 46.429890661938536,
    "BBH Score": 48.14182185507073,
    "Math Score": 48.26283987915408,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.65463798117141
  },
  {
    "Model Name": "Krystalan/DRT-o1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3219640226212213,
    "Overall Score": 31.402661796813607,
    "MMLU Score": 35.01588356973995,
    "BBH Score": 35.73893662836844,
    "Math Score": 44.78851963746224,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.754551000977827
  },
  {
    "Model Name": "Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9097203198829114,
    "Overall Score": 18.006004625989025,
    "MMLU Score": 20.268173758865245,
    "BBH Score": 16.386034485864904,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 19.79290143624202
  },
  {
    "Model Name": "Kukedlc/NeuralLLaMa-3-8b-DT-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7059282828813764,
    "Overall Score": 21.259598634719698,
    "MMLU Score": 31.017287234042552,
    "BBH Score": 28.008307823364888,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.462187800070613
  },
  {
    "Model Name": "Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8310201685600287,
    "Overall Score": 17.74874162408916,
    "MMLU Score": 22.85387115839244,
    "BBH Score": 22.39171190823084,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-07-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.693362164354161
  },
  {
    "Model Name": "Kukedlc/NeuralSynthesis-7B-v0.1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1925980596664074,
    "Overall Score": 20.01567678141308,
    "MMLU Score": 22.770759456264773,
    "BBH Score": 31.83439540006779,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.78325452500891
  },
  {
    "Model Name": "Kukedlc/NeuralSynthesis-7B-v0.3",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1671442421174545,
    "Overall Score": 20.095272707991136,
    "MMLU Score": 22.77999408983452,
    "BBH Score": 31.811748341244265,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.217471485387208
  },
  {
    "Model Name": "Kukedlc/NeuralSynthesis-7b-v0.4-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1981285001848536,
    "Overall Score": 19.530512651958592,
    "MMLU Score": 22.696882387706854,
    "BBH Score": 31.99718681136041,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.300849741029715
  },
  {
    "Model Name": "Kukedlc/Qwen-2.5-7b-Spanish-o1-CoT",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2730720495918209,
    "Overall Score": 28.57363943059837,
    "MMLU Score": 37.37071513002365,
    "BBH Score": 36.86336502529178,
    "Math Score": 27.26586102719033,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.44463653079164
  },
  {
    "Model Name": "Kumar955/Hemanth-llm",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.672246600024527,
    "Overall Score": 22.14301843712773,
    "MMLU Score": 23.47259160756501,
    "BBH Score": 33.044262388969805,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.286293052791045
  },
  {
    "Model Name": "L-RAGE/3_PRYMMAL-ECE-7B-SLERP-V1",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.17955660208701,
    "Overall Score": 14.854317212289835,
    "MMLU Score": 21.38556442080378,
    "BBH Score": 19.08300948054,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.59313642601621
  },
  {
    "Model Name": "LEESM/llama-2-7b-hf-lora-oki100p",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9676354321139934,
    "Overall Score": 8.782858998727155,
    "MMLU Score": 9.509825650118202,
    "BBH Score": 10.265743141867237,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.076619878975743
  },
  {
    "Model Name": "LEESM/llama-2-7b-hf-lora-oki10p",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4755304334859534,
    "Overall Score": 7.168375740980447,
    "MMLU Score": 7.542848699763592,
    "BBH Score": 9.438287176618806,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.858168681783877
  },
  {
    "Model Name": "LEESM/llama-3-8b-bnb-4b-kowiki231101",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5137752144009051,
    "Overall Score": 9.47249832488312,
    "MMLU Score": 15.83554964539007,
    "BBH Score": 16.93486814930169,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.257532977663382
  },
  {
    "Model Name": "LEESM/llama-3-Korean-Bllossom-8B-trexlab-oki10p",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.516715580023216,
    "Overall Score": 13.509662923847069,
    "MMLU Score": 24.183658392434985,
    "BBH Score": 19.797435760911394,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.907182798003749
  },
  {
    "Model Name": "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    "Parameters (B)": 7.8,
    "Architecture": "ExaoneForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.650255954959219,
    "Overall Score": 25.733775511042666,
    "MMLU Score": 28.63475177304965,
    "BBH Score": 17.97733539518049,
    "Math Score": 30.4380664652568,
    "Date Submitted": "2024-08-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.593808605089139
  },
  {
    "Model Name": "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct",
    "Parameters (B)": 2.405,
    "Architecture": "ExaoneForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2145429205973002,
    "Overall Score": 27.143883211239544,
    "MMLU Score": 25.33798758865248,
    "BBH Score": 15.94743717105687,
    "Math Score": 36.78247734138973,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.349052265596715
  },
  {
    "Model Name": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct",
    "Parameters (B)": 32.003,
    "Architecture": "ExaoneForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 30.99524239129728,
    "Overall Score": 37.60316575566284,
    "MMLU Score": 40.40890957446809,
    "BBH Score": 39.82420331711213,
    "Math Score": 51.283987915407856,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.2131915369766848
  },
  {
    "Model Name": "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct",
    "Parameters (B)": 7.818,
    "Architecture": "ExaoneForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.439943340986877,
    "Overall Score": 32.547229958748495,
    "MMLU Score": 34.81272163120568,
    "BBH Score": 25.65374942082902,
    "Math Score": 47.50755287009064,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.603132381890795
  },
  {
    "Model Name": "LLM360/K2",
    "Parameters (B)": 65.286,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 17.676412835458454,
    "Overall Score": 14.643753289939289,
    "MMLU Score": 22.27208924349881,
    "BBH Score": 28.220402834201128,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.8284346731574562
  },
  {
    "Model Name": "LLM360/K2-Chat",
    "Parameters (B)": 65.286,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 34.519656126302,
    "Overall Score": 24.38714515483088,
    "MMLU Score": 26.34456264775413,
    "BBH Score": 33.79382923599304,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7064712656928605
  },
  {
    "Model Name": "LLM4Binary/llm4decompile-1.3b-v2",
    "Parameters (B)": 1.346,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4951653518830693,
    "Overall Score": 6.93902486034668,
    "MMLU Score": 2.32528073286052,
    "BBH Score": 5.915475430438469,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.013550895591123
  },
  {
    "Model Name": "Lambent/qwen2.5-reinstruct-alternate-lumen-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.529301034479197,
    "Overall Score": 38.07061834522751,
    "MMLU Score": 48.757018321512994,
    "BBH Score": 48.989609006737815,
    "Math Score": 46.22356495468278,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.4054069392641
  },
  {
    "Model Name": "Langboat/Mengzi3-8B-Chat",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7038712588964957,
    "Overall Score": 20.28829250015946,
    "MMLU Score": 23.795803782505907,
    "BBH Score": 25.18829844947557,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.907174555722642
  },
  {
    "Model Name": "Lawnakk/BBA100",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7259936221060549,
    "Overall Score": 5.585008068956385,
    "MMLU Score": 1.3556442080378246,
    "BBH Score": 2.1684042140448265,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.692916161928091
  },
  {
    "Model Name": "Lawnakk/BBALAW1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.670119798592899,
    "Overall Score": 5.709610503141909,
    "MMLU Score": 1.3464095744680846,
    "BBH Score": 2.532750619273585,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.52028326148669
  },
  {
    "Model Name": "Lawnakk/BBALAW1.0",
    "Parameters (B)": 4.353,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4032986216068706,
    "Overall Score": 3.255670000142344,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 1.2476381461675576,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.07260383675678
  },
  {
    "Model Name": "Lawnakk/BBALAW1.2",
    "Parameters (B)": 4.353,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3864818206173981,
    "Overall Score": 3.417479882375676,
    "MMLU Score": 1.1709515366430252,
    "BBH Score": 1.316794909883146,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.84253721666988
  },
  {
    "Model Name": "Lawnakk/BBALAW1.3",
    "Parameters (B)": 4.353,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.373648987936219,
    "Overall Score": 3.35023590128206,
    "MMLU Score": 1.041666666666666,
    "BBH Score": 1.223376519696021,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.96626515646802
  },
  {
    "Model Name": "Lawnakk/BBALAW1.6",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6417412500395793,
    "Overall Score": 31.04865197973137,
    "MMLU Score": 38.968306737588655,
    "BBH Score": 36.42650233476133,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 48.38188596699441
  },
  {
    "Model Name": "Lawnakk/BBALAW1.61",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6594259935922203,
    "Overall Score": 31.793920081305952,
    "MMLU Score": 38.56198286052009,
    "BBH Score": 36.40356700548264,
    "Math Score": 36.63141993957704,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 48.21453869009425
  },
  {
    "Model Name": "Lawnakk/BBALAW1.62",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6135535451642553,
    "Overall Score": 29.539930945484542,
    "MMLU Score": 39.38386524822696,
    "BBH Score": 37.10453758317024,
    "Math Score": 28.24773413897281,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 48.14564462760355
  },
  {
    "Model Name": "Lawnakk/BBALAW1.63",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6989091923818987,
    "Overall Score": 29.37358914303694,
    "MMLU Score": 38.56198286052009,
    "BBH Score": 36.36091509685001,
    "Math Score": 37.00906344410876,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.02776192273429
  },
  {
    "Model Name": "Lawnakk/BBALAW1.64",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.654014424890504,
    "Overall Score": 3.181118091265469,
    "MMLU Score": 1.2817671394799046,
    "BBH Score": 1.7755006354076055,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.863987658679021
  },
  {
    "Model Name": "LenguajeNaturalAI/leniachat-gemma-2b-v0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.933155344561648,
    "Overall Score": 5.737240998088876,
    "MMLU Score": 1.891252955082742,
    "BBH Score": 4.138296963728068,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-09-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.967811673401665
  },
  {
    "Model Name": "LenguajeNaturalAI/leniachat-qwen2-1.5B-v0",
    "Parameters (B)": 1.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6891235326099068,
    "Overall Score": 8.580803348718375,
    "MMLU Score": 9.77763002364066,
    "BBH Score": 12.771666354808303,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.080033036695641
  },
  {
    "Model Name": "LeroyDyer/CheckPoint_A",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.919345737699857,
    "Overall Score": 18.929189414483588,
    "MMLU Score": 20.886894208037827,
    "BBH Score": 25.80938677777848,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.589848452273444
  },
  {
    "Model Name": "LeroyDyer/CheckPoint_B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9203635380516662,
    "Overall Score": 18.53937302293864,
    "MMLU Score": 21.19163711583924,
    "BBH Score": 26.27124893315022,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.143532698160737
  },
  {
    "Model Name": "LeroyDyer/CheckPoint_C",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8722510506606865,
    "Overall Score": 17.11316049965239,
    "MMLU Score": 22.45678191489361,
    "BBH Score": 24.18304052622304,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.619535553084205
  },
  {
    "Model Name": "LeroyDyer/CheckPoint_R1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5266344322747649,
    "Overall Score": 10.767224308402712,
    "MMLU Score": 13.388371749408984,
    "BBH Score": 17.927717512520747,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.445348136266652
  },
  {
    "Model Name": "LeroyDyer/LCARS_AI_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.163983647345908,
    "Overall Score": 14.429205739419857,
    "MMLU Score": 18.559766548463354,
    "BBH Score": 19.460966800253622,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.396399014987058
  },
  {
    "Model Name": "LeroyDyer/LCARS_AI_1x4_003_SuperAI",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.314518020334784,
    "Overall Score": 19.518229049313643,
    "MMLU Score": 21.91193853427896,
    "BBH Score": 28.423430655930204,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.88870808050161
  },
  {
    "Model Name": "LeroyDyer/LCARS_AI_StarTrek_Computer",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3238612018973137,
    "Overall Score": 14.613893572975764,
    "MMLU Score": 16.204934988179666,
    "BBH Score": 21.78100309570489,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.038841195762531
  },
  {
    "Model Name": "LeroyDyer/LCARS_TOP_SCORE",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2266362452075965,
    "Overall Score": 20.32200540421328,
    "MMLU Score": 22.567597517730498,
    "BBH Score": 31.69912679947687,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.567263101518716
  },
  {
    "Model Name": "LeroyDyer/Mixtral_AI_SwahiliTron_7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3969911569441005,
    "Overall Score": 4.358661915319342,
    "MMLU Score": 2.30681146572104,
    "BBH Score": 3.211683047233007,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-07-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 3.1200354373422496
  },
  {
    "Model Name": "LeroyDyer/SpydazWebAI_Human_AGI",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.335430798055127,
    "Overall Score": 9.970349395057786,
    "MMLU Score": 5.317302009456265,
    "BBH Score": 7.445695539873622,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.466017265423444
  },
  {
    "Model Name": "LeroyDyer/SpydazWebAI_Human_AGI_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8848131796026907,
    "Overall Score": 10.209095309808564,
    "MMLU Score": 4.735520094562647,
    "BBH Score": 8.661200013836998,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.538136575217802
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_CyberTron_Ultra_7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.31309207378268,
    "Overall Score": 13.566675630986596,
    "MMLU Score": 20.72990543735224,
    "BBH Score": 27.74553183153259,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-07-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.331854027497478
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAGI_001_M2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8947806161189631,
    "Overall Score": 18.993604787957786,
    "MMLU Score": 22.281323877068555,
    "BBH Score": 27.92150509438776,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.22710801485729
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAGI_002",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8780139193723864,
    "Overall Score": 21.01474000615888,
    "MMLU Score": 22.87234042553192,
    "BBH Score": 29.62691236357759,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.934404162043855
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2883549367569518,
    "Overall Score": 7.741907804524428,
    "MMLU Score": 3.008643617021276,
    "BBH Score": 8.06526235359233,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.00914203349301
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_006",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8978213161790637,
    "Overall Score": 4.896570612993905,
    "MMLU Score": 1.5033983451536632,
    "BBH Score": 6.725319981390316,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.453836442459026
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_007",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8974823394844018,
    "Overall Score": 10.4236168850732,
    "MMLU Score": 3.9136377068557904,
    "BBH Score": 8.46281905839016,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.614286350260112
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_009_CHAT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8955279064095867,
    "Overall Score": 9.615900799535378,
    "MMLU Score": 4.809397163120566,
    "BBH Score": 7.033815600268059,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.737689725480609
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_010_CHAT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.873459797883098,
    "Overall Score": 8.376848844277914,
    "MMLU Score": 4.781693262411347,
    "BBH Score": 7.351959868629893,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.590422895913354
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9255094767140524,
    "Overall Score": 9.775896143015682,
    "MMLU Score": 6.610150709219859,
    "BBH Score": 9.415285279602362,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.562718577149768
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT_ML",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.904510040863411,
    "Overall Score": 13.939790526210038,
    "MMLU Score": 11.31981382978723,
    "BBH Score": 15.599125312205128,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.411427067082242
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT_ML_r1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8817864153323666,
    "Overall Score": 17.981736164423843,
    "MMLU Score": 21.736480496453904,
    "BBH Score": 27.188612130290466,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.392394180450253
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_IA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4704043052333971,
    "Overall Score": 15.1139675375779,
    "MMLU Score": 14.764332151300236,
    "BBH Score": 23.116920348203426,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 32.129738970137424
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_IA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3673417812306632,
    "Overall Score": 15.141877964341816,
    "MMLU Score": 14.644281914893616,
    "BBH Score": 23.177267229664,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.073952520278807
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_MX",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.890738782445888,
    "Overall Score": 8.04579774103192,
    "MMLU Score": 1.1894208037825047,
    "BBH Score": 5.885758837366411,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.032724183108867
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_XA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4610457299103071,
    "Overall Score": 15.915086092179353,
    "MMLU Score": 15.290706264775414,
    "BBH Score": 22.464434124386614,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 34.51953908189435
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_XA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9537306082222248,
    "Overall Score": 16.451680981130227,
    "MMLU Score": 15.429225768321512,
    "BBH Score": 22.728636272258512,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.24981964435065
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8874170892010981,
    "Overall Score": 7.78223636896281,
    "MMLU Score": 3.599660165484633,
    "BBH Score": 7.176494579151711,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.769536290955147
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_AI_HumanAI_TextVision",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.911430325456633,
    "Overall Score": 9.496584895881528,
    "MMLU Score": 4.301492316784869,
    "BBH Score": 7.525593201173674,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.419430460714231
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_HumanAI_M1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3217805289052,
    "Overall Score": 10.391053333653405,
    "MMLU Score": 7.367390661938533,
    "BBH Score": 10.02754339015283,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.861405964468301
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_HumanAI_M2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.262119278883262,
    "Overall Score": 12.484114662749576,
    "MMLU Score": 11.227467494089831,
    "BBH Score": 15.397194202296944,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.89139051405321
  },
  {
    "Model Name": "LeroyDyer/SpydazWeb_HumanAI_M3",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3750988908993114,
    "Overall Score": 5.505800569799587,
    "MMLU Score": 1.6511524822695034,
    "BBH Score": 4.765388996591294,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.003930630908157
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_12",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.297050807163551,
    "Overall Score": 6.615158396750675,
    "MMLU Score": 1.521867612293143,
    "BBH Score": 4.495993524198578,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.1001536410258295
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_14",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2427017129472753,
    "Overall Score": 4.378364522899276,
    "MMLU Score": 1.549571513002364,
    "BBH Score": 2.162400468558809,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.5232626440300394
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4444431573280053,
    "Overall Score": 18.18569530640989,
    "MMLU Score": 19.27083333333333,
    "BBH Score": 24.633582827112217,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.917932938246565
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_002",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4528930157896921,
    "Overall Score": 19.869138876185648,
    "MMLU Score": 21.043882978723403,
    "BBH Score": 25.041939148110867,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.87159479936028
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_MUSR",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4626438746160488,
    "Overall Score": 20.9872217391289,
    "MMLU Score": 20.314346926713945,
    "BBH Score": 25.691235509522457,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.36366499296318
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_MasterCoder",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4411424337479603,
    "Overall Score": 19.155771203993552,
    "MMLU Score": 19.104609929078016,
    "BBH Score": 26.08792985697224,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.42309816184651
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4552535355664265,
    "Overall Score": 20.354655381937874,
    "MMLU Score": 18.679816784869978,
    "BBH Score": 27.307995975060845,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.710592651658615
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_003",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4553579115828525,
    "Overall Score": 22.118137399107567,
    "MMLU Score": 22.20744680851064,
    "BBH Score": 26.687805677059902,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.57308248411353
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_AdvancedStudent",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4530458393635682,
    "Overall Score": 24.34166379927646,
    "MMLU Score": 22.21668144208038,
    "BBH Score": 28.14931404573185,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 53.72892030853049
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_Student",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4670612939138445,
    "Overall Score": 23.588092892468367,
    "MMLU Score": 21.413268321513,
    "BBH Score": 27.80031591237029,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 50.50320632396376
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_Teacher",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4429826487447223,
    "Overall Score": 23.69427042218614,
    "MMLU Score": 21.736480496453904,
    "BBH Score": 26.94544131311821,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 53.48803274649351
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_001",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4908039443571255,
    "Overall Score": 22.49357945577393,
    "MMLU Score": 21.17316784869976,
    "BBH Score": 28.227992314307016,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.830070671573175
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_002",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4598289986506186,
    "Overall Score": 20.794293676873966,
    "MMLU Score": 20.739140070921984,
    "BBH Score": 25.171424439523,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.221797098259174
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_Coder",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2062289710968703,
    "Overall Score": 22.6446676484694,
    "MMLU Score": 20.997709810874703,
    "BBH Score": 24.68925580138104,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.77310874723705
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_Math",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4568755966333913,
    "Overall Score": 19.84226778022403,
    "MMLU Score": 21.256279550827426,
    "BBH Score": 25.173866858214165,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.43035155836081
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_MathMaster",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4462280679498404,
    "Overall Score": 21.160821436103028,
    "MMLU Score": 18.578235815602834,
    "BBH Score": 26.599272622298702,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 47.421538347699084
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Student_Coder",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.442445862401488,
    "Overall Score": 20.71902736748913,
    "MMLU Score": 19.64945330969267,
    "BBH Score": 25.0582336059518,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 46.82838993008391
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Teacher_Coder",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4511272618948587,
    "Overall Score": 20.669991182750483,
    "MMLU Score": 20.499039598108748,
    "BBH Score": 27.13550121385457,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.818537092905515
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Top_Student",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4684555914093289,
    "Overall Score": 25.30674491645848,
    "MMLU Score": 22.49372044917257,
    "BBH Score": 29.306594525870576,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 54.02165195707069
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_X1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.428180268927522,
    "Overall Score": 18.16205847224752,
    "MMLU Score": 21.006944444444443,
    "BBH Score": 26.46227536747539,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.416850542269636
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_X2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4489632683371048,
    "Overall Score": 22.42330329057481,
    "MMLU Score": 21.339391252955085,
    "BBH Score": 27.24420156630025,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 49.944627705574874
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_AGI_RP_R1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4377863974445924,
    "Overall Score": 20.102174437145493,
    "MMLU Score": 21.043882978723403,
    "BBH Score": 25.310204381698416,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.917768469929875
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_BIBLE_002",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.306499756515286,
    "Overall Score": 6.86090172693433,
    "MMLU Score": 4.089095744680851,
    "BBH Score": 6.349580156104774,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.251360892124328
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_ChatML_002",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.281609869501494,
    "Overall Score": 5.715725326733474,
    "MMLU Score": 1.0509013002364058,
    "BBH Score": 4.191974214495695,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-09-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.459801272408047
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_ChatQA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.164158799637762,
    "Overall Score": 5.115133515206828,
    "MMLU Score": 5.280363475177306,
    "BBH Score": 5.599561733978841,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.39384516682642
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_ChatQA_003",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2596251679493742,
    "Overall Score": 6.2575600117500825,
    "MMLU Score": 1.4756944444444438,
    "BBH Score": 4.293436202390652,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.967795317981119
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_TEMP_",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4634054285946802,
    "Overall Score": 21.34804249572284,
    "MMLU Score": 23.56493794326241,
    "BBH Score": 28.61644015422753,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 46.06774366123149
  },
  {
    "Model Name": "LeroyDyer/_Spydaz_Web_AI_Top_Teacher_",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4339501503886698,
    "Overall Score": 20.895686397389127,
    "MMLU Score": 23.88815011820331,
    "BBH Score": 27.7244640207969,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.152273662478954
  },
  {
    "Model Name": "LightningRodLabs/Flashlight-v1.0",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.849830641990592,
    "Overall Score": 40.5748695700393,
    "MMLU Score": 48.91400709219858,
    "BBH Score": 55.15022389243257,
    "Math Score": 49.69788519637463,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.934369908791712
  },
  {
    "Model Name": "LightningRodLabs/Flashlight-v1.1",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7236163211583977,
    "Overall Score": 40.98595152297397,
    "MMLU Score": 49.06176122931441,
    "BBH Score": 55.432811255376855,
    "Math Score": 53.24773413897282,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.77904584671627
  },
  {
    "Model Name": "LightningRodLabs/Flashlight-v1.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.9192427357924062,
    "Overall Score": 16.37861284160058,
    "MMLU Score": 16.500443262411345,
    "BBH Score": 6.159209487289303,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.179024864171649
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-2B-SLERP-V1",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6337057897117258,
    "Overall Score": 21.160448654695188,
    "MMLU Score": 18.642878250591018,
    "BBH Score": 19.53491130754225,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.823379733881515
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-2B-SLERP-V2",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.579664968730134,
    "Overall Score": 21.073953219725933,
    "MMLU Score": 19.38164893617021,
    "BBH Score": 20.19737664058305,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.169259758603381
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-7B-SLERP",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.360989849337451,
    "Overall Score": 31.51530852235753,
    "MMLU Score": 38.968306737588655,
    "BBH Score": 36.48257004939404,
    "Math Score": 36.329305135951664,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.156167209990304
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.499199739214168,
    "Overall Score": 3.733001542831197,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 2.784018230925968,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.4936787501446274
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.550422871160006,
    "Overall Score": 3.733001542831197,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 2.784018230925968,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.4636794490214557
  },
  {
    "Model Name": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.571601700573797,
    "Overall Score": 8.878726613265554,
    "MMLU Score": 9.075797872340424,
    "BBH Score": 10.612229209084203,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.452605670343296
  },
  {
    "Model Name": "Lil-R/PRYMMAL-ECE-1B-SLERP-V1",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2946189513567496,
    "Overall Score": 14.88329630475093,
    "MMLU Score": 21.39479905437352,
    "BBH Score": 17.999676133564762,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.496275633191807
  },
  {
    "Model Name": "Lil-R/PRYMMAL-ECE-7B-SLERP-V8",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.5562215438928173,
    "Overall Score": 3.386229392038714,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 2.270601109130521,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.324701061271041
  },
  {
    "Model Name": "LilRg/10PRYMMAL-3B-slerp",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.117509941048346,
    "Overall Score": 21.087895754438843,
    "MMLU Score": 32.014627659574465,
    "BBH Score": 34.877917500461,
    "Math Score": 14.954682779456194,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.121516658456378
  },
  {
    "Model Name": "LilRg/ECE-1B-merge-PRYMMAL",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3807140737643455,
    "Overall Score": 14.497652546900952,
    "MMLU Score": 21.1824024822695,
    "BBH Score": 19.141465000010825,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.50011209589173
  },
  {
    "Model Name": "LilRg/ECE_Finetunning",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.5403764871403727,
    "Overall Score": 11.987032259556209,
    "MMLU Score": 24.34988179669031,
    "BBH Score": 26.530834895216355,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3858072165760977
  },
  {
    "Model Name": "LilRg/PRYMMAL-6B-slerp",
    "Parameters (B)": 3.293,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6961630869331326,
    "Overall Score": 3.23270592407536,
    "MMLU Score": 1.198655437352245,
    "BBH Score": 2.2124311744899985,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.64360432886018
  },
  {
    "Model Name": "LilRg/PRYMMAL-ECE-7B-SLERP-V3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.562254215088475,
    "Overall Score": 3.533946396700676,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.290323331352744,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3792333234891951
  },
  {
    "Model Name": "LilRg/PRYMMAL-ECE-7B-SLERP-V4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.6114206257376,
    "Overall Score": 3.54393840309556,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.290323331352744,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3570921391089836
  },
  {
    "Model Name": "LilRg/PRYMMAL-ECE-7B-SLERP-V5",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.5728503968169294,
    "Overall Score": 3.54393840309556,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.290323331352744,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.377436638943344
  },
  {
    "Model Name": "LilRg/PRYMMAL-ECE-7B-SLERP-V6",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.495682107974202,
    "Overall Score": 3.533946396700676,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.290323331352744,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.4160242546152062
  },
  {
    "Model Name": "LilRg/PRYMMAL-ECE-7B-SLERP-V7",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.5492398159940417,
    "Overall Score": 3.54393840309556,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 2.290323331352744,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3901941986237372
  },
  {
    "Model Name": "LilRg/PRYMMAL-slerp-Merge",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.835027089600448,
    "Overall Score": 23.42765486276747,
    "MMLU Score": 31.811465721040182,
    "BBH Score": 35.553775523419816,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.263644093104318
  },
  {
    "Model Name": "LimYeri/CodeMind-Llama3-8B-unsloth_v2-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6532492673325214,
    "Overall Score": 22.47290731923821,
    "MMLU Score": 27.840573286052013,
    "BBH Score": 26.655629407381003,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.593175429315457
  },
  {
    "Model Name": "LimYeri/CodeMind-Llama3-8B-unsloth_v3-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.67256213437446,
    "Overall Score": 21.90871377207617,
    "MMLU Score": 27.729757683215126,
    "BBH Score": 27.02521610839599,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.098893800002264
  },
  {
    "Model Name": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4646248117248355,
    "Overall Score": 21.711489727026887,
    "MMLU Score": 26.150635342789595,
    "BBH Score": 26.37017668673992,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.823925931896547
  },
  {
    "Model Name": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7742841471854716,
    "Overall Score": 17.61324636978146,
    "MMLU Score": 26.14140070921986,
    "BBH Score": 24.57473532012109,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.926959217733625
  },
  {
    "Model Name": "LimYeri/CodeMind-Llama3.1-8B-unsloth-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6673737820627772,
    "Overall Score": 22.317695413728828,
    "MMLU Score": 26.002881205673763,
    "BBH Score": 24.185738827978955,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-08-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.38493843061313
  },
  {
    "Model Name": "Locutusque/CollectiveLM-Falcon-3-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.255770375940584,
    "Overall Score": 22.94962177916018,
    "MMLU Score": 28.874852245862886,
    "BBH Score": 30.78734455849681,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.2753329898953
  },
  {
    "Model Name": "Locutusque/Hercules-6.0-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.770286150299259,
    "Overall Score": 23.836013153195413,
    "MMLU Score": 29.050310283687946,
    "BBH Score": 26.63965184405082,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.464497335171515
  },
  {
    "Model Name": "Locutusque/Hercules-6.1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9136060068848613,
    "Overall Score": 22.723248561634563,
    "MMLU Score": 29.650561465721044,
    "BBH Score": 24.151873375413786,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.874570042046166
  },
  {
    "Model Name": "Locutusque/Llama-3-NeuralHercules-5.0-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7814295450242073,
    "Overall Score": 16.042475909115613,
    "MMLU Score": 21.47791075650118,
    "BBH Score": 16.34207153663529,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.005394546152324
  },
  {
    "Model Name": "Locutusque/Llama-3-Yggdrasil-2.0-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.629881836380663,
    "Overall Score": 20.46019749438689,
    "MMLU Score": 24.072842789598106,
    "BBH Score": 26.922800957191782,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.55317841925343
  },
  {
    "Model Name": "Locutusque/TinyMistral-248M-v2.5",
    "Parameters (B)": 0.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.4844288518969972,
    "Overall Score": 4.035439468453137,
    "MMLU Score": 1.5033983451536632,
    "BBH Score": 3.181881126755549,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.330303722931808
  },
  {
    "Model Name": "Luni/StarDust-12b-v1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.90526607847839,
    "Overall Score": 23.44797955440925,
    "MMLU Score": 26.7970596926714,
    "BBH Score": 34.44627563758498,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.070854414370867
  },
  {
    "Model Name": "Luni/StarDust-12b-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.0650490699095467,
    "Overall Score": 24.215076436734588,
    "MMLU Score": 27.10180260047281,
    "BBH Score": 34.95288411454464,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.900387851685912
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.879799645775924,
    "Overall Score": 41.23204160839732,
    "MMLU Score": 48.82166075650118,
    "BBH Score": 49.31202888085861,
    "Math Score": 41.616314199395774,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.627363619997261
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.967547112591384,
    "Overall Score": 39.28165983782925,
    "MMLU Score": 47.24253841607565,
    "BBH Score": 48.72079878457851,
    "Math Score": 34.66767371601209,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.900741874788382
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.61707672271528,
    "Overall Score": 40.96266321754947,
    "MMLU Score": 46.00509751773049,
    "BBH Score": 49.50507308185843,
    "Math Score": 43.58006042296073,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.33130471927633
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9257024670705207,
    "Overall Score": 40.64719439278672,
    "MMLU Score": 48.8031914893617,
    "BBH Score": 49.104366248398456,
    "Math Score": 39.57703927492447,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.10772307137424
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v6-cpt",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.968517364465306,
    "Overall Score": 34.927489569706715,
    "MMLU Score": 46.71616430260048,
    "BBH Score": 44.89488240805749,
    "Math Score": 33.157099697885194,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.743043673477484
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v7",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9439535309616705,
    "Overall Score": 40.859469762785686,
    "MMLU Score": 48.6184988179669,
    "BBH Score": 50.00470562826306,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.01874819125567
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v7-rebase",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.905122732018174,
    "Overall Score": 39.62401757502077,
    "MMLU Score": 47.519577423167846,
    "BBH Score": 48.854078526667685,
    "Math Score": 34.06344410876133,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.798669245338036
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.303604837640059,
    "Overall Score": 42.7836905135922,
    "MMLU Score": 46.73463356973996,
    "BBH Score": 49.0341381962539,
    "Math Score": 55.58912386706949,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.066907664378258
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9989400208093275,
    "Overall Score": 38.22998867442242,
    "MMLU Score": 47.667331560283685,
    "BBH Score": 49.07822518409933,
    "Math Score": 36.5558912386707,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.125130457363063
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.991233591353564,
    "Overall Score": 39.62574720619401,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 48.98525935245095,
    "Math Score": 40.70996978851964,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.900099806601773
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.7",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.563218021168188,
    "Overall Score": 43.09341097373618,
    "MMLU Score": 47.13172281323877,
    "BBH Score": 49.91009317302106,
    "Math Score": 54.0785498489426,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.093958527861329
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.8",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7597076355480763,
    "Overall Score": 41.54655143545798,
    "MMLU Score": 48.03671690307329,
    "BBH Score": 50.74642495052259,
    "Math Score": 42.37160120845921,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.609917122691773
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.9",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4618021251597524,
    "Overall Score": 42.523098714975845,
    "MMLU Score": 46.66075650118204,
    "BBH Score": 49.94686965422407,
    "Math Score": 53.70090634441088,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.283515110793203
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9849218611245187,
    "Overall Score": 38.87089983109002,
    "MMLU Score": 49.13563829787233,
    "BBH Score": 50.25550159491318,
    "Math Score": 43.65558912386707,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.5830881771177
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9-stock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0047170912565835,
    "Overall Score": 40.70544769121661,
    "MMLU Score": 49.02482269503546,
    "BBH Score": 50.620019436503945,
    "Math Score": 41.842900302114806,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.304833968219373
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6595945851512308,
    "Overall Score": 43.309072158690384,
    "MMLU Score": 47.23330378250591,
    "BBH Score": 50.73787805937095,
    "Math Score": 54.68277945619335,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.09617586498924
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6805573291447646,
    "Overall Score": 43.22504860283835,
    "MMLU Score": 47.593454491725765,
    "BBH Score": 50.455174757059126,
    "Math Score": 53.32326283987915,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 25.72066293319227
  },
  {
    "Model Name": "Lunzima/NQLSG-Qwen2.5-14B-OriginalFusion",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.70382521675319,
    "Overall Score": 40.60963092380559,
    "MMLU Score": 47.09478427895981,
    "BBH Score": 50.991749442122575,
    "Math Score": 42.74924471299094,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.834387779041865
  },
  {
    "Model Name": "Lyte/Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8314746833161264,
    "Overall Score": 25.75346114088417,
    "MMLU Score": 29.08724881796691,
    "BBH Score": 27.83521213410715,
    "Math Score": 19.033232628398792,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.061598216719071
  },
  {
    "Model Name": "Lyte/Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9002666105733118,
    "Overall Score": 14.64730777109662,
    "MMLU Score": 9.362071513002364,
    "BBH Score": 8.894408584162113,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.269966695497967
  },
  {
    "Model Name": "Lyte/Llama-3.2-3B-Overthinker",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4672793947890184,
    "Overall Score": 21.16747363194216,
    "MMLU Score": 22.0596926713948,
    "BBH Score": 20.09558222645716,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.426341504636103
  },
  {
    "Model Name": "M4-ai/TinyMistral-248M-v3",
    "Parameters (B)": 0.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4683672228415573,
    "Overall Score": 4.20563631018843,
    "MMLU Score": 1.466459810874704,
    "BBH Score": 1.7775539303863237,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.979356592617805
  },
  {
    "Model Name": "MEscriva/ECE-PRYMMAL-0.5B-FT-V5-MUSR-Mathis",
    "Parameters (B)": 0.63,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.103112462385385,
    "Overall Score": 3.918738619379433,
    "MMLU Score": 1.7157949172576823,
    "BBH Score": 3.237774271047842,
    "Math Score": 1.0574018126888216,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.8633043593563867
  },
  {
    "Model Name": "MLP-KTLim/llama-3-Korean-Bllossom-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5494411286696896,
    "Overall Score": 20.39691634614766,
    "MMLU Score": 28.819444444444446,
    "BBH Score": 26.927527973055067,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-07-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.164047325670209
  },
  {
    "Model Name": "MTSAIR/Cotype-Nano",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.986576031111959,
    "Overall Score": 13.8127563761264,
    "MMLU Score": 16.40809692671395,
    "BBH Score": 14.446870023241225,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.000701355533838
  },
  {
    "Model Name": "MTSAIR/MultiVerse_70B",
    "Parameters (B)": 72.289,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 27.203634766972748,
    "Overall Score": 32.24436452801163,
    "MMLU Score": 42.89302600472813,
    "BBH Score": 46.135898982415,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.1852961857567175
  },
  {
    "Model Name": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6671382773267995,
    "Overall Score": 15.954087586908154,
    "MMLU Score": 20.702201536643024,
    "BBH Score": 23.990124398411343,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.569744635993843
  },
  {
    "Model Name": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7908402381549982,
    "Overall Score": 17.55322537025943,
    "MMLU Score": 21.1362293144208,
    "BBH Score": 23.698815892387582,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.801670186025934
  },
  {
    "Model Name": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9068485399826428,
    "Overall Score": 16.473094269110153,
    "MMLU Score": 22.2905585106383,
    "BBH Score": 26.69176089392447,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 18.16521011262305
  },
  {
    "Model Name": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7745806463451914,
    "Overall Score": 16.484004626097455,
    "MMLU Score": 22.23515070921986,
    "BBH Score": 26.289712088654472,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.941079653896874
  },
  {
    "Model Name": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4845792557938584,
    "Overall Score": 17.40249479320385,
    "MMLU Score": 23.712692080378247,
    "BBH Score": 24.31144680758701,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.7221729491957
  },
  {
    "Model Name": "Magpie-Align/Llama-3.1-8B-Magpie-Align-SFT-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.749024212957996,
    "Overall Score": 17.975799245688165,
    "MMLU Score": 21.588726359338057,
    "BBH Score": 26.13667696363235,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.538974506283415
  },
  {
    "Model Name": "Magpie-Align/Llama-3.1-8B-Magpie-Align-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4160822155654091,
    "Overall Score": 17.54685483954604,
    "MMLU Score": 25.1348256501182,
    "BBH Score": 24.04053735093787,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.391127186453636
  },
  {
    "Model Name": "Magpie-Align/MagpieLM-8B-Chat-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4737531937094557,
    "Overall Score": 15.026344312964897,
    "MMLU Score": 24.386820330969268,
    "BBH Score": 18.25580502860485,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.195970653093816
  },
  {
    "Model Name": "Magpie-Align/MagpieLM-8B-SFT-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6008421965008803,
    "Overall Score": 17.78392950063439,
    "MMLU Score": 22.1058658392435,
    "BBH Score": 23.61231335017796,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.109108405254739
  },
  {
    "Model Name": "MagusCorp/grpo_lora_enem_llama3_7b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9166090008924256,
    "Overall Score": 21.63438807513112,
    "MMLU Score": 28.59781323877068,
    "BBH Score": 25.896379467976946,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.60263542477493
  },
  {
    "Model Name": "ManoloPueblo/ContentCuisine_1-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.999011673173047,
    "Overall Score": 21.05279849551743,
    "MMLU Score": 22.81693262411348,
    "BBH Score": 32.78974404613455,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.073626125558498
  },
  {
    "Model Name": "ManoloPueblo/LLM_MERGE_CC2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1470867378640075,
    "Overall Score": 20.747367714260108,
    "MMLU Score": 22.57683215130024,
    "BBH Score": 33.241073524404655,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.08700861880229
  },
  {
    "Model Name": "ManoloPueblo/LLM_MERGE_CC3",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.073860880696609,
    "Overall Score": 21.67864029208779,
    "MMLU Score": 23.95279255319149,
    "BBH Score": 33.23001780763082,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.187568689554038
  },
  {
    "Model Name": "MarinaraSpaghetti/NemoReRemix-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.1540150968180765,
    "Overall Score": 22.03458082808498,
    "MMLU Score": 28.865617612293136,
    "BBH Score": 36.12470152357596,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.986200177137559
  },
  {
    "Model Name": "MarinaraSpaghetti/Nemomix-v4.0-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7090968927914263,
    "Overall Score": 24.46797663801924,
    "MMLU Score": 29.03184101654845,
    "BBH Score": 32.879942700903165,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-08-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.031783508048575
  },
  {
    "Model Name": "Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9055799546244083,
    "Overall Score": 12.494620122547149,
    "MMLU Score": 14.154846335697396,
    "BBH Score": 15.297499289020854,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.300215556849914
  },
  {
    "Model Name": "Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3783159566860677,
    "Overall Score": 15.081989145779028,
    "MMLU Score": 21.35786052009456,
    "BBH Score": 19.019948525917457,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.942330800581582
  },
  {
    "Model Name": "Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial",
    "Parameters (B)": 24.16,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8130180920348336,
    "Overall Score": 6.761759514131008,
    "MMLU Score": 4.209145981087471,
    "BBH Score": 8.870227428732667,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7733352821629456
  },
  {
    "Model Name": "Marsouuu/general3B-ECE-PRYMMAL-Martial",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.448885195945408,
    "Overall Score": 22.978904737174783,
    "MMLU Score": 31.959219858156025,
    "BBH Score": 35.70087336193955,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.859713938329588
  },
  {
    "Model Name": "Marsouuu/general3Bv2-ECE-PRYMMAL-Martial",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.434263453665052,
    "Overall Score": 31.917859287211872,
    "MMLU Score": 38.86672576832151,
    "BBH Score": 37.66776306891555,
    "Math Score": 36.70694864048338,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.25383293818888
  },
  {
    "Model Name": "Marsouuu/lareneg1_78B-ECE-PRYMMAL-Martial",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2657841773350142,
    "Overall Score": 15.081989145779028,
    "MMLU Score": 21.35786052009456,
    "BBH Score": 19.019948525917457,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.915134835650019
  },
  {
    "Model Name": "Marsouuu/lareneg3B-ECE-PRYMMAL-Martial",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9819892075314532,
    "Overall Score": 23.942055269453448,
    "MMLU Score": 30.74024822695036,
    "BBH Score": 36.35072191454026,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.381179636016093
  },
  {
    "Model Name": "Marsouuu/lareneg3Bv2-ECE-PRYMMAL-Martial",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3314888159040754,
    "Overall Score": 32.112665840964375,
    "MMLU Score": 39.01447990543734,
    "BBH Score": 37.47164011473157,
    "Math Score": 36.5558912386707,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.117863745749908
  },
  {
    "Model Name": "MaziyarPanahi/Calme-4x7B-MoE-v0.1",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7219662057105984,
    "Overall Score": 20.02390332852601,
    "MMLU Score": 22.85387115839244,
    "BBH Score": 31.26187805626151,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.35641143762788
  },
  {
    "Model Name": "MaziyarPanahi/Calme-4x7B-MoE-v0.2",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.83142235775091,
    "Overall Score": 20.176360946073107,
    "MMLU Score": 22.86310579196217,
    "BBH Score": 31.396819621762447,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.125874700692778
  },
  {
    "Model Name": "MaziyarPanahi/Llama-3-70B-Instruct-v0.1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 22.52797197482258,
    "Overall Score": 26.33391343739024,
    "MMLU Score": 40.196513002364064,
    "BBH Score": 32.71291726367119,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.1689429242375304
  },
  {
    "Model Name": "MaziyarPanahi/Llama-3-8B-Instruct-v0.10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.284261240148562,
    "Overall Score": 26.79740338813341,
    "MMLU Score": 31.80223108747045,
    "BBH Score": 27.924674302120888,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.731321670716868
  },
  {
    "Model Name": "MaziyarPanahi/Llama-3-8B-Instruct-v0.8",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.624846616969708,
    "Overall Score": 26.888884373724007,
    "MMLU Score": 31.700650118203303,
    "BBH Score": 28.270418759783485,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.417937147421295
  },
  {
    "Model Name": "MaziyarPanahi/Llama-3-8B-Instruct-v0.9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5327136470619735,
    "Overall Score": 26.786644392116216,
    "MMLU Score": 31.61753841607564,
    "BBH Score": 27.903013285410186,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.476613745472267
  },
  {
    "Model Name": "MaziyarPanahi/Qwen1.5-MoE-A2.7B-Wikihow",
    "Parameters (B)": 14.316,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 16.612165900607092,
    "Overall Score": 12.325434589632,
    "MMLU Score": 15.336879432624112,
    "BBH Score": 15.47343942401254,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.7419522934803803
  },
  {
    "Model Name": "MaziyarPanahi/Qwen2-7B-Instruct-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9071985413619625,
    "Overall Score": 22.98150895877193,
    "MMLU Score": 31.746823286052013,
    "BBH Score": 31.92360727430821,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2024-07-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.905035941578853
  },
  {
    "Model Name": "MaziyarPanahi/Qwen2-7B-Instruct-v0.8",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.668212714788885,
    "Overall Score": 19.558137588276004,
    "MMLU Score": 28.514701536643027,
    "BBH Score": 25.53252452836148,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2024-07-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.330051865757445
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-llama3.1-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 30.909679147607232,
    "Overall Score": 40.93603260877296,
    "MMLU Score": 47.58421985815603,
    "BBH Score": 48.55364600487639,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2024-07-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.3243758504669527
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-phi3-4b",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5049372475909382,
    "Overall Score": 25.985365252885945,
    "MMLU Score": 30.50938238770685,
    "BBH Score": 38.1242795228128,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.266743377162467
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-phi3.5-4b",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.0091025057578364,
    "Overall Score": 28.000378443622285,
    "MMLU Score": 32.61487884160757,
    "BBH Score": 36.11009692957303,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2024-08-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.93675950499126
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-qwen2-72b",
    "Parameters (B)": 72.699,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.269742406950456,
    "Overall Score": 44.39894388647036,
    "MMLU Score": 49.05252659574468,
    "BBH Score": 57.3258823447103,
    "Math Score": 40.78549848942598,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.6901172154137025
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8685104076670456,
    "Overall Score": 23.5418799100886,
    "MMLU Score": 29.918365839243503,
    "BBH Score": 31.00709744702013,
    "Math Score": 23.11178247734139,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.207005227230523
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-qwen2.5-72b",
    "Parameters (B)": 72.7,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 29.497787277892904,
    "Overall Score": 47.85672202584548,
    "MMLU Score": 51.3242464539007,
    "BBH Score": 61.65570318314716,
    "Math Score": 59.13897280966768,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.6223834545620872
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.1-rys-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 28.66457680547633,
    "Overall Score": 44.64399850290042,
    "MMLU Score": 49.37573877068559,
    "BBH Score": 59.4700307859535,
    "Math Score": 39.42598187311178,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.5574623273130357
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-llama3-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 21.25654661502261,
    "Overall Score": 38.14006369052438,
    "MMLU Score": 46.74386820330969,
    "BBH Score": 48.57170594999846,
    "Math Score": 23.94259818731118,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.7942737539299871
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-llama3.1-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 31.683647635659195,
    "Overall Score": 43.31100681386724,
    "MMLU Score": 49.05252659574468,
    "BBH Score": 54.20646208605566,
    "Math Score": 43.65558912386707,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.3669829721601159
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-phi3-4b",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5935829335350735,
    "Overall Score": 25.23264053363112,
    "MMLU Score": 31.26662234042553,
    "BBH Score": 37.733734155011526,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.83390484589158
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-qwen2-72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 27.03482915645056,
    "Overall Score": 44.09009576064759,
    "MMLU Score": 49.27415780141844,
    "BBH Score": 56.79594225047665,
    "Math Score": 45.31722054380665,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6308627476614779
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.097499105042824,
    "Overall Score": 23.58331943928233,
    "MMLU Score": 32.208554964539005,
    "BBH Score": 33.10936559556884,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.61366464993903
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-qwen2.5-72b",
    "Parameters (B)": 72.7,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 28.5161275490216,
    "Overall Score": 47.22457675508573,
    "MMLU Score": 51.305777186761226,
    "BBH Score": 61.80360419146786,
    "Math Score": 58.91238670694864,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.6560655605815602
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.2-rys-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 27.046712502629788,
    "Overall Score": 44.38633440385336,
    "MMLU Score": 48.72931442080378,
    "BBH Score": 59.268645675184494,
    "Math Score": 40.70996978851964,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6410990577704265
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-llama3-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 19.27361812629732,
    "Overall Score": 37.067032265745496,
    "MMLU Score": 46.71616430260048,
    "BBH Score": 48.0085850617923,
    "Math Score": 23.26283987915408,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.9232005128902332
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-llama3.1-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 28.12111574040212,
    "Overall Score": 43.275189943129554,
    "MMLU Score": 48.4799793144208,
    "BBH Score": 55.58549511699308,
    "Math Score": 39.27492447129909,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.5388859511344102
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-phi3-4b",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6758616959307877,
    "Overall Score": 24.981612770364112,
    "MMLU Score": 31.42361111111111,
    "BBH Score": 37.65889241962552,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.906726987688035
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-qwen2-72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 38.89696999088852,
    "Overall Score": 33.00083092091415,
    "MMLU Score": 49.09869976359338,
    "BBH Score": 51.22830430718469,
    "Math Score": 31.72205438066465,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.8484164943604727
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.6603998269542943,
    "Overall Score": 23.08170100435127,
    "MMLU Score": 29.01337174940898,
    "BBH Score": 30.95608211537095,
    "Math Score": 20.694864048338367,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.305786825358049
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.3-rys-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.59721922269461,
    "Overall Score": 44.55737382877077,
    "MMLU Score": 49.7266548463357,
    "BBH Score": 59.57454695904105,
    "Math Score": 39.80362537764351,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.6752643746588103
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.4-llama3-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 35.487516640485715,
    "Overall Score": 32.48622524876468,
    "MMLU Score": 46.706929669030735,
    "BBH Score": 48.39776612820646,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.9154268408768557
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.4-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2369807670677138,
    "Overall Score": 22.85144077010553,
    "MMLU Score": 33.076610520094555,
    "BBH Score": 31.8182656422348,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.059492290652682
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.4-rys-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.95265640253692,
    "Overall Score": 50.76504719022304,
    "MMLU Score": 66.690676713948,
    "BBH Score": 62.15654929467119,
    "Math Score": 40.70996978851964,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.956063626121165
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.5-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7983382435944977,
    "Overall Score": 22.6595386850518,
    "MMLU Score": 29.79831560283688,
    "BBH Score": 28.28099517875505,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.097498126582925
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.6-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2805416064207,
    "Overall Score": 21.23233085446529,
    "MMLU Score": 30.352393617021285,
    "BBH Score": 29.30841923308876,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.472202886532278
  },
  {
    "Model Name": "MaziyarPanahi/calme-2.7-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.728560577007425,
    "Overall Score": 22.35526715111473,
    "MMLU Score": 30.056885342789595,
    "BBH Score": 28.912244614673995,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.193062429873954
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.1-baguette-3b",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4631794412606185,
    "Overall Score": 25.581601911367752,
    "MMLU Score": 26.658540189125297,
    "BBH Score": 25.50768075774144,
    "Math Score": 25.604229607250755,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.483571180666424
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.1-instruct-3b",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7873243394680145,
    "Overall Score": 21.50709063608992,
    "MMLU Score": 28.413120567375884,
    "BBH Score": 27.30989595933989,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.716034453383613
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.1-instruct-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 64.4378892937895,
    "Overall Score": 51.28748997363473,
    "MMLU Score": 68.72229609929079,
    "BBH Score": 62.40968270370106,
    "Math Score": 39.27492447129909,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.7959213210693696
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.1-llamaloi-3b",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7873980509685603,
    "Overall Score": 24.0933506270088,
    "MMLU Score": 24.497635933806144,
    "BBH Score": 23.7691655758483,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.47956635286305
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.2-baguette-3b",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5520249950030056,
    "Overall Score": 26.332491008465908,
    "MMLU Score": 25.975177304964536,
    "BBH Score": 25.865746650731108,
    "Math Score": 28.24773413897281,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.966537970230895
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.2-instruct-3b",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4868663383387295,
    "Overall Score": 24.62035249644337,
    "MMLU Score": 29.47510342789598,
    "BBH Score": 27.976798242393084,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.558551270957956
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.2-instruct-78b",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 66.01113070973882,
    "Overall Score": 52.08138397879168,
    "MMLU Score": 70.03361406619385,
    "BBH Score": 62.6094432829016,
    "Math Score": 40.33232628398791,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.7889788194630629
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.3-baguette-3b",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.493845837612514,
    "Overall Score": 27.40710052469249,
    "MMLU Score": 26.021350472813243,
    "BBH Score": 25.59659410609641,
    "Math Score": 38.06646525679759,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.34667261816983
  },
  {
    "Model Name": "MaziyarPanahi/calme-3.3-instruct-3b",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5050970304024172,
    "Overall Score": 27.77891097790277,
    "MMLU Score": 25.615026595744684,
    "BBH Score": 25.682137818579093,
    "Math Score": 37.38670694864049,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.456558226332778
  },
  {
    "Model Name": "Minami-su/Amara-o1-7B-Qwen",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2751190711213067,
    "Overall Score": 34.488976713679584,
    "MMLU Score": 34.258643617021285,
    "BBH Score": 32.7968298710958,
    "Math Score": 51.81268882175226,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.04765185838752
  },
  {
    "Model Name": "Minami-su/Amara-o2-7B-Qwen",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9848082871947184,
    "Overall Score": 31.034506834602485,
    "MMLU Score": 35.163637706855795,
    "BBH Score": 31.79812727299554,
    "Math Score": 40.86102719033233,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 31.513247033091098
  },
  {
    "Model Name": "Minami-su/test-7B-00",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5012082113522585,
    "Overall Score": 29.950834319546107,
    "MMLU Score": 28.75480200945626,
    "BBH Score": 21.48995001898129,
    "Math Score": 45.16616314199396,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.951152740209828
  },
  {
    "Model Name": "Minami-su/test-7B-01",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5290372610276757,
    "Overall Score": 30.08150931571436,
    "MMLU Score": 28.173020094562645,
    "BBH Score": 20.824494266256867,
    "Math Score": 45.54380664652568,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.673496573586693
  },
  {
    "Model Name": "Minami-su/test-v2-7B-00",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5334495807759827,
    "Overall Score": 29.484350067576724,
    "MMLU Score": 27.47118794326241,
    "BBH Score": 21.19075482398095,
    "Math Score": 44.18429003021148,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.22746625464956
  },
  {
    "Model Name": "ModelCloud/Llama-3.2-1B-Instruct-gptqmodel-4bit-vortex-v1",
    "Parameters (B)": 5.453,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3218277469924238,
    "Overall Score": 12.430004377968435,
    "MMLU Score": 8.494015957446807,
    "BBH Score": 5.859172283470534,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.403649156443135
  },
  {
    "Model Name": "ModelSpace/GemmaX2-28-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0660588261144064,
    "Overall Score": 5.991108905848541,
    "MMLU Score": 13.67464539007092,
    "BBH Score": 11.707676917585225,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.619867083400135
  },
  {
    "Model Name": "MoonRide/Llama-3.2-3B-Khelavaster",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5762180237117631,
    "Overall Score": 20.144904682630184,
    "MMLU Score": 23.57417257683215,
    "BBH Score": 22.686343682382105,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 34.96055981183106
  },
  {
    "Model Name": "Mostafa8Mehrabi/llama-3.2-1b-Insomnia-ChatBot-merged",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.776372786246016,
    "Overall Score": 3.192716297399995,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 2.4675184428555217,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.112349574793431
  },
  {
    "Model Name": "MrRobotoAI/MrRoboto-ProLong-8b-v4i",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.158625045394304,
    "Overall Score": 17.58291861856009,
    "MMLU Score": 22.9831560283688,
    "BBH Score": 23.792248519686385,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.175676279789254
  },
  {
    "Model Name": "MrRobotoAI/MrRoboto-ProLongBASE-pt8-unaligned-8b",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4513738415171142,
    "Overall Score": 15.935345737822864,
    "MMLU Score": 17.396202718676122,
    "BBH Score": 22.9412099929998,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.979490798294753
  },
  {
    "Model Name": "MultivexAI/Gladiator-Mini-Exp-1211-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1915628190823662,
    "Overall Score": 22.27221013046616,
    "MMLU Score": 23.90661938534279,
    "BBH Score": 22.116062493215253,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.691595418878713
  },
  {
    "Model Name": "MultivexAI/Gladiator-Mini-Exp-1221-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2021382255133486,
    "Overall Score": 20.11435226147892,
    "MMLU Score": 22.76152482269504,
    "BBH Score": 20.39546213621821,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.73214596673315
  },
  {
    "Model Name": "MultivexAI/Gladiator-Mini-Exp-1221-3B-Instruct-V2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1815760239132476,
    "Overall Score": 20.41519559580984,
    "MMLU Score": 22.50295508274231,
    "BBH Score": 20.65124813871924,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.277936571695996
  },
  {
    "Model Name": "MultivexAI/Gladiator-Mini-Exp-1222-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2116490881751003,
    "Overall Score": 20.35308859293152,
    "MMLU Score": 22.410608747044915,
    "BBH Score": 20.567490871055163,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.79784088608187
  },
  {
    "Model Name": "MultivexAI/Phi-3.5-Mini-Instruct-MultiVex-v0.25-GGUF",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0121245066641238,
    "Overall Score": 3.83477046380236,
    "MMLU Score": 1.2078900709219855,
    "BBH Score": 1.6023814703484736,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.7888327360449328
  },
  {
    "Model Name": "Mxode/NanoLM-0.3B-Instruct-v1",
    "Parameters (B)": 0.315,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.212551609892044,
    "Overall Score": 5.737739264323998,
    "MMLU Score": 1.1709515366430252,
    "BBH Score": 3.104609898338746,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.731954679302138
  },
  {
    "Model Name": "Mxode/NanoLM-0.3B-Instruct-v1.1",
    "Parameters (B)": 0.315,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2149597582994591,
    "Overall Score": 5.974298608437977,
    "MMLU Score": 1.3464095744680846,
    "BBH Score": 3.0952799822018195,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.917281060238583
  },
  {
    "Model Name": "Mxode/NanoLM-0.3B-Instruct-v2",
    "Parameters (B)": 0.315,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2130422448625946,
    "Overall Score": 5.01367055199107,
    "MMLU Score": 1.4941637115839237,
    "BBH Score": 2.20948104466638,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.133137632448229
  },
  {
    "Model Name": "Mxode/NanoLM-1B-Instruct-v1.1",
    "Parameters (B)": 1.076,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6509597362924062,
    "Overall Score": 6.756723242219516,
    "MMLU Score": 2.3899231678486985,
    "BBH Score": 6.106919191919192,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.092603286251684
  },
  {
    "Model Name": "Mxode/NanoLM-1B-Instruct-v2",
    "Parameters (B)": 1.076,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6205629500777163,
    "Overall Score": 7.35441459615685,
    "MMLU Score": 2.639258274231678,
    "BBH Score": 4.910622895622894,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.538185076861198
  },
  {
    "Model Name": "NAPS-ai/naps-gemma-2-27b-v-0.1.0",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 22.449722077818265,
    "Overall Score": 1.6796019124036488,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.07481615614579037
  },
  {
    "Model Name": "NAPS-ai/naps-gemma-2-27b-v0.1.0",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 34.0134345443038,
    "Overall Score": 1.6796019124036488,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.0493805443321492
  },
  {
    "Model Name": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9386157659309933,
    "Overall Score": 23.27833752065767,
    "MMLU Score": 26.64930555555556,
    "BBH Score": 26.27454019814682,
    "Math Score": 19.033232628398792,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.007710826326933
  },
  {
    "Model Name": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7838555808247465,
    "Overall Score": 27.71508453774743,
    "MMLU Score": 27.498891843971627,
    "BBH Score": 27.832818693945708,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.536619015387814
  },
  {
    "Model Name": "NAPS-ai/naps-llama-3_1-instruct-v0.5.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.2752422230364955,
    "Overall Score": 16.000822862572466,
    "MMLU Score": 17.93181146572104,
    "BBH Score": 18.110133310152776,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.032579960307729
  },
  {
    "Model Name": "NAPS-ai/naps-llama-3_1_instruct-v0.6.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5754005635001274,
    "Overall Score": 15.779501356421212,
    "MMLU Score": 24.894725177304963,
    "BBH Score": 22.339533869982745,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.016183643709821
  },
  {
    "Model Name": "NAPS-ai/naps-llama3.1-70B-v0.2-fp16",
    "Parameters (B)": 70.761,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 148.7725359700582,
    "Overall Score": 4.215465224433852,
    "MMLU Score": 1.0970744680851066,
    "BBH Score": 3.070260983991484,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.028334969199437808
  },
  {
    "Model Name": "NCSOFT/Llama-VARCO-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1900045983108498,
    "Overall Score": 20.98350927266516,
    "MMLU Score": 24.33141252955083,
    "BBH Score": 29.177056729688577,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.633132932805612
  },
  {
    "Model Name": "NJS26/NJS_777",
    "Parameters (B)": 10.362,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9693995075895436,
    "Overall Score": 4.500174317249103,
    "MMLU Score": 1.8081412529550824,
    "BBH Score": 3.1606011091305213,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.6422288045503475
  },
  {
    "Model Name": "NLPark/AnFeng_v3.1-Avocet",
    "Parameters (B)": 34.393,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.344016066691716,
    "Overall Score": 28.39095634882293,
    "MMLU Score": 38.20183215130024,
    "BBH Score": 40.309033651453255,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.475233992215955
  },
  {
    "Model Name": "NLPark/B-and-W_Flycatcher-3AD1E",
    "Parameters (B)": 14.77,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.1026445938483675,
    "Overall Score": 30.46733295261729,
    "MMLU Score": 41.56323877068557,
    "BBH Score": 43.74245801092346,
    "Math Score": 23.791540785498487,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.81979470449985
  },
  {
    "Model Name": "NLPark/Shi-Ci-Robin-Test_3AD80",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.89350896071393,
    "Overall Score": 39.234122021270416,
    "MMLU Score": 45.78346631205674,
    "BBH Score": 52.265661751102094,
    "Math Score": 31.57099697885196,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.5760784099657603
  },
  {
    "Model Name": "NTQAI/NxMobileLM-1.5B-SFT",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6783146614348514,
    "Overall Score": 18.734829287552035,
    "MMLU Score": 20.19429669030733,
    "BBH Score": 16.162542725891466,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.162882454673284
  },
  {
    "Model Name": "NTQAI/Nxcode-CQ-7B-orpo",
    "Parameters (B)": 7.25,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6843498267871817,
    "Overall Score": 12.373779699446112,
    "MMLU Score": 6.794843380614658,
    "BBH Score": 17.58000487008142,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.346324084616387
  },
  {
    "Model Name": "NYTK/PULI-GPTrio",
    "Parameters (B)": 7.673,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.444093990695365,
    "Overall Score": 5.833727911056492,
    "MMLU Score": 1.521867612293143,
    "BBH Score": 3.015221141570497,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.039714830644379
  },
  {
    "Model Name": "NYTK/PULI-LlumiX-32K",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.6451394799256278,
    "Overall Score": 6.519109356715034,
    "MMLU Score": 7.561317966903072,
    "BBH Score": 5.107047129907727,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.9626484175127477
  },
  {
    "Model Name": "Naveenpoliasetty/llama3-8B-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.50402447937112,
    "Overall Score": 20.820686737632144,
    "MMLU Score": 30.41703605200945,
    "BBH Score": 30.873209425039573,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.843316397574812
  },
  {
    "Model Name": "NbAiLab/nb-llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.495082112488492,
    "Overall Score": 8.479797435320535,
    "MMLU Score": 2.186761229314421,
    "BBH Score": 5.448858800501278,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.671793786099361
  },
  {
    "Model Name": "NbAiLab/nb-llama-3.1-8B-sft",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.476169872939846,
    "Overall Score": 8.180260967339196,
    "MMLU Score": 2.4638002364066187,
    "BBH Score": 5.952497646658256,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.5415444504689075
  },
  {
    "Model Name": "Nekochu/Llama-3.1-8B-German-ORPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8883950726456664,
    "Overall Score": 23.25405221583384,
    "MMLU Score": 26.59389775413712,
    "BBH Score": 29.419254274936463,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.314188144567973
  },
  {
    "Model Name": "Nekochu/Llama-3.1-8B-french-DPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6424149313308514,
    "Overall Score": 21.701292312420733,
    "MMLU Score": 26.824763593380613,
    "BBH Score": 30.03259699633449,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.213038860305625
  },
  {
    "Model Name": "Nekochu/Luminia-13B-v3",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.277759486101257,
    "Overall Score": 11.635076640566735,
    "MMLU Score": 13.499187352245862,
    "BBH Score": 17.690523920374847,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.10812344831104
  },
  {
    "Model Name": "Nekochu/Luminia-8B-RP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9051954807151352,
    "Overall Score": 24.61809279716832,
    "MMLU Score": 29.235002955082745,
    "BBH Score": 31.802699112572423,
    "Math Score": 13.595166163141997,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.921557418311563
  },
  {
    "Model Name": "NeverSleep/Lumimaid-v0.2-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.1283867273639814,
    "Overall Score": 18.14731443655369,
    "MMLU Score": 27.905215721040182,
    "BBH Score": 34.40988943485442,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.800853928262523
  },
  {
    "Model Name": "NeverSleep/Lumimaid-v0.2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4793910691125391,
    "Overall Score": 24.41199658071584,
    "MMLU Score": 29.290410756501185,
    "BBH Score": 31.96337378118024,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2024-08-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.50138160923208
  },
  {
    "Model Name": "Nexesenex/Dolphin3.0-Llama3.1-1B-abliterated",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.34511206922249,
    "Overall Score": 11.3783917872545,
    "MMLU Score": 4.14450354609929,
    "BBH Score": 6.8620788810826765,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 32.970135796435954
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DeepDive_3_Prev_v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6851869942793544,
    "Overall Score": 26.648390871227136,
    "MMLU Score": 27.08333333333333,
    "BBH Score": 31.12274661129916,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.89214344947482
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DeepDive_3_R1_Prev_v1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3836783278954334,
    "Overall Score": 27.472783833453928,
    "MMLU Score": 27.12027186761229,
    "BBH Score": 30.73278378127992,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.854892050842388
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DobHerWild_R1_v1.1R",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6974687182638726,
    "Overall Score": 29.728397716509164,
    "MMLU Score": 29.8721926713948,
    "BBH Score": 32.825750312399464,
    "Math Score": 23.187311178247736,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.623270317425266
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DoberWild_v2.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6568801609790043,
    "Overall Score": 30.16438239831213,
    "MMLU Score": 31.00805260047281,
    "BBH Score": 32.37775915384321,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.92067806303602
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DoberWild_v2.02",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6844381598060006,
    "Overall Score": 29.47563015963895,
    "MMLU Score": 30.71254432624113,
    "BBH Score": 33.35331271516665,
    "Math Score": 19.939577039274926,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.06543949564942
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DoberWild_v2.03",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6694867320616492,
    "Overall Score": 29.82476968118114,
    "MMLU Score": 30.24157801418439,
    "BBH Score": 33.032829118870865,
    "Math Score": 20.77039274924472,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.54870911233346
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DodoWild_v2.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6917604997282902,
    "Overall Score": 30.309648600363573,
    "MMLU Score": 30.4262706855792,
    "BBH Score": 32.110872058033216,
    "Math Score": 19.86404833836858,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.81523462566683
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DodoWild_v2.02",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6860352698884155,
    "Overall Score": 30.73355916962436,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 32.31915252588661,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.79880338313104
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DodoWild_v2.03",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6845834230731944,
    "Overall Score": 30.60438973869286,
    "MMLU Score": 30.952644799054376,
    "BBH Score": 33.022959512096214,
    "Math Score": 22.20543806646526,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.70512826808646
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_DodoWild_v2.10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6632804225210029,
    "Overall Score": 30.406547342023725,
    "MMLU Score": 31.719119385342783,
    "BBH Score": 32.75807763538685,
    "Math Score": 19.71299093655589,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.842672736297885
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Dolermed_R1_V1.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.711628014074646,
    "Overall Score": 29.312043044222406,
    "MMLU Score": 30.361628250591018,
    "BBH Score": 33.28793158004305,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.19011964746476
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Dolermed_R1_V1.03",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6868622213761216,
    "Overall Score": 29.78932292513281,
    "MMLU Score": 30.223108747044915,
    "BBH Score": 33.285577384040586,
    "Math Score": 20.921450151057403,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.37015779591167
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Dolermed_V1.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7476537745023463,
    "Overall Score": 23.45268314376055,
    "MMLU Score": 28.56087470449172,
    "BBH Score": 31.7058028455963,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.368373896555443
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Dolerstormed_V1.04",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6572829499007699,
    "Overall Score": 30.11303338680009,
    "MMLU Score": 32.097739361702125,
    "BBH Score": 31.64115192515533,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.81441431174544
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Hermedash_R1_V1.04",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6696681062849801,
    "Overall Score": 30.277769930189056,
    "MMLU Score": 32.023862293144205,
    "BBH Score": 31.65897163469844,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.21309831844407
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Hermedive_R1_V1.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7556058524578672,
    "Overall Score": 23.809186985379387,
    "MMLU Score": 26.96328309692672,
    "BBH Score": 31.12996175276656,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.510061638527336
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Hermedive_R1_V1.03",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6914988124726777,
    "Overall Score": 26.50163295870381,
    "MMLU Score": 27.64664598108747,
    "BBH Score": 30.80123767972744,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.324914635700736
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Hermedive_V1.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7053396012461731,
    "Overall Score": 22.78885888839048,
    "MMLU Score": 28.33924349881796,
    "BBH Score": 27.6484297794192,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.30905913708489
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Mediver_V1.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7479143699507365,
    "Overall Score": 11.984272459370358,
    "MMLU Score": 22.1520390070922,
    "BBH Score": 20.44150346627676,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.02358898407011
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Medusa_v1.01",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.65086918442432,
    "Overall Score": 27.38168287785029,
    "MMLU Score": 28.12684692671393,
    "BBH Score": 30.029014461113167,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.06941046389961
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Smarteaz_0.2_R1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7310147805115926,
    "Overall Score": 28.105107642426063,
    "MMLU Score": 29.39199172576832,
    "BBH Score": 30.6976172290985,
    "Math Score": 26.057401812688823,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.446702298901556
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Smarteaz_V1.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6993025622981146,
    "Overall Score": 30.62363412318741,
    "MMLU Score": 30.39856678486997,
    "BBH Score": 32.275457070272665,
    "Math Score": 23.413897280966765,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.79168013134274
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Stormeder_v1.04",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6546167837636284,
    "Overall Score": 29.709951883012703,
    "MMLU Score": 31.691415484633573,
    "BBH Score": 31.780498933752288,
    "Math Score": 18.50453172205438,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.38525839835553
  },
  {
    "Model Name": "Nexesenex/Llama_3.1_8b_Typhoon_v1.03",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6863833166655988,
    "Overall Score": 30.63480151106757,
    "MMLU Score": 31.580599881796683,
    "BBH Score": 33.3207800758965,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.63220589318699
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_AquaSyn_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3720924895779698,
    "Overall Score": 6.988906174606645,
    "MMLU Score": 4.199911347517731,
    "BBH Score": 6.212570678140739,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.782712283533368
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_AquaSyn_0.11",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3933945116905594,
    "Overall Score": 5.867026710843518,
    "MMLU Score": 1.291001773049644,
    "BBH Score": 3.648692187121848,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.913849930520813
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Dolto_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3695687778343242,
    "Overall Score": 11.865611272101535,
    "MMLU Score": 4.042922576832151,
    "BBH Score": 6.613056736761025,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.1066388281881
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Odyssea_V1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3712381482100285,
    "Overall Score": 5.724136311067048,
    "MMLU Score": 1.6973256501182026,
    "BBH Score": 2.6467030023577163,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.419041223717693
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Odyssea_V1.01",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3888020975076618,
    "Overall Score": 5.655298422411647,
    "MMLU Score": 1.6880910165484628,
    "BBH Score": 2.848403718897272,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.545442163670948
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_OpenTree_R1_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3669722679816723,
    "Overall Score": 12.343255865705624,
    "MMLU Score": 7.496675531914894,
    "BBH Score": 6.205590121534224,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 33.63539139781015
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_OrcaSun_V1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3649577293888529,
    "Overall Score": 14.801537525133924,
    "MMLU Score": 10.04543439716312,
    "BBH Score": 9.790397902616846,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.55685448810778
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_RandomLego_RP_R1_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3584078542302758,
    "Overall Score": 12.811633255227909,
    "MMLU Score": 6.259234633569739,
    "BBH Score": 7.937728461020434,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.74596121154331
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_SunOrca_V1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3575000928997862,
    "Overall Score": 14.008724276561884,
    "MMLU Score": 9.82380319148936,
    "BBH Score": 7.852676178179103,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 39.185232548985056
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Sydonia_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3707069284997356,
    "Overall Score": 5.524505982897409,
    "MMLU Score": 2.491504137115838,
    "BBH Score": 4.742438568322573,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.902624035799077
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Syneridol_0.2",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3781858495922464,
    "Overall Score": 5.41209307631663,
    "MMLU Score": 2.519208037825059,
    "BBH Score": 4.769662709936999,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.310670486883255
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Synopsys_0.1",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.377301673436357,
    "Overall Score": 4.959888823517752,
    "MMLU Score": 2.565381205673758,
    "BBH Score": 4.9658457398394615,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.145684667508856
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_1b_Synopsys_0.11",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3999450405712147,
    "Overall Score": 6.557108632155365,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 3.4442338168143976,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.39502423330537
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_3b_Kermes_v1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5856456956570596,
    "Overall Score": 17.069896218578325,
    "MMLU Score": 17.193040780141843,
    "BBH Score": 21.16913127462915,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.14713852618163
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_3b_Kermes_v2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.593093942086941,
    "Overall Score": 18.49497166284455,
    "MMLU Score": 19.27083333333333,
    "BBH Score": 22.049944802060324,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.183882266215072
  },
  {
    "Model Name": "Nexesenex/Llama_3.2_3b_Kermes_v2.1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5762673428022961,
    "Overall Score": 18.90711773153537,
    "MMLU Score": 18.7998670212766,
    "BBH Score": 22.16637011489344,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.8096290162706
  },
  {
    "Model Name": "Nexesenex/Nemotron_W_4b_Halo_0.1",
    "Parameters (B)": 4.513,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7189799733472263,
    "Overall Score": 15.094245712466758,
    "MMLU Score": 16.722074468085104,
    "BBH Score": 18.55038854839016,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.993972394245116
  },
  {
    "Model Name": "Nexesenex/Nemotron_W_4b_MagLight_0.1",
    "Parameters (B)": 4.513,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6645364215346731,
    "Overall Score": 16.194616822912348,
    "MMLU Score": 17.165336879432623,
    "BBH Score": 19.287938293762227,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.36979569233042
  },
  {
    "Model Name": "Nexesenex/Qwen_2.5_3b_Smarteaz_0.01a",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7280219550441767,
    "Overall Score": 19.961623188488065,
    "MMLU Score": 20.665263002364064,
    "BBH Score": 24.370416982068875,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.418985169584325
  },
  {
    "Model Name": "Nexesenex/pankajmathur_orca_mini_v9_6_1B-instruct-Abliterated-LPL",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3439868370003894,
    "Overall Score": 15.011891964697456,
    "MMLU Score": 8.918809101654844,
    "BBH Score": 9.728333239440492,
    "Math Score": 7.477341389728095,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.64089072594503
  },
  {
    "Model Name": "Nexusflow/NexusRaven-V2-13B",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.179609826431666,
    "Overall Score": 8.488064786804268,
    "MMLU Score": 9.685283687943262,
    "BBH Score": 15.336448395229596,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.8943046979653455
  },
  {
    "Model Name": "NikolaSigmoid/AceMath-1.5B-Instruct-1epoch",
    "Parameters (B)": 1.791,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3141206228546138,
    "Overall Score": 17.507477680245945,
    "MMLU Score": 15.290706264775414,
    "BBH Score": 19.829634263073658,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.322580420521156
  },
  {
    "Model Name": "NikolaSigmoid/AceMath-1.5B-Instruct-dolphin-r1-200",
    "Parameters (B)": 0.928,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.363059836301886,
    "Overall Score": 4.389863637734279,
    "MMLU Score": 1.5865100472813234,
    "BBH Score": 1.586299722165597,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 1.3053183265872232
  },
  {
    "Model Name": "NikolaSigmoid/DeepSeek-R1-Distill-Qwen-1.5B-500",
    "Parameters (B)": 1.157,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9581683956345384,
    "Overall Score": 3.5788564701687924,
    "MMLU Score": 1.383348108747044,
    "BBH Score": 0.3579812834224598,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 3.73510176966203
  },
  {
    "Model Name": "NikolaSigmoid/acemath-200",
    "Parameters (B)": 1.791,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.310058879931355,
    "Overall Score": 17.507477680245945,
    "MMLU Score": 15.290706264775414,
    "BBH Score": 19.829634263073658,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.363886118739417
  },
  {
    "Model Name": "NikolaSigmoid/phi-4-14b",
    "Parameters (B)": 14.704,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3519592058580718,
    "Overall Score": 29.913839706837063,
    "MMLU Score": 47.538046690307326,
    "BBH Score": 52.50069258575488,
    "Math Score": 29.38066465256798,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.12628870547253
  },
  {
    "Model Name": "NikolaSigmoid/phi-4-1steps",
    "Parameters (B)": 14.704,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.345177424004227,
    "Overall Score": 29.87038792129772,
    "MMLU Score": 47.48263888888889,
    "BBH Score": 52.760921126950045,
    "Math Score": 29.83383685800604,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.205537640069597
  },
  {
    "Model Name": "NikolaSigmoid/phi-4-300steps",
    "Parameters (B)": 14.704,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.712571051487887,
    "Overall Score": 29.96026018369876,
    "MMLU Score": 47.63962765957447,
    "BBH Score": 52.64505879688579,
    "Math Score": 29.45619335347432,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 11.044967897620635
  },
  {
    "Model Name": "Nitral-AI/Captain-Eris-BMO_Violent-GRPO-v0.420",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.511220389133317,
    "Overall Score": 25.923807450212067,
    "MMLU Score": 28.847148345153663,
    "BBH Score": 30.43355174896298,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.15422028224443
  },
  {
    "Model Name": "Nitral-AI/Captain-Eris_BMO-Violent-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4590005564920685,
    "Overall Score": 25.922969151836924,
    "MMLU Score": 28.570109338061467,
    "BBH Score": 31.04189693245688,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.767621154418556
  },
  {
    "Model Name": "Nitral-AI/Captain-Eris_Violet-GRPO-v0.420",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.787860975370184,
    "Overall Score": 25.272146530177896,
    "MMLU Score": 28.1637854609929,
    "BBH Score": 31.108573670502523,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.076911181320455
  },
  {
    "Model Name": "Nitral-AI/Captain-Eris_Violet-V0.420-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.0311565732739445,
    "Overall Score": 23.62662051748553,
    "MMLU Score": 30.25081264775413,
    "BBH Score": 35.32694075023367,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.794589275197512
  },
  {
    "Model Name": "Nitral-AI/Captain_BMO-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4242954711669777,
    "Overall Score": 23.21048454065836,
    "MMLU Score": 28.54240543735224,
    "BBH Score": 32.44069784748834,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.7781780912581056
  },
  {
    "Model Name": "Nitral-AI/Hathor_Stable-v0.2-L3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6168459294512427,
    "Overall Score": 25.917956738512263,
    "MMLU Score": 29.955304373522463,
    "BBH Score": 32.826028565585965,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.029948349691434
  },
  {
    "Model Name": "Nitral-AI/Hathor_Tahsin-L3-8B-v0.85",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.209051703922841,
    "Overall Score": 25.499607921720123,
    "MMLU Score": 30.223108747044915,
    "BBH Score": 32.71311306903596,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.090585157760508
  },
  {
    "Model Name": "Nitral-AI/Nera_Noctis-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8487588281915823,
    "Overall Score": 20.66135160587692,
    "MMLU Score": 27.425014775413715,
    "BBH Score": 31.86959138887418,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.175796048036956
  },
  {
    "Model Name": "Nohobby/MS-Schisandra-22B-v0.1",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.2011072958523936,
    "Overall Score": 30.1116442664472,
    "MMLU Score": 34.39716312056737,
    "BBH Score": 40.01139961622215,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2024-10-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.406633856185394
  },
  {
    "Model Name": "Nohobby/MS-Schisandra-22B-v0.2",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.070015853323648,
    "Overall Score": 30.28148918014972,
    "MMLU Score": 34.84966016548463,
    "BBH Score": 40.61445808855272,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-11-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.62862669941842
  },
  {
    "Model Name": "Norquinal/Alpha",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4355619240995623,
    "Overall Score": 12.081123216031896,
    "MMLU Score": 22.25361997635934,
    "BBH Score": 8.664581329003166,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.415605773056168
  },
  {
    "Model Name": "Norquinal/Bravo",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.394500715728391,
    "Overall Score": 13.664477714927273,
    "MMLU Score": 23.63881501182033,
    "BBH Score": 10.654043944684554,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.79883162540357
  },
  {
    "Model Name": "Norquinal/Charlie",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2929580750047036,
    "Overall Score": 13.162885018671323,
    "MMLU Score": 23.25096040189125,
    "BBH Score": 9.860055463308887,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.180442253414473
  },
  {
    "Model Name": "Norquinal/Delta",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3069019975141656,
    "Overall Score": 11.354799915155942,
    "MMLU Score": 21.76418439716312,
    "BBH Score": 9.097511313782466,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.688333124253923
  },
  {
    "Model Name": "Norquinal/Echo",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3417240510190622,
    "Overall Score": 13.446736463673105,
    "MMLU Score": 23.278664302600472,
    "BBH Score": 10.011495800063487,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.02198362134157
  },
  {
    "Model Name": "Norquinal/Foxtrot",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2730054105347166,
    "Overall Score": 13.353623855929651,
    "MMLU Score": 22.77999408983452,
    "BBH Score": 10.170272602468412,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.489840612948031
  },
  {
    "Model Name": "Norquinal/Golf",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.373041827866632,
    "Overall Score": 13.926818361317824,
    "MMLU Score": 22.844636524822693,
    "BBH Score": 9.89858882268834,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.143040130799701
  },
  {
    "Model Name": "Norquinal/Hotel",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4087752184140758,
    "Overall Score": 13.283271661420043,
    "MMLU Score": 23.96202718676123,
    "BBH Score": 11.514936892426824,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.428950401593267
  },
  {
    "Model Name": "NotASI/FineTome-Llama3.2-1B-0929",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9308168466890548,
    "Overall Score": 9.953180599897282,
    "MMLU Score": 4.763223995271866,
    "BBH Score": 5.741405038838561,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.692952792271715
  },
  {
    "Model Name": "NotASI/FineTome-Llama3.2-3B-1002",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1309013376834227,
    "Overall Score": 16.7624003049829,
    "MMLU Score": 15.96483451536643,
    "BBH Score": 19.52006065248879,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.866342757664178
  },
  {
    "Model Name": "NotASI/FineTome-v1.5-Llama3.2-1B-1007",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9484630415430834,
    "Overall Score": 9.24257019295171,
    "MMLU Score": 4.744754728132387,
    "BBH Score": 5.801724673541757,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.744786868990374
  },
  {
    "Model Name": "NotASI/FineTome-v1.5-Llama3.2-3B-1007",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4507570508509495,
    "Overall Score": 17.113696212626593,
    "MMLU Score": 16.094119385342786,
    "BBH Score": 19.457219278849333,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.796390169248848
  },
  {
    "Model Name": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.459075136536812,
    "Overall Score": 31.98701372074271,
    "MMLU Score": 39.891770094562645,
    "BBH Score": 48.963404310757504,
    "Math Score": 25.755287009063444,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.922800902951092
  },
  {
    "Model Name": "NousResearch/Hermes-2-Pro-Llama-3-8B",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.499966412528088,
    "Overall Score": 22.06997572152565,
    "MMLU Score": 22.798463356974,
    "BBH Score": 30.667993420825,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.713646610478602
  },
  {
    "Model Name": "NousResearch/Hermes-2-Pro-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9455950387200668,
    "Overall Score": 21.84057680720769,
    "MMLU Score": 21.625664893617017,
    "BBH Score": 29.427578860536,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 23.097177875182737
  },
  {
    "Model Name": "NousResearch/Hermes-2-Theta-Llama-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.487844835193733,
    "Overall Score": 24.78837646080699,
    "MMLU Score": 26.316858747044915,
    "BBH Score": 32.046073848075835,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.66059247204987
  },
  {
    "Model Name": "NousResearch/Hermes-3-Llama-3.1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 22.415781841842687,
    "Overall Score": 38.51477067349896,
    "MMLU Score": 41.40625,
    "BBH Score": 53.76540869130056,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.718198854059371
  },
  {
    "Model Name": "NousResearch/Hermes-3-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9058079001429432,
    "Overall Score": 23.49087671148001,
    "MMLU Score": 23.768099881796687,
    "BBH Score": 30.72409661414796,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 25.933618715152488
  },
  {
    "Model Name": "NousResearch/Hermes-3-Llama-3.2-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6523844958310772,
    "Overall Score": 15.242119392530276,
    "MMLU Score": 17.156102245862883,
    "BBH Score": 20.187188037454582,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.224317603430524
  },
  {
    "Model Name": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9491978373976354,
    "Overall Score": 21.10058697437334,
    "MMLU Score": 22.392139479905435,
    "BBH Score": 27.792545658366084,
    "Math Score": 4.758308157099697,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 22.229914716434333
  },
  {
    "Model Name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 15.653110501660985,
    "Overall Score": 27.35319043857164,
    "MMLU Score": 29.622857565011817,
    "BBH Score": 37.10778379133987,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.7474603808405451
  },
  {
    "Model Name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 20.77587969234417,
    "Overall Score": 21.841010891461725,
    "MMLU Score": 22.95545212765957,
    "BBH Score": 30.594312778864406,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.0512676822782168
  },
  {
    "Model Name": "NousResearch/Nous-Hermes-2-SOLAR-10.7B",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2868882760344564,
    "Overall Score": 23.412543159550665,
    "MMLU Score": 27.314199172576835,
    "BBH Score": 34.990894584465195,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.193143566197037
  },
  {
    "Model Name": "NousResearch/Nous-Hermes-llama-2-7b",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.116114115406325,
    "Overall Score": 9.316715938919105,
    "MMLU Score": 10.442523640661936,
    "BBH Score": 13.78941955171473,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.821053191691594
  },
  {
    "Model Name": "NousResearch/Yarn-Llama-2-13b-128k",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 103.87156662170432,
    "Overall Score": 8.494146676691704,
    "MMLU Score": 14.671985815602836,
    "BBH Score": 13.505319085673955,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.08177547478057218
  },
  {
    "Model Name": "NousResearch/Yarn-Llama-2-7b-128k",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.6794776736133492,
    "Overall Score": 6.814800680431223,
    "MMLU Score": 8.789524231678488,
    "BBH Score": 6.1446917129934855,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.0576905471862394
  },
  {
    "Model Name": "NousResearch/Yarn-Llama-2-7b-64k",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.6608026524383015,
    "Overall Score": 7.222883145587748,
    "MMLU Score": 8.872635933806146,
    "BBH Score": 7.0440554144724175,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.349031557110953
  },
  {
    "Model Name": "NousResearch/Yarn-Mistral-7b-128k",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.1005220635485915,
    "Overall Score": 13.268755393260784,
    "MMLU Score": 21.034648345153663,
    "BBH Score": 20.633112436478672,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.056782714992726
  },
  {
    "Model Name": "NousResearch/Yarn-Mistral-7b-64k",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.082320291391451,
    "Overall Score": 13.540457995525928,
    "MMLU Score": 21.26551418439716,
    "BBH Score": 20.23020020918289,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.510583145510527
  },
  {
    "Model Name": "NousResearch/Yarn-Solar-10b-32k",
    "Parameters (B)": 10.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.0301957352344906,
    "Overall Score": 15.721261422706204,
    "MMLU Score": 25.24564125295508,
    "BBH Score": 28.99482436025671,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.743717095775682
  },
  {
    "Model Name": "NousResearch/Yarn-Solar-10b-64k",
    "Parameters (B)": 10.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.5275057461018122,
    "Overall Score": 15.162050446653282,
    "MMLU Score": 23.86968085106384,
    "BBH Score": 28.395714153595826,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.926018599502337
  },
  {
    "Model Name": "Novaciano/ASTAROTH-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3488551221706949,
    "Overall Score": 14.173861365477634,
    "MMLU Score": 10.10084219858156,
    "BBH Score": 9.493517929020854,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.62964957281711
  },
  {
    "Model Name": "Novaciano/BLAST_PROCESSING-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3528381813144995,
    "Overall Score": 11.950699067123438,
    "MMLU Score": 10.460992907801415,
    "BBH Score": 9.362853718947571,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 33.870198011454086
  },
  {
    "Model Name": "Novaciano/Cerberus-3.2-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3553566221681203,
    "Overall Score": 13.731435487093222,
    "MMLU Score": 7.367390661938533,
    "BBH Score": 16.97415923404232,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.641282110670325
  },
  {
    "Model Name": "Novaciano/Cultist-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7370580211066066,
    "Overall Score": 12.939673802761396,
    "MMLU Score": 7.930703309692672,
    "BBH Score": 7.520040161824312,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.55584151073207
  },
  {
    "Model Name": "Novaciano/FuseChat-3.2-1B-GRPO_Creative_RP",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3441348832380188,
    "Overall Score": 13.847576006756135,
    "MMLU Score": 8.16156914893617,
    "BBH Score": 8.942707229882872,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.23880368203925
  },
  {
    "Model Name": "Novaciano/Fusetrix-3.2-1B-GRPO_RP_Creative",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3315420554652407,
    "Overall Score": 13.986208661387776,
    "MMLU Score": 8.420138888888888,
    "BBH Score": 8.772109627787136,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 42.18532288991648
  },
  {
    "Model Name": "Novaciano/Fusetrix-Dolphin-3.2-1B-GRPO_Creative_RP",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3258218753178624,
    "Overall Score": 14.279018663933527,
    "MMLU Score": 9.149674940898343,
    "BBH Score": 9.680798809347326,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.824616287667396
  },
  {
    "Model Name": "Novaciano/HarmfulProject-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3677579604313725,
    "Overall Score": 10.686879934293591,
    "MMLU Score": 9.140440307328603,
    "BBH Score": 6.5128050720912585,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.0595475397952
  },
  {
    "Model Name": "Novaciano/LEWD-Mental-Cultist-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3636603205744116,
    "Overall Score": 12.977293713777764,
    "MMLU Score": 8.540189125295509,
    "BBH Score": 8.636853527747606,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 35.68520671510097
  },
  {
    "Model Name": "Novaciano/La_Mejor_Mezcla-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3245599690815359,
    "Overall Score": 14.056697294328709,
    "MMLU Score": 9.214317375886525,
    "BBH Score": 9.41305894751064,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.310015508404824
  },
  {
    "Model Name": "Novaciano/Sigil-Of-Satan-3.2-1B",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3714004593019818,
    "Overall Score": 13.692280425316104,
    "MMLU Score": 9.500591016548462,
    "BBH Score": 9.400065990891235,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 36.866622219718515
  },
  {
    "Model Name": "NucleusAI/nucleus-22B-token-500B",
    "Parameters (B)": 21.828,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.18963543732518,
    "Overall Score": 1.6334163485881146,
    "MMLU Score": 1.798906619385342,
    "BBH Score": 1.8879990685708248,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.373039418076472
  },
  {
    "Model Name": "NyxKrage/Microsoft_Phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.788963081142109,
    "Overall Score": 30.06860112453852,
    "MMLU Score": 47.630393026004725,
    "BBH Score": 52.42784845820486,
    "Math Score": 29.909365558912388,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.807837703024113
  },
  {
    "Model Name": "OEvortex/Emotional-llama-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.363628341660931,
    "Overall Score": 17.789126430453027,
    "MMLU Score": 28.1637854609929,
    "BBH Score": 26.45405447203827,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.045436125788834
  },
  {
    "Model Name": "OEvortex/HelpingAI-15B",
    "Parameters (B)": 15.323,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.45447461771735,
    "Overall Score": 4.515495603660534,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 1.8153805514942327,
    "Math Score": 0.0,
    "Date Submitted": "2024-07-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.839699449758386
  },
  {
    "Model Name": "OEvortex/HelpingAI-3B-reloaded",
    "Parameters (B)": 2.81,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.1232528968367588,
    "Overall Score": 14.768420533149955,
    "MMLU Score": 17.719414893617017,
    "BBH Score": 16.98574044907848,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-10-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.147903357062283
  },
  {
    "Model Name": "OEvortex/HelpingAI2-9B",
    "Parameters (B)": 8.903,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.0813028218866374,
    "Overall Score": 17.606927062260286,
    "MMLU Score": 21.108525413711583,
    "BBH Score": 27.073241609173305,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.459570071740039
  },
  {
    "Model Name": "OEvortex/HelpingAI2.5-10B",
    "Parameters (B)": 10.211,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.878786764354815,
    "Overall Score": 13.711774162686112,
    "MMLU Score": 17.49778368794326,
    "BBH Score": 21.135366144659056,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.298206705961549
  },
  {
    "Model Name": "OliveiraJLT/Sagui-7B-Instruct-v0.1",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.64709154275852,
    "Overall Score": 8.579407330639999,
    "MMLU Score": 5.391179078014184,
    "BBH Score": 5.043571655312187,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.208822404777428
  },
  {
    "Model Name": "Omkar1102/code-yi",
    "Parameters (B)": 2.084,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4425204926938784,
    "Overall Score": 4.921767050278931,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 1.8441580122160068,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.122122323233635
  },
  {
    "Model Name": "Omkar1102/code-yi",
    "Parameters (B)": 2.084,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2813594071547754,
    "Overall Score": 5.170300155045384,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.5813991446240263,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.035011665092386
  },
  {
    "Model Name": "OmnicromsBrain/NeuralStar_FusionWriter_4x7b",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7529296011383395,
    "Overall Score": 20.071645037035577,
    "MMLU Score": 17.83946513002364,
    "BBH Score": 26.038439832659787,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.291012828201611
  },
  {
    "Model Name": "OnlyCheeini/greesychat-turbo",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.510856749159255,
    "Overall Score": 1.8020688847846804,
    "MMLU Score": 1.5311022458628842,
    "BBH Score": 4.018369933555268,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.527542481821849
  },
  {
    "Model Name": "Open-Orca/Mistral-7B-OpenOrca",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.067159686748811,
    "Overall Score": 17.72165111279921,
    "MMLU Score": 18.36583924349882,
    "BBH Score": 25.840025395269805,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.606372347881383
  },
  {
    "Model Name": "OpenAssistant/oasst-sft-1-pythia-12b",
    "Parameters (B)": 12.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.77611447437514,
    "Overall Score": 3.681830493398632,
    "MMLU Score": 1.2540632387706852,
    "BBH Score": 4.778508799161477,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.0729691393872276
  },
  {
    "Model Name": "OpenBuddy/openbuddy-falcon3-10b-v24.2-131k",
    "Parameters (B)": 10.34,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6406392065022917,
    "Overall Score": 27.273412962757565,
    "MMLU Score": 31.488253546099287,
    "BBH Score": 42.72636129353911,
    "Math Score": 21.299093655589125,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.623650620237367
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3-70b-v21.2-32k",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.07187203032198,
    "Overall Score": 35.5534575981615,
    "MMLU Score": 42.579048463356976,
    "BBH Score": 49.969365808428186,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.3636710688366487
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3-8b-v21.1-8k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.638844215778852,
    "Overall Score": 20.162938316635703,
    "MMLU Score": 21.71801122931442,
    "BBH Score": 26.115045337590946,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.303145181528661
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3-8b-v21.2-32k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6997787342459103,
    "Overall Score": 22.069479074823068,
    "MMLU Score": 25.54114952718676,
    "BBH Score": 27.2523347365588,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.983736430032447
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.383246608651035,
    "Overall Score": 41.24947292836925,
    "MMLU Score": 47.82432033096927,
    "BBH Score": 51.94077625159233,
    "Math Score": 39.50151057401813,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6917137241984082
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5821261970512388,
    "Overall Score": 24.4181731020086,
    "MMLU Score": 25.67043439716312,
    "BBH Score": 29.057538243651496,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.4337708000279
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.668446440491569,
    "Overall Score": 23.317953936657844,
    "MMLU Score": 25.30104905437352,
    "BBH Score": 30.3195108847562,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.975848052867523
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8922852234636237,
    "Overall Score": 9.350033548941015,
    "MMLU Score": 9.334367612293144,
    "BBH Score": 6.043619508652057,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.47874973503043
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.2-3b-v23.2-131k",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.391143644717637,
    "Overall Score": 13.797653889948387,
    "MMLU Score": 16.435800827423165,
    "BBH Score": 16.588825592691695,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-10-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.918209339732794
  },
  {
    "Model Name": "OpenBuddy/openbuddy-llama3.3-70b-v24.1-131k",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 67.52554694715876,
    "Overall Score": 45.73679489100153,
    "MMLU Score": 48.082890070921984,
    "BBH Score": 54.14664796972127,
    "Math Score": 44.10876132930513,
    "Date Submitted": "2024-12-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.6773257968097951
  },
  {
    "Model Name": "OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k",
    "Parameters (B)": 46.741,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.737751356111918,
    "Overall Score": 22.32980884946828,
    "MMLU Score": 31.15580673758865,
    "BBH Score": 24.5354429684368,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.2931175825775147
  },
  {
    "Model Name": "OpenBuddy/openbuddy-nemotron-70b-v23.1-131k",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 36.442432638282575,
    "Overall Score": 39.78505127265852,
    "MMLU Score": 46.38371749408983,
    "BBH Score": 53.18804887163517,
    "Math Score": 32.09969788519638,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.0917232575430362
  },
  {
    "Model Name": "OpenBuddy/openbuddy-nemotron-70b-v23.2-131k",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.78981565434613,
    "Overall Score": 39.234122021270416,
    "MMLU Score": 45.78346631205674,
    "BBH Score": 52.265661751102094,
    "Math Score": 31.57099697885196,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.5826709874864247
  },
  {
    "Model Name": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k",
    "Parameters (B)": 14.77,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9134999987930428,
    "Overall Score": 32.52829892906403,
    "MMLU Score": 40.81523345153664,
    "BBH Score": 43.27649863201484,
    "Math Score": 25.37764350453172,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.16468129141559
  },
  {
    "Model Name": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k",
    "Parameters (B)": 14.77,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9958980156195016,
    "Overall Score": 32.29791522872073,
    "MMLU Score": 42.16348995271868,
    "BBH Score": 44.1839402106242,
    "Math Score": 23.11178247734139,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.780712514355088
  },
  {
    "Model Name": "OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k",
    "Parameters (B)": 7.615,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7637336349126245,
    "Overall Score": 27.863254758763023,
    "MMLU Score": 32.75339834515366,
    "BBH Score": 36.3981275172541,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.081743915832874
  },
  {
    "Model Name": "OpenBuddy/openbuddy-qwq-32b-v24.1-200k",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.90692943946993,
    "Overall Score": 39.96232491540321,
    "MMLU Score": 49.89287825059102,
    "BBH Score": 54.46917637764042,
    "Math Score": 37.38670694864049,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.785830775545045
  },
  {
    "Model Name": "OpenBuddy/openbuddy-qwq-32b-v24.2-200k",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.0469398673429895,
    "Overall Score": 39.56011201711714,
    "MMLU Score": 49.4034426713948,
    "BBH Score": 54.16349558366793,
    "Math Score": 37.764350453172206,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.542170566432267
  },
  {
    "Model Name": "OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k",
    "Parameters (B)": 34.407,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.076653422339551,
    "Overall Score": 30.92470371318825,
    "MMLU Score": 39.99335106382979,
    "BBH Score": 45.637092606204,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.089101116002439
  },
  {
    "Model Name": "OpenBuddy/openbuddy-zero-14b-v22.3-32k",
    "Parameters (B)": 14.022,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.377537827650708,
    "Overall Score": 19.406071028276457,
    "MMLU Score": 24.30370862884161,
    "BBH Score": 26.289506846678147,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.74562655358167
  },
  {
    "Model Name": "OpenBuddy/openbuddy-zero-3b-v21.2-32k",
    "Parameters (B)": 4.769,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7572375059674723,
    "Overall Score": 11.713302286048616,
    "MMLU Score": 11.486037234042552,
    "BBH Score": 15.293406418468868,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.665747940315951
  },
  {
    "Model Name": "OpenBuddy/openbuddy-zero-56b-v21.2-32k",
    "Parameters (B)": 56.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 15.147491894006654,
    "Overall Score": 28.536019963329736,
    "MMLU Score": 37.76780437352246,
    "BBH Score": 44.79654161573056,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.883877552997435
  },
  {
    "Model Name": "OpenGenerativeAI/Bifrost",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7108119851231949,
    "Overall Score": 37.14746413152554,
    "MMLU Score": 46.21749408983452,
    "BBH Score": 55.09700864855187,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.71335275562181
  },
  {
    "Model Name": "OpenGenerativeAI/Bifrost-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8638634012216105,
    "Overall Score": 37.39963457924099,
    "MMLU Score": 45.26632683215129,
    "BBH Score": 55.08806649361424,
    "Math Score": 23.56495468277945,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.29345881114218
  },
  {
    "Model Name": "OpenLLM-France/Lucie-7B",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.9548920211955724,
    "Overall Score": 8.611731815760395,
    "MMLU Score": 5.529698581560284,
    "BBH Score": 9.91394298206345,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.018539923475409
  },
  {
    "Model Name": "OpenLLM-France/Lucie-7B-Instruct",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9798951820675718,
    "Overall Score": 8.364897117485063,
    "MMLU Score": 6.176122931442081,
    "BBH Score": 7.261384026200003,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.536522345007544
  },
  {
    "Model Name": "OpenLLM-France/Lucie-7B-Instruct-human-data",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9751521222163676,
    "Overall Score": 8.574866924872492,
    "MMLU Score": 4.772458628841606,
    "BBH Score": 7.629771133304573,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.793363342514361
  },
  {
    "Model Name": "OpenLLM-France/Lucie-7B-Instruct-v1.1",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4879356419067323,
    "Overall Score": 10.999352587987945,
    "MMLU Score": 9.602171985815602,
    "BBH Score": 14.739314179940692,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.542629894805767
  },
  {
    "Model Name": "OpenLeecher/llama3-8b-lima",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.917858732048215,
    "Overall Score": 15.025432287041792,
    "MMLU Score": 18.070330969267136,
    "BBH Score": 19.573064881964964,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.8344833412182995
  },
  {
    "Model Name": "OpenScholar/Llama-3.1_OpenScholar-8B",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2652134388784446,
    "Overall Score": 25.961332257431867,
    "MMLU Score": 30.093823877068555,
    "BBH Score": 32.40392120448785,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.51933014594394
  },
  {
    "Model Name": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7134701351201276,
    "Overall Score": 27.17511614274033,
    "MMLU Score": 30.99881796690307,
    "BBH Score": 29.24254324176861,
    "Math Score": 15.709969788519636,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.85969640540898
  },
  {
    "Model Name": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.739372628969439,
    "Overall Score": 28.390881228317323,
    "MMLU Score": 30.897236997635936,
    "BBH Score": 29.687032745631218,
    "Math Score": 19.71299093655589,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.32248361016158
  },
  {
    "Model Name": "Orion-zhen/Qwen2.5-7B-Instruct-Uncensored",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.2336238849080123,
    "Overall Score": 35.71881524964477,
    "MMLU Score": 38.07254728132387,
    "BBH Score": 35.83245286228819,
    "Math Score": 47.73413897280967,
    "Date Submitted": "2024-10-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.99141891837165
  },
  {
    "Model Name": "Orion-zhen/phi-4-abliterated",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7887019249616476,
    "Overall Score": 29.97907708859114,
    "MMLU Score": 47.685800827423165,
    "BBH Score": 52.45712922578372,
    "Math Score": 30.211480362537763,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.760241977843197
  },
  {
    "Model Name": "P0x0/Astra-v1-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.211346744195269,
    "Overall Score": 19.737240466519605,
    "MMLU Score": 27.34190307328605,
    "BBH Score": 31.80990734117942,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.146094470239325
  },
  {
    "Model Name": "PJMixers/LLaMa-3-CursedStock-v2.0-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.8053841117290728,
    "Overall Score": 24.166133893343385,
    "MMLU Score": 28.40388593380615,
    "BBH Score": 32.56361170891586,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.614197889090065
  },
  {
    "Model Name": "PJMixers-Dev/L3.2-Instruct-Thinking-v0.1-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7410305950739005,
    "Overall Score": 10.902648327773704,
    "MMLU Score": 5.363475177304964,
    "BBH Score": 6.3866369990439695,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.712818067500196
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.1-Instruct-Interleaved-Zeroed-13B",
    "Parameters (B)": 13.047,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.5927314715878755,
    "Overall Score": 28.894562181103485,
    "MMLU Score": 30.74948286052009,
    "BBH Score": 29.89275635245275,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.144448431216631
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.1-RomboTiesTest-8B",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4369043060818494,
    "Overall Score": 28.818375441031588,
    "MMLU Score": 30.74948286052009,
    "BBH Score": 29.89275635245275,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.05587659460325
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.1-RomboTiesTest2-8B",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4410469707927869,
    "Overall Score": 28.818375441031588,
    "MMLU Score": 30.74948286052009,
    "BBH Score": 29.89275635245275,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.99822075555057
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4273887421986473,
    "Overall Score": 22.701739941091272,
    "MMLU Score": 23.63881501182033,
    "BBH Score": 23.80830677255767,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.904384888256256
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.2-SFT-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4197984758501463,
    "Overall Score": 21.772674131965854,
    "MMLU Score": 23.50029550827423,
    "BBH Score": 23.34123990373789,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.3350454323659
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.2-SFT-HailMary-v0.1-KTO-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3580841575987257,
    "Overall Score": 21.826266808747885,
    "MMLU Score": 23.41718380614657,
    "BBH Score": 22.28871530922464,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.07136545009084
  },
  {
    "Model Name": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMixBread-v0.1-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4048551500864417,
    "Overall Score": 19.737295916446044,
    "MMLU Score": 23.149379432624112,
    "BBH Score": 22.759588390933697,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.049345881126317
  },
  {
    "Model Name": "PJMixers-Dev/Qwen2.5-RomboTiesTest-7B",
    "Parameters (B)": 3.808,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3427656159126633,
    "Overall Score": 35.28885377363677,
    "MMLU Score": 36.50265957446809,
    "BBH Score": 34.93145651665548,
    "Math Score": 49.62235649546828,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 26.280724912404995
  },
  {
    "Model Name": "Parissa3/test-model",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.946705805822806,
    "Overall Score": 20.745917611192755,
    "MMLU Score": 22.85387115839244,
    "BBH Score": 32.83903240379116,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.913795694071986
  },
  {
    "Model Name": "Pinkstack/PARM-V1.5-base-QwQ-Qwen-2.5-o1-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5607975432210763,
    "Overall Score": 23.92876945667705,
    "MMLU Score": 27.89598108747045,
    "BBH Score": 26.33092647670804,
    "Math Score": 16.91842900302115,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.331116813071317
  },
  {
    "Model Name": "Pinkstack/SuperThoughts-CoT-14B-16k-o1-QwQ",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.863033951113376,
    "Overall Score": 31.36951233941903,
    "MMLU Score": 47.42723108747045,
    "BBH Score": 52.848496844057365,
    "Math Score": 41.99395770392749,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.83786402318227
  },
  {
    "Model Name": "Pinkstack/Superthoughts-lite-1.8B-experimental-o1",
    "Parameters (B)": 1.812,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.6183011818245351,
    "Overall Score": 5.104091175053128,
    "MMLU Score": 9.454417848699762,
    "BBH Score": 9.132472807581593,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.255024129165575
  },
  {
    "Model Name": "Pinkstack/Superthoughts-lite-v1",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3315824738991609,
    "Overall Score": 7.399417613485791,
    "MMLU Score": 8.39243498817967,
    "BBH Score": 8.902845043233844,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.315466576005047
  },
  {
    "Model Name": "PocketDoc/Dans-Instruct-CoreCurriculum-12b",
    "Parameters (B)": 12.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.177076304074408,
    "Overall Score": 9.490940527989816,
    "MMLU Score": 2.4360963356974,
    "BBH Score": 13.232564953040011,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-09-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.987319037889729
  },
  {
    "Model Name": "PocketDoc/Dans-PersonalityEngine-V1.1.0-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.1727081280344622,
    "Overall Score": 27.04494433244724,
    "MMLU Score": 25.1348256501182,
    "BBH Score": 33.666618823462954,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.524245925263212
  },
  {
    "Model Name": "PocketDoc/Dans-PersonalityEngine-V1.2.0-24b",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.056940773564168,
    "Overall Score": 36.3754641013882,
    "MMLU Score": 44.73071808510639,
    "BBH Score": 47.56102293719791,
    "Math Score": 24.54682779456193,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.899302863816065
  },
  {
    "Model Name": "PocketDoc/Dans-PersonalityEngine-v1.0.0-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.801948516818772,
    "Overall Score": 19.207416194838743,
    "MMLU Score": 22.94621749408983,
    "BBH Score": 25.68795976908214,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.659248039310379
  },
  {
    "Model Name": "PocketDoc/Dans-SakuraKaze-V1.0.0-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8727770487974009,
    "Overall Score": 27.119777597401505,
    "MMLU Score": 28.440824468085108,
    "BBH Score": 34.38815279713936,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.072972914182188
  },
  {
    "Model Name": "PowerInfer/SmallThinker-3B-Preview",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.475888162898983,
    "Overall Score": 23.22006340641872,
    "MMLU Score": 22.41984338061465,
    "BBH Score": 22.062104642168745,
    "Math Score": 27.794561933534744,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.732942366587714
  },
  {
    "Model Name": "PranavHarshan/LaMistral-V4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3944647401800156,
    "Overall Score": 24.21076517685928,
    "MMLU Score": 28.874852245862886,
    "BBH Score": 31.091348681794813,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.36204902085501
  },
  {
    "Model Name": "PranavHarshan/MedNarra-X1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3523218777350892,
    "Overall Score": 18.078329076163104,
    "MMLU Score": 27.00945626477541,
    "BBH Score": 23.52349513234211,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.368362498461723
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6721992205670189,
    "Overall Score": 22.735876089495267,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 24.05717251228861,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.596391990773597
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6731843520126088,
    "Overall Score": 22.67170160577124,
    "MMLU Score": 25.54114952718676,
    "BBH Score": 24.05717251228861,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-08-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.55003205624074
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_32K-PoSE",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9458762678591882,
    "Overall Score": 12.903680149442671,
    "MMLU Score": 11.458333333333332,
    "BBH Score": 8.828394853721203,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.642038169165305
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended",
    "Parameters (B)": 8.114,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3674142829393898,
    "Overall Score": 22.761271669519232,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 24.05717251228861,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.6454833429059
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved",
    "Parameters (B)": 8.114,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3209091512623283,
    "Overall Score": 22.630312716882344,
    "MMLU Score": 25.54114952718676,
    "BBH Score": 24.075505845621944,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-08-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.132376360066594
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended",
    "Parameters (B)": 8.987,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4384987932245612,
    "Overall Score": 22.735876089495267,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 24.05717251228861,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.805279918608882
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved",
    "Parameters (B)": 8.987,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.455622745014315,
    "Overall Score": 22.65570829690631,
    "MMLU Score": 25.54114952718676,
    "BBH Score": 24.075505845621944,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-08-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.564271975348603
  },
  {
    "Model Name": "Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended",
    "Parameters (B)": 9.859,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.573526102454317,
    "Overall Score": 22.735876089495267,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 24.05717251228861,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.448998369987537
  },
  {
    "Model Name": "Pretergeek/openchat-3.5-0106_Rebased_Mistral-7B-v0.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2436758634757044,
    "Overall Score": 16.052276387715246,
    "MMLU Score": 20.33281619385342,
    "BBH Score": 10.910767600799836,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-07-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.90712223268039
  },
  {
    "Model Name": "PrimeIntellect/INTELLECT-1",
    "Parameters (B)": 10.211,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.9953176565006856,
    "Overall Score": 3.806301801901869,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.043500157895444,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.824208057640588
  },
  {
    "Model Name": "PrimeIntellect/INTELLECT-1",
    "Parameters (B)": 10.211,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.99276823475716,
    "Overall Score": 4.016002158495076,
    "MMLU Score": 1.337174940898345,
    "BBH Score": 1.043500157895444,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 2.0152881245542678
  },
  {
    "Model Name": "PrimeIntellect/INTELLECT-1-Instruct",
    "Parameters (B)": 10.211,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.85273565713582,
    "Overall Score": 1.4059110426100174,
    "MMLU Score": 0.7092198581560278,
    "BBH Score": 1.7494478703137453,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.49282906360190715
  },
  {
    "Model Name": "PuxAI/LUA_model",
    "Parameters (B)": 7.386,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2601842278060176,
    "Overall Score": 5.148723748211869,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.815668408500801,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.085691309734771
  },
  {
    "Model Name": "PygmalionAI/pygmalion-6b",
    "Parameters (B)": 6.0,
    "Architecture": "GPTJForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 63.84623856095976,
    "Overall Score": 5.430124009362374,
    "MMLU Score": 2.039007092198581,
    "BBH Score": 5.089577143988909,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.0850500222370617
  },
  {
    "Model Name": "Q-bert/MetaMath-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9300559878633528,
    "Overall Score": 12.36906160654443,
    "MMLU Score": 5.501994680851065,
    "BBH Score": 8.434610644832558,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.299265601160494
  },
  {
    "Model Name": "Quazim0t0/1up-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9299007072842976,
    "Overall Score": 41.15181002280717,
    "MMLU Score": 48.96018026004729,
    "BBH Score": 55.83975950522497,
    "Math Score": 41.616314199395774,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.25398292575539
  },
  {
    "Model Name": "Quazim0t0/Adamant-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8079077749966712,
    "Overall Score": 40.32150902413576,
    "MMLU Score": 48.5723256501182,
    "BBH Score": 54.97141906331953,
    "Math Score": 39.87915407854985,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.302857248462246
  },
  {
    "Model Name": "Quazim0t0/Alice-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9336340789377652,
    "Overall Score": 41.354214475080205,
    "MMLU Score": 49.09869976359338,
    "BBH Score": 56.00650513096938,
    "Math Score": 45.69486404833837,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.29381425550644
  },
  {
    "Model Name": "Quazim0t0/Alien-CoT-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.912128570185909,
    "Overall Score": 32.21054018658256,
    "MMLU Score": 46.33754432624114,
    "BBH Score": 48.047822818905125,
    "Math Score": 52.0392749244713,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.845384085993157
  },
  {
    "Model Name": "Quazim0t0/Aura-8B-Linear",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4172796772465954,
    "Overall Score": 27.587590048832727,
    "MMLU Score": 31.11886820330969,
    "BBH Score": 29.451689498631435,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.465170136658006
  },
  {
    "Model Name": "Quazim0t0/Casa-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.92197207364407,
    "Overall Score": 40.41164680106136,
    "MMLU Score": 49.17257683215129,
    "BBH Score": 55.3984513931396,
    "Math Score": 46.97885196374622,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.831747138864415
  },
  {
    "Model Name": "Quazim0t0/Casa-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8578754867311853,
    "Overall Score": 40.99359561827428,
    "MMLU Score": 48.97864952718677,
    "BBH Score": 55.32965321791952,
    "Math Score": 49.848942598187314,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.064770169501468
  },
  {
    "Model Name": "Quazim0t0/Charlie-8B-Linear",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7056474850461021,
    "Overall Score": 28.060174123056736,
    "MMLU Score": 28.588578605200944,
    "BBH Score": 31.52437481276685,
    "Math Score": 26.51057401812689,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.765144378320116
  },
  {
    "Model Name": "Quazim0t0/Chromatic-8b-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.401494411400827,
    "Overall Score": 24.16855020752669,
    "MMLU Score": 30.610963356974,
    "BBH Score": 28.86594147433648,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.244842370344987
  },
  {
    "Model Name": "Quazim0t0/CoT_Phi",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9037506905901384,
    "Overall Score": 36.20889872430018,
    "MMLU Score": 43.345523049645394,
    "BBH Score": 53.36568538313751,
    "Math Score": 33.081570996978854,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.065140863855056
  },
  {
    "Model Name": "Quazim0t0/Dyson-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.954136034124844,
    "Overall Score": 39.579565021915634,
    "MMLU Score": 48.87706855791962,
    "BBH Score": 54.72936481142644,
    "Math Score": 53.92749244712991,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 41.482098575408
  },
  {
    "Model Name": "Quazim0t0/Edu-14B-Linear",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8959461527664812,
    "Overall Score": 34.65497010041746,
    "MMLU Score": 45.39561170212767,
    "BBH Score": 53.21378883250136,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.679746537680494
  },
  {
    "Model Name": "Quazim0t0/Fugazi14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9163709788150664,
    "Overall Score": 41.93859963937472,
    "MMLU Score": 49.0802304964539,
    "BBH Score": 56.092125930693726,
    "Math Score": 46.52567975830816,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.76596226738253
  },
  {
    "Model Name": "Quazim0t0/GZA-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.87082310404564,
    "Overall Score": 38.22035199697927,
    "MMLU Score": 47.02090721040189,
    "BBH Score": 52.49322024679916,
    "Math Score": 47.205438066465256,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.429698518437185
  },
  {
    "Model Name": "Quazim0t0/Geedorah-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9325925427874288,
    "Overall Score": 41.39114666181808,
    "MMLU Score": 49.1264036643026,
    "BBH Score": 56.46229284952974,
    "Math Score": 44.48640483383686,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.38288401717641
  },
  {
    "Model Name": "Quazim0t0/GivingTree-8b-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4057611338885363,
    "Overall Score": 23.90329552226861,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 28.49899863064304,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.003810210735217
  },
  {
    "Model Name": "Quazim0t0/GuiltySpark-14B-ties",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8577733596461905,
    "Overall Score": 40.52404330224518,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 55.72193711661121,
    "Math Score": 38.36858006042296,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.813233079175443
  },
  {
    "Model Name": "Quazim0t0/Halo-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1798576748339618,
    "Overall Score": 40.258932389336,
    "MMLU Score": 48.62773345153664,
    "BBH Score": 55.27080618595605,
    "Math Score": 42.90030211480362,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.468605934285364
  },
  {
    "Model Name": "Quazim0t0/Heretic1.5b",
    "Parameters (B)": 1.73,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5781061805882853,
    "Overall Score": 11.59950597926467,
    "MMLU Score": 8.087692080378249,
    "BBH Score": 9.643860937325522,
    "Math Score": 24.395770392749245,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.064663497388874
  },
  {
    "Model Name": "Quazim0t0/Hyde-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7907659326317025,
    "Overall Score": 36.65991703864476,
    "MMLU Score": 47.778147163120565,
    "BBH Score": 54.89781444986736,
    "Math Score": 27.34138972809668,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.471640860829584
  },
  {
    "Model Name": "Quazim0t0/Imagine-v0.5-16bit",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9823815613014714,
    "Overall Score": 28.789019815038216,
    "MMLU Score": 48.37839834515367,
    "BBH Score": 53.73606811245789,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.305334046475956
  },
  {
    "Model Name": "Quazim0t0/Imbue-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9450565980186212,
    "Overall Score": 38.07335261061783,
    "MMLU Score": 48.91400709219858,
    "BBH Score": 54.47623938595546,
    "Math Score": 53.17220543806647,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.28684915849627
  },
  {
    "Model Name": "Quazim0t0/Insom",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9900747099814388,
    "Overall Score": 39.54769675145718,
    "MMLU Score": 48.35992907801419,
    "BBH Score": 55.318559572553454,
    "Math Score": 38.51963746223565,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.94415406509938
  },
  {
    "Model Name": "Quazim0t0/InspectorDeck-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.911837218018592,
    "Overall Score": 29.601861765438738,
    "MMLU Score": 47.34411938534279,
    "BBH Score": 52.01189149482676,
    "Math Score": 31.64652567975831,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.483463490745198
  },
  {
    "Model Name": "Quazim0t0/Jekyl-8b-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.431155965593621,
    "Overall Score": 24.085441896511327,
    "MMLU Score": 29.84448877068557,
    "BBH Score": 28.232789513696968,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.829362051061334
  },
  {
    "Model Name": "Quazim0t0/Jigsaw-14B-Linear",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8862138639072998,
    "Overall Score": 36.85975504597242,
    "MMLU Score": 47.03937647754137,
    "BBH Score": 54.79132672161592,
    "Math Score": 26.51057401812689,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.59239270243243
  },
  {
    "Model Name": "Quazim0t0/Katana-8b-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.451141681464865,
    "Overall Score": 24.188001040020307,
    "MMLU Score": 30.786421394799056,
    "BBH Score": 29.004160225251976,
    "Math Score": 15.105740181268882,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.668256000753534
  },
  {
    "Model Name": "Quazim0t0/Knot-CoT-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.950989494317381,
    "Overall Score": 33.73448595442946,
    "MMLU Score": 46.15285165484633,
    "BBH Score": 51.44445678655166,
    "Math Score": 39.95468277945619,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.290962382261622
  },
  {
    "Model Name": "Quazim0t0/Lineage-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.917298302104046,
    "Overall Score": 41.64434282329166,
    "MMLU Score": 49.00635342789597,
    "BBH Score": 56.02223040682762,
    "Math Score": 42.44712990936556,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.39890974154238
  },
  {
    "Model Name": "Quazim0t0/Lo-Phi-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0540242970942009,
    "Overall Score": 37.88897941168211,
    "MMLU Score": 48.54462174940899,
    "BBH Score": 54.70598224151049,
    "Math Score": 51.96374622356496,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 35.946969643998514
  },
  {
    "Model Name": "Quazim0t0/Loke-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.157607540885205,
    "Overall Score": 40.85820722600513,
    "MMLU Score": 48.90477245862885,
    "BBH Score": 55.83477772401803,
    "Math Score": 39.04833836858006,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.939609085982521
  },
  {
    "Model Name": "Quazim0t0/MFDOOM-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.894646411603964,
    "Overall Score": 41.4412132005641,
    "MMLU Score": 49.17257683215129,
    "BBH Score": 55.53057914384544,
    "Math Score": 52.64350453172205,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.872795338883797
  },
  {
    "Model Name": "Quazim0t0/MFGRIMM-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.980466808213746,
    "Overall Score": 41.51803168899253,
    "MMLU Score": 49.07099586288417,
    "BBH Score": 55.52294469432744,
    "Math Score": 50.60422960725075,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 42.34516797629463
  },
  {
    "Model Name": "Quazim0t0/Math_Phi4_Reason",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9604983306174952,
    "Overall Score": 28.118748796782256,
    "MMLU Score": 44.77689125295508,
    "BBH Score": 45.05751713788222,
    "Math Score": 32.779456193353475,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.27516675505826
  },
  {
    "Model Name": "Quazim0t0/Mithril-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7925213392250092,
    "Overall Score": 40.98225259227315,
    "MMLU Score": 48.92324172576833,
    "BBH Score": 55.92521598371362,
    "Math Score": 38.21752265861027,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.86290918577945
  },
  {
    "Model Name": "Quazim0t0/Mononoke-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9168044272834093,
    "Overall Score": 33.97900480209152,
    "MMLU Score": 47.75044326241135,
    "BBH Score": 53.15959925346656,
    "Math Score": 46.97885196374622,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.726902295529573
  },
  {
    "Model Name": "Quazim0t0/Motion-8B-Linear",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6920789114823463,
    "Overall Score": 27.23537322336956,
    "MMLU Score": 30.94341016548463,
    "BBH Score": 29.388867774583897,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.3529881802565
  },
  {
    "Model Name": "Quazim0t0/Mouse-9B",
    "Parameters (B)": 9.207,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6286929773056579,
    "Overall Score": 3.736733161665297,
    "MMLU Score": 1.540336879432624,
    "BBH Score": 2.506439889086948,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.943653415184519
  },
  {
    "Model Name": "Quazim0t0/Nova-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.828837001200642,
    "Overall Score": 41.40631180934072,
    "MMLU Score": 49.03405732860521,
    "BBH Score": 56.03433191471312,
    "Math Score": 41.616314199395774,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.64078853509484
  },
  {
    "Model Name": "Quazim0t0/NovaScotia-14b-stock",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8867562083503056,
    "Overall Score": 41.34811039930162,
    "MMLU Score": 48.9878841607565,
    "BBH Score": 56.02714781885254,
    "Math Score": 46.299093655589125,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.91491948790487
  },
  {
    "Model Name": "Quazim0t0/ODB-14B-sce",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 2.98336784194147,
    "Overall Score": 26.92045655620284,
    "MMLU Score": 46.74386820330969,
    "BBH Score": 50.69950430097801,
    "Math Score": 25.45317220543807,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 9.023512346598185
  },
  {
    "Model Name": "Quazim0t0/ODB-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9916176982845046,
    "Overall Score": 41.33656100926671,
    "MMLU Score": 49.01558806146573,
    "BBH Score": 56.192610781815496,
    "Math Score": 41.1631419939577,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.685985517179475
  },
  {
    "Model Name": "Quazim0t0/Oasis-14B-ties",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8898820897532416,
    "Overall Score": 40.59264321385063,
    "MMLU Score": 48.94171099290781,
    "BBH Score": 55.75379172237363,
    "Math Score": 37.53776435045317,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.47892899453359
  },
  {
    "Model Name": "Quazim0t0/Origami-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9383875192333773,
    "Overall Score": 28.97226828673041,
    "MMLU Score": 47.15942671394799,
    "BBH Score": 51.44967004592488,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.946582145859463
  },
  {
    "Model Name": "Quazim0t0/Phi4.Turn.R1Distill.16bit",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9789495488494413,
    "Overall Score": 27.502616984496523,
    "MMLU Score": 47.29794621749409,
    "BBH Score": 50.4691726466956,
    "Math Score": 23.11178247734139,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.897583695595731
  },
  {
    "Model Name": "Quazim0t0/Phi4.Turn.R1Distill_v1.5.1-Tensors",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9542927927918283,
    "Overall Score": 26.05365187808444,
    "MMLU Score": 45.74652777777778,
    "BBH Score": 49.218136716618574,
    "Math Score": 21.90332326283988,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.33149872638336
  },
  {
    "Model Name": "Quazim0t0/Phi4Basis-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.738831305952888,
    "Overall Score": 40.31326092128696,
    "MMLU Score": 48.77548758865248,
    "BBH Score": 55.6651943464438,
    "Math Score": 47.88519637462236,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.719147117117263
  },
  {
    "Model Name": "Quazim0t0/Ponder-14B-linear",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8202759937273685,
    "Overall Score": 41.30752865997557,
    "MMLU Score": 48.97864952718677,
    "BBH Score": 56.21485209781756,
    "Math Score": 42.82477341389728,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.693003040374325
  },
  {
    "Model Name": "Quazim0t0/RZA-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9062650010149924,
    "Overall Score": 36.03485909755687,
    "MMLU Score": 48.70161052009456,
    "BBH Score": 52.297746865541455,
    "Math Score": 51.88821752265861,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.90338388333735
  },
  {
    "Model Name": "Quazim0t0/Rosemary-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9054265142213616,
    "Overall Score": 41.33770500916808,
    "MMLU Score": 48.84936465721041,
    "BBH Score": 56.38346045501811,
    "Math Score": 43.8821752265861,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.65550528936875
  },
  {
    "Model Name": "Quazim0t0/Rune-14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9545781162215536,
    "Overall Score": 41.81723237189117,
    "MMLU Score": 49.01558806146573,
    "BBH Score": 56.053987787163095,
    "Math Score": 45.84592145015105,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.807030206614925
  },
  {
    "Model Name": "Quazim0t0/SZA-14B-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.904461554104428,
    "Overall Score": 39.55774467541249,
    "MMLU Score": 48.36916371158392,
    "BBH Score": 55.23013277164075,
    "Math Score": 52.41691842900303,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.771091225317225
  },
  {
    "Model Name": "Quazim0t0/Sake-20b",
    "Parameters (B)": 21.475,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.265105455924606,
    "Overall Score": 40.18907381003569,
    "MMLU Score": 48.79395685579197,
    "BBH Score": 53.939346240687655,
    "Math Score": 46.52567975830816,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.74269436547301
  },
  {
    "Model Name": "Quazim0t0/Spok-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.762264576767201,
    "Overall Score": 36.71086980721715,
    "MMLU Score": 47.75044326241135,
    "BBH Score": 55.09355794451866,
    "Math Score": 27.19033232628399,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.831644856961077
  },
  {
    "Model Name": "Quazim0t0/Sumatra-20b",
    "Parameters (B)": 21.475,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.398667489951043,
    "Overall Score": 39.21426941729526,
    "MMLU Score": 49.05252659574468,
    "BBH Score": 55.13298201406423,
    "Math Score": 36.70694864048338,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.915033815782179
  },
  {
    "Model Name": "Quazim0t0/SuperNova14b",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9194569237304816,
    "Overall Score": 41.675071451846414,
    "MMLU Score": 49.27415780141844,
    "BBH Score": 56.0926914908668,
    "Math Score": 43.957703927492446,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 45.32574650997194
  },
  {
    "Model Name": "Quazim0t0/TB0-8B-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.448864235637514,
    "Overall Score": 24.188001040020307,
    "MMLU Score": 30.786421394799056,
    "BBH Score": 29.004160225251976,
    "Math Score": 15.105740181268882,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.694456557813613
  },
  {
    "Model Name": "Quazim0t0/TBL-8B-sce",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.454904623466604,
    "Overall Score": 23.75992624783128,
    "MMLU Score": 29.88142730496453,
    "BBH Score": 28.362465633086348,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.33091672443686
  },
  {
    "Model Name": "Quazim0t0/ThinkPhi1.1-Tensors",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9240926057904264,
    "Overall Score": 27.93499270632092,
    "MMLU Score": 43.419400118203306,
    "BBH Score": 49.14167915090875,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.518528173879183
  },
  {
    "Model Name": "Quazim0t0/Venti-20b",
    "Parameters (B)": 21.475,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.333502389912341,
    "Overall Score": 38.50341402978516,
    "MMLU Score": 48.73854905437352,
    "BBH Score": 55.7998371351703,
    "Math Score": 33.91238670694864,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.885056604425692
  },
  {
    "Model Name": "Quazim0t0/Venti-Blend-sce",
    "Parameters (B)": 21.475,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.584613142913738,
    "Overall Score": 39.44869800438639,
    "MMLU Score": 49.04329196217494,
    "BBH Score": 54.99405204157026,
    "Math Score": 40.55891238670695,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.991042624400871
  },
  {
    "Model Name": "Quazim0t0/Vine-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8376647721984032,
    "Overall Score": 41.05675554875142,
    "MMLU Score": 48.97864952718677,
    "BBH Score": 55.32965321791952,
    "Math Score": 50.07552870090635,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.341809110066965
  },
  {
    "Model Name": "Quazim0t0/Wendy-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9582473940757206,
    "Overall Score": 41.208648788347965,
    "MMLU Score": 49.27415780141844,
    "BBH Score": 56.172047866798856,
    "Math Score": 48.338368580060425,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.00418560292131
  },
  {
    "Model Name": "Quazim0t0/Wu-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7618624186247975,
    "Overall Score": 36.491123345831,
    "MMLU Score": 47.69503546099291,
    "BBH Score": 54.94466630171922,
    "Math Score": 26.132930513595166,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.711675872122722
  },
  {
    "Model Name": "Quazim0t0/bloom-14b-stock",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9036596300110888,
    "Overall Score": 40.29106535634419,
    "MMLU Score": 48.59079491725768,
    "BBH Score": 55.2730368732428,
    "Math Score": 48.11178247734139,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.16505740898098
  },
  {
    "Model Name": "Quazim0t0/caramel-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0066945945785353,
    "Overall Score": 41.2217763981026,
    "MMLU Score": 49.28339243498819,
    "BBH Score": 55.75618206414753,
    "Math Score": 47.12990936555892,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.94764849250093
  },
  {
    "Model Name": "Quazim0t0/graphite-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9263422470023133,
    "Overall Score": 29.108509572328675,
    "MMLU Score": 47.55651595744681,
    "BBH Score": 51.50924362930217,
    "Math Score": 30.06042296072508,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.11076737149176
  },
  {
    "Model Name": "Quazim0t0/mocha-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.001270119482356,
    "Overall Score": 39.84779848605735,
    "MMLU Score": 48.71084515366431,
    "BBH Score": 55.23219353529195,
    "Math Score": 52.64350453172205,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 39.79725122193616
  },
  {
    "Model Name": "Quazim0t0/mosaic-14b-sce",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.807014919375356,
    "Overall Score": 40.83043805791301,
    "MMLU Score": 48.84936465721041,
    "BBH Score": 55.69112578019082,
    "Math Score": 40.25679758308157,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.595517956225375
  },
  {
    "Model Name": "Quazim0t0/tesseract-14b-stock",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9337244100876665,
    "Overall Score": 39.40111037897865,
    "MMLU Score": 48.76625295508275,
    "BBH Score": 54.99686477095802,
    "Math Score": 51.43504531722054,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.375763047430517
  },
  {
    "Model Name": "Quazim0t0/time-14b-stock",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.851146036356196,
    "Overall Score": 41.17536154259003,
    "MMLU Score": 49.09869976359338,
    "BBH Score": 55.35905866101553,
    "Math Score": 50.83081570996979,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.24317300413521
  },
  {
    "Model Name": "Qwen/QwQ-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 48.30528943515114,
    "Overall Score": 12.21487061660057,
    "MMLU Score": 2.177526595744679,
    "BBH Score": 2.868335388534824,
    "Math Score": 16.08761329305136,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 0.2528681798501339
  },
  {
    "Model Name": "Qwen/QwQ-32B-Preview",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 20.42077955247921,
    "Overall Score": 34.11985336826446,
    "MMLU Score": 51.97990543735224,
    "BBH Score": 53.3876763517132,
    "Math Score": 44.93957703927492,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.67083990503791
  },
  {
    "Model Name": "Qwen/Qwen1.5-0.5B",
    "Parameters (B)": 0.62,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.957474747101484,
    "Overall Score": 5.3510150735736985,
    "MMLU Score": 3.4149674940898342,
    "BBH Score": 5.035475836799366,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.7336317270489308
  },
  {
    "Model Name": "Qwen/Qwen1.5-0.5B-Chat",
    "Parameters (B)": 0.62,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0994887806344995,
    "Overall Score": 5.67816209115329,
    "MMLU Score": 2.362219267139479,
    "BBH Score": 4.318032636938059,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.164365649894583
  },
  {
    "Model Name": "Qwen/Qwen1.5-1.8B",
    "Parameters (B)": 1.837,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.897741573199241,
    "Overall Score": 9.269492522098927,
    "MMLU Score": 9.79609929078014,
    "BBH Score": 9.759901587727937,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.884486198229972
  },
  {
    "Model Name": "Qwen/Qwen1.5-1.8B-Chat",
    "Parameters (B)": 1.837,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1286577147946053,
    "Overall Score": 9.257783499275524,
    "MMLU Score": 8.928043735224584,
    "BBH Score": 5.908662877770453,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.202472173736275
  },
  {
    "Model Name": "Qwen/Qwen1.5-110B",
    "Parameters (B)": 111.21,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 142.54177685205886,
    "Overall Score": 29.83367750486893,
    "MMLU Score": 48.45227541371159,
    "BBH Score": 44.28047655387545,
    "Math Score": 24.69788519637462,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.20929778036815608
  },
  {
    "Model Name": "Qwen/Qwen1.5-110B-Chat",
    "Parameters (B)": 111.21,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 145.1305861122314,
    "Overall Score": 33.12715289782008,
    "MMLU Score": 42.49593676122932,
    "BBH Score": 44.98454525616634,
    "Math Score": 23.413897280966765,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.2282575560757566
  },
  {
    "Model Name": "Qwen/Qwen1.5-14B",
    "Parameters (B)": 14.167,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.85098117295462,
    "Overall Score": 20.854080062460586,
    "MMLU Score": 29.37352245862884,
    "BBH Score": 30.063103282917453,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.415264091374547
  },
  {
    "Model Name": "Qwen/Qwen1.5-14B-Chat",
    "Parameters (B)": 14.167,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.67693202001456,
    "Overall Score": 23.56610647505137,
    "MMLU Score": 29.08724881796691,
    "BBH Score": 32.75647930053065,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.803401169269584
  },
  {
    "Model Name": "Qwen/Qwen1.5-32B",
    "Parameters (B)": 32.512,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 119.93431883170672,
    "Overall Score": 27.2987558571606,
    "MMLU Score": 38.88519503546098,
    "BBH Score": 38.980351633108974,
    "Math Score": 30.28700906344411,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.22761421520612915
  },
  {
    "Model Name": "Qwen/Qwen1.5-32B-Chat",
    "Parameters (B)": 32.512,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 92.1188994620152,
    "Overall Score": 29.25746822860332,
    "MMLU Score": 38.41422872340425,
    "BBH Score": 44.55485402391639,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.31760549028994317
  },
  {
    "Model Name": "Qwen/Qwen1.5-4B",
    "Parameters (B)": 3.95,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.277364333807762,
    "Overall Score": 11.76818275851784,
    "MMLU Score": 16.22340425531915,
    "BBH Score": 16.249142581095292,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.590745965324256
  },
  {
    "Model Name": "Qwen/Qwen1.5-4B-Chat",
    "Parameters (B)": 3.95,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7323012956775985,
    "Overall Score": 12.627280110791752,
    "MMLU Score": 15.512337470449172,
    "BBH Score": 16.29707852890831,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.289309395714864
  },
  {
    "Model Name": "Qwen/Qwen1.5-7B",
    "Parameters (B)": 7.721,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.65470810819048,
    "Overall Score": 16.024674155407357,
    "MMLU Score": 21.293218085106385,
    "BBH Score": 23.075768754340448,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.384665938025211
  },
  {
    "Model Name": "Qwen/Qwen1.5-7B-Chat",
    "Parameters (B)": 7.721,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.15765319338272,
    "Overall Score": 17.62098662745355,
    "MMLU Score": 21.681072695035464,
    "BBH Score": 22.379129599952787,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.166737213142103
  },
  {
    "Model Name": "Qwen/Qwen1.5-MoE-A2.7B",
    "Parameters (B)": 14.316,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 19.09122579213944,
    "Overall Score": 13.945920112290064,
    "MMLU Score": 19.751034278959807,
    "BBH Score": 18.837858500547185,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7304884591555202
  },
  {
    "Model Name": "Qwen/Qwen1.5-MoE-A2.7B-Chat",
    "Parameters (B)": 14.316,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 17.803943075071622,
    "Overall Score": 15.880899856122356,
    "MMLU Score": 21.3670951536643,
    "BBH Score": 20.04181889554096,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.8919877910842214
  },
  {
    "Model Name": "Qwen/Qwen2-0.5B",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.6323615007483467,
    "Overall Score": 7.224121473565234,
    "MMLU Score": 7.99534574468085,
    "BBH Score": 7.918512040903256,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.7443500717935243
  },
  {
    "Model Name": "Qwen/Qwen2-0.5B-Instruct",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1156954462905264,
    "Overall Score": 6.586780633287707,
    "MMLU Score": 5.89908392434988,
    "BBH Score": 5.876044259408482,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.903744301536311
  },
  {
    "Model Name": "Qwen/Qwen2-1.5B",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.2163897840094315,
    "Overall Score": 10.445452935561454,
    "MMLU Score": 17.239213947990542,
    "BBH Score": 11.781833653483533,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.712823083251048
  },
  {
    "Model Name": "Qwen/Qwen2-1.5B-Instruct",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3176478771125482,
    "Overall Score": 14.141936815181689,
    "MMLU Score": 16.675901300236408,
    "BBH Score": 13.695346827502664,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.732713239118088
  },
  {
    "Model Name": "Qwen/Qwen2-57B-A14B",
    "Parameters (B)": 57.409,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 107.03147746473374,
    "Overall Score": 25.0338731324107,
    "MMLU Score": 43.51174645390071,
    "BBH Score": 38.87598905034189,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.23389262416431858
  },
  {
    "Model Name": "Qwen/Qwen2-57B-A14B-Instruct",
    "Parameters (B)": 57.409,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 85.0124950064074,
    "Overall Score": 33.015868823547095,
    "MMLU Score": 39.725546690307326,
    "BBH Score": 41.785917734842535,
    "Math Score": 28.172205438066467,
    "Date Submitted": "2024-08-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.3883648964903181
  },
  {
    "Model Name": "Qwen/Qwen2-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 128.12455847973288,
    "Overall Score": 35.45667093247413,
    "MMLU Score": 52.56168735224587,
    "BBH Score": 51.85613118695519,
    "Math Score": 31.1178247734139,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.27673594627904824
  },
  {
    "Model Name": "Qwen/Qwen2-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 75.10794884539997,
    "Overall Score": 43.59406246367795,
    "MMLU Score": 48.92324172576833,
    "BBH Score": 57.48300911876294,
    "Math Score": 41.76737160120846,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5804187590505328
  },
  {
    "Model Name": "Qwen/Qwen2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.561164511151682,
    "Overall Score": 23.9251621404824,
    "MMLU Score": 35.366799645390074,
    "BBH Score": 34.711136202753416,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.341517124850345
  },
  {
    "Model Name": "Qwen/Qwen2-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.084077971714984,
    "Overall Score": 27.93668778218485,
    "MMLU Score": 31.636007683215123,
    "BBH Score": 37.80839092310167,
    "Math Score": 27.64350453172205,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.404818898976126
  },
  {
    "Model Name": "Qwen/Qwen2-Math-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.33649538965421,
    "Overall Score": 38.020957002292825,
    "MMLU Score": 36.364140070921984,
    "BBH Score": 47.96019950734914,
    "Math Score": 55.36253776435045,
    "Date Submitted": "2024-08-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.5623020650071116
  },
  {
    "Model Name": "Qwen/Qwen2-Math-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.126072125810204,
    "Overall Score": 12.016921148016648,
    "MMLU Score": 2.186761229314421,
    "BBH Score": 14.064494488871304,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2024-08-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.8440959339356717
  },
  {
    "Model Name": "Qwen/Qwen2-VL-72B-Instruct",
    "Parameters (B)": 73.406,
    "Architecture": "Qwen2VLForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 54.4994330312004,
    "Overall Score": 39.53661995549832,
    "MMLU Score": 52.41393321513003,
    "BBH Score": 56.3112338791251,
    "Math Score": 34.44108761329305,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.7254501149188833
  },
  {
    "Model Name": "Qwen/Qwen2-VL-7B-Instruct",
    "Parameters (B)": 8.291,
    "Architecture": "Qwen2VLForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 2.1087645694479167,
    "Overall Score": 26.493258763428177,
    "MMLU Score": 34.38792848699764,
    "BBH Score": 35.87710314498947,
    "Math Score": 19.86404833836858,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.563402831812667
  },
  {
    "Model Name": "Qwen/Qwen2.5-0.5B",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.330685257636701,
    "Overall Score": 6.550067614297009,
    "MMLU Score": 10.0639036643026,
    "BBH Score": 6.953961634882263,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.810361284448477
  },
  {
    "Model Name": "Qwen/Qwen2.5-0.5B-Instruct",
    "Parameters (B)": 0.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6308244528197698,
    "Overall Score": 8.140647319276075,
    "MMLU Score": 7.746010638297871,
    "BBH Score": 8.434863610588833,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.904774510384913
  },
  {
    "Model Name": "Qwen/Qwen2.5-0.5B-Instruct",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2371519491666767,
    "Overall Score": 10.107543850719257,
    "MMLU Score": 7.99534574468085,
    "BBH Score": 8.169502268182768,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.170010044059273
  },
  {
    "Model Name": "Qwen/Qwen2.5-1.5B",
    "Parameters (B)": 1.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.497002020007018,
    "Overall Score": 13.852701161320264,
    "MMLU Score": 20.609855200945624,
    "BBH Score": 16.660465167691854,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.547733261858286
  },
  {
    "Model Name": "Qwen/Qwen2.5-1.5B-Instruct",
    "Parameters (B)": 1.5,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3743786623908494,
    "Overall Score": 18.430509141644382,
    "MMLU Score": 19.99113475177305,
    "BBH Score": 19.80978649735897,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.41006641472659
  },
  {
    "Model Name": "Qwen/Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 8.733912171643484,
    "Overall Score": 31.951062693148973,
    "MMLU Score": 47.20559988179669,
    "BBH Score": 45.078312404984935,
    "Math Score": 29.003021148036257,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.6582761613844643
  },
  {
    "Model Name": "Qwen/Qwen2.5-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.547300640675203,
    "Overall Score": 41.30945747711163,
    "MMLU Score": 43.382461583924346,
    "BBH Score": 48.36070661282705,
    "Math Score": 54.7583081570997,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.645321798619435
  },
  {
    "Model Name": "Qwen/Qwen2.5-14B-Instruct-1M",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2822772236538045,
    "Overall Score": 41.559026792386994,
    "MMLU Score": 42.77297576832151,
    "BBH Score": 45.65828060023316,
    "Math Score": 53.02114803625378,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.661644328178904
  },
  {
    "Model Name": "Qwen/Qwen2.5-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 11.74977108549449,
    "Overall Score": 38.00796730514634,
    "MMLU Score": 53.39280437352246,
    "BBH Score": 53.954752851332,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.2347836420463136
  },
  {
    "Model Name": "Qwen/Qwen2.5-32B-Instruct",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 11.50496634068574,
    "Overall Score": 46.59714569921449,
    "MMLU Score": 51.85062056737589,
    "BBH Score": 56.48934826159387,
    "Math Score": 62.53776435045317,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.050176621067552
  },
  {
    "Model Name": "Qwen/Qwen2.5-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.386605082306483,
    "Overall Score": 18.10277021768368,
    "MMLU Score": 24.479166666666664,
    "BBH Score": 24.30424172637169,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3607012099599256
  },
  {
    "Model Name": "Qwen/Qwen2.5-3B-Instruct",
    "Parameters (B)": 3.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.776948611161924,
    "Overall Score": 27.16175720903232,
    "MMLU Score": 25.05171394799054,
    "BBH Score": 25.801393944088584,
    "Math Score": 36.78247734138973,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.781152269025016
  },
  {
    "Model Name": "Qwen/Qwen2.5-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 36.18385317998766,
    "Overall Score": 38.441143572535815,
    "MMLU Score": 55.20279255319149,
    "BBH Score": 54.61505780163693,
    "Math Score": 39.12386706948641,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.062383914209463
  },
  {
    "Model Name": "Qwen/Qwen2.5-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 47.64549134130984,
    "Overall Score": 47.98045991216864,
    "MMLU Score": 51.39812352245864,
    "BBH Score": 61.87325566878789,
    "Math Score": 59.818731117824775,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.0070304358592765
  },
  {
    "Model Name": "Qwen/Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 4.686730426753914,
    "Overall Score": 26.019159924095096,
    "MMLU Score": 37.38918439716312,
    "BBH Score": 35.81347328754777,
    "Math Score": 25.075528700906347,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.5516655653088804
  },
  {
    "Model Name": "Qwen/Qwen2.5-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.2405911036770783,
    "Overall Score": 35.200108659947965,
    "MMLU Score": 36.52112884160757,
    "BBH Score": 34.89211675876548,
    "Math Score": 50.0,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.862249365557606
  },
  {
    "Model Name": "Qwen/Qwen2.5-7B-Instruct-1M",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2526745301638325,
    "Overall Score": 32.76394723937119,
    "MMLU Score": 27.83133865248227,
    "BBH Score": 35.02629094112727,
    "Math Score": 43.353474320241695,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.155195504043753
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 7.265250401506517,
    "Overall Score": 24.82905228038836,
    "MMLU Score": 39.12529550827424,
    "BBH Score": 40.52300211536303,
    "Math Score": 22.507552870090635,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.4175081254239807
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7664281305179466,
    "Overall Score": 32.12283417812606,
    "MMLU Score": 32.661052009456256,
    "BBH Score": 44.220018215668375,
    "Math Score": 32.477341389728096,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.611664089069192
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 9.380500534599602,
    "Overall Score": 33.2623633375386,
    "MMLU Score": 47.80585106382979,
    "BBH Score": 48.51121340614174,
    "Math Score": 30.891238670694865,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.5459049562282634
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.388779325959574,
    "Overall Score": 39.8854717744228,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 52.26651520943606,
    "Math Score": 49.546827794561935,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.248206331161834
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 4.60353433601591,
    "Overall Score": 19.20949053896225,
    "MMLU Score": 29.770611702127653,
    "BBH Score": 28.43894411525553,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.1727701233107215
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.466291949742477,
    "Overall Score": 28.05232118270496,
    "MMLU Score": 26.13216607565012,
    "BBH Score": 28.938504045379137,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.374290535893003
  },
  {
    "Model Name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6976473478971377,
    "Overall Score": 22.52451581645211,
    "MMLU Score": 26.15986997635934,
    "BBH Score": 28.72657796895031,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 32.286392092431726
  },
  {
    "Model Name": "Qwen/Qwen2.5-Math-1.5B-Instruct",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5143773674194003,
    "Overall Score": 12.024869614820515,
    "MMLU Score": 8.900339834515366,
    "BBH Score": 12.859775311917048,
    "Math Score": 26.28398791540785,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.377524705545557
  },
  {
    "Model Name": "Qwen/Qwen2.5-Math-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 43.05624224831484,
    "Overall Score": 36.82286386234789,
    "MMLU Score": 42.35741725768321,
    "BBH Score": 48.966096029421145,
    "Math Score": 62.38670694864048,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.8552270690503438
  },
  {
    "Model Name": "Qwen/Qwen2.5-Math-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.6794594912552814,
    "Overall Score": 17.836657156289718,
    "MMLU Score": 19.086140661938536,
    "BBH Score": 22.00876067958663,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.656811649700868
  },
  {
    "Model Name": "Qwen/Qwen2.5-Math-7B-Instruct",
    "Parameters (B)": 7.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.2785331217726195,
    "Overall Score": 21.76814573761254,
    "MMLU Score": 20.222000591016545,
    "BBH Score": 21.489765755272032,
    "Math Score": 58.08157099697885,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.553578804541441
  },
  {
    "Model Name": "RDson/WomboCombo-R1-Coder-14B-Preview",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9961055061782886,
    "Overall Score": 41.45611578076993,
    "MMLU Score": 46.30984042553191,
    "BBH Score": 48.15414248872669,
    "Math Score": 59.89425981873112,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.374129440945831
  },
  {
    "Model Name": "RESMPDEV/EVA-Qwen2.5-1.5B-FRFR",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.822263854006556,
    "Overall Score": 14.185076993762264,
    "MMLU Score": 19.66792257683215,
    "BBH Score": 15.629561469371746,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.784315626177826
  },
  {
    "Model Name": "RESMPDEV/Qwen2-Wukong-0.5B",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.974538186250253,
    "Overall Score": 4.975539710746782,
    "MMLU Score": 3.6365986997635926,
    "BBH Score": 4.19666315993673,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.5198498288835736
  },
  {
    "Model Name": "RLHFlow/ArmoRM-Llama3-8B-v0.1",
    "Parameters (B)": 7.511,
    "Architecture": "LlamaForRewardModelWithGating",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.84704582456392,
    "Overall Score": 4.705487409302649,
    "MMLU Score": 0.8662086288416063,
    "BBH Score": 1.7494478703137453,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.547574806604268
  },
  {
    "Model Name": "RLHFlow/LLaMA3-iterative-DPO-final",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9858864014385222,
    "Overall Score": 21.10915279745133,
    "MMLU Score": 25.07941784869976,
    "BBH Score": 29.787760272097795,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.069643636570196
  },
  {
    "Model Name": "RWKV/rwkv-raven-14b",
    "Parameters (B)": 14.0,
    "Architecture": "RwkvForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.18125813986212,
    "Overall Score": 3.960585302315618,
    "MMLU Score": 1.6696217494089831,
    "BBH Score": 6.763765061303336,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-07-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.244974512658465
  },
  {
    "Model Name": "Rakuten/RakutenAI-2.0-mini-instruct",
    "Parameters (B)": 1.535,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.2994162703932504,
    "Overall Score": 13.318016561874655,
    "MMLU Score": 1.309471040189124,
    "BBH Score": 2.429693164521931,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.479936058193836
  },
  {
    "Model Name": "Rakuten/RakutenAI-7B",
    "Parameters (B)": 7.373,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.283697362467484,
    "Overall Score": 11.546978376746557,
    "MMLU Score": 20.859190307328607,
    "BBH Score": 20.98205231291448,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.995093948429798
  },
  {
    "Model Name": "Rakuten/RakutenAI-7B-chat",
    "Parameters (B)": 7.373,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2481386253427609,
    "Overall Score": 12.803095362134842,
    "MMLU Score": 19.98190011820331,
    "BBH Score": 20.23755200474476,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.257751104064171
  },
  {
    "Model Name": "Replete-AI/L3-Pneuma-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.0535998520828125,
    "Overall Score": 16.691758570090254,
    "MMLU Score": 24.174423758865245,
    "BBH Score": 28.163142118962657,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-10-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.3029442493771723
  },
  {
    "Model Name": "Replete-AI/L3.1-Pneuma-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.411702210150894,
    "Overall Score": 27.68476446634547,
    "MMLU Score": 29.89989657210401,
    "BBH Score": 30.26262992696204,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.610909629011843
  },
  {
    "Model Name": "Replete-AI/Llama3-8B-Instruct-Replete-Adapted",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.52075572419241,
    "Overall Score": 22.778517848782894,
    "MMLU Score": 26.56619385342789,
    "BBH Score": 26.88896431517229,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-07-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.978419930577159
  },
  {
    "Model Name": "Replete-AI/Replete-Coder-Instruct-8b-Merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8290703222264988,
    "Overall Score": 16.427667565252104,
    "MMLU Score": 8.946513002364064,
    "BBH Score": 21.937706578272657,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.981430273962873
  },
  {
    "Model Name": "Replete-AI/Replete-Coder-Llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8316138780159936,
    "Overall Score": 11.957974284260397,
    "MMLU Score": 3.673537234042553,
    "BBH Score": 7.055475836799367,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.2230243244318695
  },
  {
    "Model Name": "Replete-AI/Replete-Coder-Qwen2-1.5b",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.423742103559073,
    "Overall Score": 11.561043907502103,
    "MMLU Score": 12.741947399527188,
    "BBH Score": 10.4265158026681,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.3767274396877274
  },
  {
    "Model Name": "Replete-AI/Replete-LLM-Qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2272244583500491,
    "Overall Score": 3.325393716070183,
    "MMLU Score": 1.7527334515366433,
    "BBH Score": 2.8429334106486,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.709686637553682
  },
  {
    "Model Name": "Replete-AI/Replete-LLM-Qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8560068866327823,
    "Overall Score": 3.509166955357833,
    "MMLU Score": 1.7434988179669018,
    "BBH Score": 2.7249704476856373,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.8907079389798267
  },
  {
    "Model Name": "Replete-AI/Replete-LLM-Qwen2-7b_Beta-Preview",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7141374098407907,
    "Overall Score": 3.5774317458290468,
    "MMLU Score": 3.1656323877068555,
    "BBH Score": 1.965676941851036,
    "Math Score": 0.0,
    "Date Submitted": "2024-07-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.009444536208511
  },
  {
    "Model Name": "Replete-AI/Replete-LLM-V2-Llama-3.1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8173619569423272,
    "Overall Score": 24.979162332053424,
    "MMLU Score": 30.59249408983452,
    "BBH Score": 33.20757217219532,
    "Math Score": 14.04833836858006,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.74473711009134
  },
  {
    "Model Name": "RezVortex/JAJUKA-WEWILLNEVERFORGETYOU-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5911842340907093,
    "Overall Score": 23.21508244249907,
    "MMLU Score": 23.814273049645383,
    "BBH Score": 23.76082401416404,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.26877799474102
  },
  {
    "Model Name": "RezVortex/Jajuka-3b",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5819576797318761,
    "Overall Score": 23.475390627446263,
    "MMLU Score": 23.749630614657207,
    "BBH Score": 23.204983328457303,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.33865596251264
  },
  {
    "Model Name": "Ro-xe/FMixIA-7B-DARE-0",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.922862416191407,
    "Overall Score": 18.934625270182,
    "MMLU Score": 22.40137411347517,
    "BBH Score": 30.438332290985624,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.5172785650151
  },
  {
    "Model Name": "Ro-xe/FMixIA-7B-SLERP-27",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9396340099477578,
    "Overall Score": 19.827314533484948,
    "MMLU Score": 22.30902777777777,
    "BBH Score": 31.938224362460755,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.101103539863693
  },
  {
    "Model Name": "Ro-xe/FMixIA-7B-TIES-1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9815896320268432,
    "Overall Score": 19.54118956968649,
    "MMLU Score": 22.13356973995272,
    "BBH Score": 31.12772625110915,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.907697608150883
  },
  {
    "Model Name": "Ro-xe/FMixIA-FrankenMerge-9.5B-PT-9",
    "Parameters (B)": 14.141,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.393437482412552,
    "Overall Score": 16.18640423218573,
    "MMLU Score": 29.521276595744684,
    "BBH Score": 30.71304149113964,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.6842231844613273
  },
  {
    "Model Name": "Rombo-Org/Rombo-LLM-V2.5-Qwen-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3722715337968086,
    "Overall Score": 35.259585169099566,
    "MMLU Score": 36.47495567375886,
    "BBH Score": 34.90725375177349,
    "Math Score": 50.6797583081571,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.694320912963303
  },
  {
    "Model Name": "RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.675063876394784,
    "Overall Score": 20.11738926127926,
    "MMLU Score": 23.19555260047281,
    "BBH Score": 32.794801632016096,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.00992364815223
  },
  {
    "Model Name": "SaisExperiments/Evil-Alpaca-3B-L3.2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4662990719171607,
    "Overall Score": 15.188052941960947,
    "MMLU Score": 18.0149231678487,
    "BBH Score": 20.8519483855812,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.358086718354688
  },
  {
    "Model Name": "SaisExperiments/Gemma-2-2B-Opus-Instruct",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3151877623198,
    "Overall Score": 17.2459909559155,
    "MMLU Score": 18.3381353427896,
    "BBH Score": 19.52953299453869,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.4490679488713045
  },
  {
    "Model Name": "SaisExperiments/Gemma-2-2B-Stheno-Filtered",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7767344071723716,
    "Overall Score": 15.491102762862866,
    "MMLU Score": 18.107269503546096,
    "BBH Score": 17.47886723805338,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.718862369258987
  },
  {
    "Model Name": "SaisExperiments/Not-So-Small-Alpaca-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.641718285116668,
    "Overall Score": 28.3830645086872,
    "MMLU Score": 29.93683510638298,
    "BBH Score": 33.01860534638029,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.744167789804166
  },
  {
    "Model Name": "SaisExperiments/QwOwO-7B-V1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6211564839381374,
    "Overall Score": 27.075777072300355,
    "MMLU Score": 35.819296690307326,
    "BBH Score": 35.132501310841604,
    "Math Score": 38.59516616314199,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.5893012025564
  },
  {
    "Model Name": "SaisExperiments/RightSheep-Llama3.2-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1538792911990543,
    "Overall Score": 15.85739377536482,
    "MMLU Score": 17.109929078014183,
    "BBH Score": 18.64329803541729,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.74267992875286
  },
  {
    "Model Name": "Sakalti/Anemoi-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4790797503578654,
    "Overall Score": 22.61986902453321,
    "MMLU Score": 30.73101359338061,
    "BBH Score": 29.05396043035601,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.293204453012287
  },
  {
    "Model Name": "Sakalti/Euphrates-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.024972004103708,
    "Overall Score": 30.662907563811626,
    "MMLU Score": 47.27947695035461,
    "BBH Score": 44.60858230795797,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.1365921807587
  },
  {
    "Model Name": "Sakalti/Llama3.2-3B-Uranus-1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.16946476137345,
    "Overall Score": 21.030483022816096,
    "MMLU Score": 23.26942966903073,
    "BBH Score": 21.416406817010444,
    "Math Score": 14.954682779456194,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.982998477113025
  },
  {
    "Model Name": "Sakalti/Magro-7B-v1.1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8638460693173928,
    "Overall Score": 12.14114119775379,
    "MMLU Score": 19.60328014184397,
    "BBH Score": 19.41013217726553,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.054750758254492
  },
  {
    "Model Name": "Sakalti/Neptuno-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4880946044373673,
    "Overall Score": 23.466342186693208,
    "MMLU Score": 30.81412529550828,
    "BBH Score": 27.482799614341257,
    "Math Score": 25.528700906344408,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.769388664348783
  },
  {
    "Model Name": "Sakalti/Neptuno-Alpha",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4104846818544805,
    "Overall Score": 22.739135010323626,
    "MMLU Score": 30.74948286052009,
    "BBH Score": 29.029618644319683,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.121504404022744
  },
  {
    "Model Name": "Sakalti/Oxyge1-33B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 11.323784419799072,
    "Overall Score": 41.60924567669207,
    "MMLU Score": 54.54713356973996,
    "BBH Score": 58.03229697403189,
    "Math Score": 49.62235649546828,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.674499984646509
  },
  {
    "Model Name": "Sakalti/Phi3.5-Comets-3.8B",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0273448195668746,
    "Overall Score": 5.760043006242388,
    "MMLU Score": 1.6973256501182026,
    "BBH Score": 6.53359017300762,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.606728039637952
  },
  {
    "Model Name": "Sakalti/Qwen2.5-1B-Instruct",
    "Parameters (B)": 0.988,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.910389994689229,
    "Overall Score": 4.275488298707521,
    "MMLU Score": 2.3714539007092186,
    "BBH Score": 3.437039790947589,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.238018577669023
  },
  {
    "Model Name": "Sakalti/QwenTest-7",
    "Parameters (B)": 0.988,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.878241224216624,
    "Overall Score": 4.255208552096732,
    "MMLU Score": 2.352984633569739,
    "BBH Score": 3.6327089522677753,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.2655282491052198
  },
  {
    "Model Name": "Sakalti/SJT-0.5B",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0150278917178388,
    "Overall Score": 8.576015804911226,
    "MMLU Score": 9.89768026004728,
    "BBH Score": 8.409743934103323,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.449044479356257
  },
  {
    "Model Name": "Sakalti/SJT-1.5B-Alpha",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.109603817087066,
    "Overall Score": 16.911765349077854,
    "MMLU Score": 21.79188829787234,
    "BBH Score": 18.535867065098497,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.241264574480875
  },
  {
    "Model Name": "Sakalti/SJT-1.5B-Alpha-1.1",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0746383971386602,
    "Overall Score": 16.820570294667494,
    "MMLU Score": 21.84729609929078,
    "BBH Score": 18.576163936656105,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.652307175561626
  },
  {
    "Model Name": "Sakalti/SJT-1.7B",
    "Parameters (B)": 1.684,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2959849868492936,
    "Overall Score": 5.034230484246264,
    "MMLU Score": 1.4756944444444438,
    "BBH Score": 2.896901055053732,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.8844821007418666
  },
  {
    "Model Name": "Sakalti/SJT-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.510360371451952,
    "Overall Score": 38.21030695378075,
    "MMLU Score": 48.67390661938534,
    "BBH Score": 49.99070835617017,
    "Math Score": 38.4441087613293,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.471674945450154
  },
  {
    "Model Name": "Sakalti/SJT-2.4B",
    "Parameters (B)": 2.432,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7115605292280882,
    "Overall Score": 8.90691477930258,
    "MMLU Score": 9.537529550827422,
    "BBH Score": 8.383641553044898,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.203972998442298
  },
  {
    "Model Name": "Sakalti/SJT-24B-Alpha",
    "Parameters (B)": 24.125,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.570278523730434,
    "Overall Score": 29.687175261647443,
    "MMLU Score": 42.856087470449175,
    "BBH Score": 44.44992027804292,
    "Math Score": 25.302114803625376,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.329567477671806
  },
  {
    "Model Name": "Sakalti/SJT-2B",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.407519547751544,
    "Overall Score": 4.821696209153122,
    "MMLU Score": 2.0759456264775418,
    "BBH Score": 1.885908059916924,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.0027651337893606
  },
  {
    "Model Name": "Sakalti/SJT-2B-V1.1",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6165986508412546,
    "Overall Score": 14.58950928973948,
    "MMLU Score": 12.492612293144209,
    "BBH Score": 15.547066237177036,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.02481842487454
  },
  {
    "Model Name": "Sakalti/SJT-3.7B",
    "Parameters (B)": 3.783,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2065671720503752,
    "Overall Score": 5.089318203640183,
    "MMLU Score": 5.612810283687943,
    "BBH Score": 7.8072799104561055,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.21801481221445
  },
  {
    "Model Name": "Sakalti/SJT-4B",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.833496941991619,
    "Overall Score": 21.994031536147386,
    "MMLU Score": 25.34722222222222,
    "BBH Score": 28.91383734049992,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.387657144360034
  },
  {
    "Model Name": "Sakalti/SJT-7.5B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4681774046591205,
    "Overall Score": 25.88865048007519,
    "MMLU Score": 32.790336879432616,
    "BBH Score": 34.23401639666226,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.633189557283767
  },
  {
    "Model Name": "Sakalti/SJT-7B-V1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.323080701100286,
    "Overall Score": 28.195244495354924,
    "MMLU Score": 37.90632387706855,
    "BBH Score": 35.097523213785486,
    "Math Score": 24.3202416918429,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.31029836041558
  },
  {
    "Model Name": "Sakalti/SJT-7B-V1.1-Multilingal",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4192332933550222,
    "Overall Score": 4.71738898050407,
    "MMLU Score": 1.521867612293143,
    "BBH Score": 3.060666963755198,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.323899603110573
  },
  {
    "Model Name": "Sakalti/SJT-8B",
    "Parameters (B)": 8.548,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.839929665668291,
    "Overall Score": 29.90631962140043,
    "MMLU Score": 36.290263002364064,
    "BBH Score": 33.33083133498579,
    "Math Score": 25.37764350453172,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.254055891064723
  },
  {
    "Model Name": "Sakalti/SJT-8B-V1.1",
    "Parameters (B)": 8.545,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7253098966587963,
    "Overall Score": 26.20087403142101,
    "MMLU Score": 35.90240839243498,
    "BBH Score": 31.31949877760972,
    "Math Score": 20.694864048338367,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.613906317055182
  },
  {
    "Model Name": "Sakalti/SJT-900M",
    "Parameters (B)": 0.899,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7087868760604994,
    "Overall Score": 5.791993813854994,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 4.3018424038847485,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.3895355207830664
  },
  {
    "Model Name": "Sakalti/SJT-Moe2x7.5B",
    "Parameters (B)": 13.401,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6970671992670097,
    "Overall Score": 25.679678830683567,
    "MMLU Score": 32.81804078014184,
    "BBH Score": 34.245683063328926,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.521334447158978
  },
  {
    "Model Name": "Sakalti/SJTPass-2",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0617289263368817,
    "Overall Score": 8.578554710120141,
    "MMLU Score": 10.0177304964539,
    "BBH Score": 8.362336526695914,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.079797486273069
  },
  {
    "Model Name": "Sakalti/SJTPass-4",
    "Parameters (B)": 1.167,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.363076527133505,
    "Overall Score": 5.078209950944516,
    "MMLU Score": 0.9216164302600468,
    "BBH Score": 2.456191569806904,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.148982435666002
  },
  {
    "Model Name": "Sakalti/SJTPass-5",
    "Parameters (B)": 0.809,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.460292660441067,
    "Overall Score": 6.780863382054697,
    "MMLU Score": 3.6365986997635926,
    "BBH Score": 4.049294123683027,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.643496174257702
  },
  {
    "Model Name": "Sakalti/Saba-Passthrough-2",
    "Parameters (B)": 3.087,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.203399559283904,
    "Overall Score": 8.019416015292425,
    "MMLU Score": 11.966238179669029,
    "BBH Score": 11.94868585880535,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.639565044616194
  },
  {
    "Model Name": "Sakalti/Saba1-1.8B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1643531206320985,
    "Overall Score": 17.174113467091598,
    "MMLU Score": 21.39479905437352,
    "BBH Score": 17.532918576799144,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.749918356184073
  },
  {
    "Model Name": "Sakalti/Saba1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3641929348973936,
    "Overall Score": 30.52372634788429,
    "MMLU Score": 37.50923463356973,
    "BBH Score": 35.23563153262108,
    "Math Score": 36.63141993957704,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.374933608771475
  },
  {
    "Model Name": "Sakalti/Saba1.5-1.5B",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1457239270410775,
    "Overall Score": 17.174113467091598,
    "MMLU Score": 21.39479905437352,
    "BBH Score": 17.532918576799144,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.989748456633093
  },
  {
    "Model Name": "Sakalti/Saba1.5-Pro-3B",
    "Parameters (B)": 2.9,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0211880085819254,
    "Overall Score": 10.788079074661752,
    "MMLU Score": 10.645685579196217,
    "BBH Score": 11.041395854945073,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.33749410191223
  },
  {
    "Model Name": "Sakalti/Saba2-14B-Preview",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.1790733504217985,
    "Overall Score": 35.687158487523945,
    "MMLU Score": 48.71084515366431,
    "BBH Score": 49.64957000538939,
    "Math Score": 31.268882175226587,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.225648028155431
  },
  {
    "Model Name": "Sakalti/Saba2-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.630537214027361,
    "Overall Score": 7.068766556279139,
    "MMLU Score": 2.33451536643026,
    "BBH Score": 2.002419101562576,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.335237794922553
  },
  {
    "Model Name": "Sakalti/Sailor-japanese",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.472633047697636,
    "Overall Score": 4.518102124361933,
    "MMLU Score": 1.8266105200945613,
    "BBH Score": 1.721791288073509,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.3010594734037464
  },
  {
    "Model Name": "Sakalti/Saka-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2166855344358272,
    "Overall Score": 12.780380949151962,
    "MMLU Score": 15.724734042553193,
    "BBH Score": 16.01477085551285,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.504259800440694
  },
  {
    "Model Name": "Sakalti/Saka-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.817782434928411,
    "Overall Score": 41.90788417749271,
    "MMLU Score": 48.84013002364066,
    "BBH Score": 49.72322791125956,
    "Math Score": 40.93655589123867,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.97702262813165
  },
  {
    "Model Name": "Sakalti/Saka-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5344282496185704,
    "Overall Score": 28.23669492021674,
    "MMLU Score": 41.84027777777778,
    "BBH Score": 43.31107440533594,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.141248494395665
  },
  {
    "Model Name": "Sakalti/Saka-7.2B",
    "Parameters (B)": 7.292,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4495863626061547,
    "Overall Score": 3.869360483737708,
    "MMLU Score": 1.7804373522458627,
    "BBH Score": 2.1709866331347283,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.669285931181869
  },
  {
    "Model Name": "Sakalti/Saka-7.6B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3050669573744147,
    "Overall Score": 29.81529957886164,
    "MMLU Score": 39.33769208037825,
    "BBH Score": 37.97118088942005,
    "Math Score": 32.55287009063444,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.845800677419064
  },
  {
    "Model Name": "Sakalti/SakaMoe-3x1.6B-Instruct",
    "Parameters (B)": 1.572,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0961688491425574,
    "Overall Score": 8.276328372160824,
    "MMLU Score": 9.80533392434988,
    "BBH Score": 7.525328438833678,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.550231315763729
  },
  {
    "Model Name": "Sakalti/SakalFusion-7B-Alpha",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2594490151745308,
    "Overall Score": 32.1092425705961,
    "MMLU Score": 38.598921394799056,
    "BBH Score": 36.780545262095615,
    "Math Score": 38.4441087613293,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.49467440422469
  },
  {
    "Model Name": "Sakalti/SakalFusion-7B-Beta",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3951089379366617,
    "Overall Score": 4.453145556903973,
    "MMLU Score": 0.9954934988179668,
    "BBH Score": 1.4987820116285064,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.1919697708267045
  },
  {
    "Model Name": "Sakalti/Tara-3.8B-v1.1",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8283155253074412,
    "Overall Score": 21.968635956123418,
    "MMLU Score": 25.34722222222222,
    "BBH Score": 28.91383734049992,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.522062287760985
  },
  {
    "Model Name": "Sakalti/light-1.1-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4902297180434927,
    "Overall Score": 6.923496536132208,
    "MMLU Score": 2.32528073286052,
    "BBH Score": 1.880515639056776,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.64592569340383
  },
  {
    "Model Name": "Sakalti/light-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.4053189900210823,
    "Overall Score": 25.284693562377303,
    "MMLU Score": 30.83259456264776,
    "BBH Score": 27.46784968544221,
    "Math Score": 25.90634441087613,
    "Date Submitted": "2025-01-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.511991826146804
  },
  {
    "Model Name": "Sakalti/light-3b-beta",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5219403009060517,
    "Overall Score": 25.809275245445864,
    "MMLU Score": 30.64790189125296,
    "BBH Score": 27.27438755254684,
    "Math Score": 27.7190332326284,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.95813904795143
  },
  {
    "Model Name": "Sakalti/light-7b-beta",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3886399483488214,
    "Overall Score": 32.68982935684443,
    "MMLU Score": 38.39575945626477,
    "BBH Score": 36.37504670970679,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.54089654104698
  },
  {
    "Model Name": "Sakalti/llama-3-yanyuedao-8b-instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.494317719320831,
    "Overall Score": 13.935841337684982,
    "MMLU Score": 21.22857565011821,
    "BBH Score": 20.593160052037973,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.325889104774076
  },
  {
    "Model Name": "Sakalti/magro-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9045520120665084,
    "Overall Score": 12.382552499684506,
    "MMLU Score": 19.61251477541371,
    "BBH Score": 19.54888376105943,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.68915477993991
  },
  {
    "Model Name": "Sakalti/mergekit-01",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3946770910685848,
    "Overall Score": 32.68982935684443,
    "MMLU Score": 38.39575945626477,
    "BBH Score": 36.37504670970679,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.438994994746686
  },
  {
    "Model Name": "Sakalti/mergekit-della_linear-vmeykci",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3824972617381066,
    "Overall Score": 3.741275884240794,
    "MMLU Score": 0.9862588652482256,
    "BBH Score": 0.975893246187364,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.706172364882067
  },
  {
    "Model Name": "Sakalti/model-3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3637598052620072,
    "Overall Score": 32.57244122186464,
    "MMLU Score": 38.38652482269504,
    "BBH Score": 36.31775528213533,
    "Math Score": 37.08459214501511,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.884294797504158
  },
  {
    "Model Name": "Sakalti/qwen2.5-2.3B",
    "Parameters (B)": 2.339,
    "Architecture": "Qwen2Model",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.213831595366386,
    "Overall Score": 3.701324621254564,
    "MMLU Score": 1.9189568557919607,
    "BBH Score": 1.1167186571598344,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.0492900624631925
  },
  {
    "Model Name": "Sakalti/tara-3.8B",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8321437628531957,
    "Overall Score": 21.994031536147386,
    "MMLU Score": 25.34722222222222,
    "BBH Score": 28.91383734049992,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.430567070208884
  },
  {
    "Model Name": "Sakalti/ultiima-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.9443342818350255,
    "Overall Score": 39.61010623253845,
    "MMLU Score": 48.67390661938534,
    "BBH Score": 49.51071627853103,
    "Math Score": 46.97885196374622,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.042279229464956
  },
  {
    "Model Name": "Sakalti/ultiima-14B-v0.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.8941810988986063,
    "Overall Score": 40.962282081659104,
    "MMLU Score": 48.74778368794326,
    "BBH Score": 49.51261036714752,
    "Math Score": 39.95468277945619,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.518843639101554
  },
  {
    "Model Name": "Sakalti/ultiima-14B-v0.3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.831010188497662,
    "Overall Score": 40.38402709174191,
    "MMLU Score": 48.18447104018913,
    "BBH Score": 48.445133231959545,
    "Math Score": 39.65256797583081,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.925734270093379
  },
  {
    "Model Name": "Sakalti/ultiima-14B-v0.4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.268835835549344,
    "Overall Score": 33.64162669559072,
    "MMLU Score": 47.538046690307326,
    "BBH Score": 48.24803486437804,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.291623191880813
  },
  {
    "Model Name": "Sakalti/ultiima-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.511603801652418,
    "Overall Score": 45.40321787320272,
    "MMLU Score": 54.55636820330969,
    "BBH Score": 58.112446786765965,
    "Math Score": 49.62235649546828,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.319342578918866
  },
  {
    "Model Name": "Sakalti/ultiima-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 36.96552782603761,
    "Overall Score": 46.76723892225559,
    "MMLU Score": 54.510195035461,
    "BBH Score": 61.10313258693403,
    "Math Score": 53.54984894259819,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.2651581533569745
  },
  {
    "Model Name": "Sakalti/ultiima-72B-v1.5",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 32.194072335681284,
    "Overall Score": 44.89912916202218,
    "MMLU Score": 56.153959810874696,
    "BBH Score": 63.438206058920265,
    "Math Score": 43.957703927492446,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.3946396309813731
  },
  {
    "Model Name": "Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7147848610366037,
    "Overall Score": 18.527751291550988,
    "MMLU Score": 24.137485224586285,
    "BBH Score": 29.15028934976556,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.804708924448276
  },
  {
    "Model Name": "SanjiWatsuki/Kunoichi-DPO-v2-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4164136863768286,
    "Overall Score": 20.5816311223652,
    "MMLU Score": 23.407949172576835,
    "BBH Score": 20.903472484123803,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.517428633350153
  },
  {
    "Model Name": "SanjiWatsuki/Silicon-Maid-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2123266045650976,
    "Overall Score": 19.412095533357363,
    "MMLU Score": 23.149379432624112,
    "BBH Score": 16.692746753586437,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.01226555637714
  },
  {
    "Model Name": "Sao10K/70B-L3.3-Cirrus-x1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 27.049162520156,
    "Overall Score": 43.0025823792082,
    "MMLU Score": 48.64620271867612,
    "BBH Score": 57.13231216638128,
    "Math Score": 37.38670694864049,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.5897934861075393
  },
  {
    "Model Name": "Sao10K/Fimbulvetr-11B-v2",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6424083021526863,
    "Overall Score": 21.089256463822466,
    "MMLU Score": 25.56885342789598,
    "BBH Score": 22.65512081005865,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.840446822011927
  },
  {
    "Model Name": "Sao10K/L3-70B-Euryale-v2.1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 17.236697092399766,
    "Overall Score": 35.43613152375533,
    "MMLU Score": 45.598773640661946,
    "BBH Score": 48.70118672944805,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.055853933836332
  },
  {
    "Model Name": "Sao10K/L3-70B-Euryale-v2.1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.616454319859539,
    "Overall Score": 35.473252668728755,
    "MMLU Score": 45.50642730496454,
    "BBH Score": 49.193003079898574,
    "Math Score": 22.43202416918429,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.116919947799018
  },
  {
    "Model Name": "Sao10K/L3-8B-Lunaris-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3209972770416638,
    "Overall Score": 25.577983918433663,
    "MMLU Score": 30.971114066193856,
    "BBH Score": 32.11434845509543,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-07-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 19.362631825945044
  },
  {
    "Model Name": "Sao10K/L3-8B-Niitama-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0607544329948946,
    "Overall Score": 25.7912140312776,
    "MMLU Score": 30.010712174940902,
    "BBH Score": 33.209787820927936,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.314028986388156
  },
  {
    "Model Name": "Sao10K/L3-8B-Stheno-v3.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.783344467254921,
    "Overall Score": 25.88439358819513,
    "MMLU Score": 30.75871749408984,
    "BBH Score": 32.02159792407502,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.514522608208521
  },
  {
    "Model Name": "Sao10K/L3-8B-Stheno-v3.3-32K",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.937264492143905,
    "Overall Score": 12.649981104473916,
    "MMLU Score": 9.95308806146572,
    "BBH Score": 13.51200898319754,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.306721828527166
  },
  {
    "Model Name": "Sao10K/MN-12B-Lyra-v3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.169329542761872,
    "Overall Score": 19.63563111181339,
    "MMLU Score": 24.987071513002363,
    "BBH Score": 25.870963383072453,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.709541644627649
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B",
    "Parameters (B)": 32.76,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.953929556785364,
    "Overall Score": 47.33695645964031,
    "MMLU Score": 53.25428486997635,
    "BBH Score": 57.63392862080288,
    "Math Score": 60.27190332326284,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.95139246855134
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V2-32B",
    "Parameters (B)": 32.76,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.597440968045287,
    "Overall Score": 43.33912719384693,
    "MMLU Score": 52.44163711583924,
    "BBH Score": 58.07744907944319,
    "Math Score": 56.64652567975831,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.040933384123079
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V3-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.081442953722984,
    "Overall Score": 46.36626657304592,
    "MMLU Score": 51.82291666666666,
    "BBH Score": 56.52792400025388,
    "Math Score": 61.78247734138973,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.547573266641852
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V4-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.50944829748876,
    "Overall Score": 45.60530808037683,
    "MMLU Score": 52.8017878250591,
    "BBH Score": 56.552203892922165,
    "Math Score": 53.625377643504535,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.073057070734175
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V5-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.573451455506034,
    "Overall Score": 45.67269839307991,
    "MMLU Score": 52.91260342789597,
    "BBH Score": 56.67538301839144,
    "Math Score": 54.607250755287005,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.0306319597354845
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Avengers-V6-32B",
    "Parameters (B)": 32.76,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.305351304120306,
    "Overall Score": 46.23110024344452,
    "MMLU Score": 51.915263002364064,
    "BBH Score": 56.18657609330364,
    "Math Score": 62.2356495468278,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.328388371599546
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Korean-Avengers-V2-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.744957095859188,
    "Overall Score": 37.17096025005312,
    "MMLU Score": 39.984116430260045,
    "BBH Score": 49.64505290373823,
    "Math Score": 28.02114803625378,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.250559475889697
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Korean-Avengers-V3-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.22797798661364,
    "Overall Score": 37.3287116618655,
    "MMLU Score": 39.15299940898345,
    "BBH Score": 48.69836786250173,
    "Math Score": 24.924471299093657,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.536802568334137
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Korean-Superb-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.026993687258279,
    "Overall Score": 29.3316606382556,
    "MMLU Score": 31.903812056737586,
    "BBH Score": 36.57802382251899,
    "Math Score": 23.716012084592144,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.47052392054054
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Korean-Superb-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.776938011044043,
    "Overall Score": 38.3619715244158,
    "MMLU Score": 40.51972517730496,
    "BBH Score": 50.60725661580997,
    "Math Score": 27.19033232628399,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.93278607466562
  },
  {
    "Model Name": "Saxo/Linkbricks-Horizon-AI-Superb-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 9.249224923882933,
    "Overall Score": 34.63303350305584,
    "MMLU Score": 34.00007387706855,
    "BBH Score": 45.69432391004359,
    "Math Score": 22.20543806646526,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.7444254830075523
  },
  {
    "Model Name": "SeaLLMs/SeaLLM-7B-v2",
    "Parameters (B)": 7.376,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.26978602248258,
    "Overall Score": 18.166389781627085,
    "MMLU Score": 23.140144799054376,
    "BBH Score": 27.43815940157093,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.306654396864182
  },
  {
    "Model Name": "SeaLLMs/SeaLLM-7B-v2.5",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.201953443704072,
    "Overall Score": 20.73056803415737,
    "MMLU Score": 24.479166666666664,
    "BBH Score": 28.73815393010281,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.41462595107593
  },
  {
    "Model Name": "SeaLLMs/SeaLLMs-v3-7B-Chat",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.685706249390413,
    "Overall Score": 24.21169585668884,
    "MMLU Score": 32.16238179669031,
    "BBH Score": 33.801622722378404,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.3629388960528
  },
  {
    "Model Name": "SenseLLM/ReflectionCoder-CL-34B",
    "Parameters (B)": 33.744,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.9401396540259577,
    "Overall Score": 12.147932297450376,
    "MMLU Score": 4.707816193853427,
    "BBH Score": 14.264686822563537,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.0831222657394535
  },
  {
    "Model Name": "SenseLLM/ReflectionCoder-DS-33B",
    "Parameters (B)": 33.34,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.619056319496223,
    "Overall Score": 9.194495021407294,
    "MMLU Score": 2.24216903073286,
    "BBH Score": 8.337659356727954,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.9905570284126977
  },
  {
    "Model Name": "SentientAGI/Dobby-Mini-Leashed-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5346435887257317,
    "Overall Score": 29.43899218809408,
    "MMLU Score": 29.93683510638298,
    "BBH Score": 30.77304532336984,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.182950624084842
  },
  {
    "Model Name": "SentientAGI/Dobby-Mini-Unhinged-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.351298557406623,
    "Overall Score": 27.45756521473049,
    "MMLU Score": 28.717863475177303,
    "BBH Score": 30.369934195446422,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.319392087139008
  },
  {
    "Model Name": "SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6543926123142053,
    "Overall Score": 4.299518611352284,
    "MMLU Score": 1.7896719858156025,
    "BBH Score": 3.612865412111988,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.570243200251593
  },
  {
    "Model Name": "Sharathhebbar24/SSH_355M",
    "Parameters (B)": 0.355,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1718255337916485,
    "Overall Score": 5.371931358828882,
    "MMLU Score": 1.9558953900709208,
    "BBH Score": 3.496136025027686,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 31.263871208703804
  },
  {
    "Model Name": "Sharathhebbar24/chat_gpt2_dpo",
    "Parameters (B)": 0.124,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1287547549876503,
    "Overall Score": 3.406545907558898,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 1.6986044099668711,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.457631858999243
  },
  {
    "Model Name": "Shreyash2010/Uma-4x4B-Instruct-v0.1",
    "Parameters (B)": 3.821,
    "Architecture": "?",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.3835301665966497,
    "Overall Score": 27.92210478503609,
    "MMLU Score": 31.885342789598106,
    "BBH Score": 36.28453127383045,
    "Math Score": 17.749244712990937,
    "Date Submitted": "2024-08-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.714600963035002
  },
  {
    "Model Name": "Sicarius-Prototyping/Brainy_LLAMA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4562784679275762,
    "Overall Score": 24.22551281841119,
    "MMLU Score": 31.654476950354614,
    "BBH Score": 30.294986762557475,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.635220084580673
  },
  {
    "Model Name": "Sicarius-Prototyping/Micropenis_1B",
    "Parameters (B)": 0.618,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7227822905689283,
    "Overall Score": 10.141053791929547,
    "MMLU Score": 9.555998817966902,
    "BBH Score": 7.664224287376964,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.03057867390076
  },
  {
    "Model Name": "Sicarius-Prototyping/bacon_and_food",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.332752887985638,
    "Overall Score": 22.242423887650176,
    "MMLU Score": 25.144060283687946,
    "BBH Score": 24.93079263718865,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.689083241281157
  },
  {
    "Model Name": "SicariusSicariiStuff/2B-ad",
    "Parameters (B)": 3.204,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4785996796507748,
    "Overall Score": 15.93131891082937,
    "MMLU Score": 18.467420212765955,
    "BBH Score": 16.007592932115813,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.579808077378066
  },
  {
    "Model Name": "SicariusSicariiStuff/2B_or_not_2B",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.754271302947184,
    "Overall Score": 6.592012664617282,
    "MMLU Score": 4.43077718676123,
    "BBH Score": 7.68230049623281,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.7576928115637926
  },
  {
    "Model Name": "SicariusSicariiStuff/Dusk_Rainbow",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4012977293319704,
    "Overall Score": 18.623890627323348,
    "MMLU Score": 27.14797576832151,
    "BBH Score": 25.95903682422342,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.755760728805764
  },
  {
    "Model Name": "SicariusSicariiStuff/Eximius_Persona_5B",
    "Parameters (B)": 5.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.961155951705545,
    "Overall Score": 21.833611932328903,
    "MMLU Score": 23.777334515366427,
    "BBH Score": 22.201333094135222,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.133031982153696
  },
  {
    "Model Name": "SicariusSicariiStuff/Impish_LLAMA_3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.445904762553517,
    "Overall Score": 17.791947493881953,
    "MMLU Score": 21.570257092198577,
    "BBH Score": 16.98575485690441,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.305061823339434
  },
  {
    "Model Name": "SicariusSicariiStuff/Impish_Mind_8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3695634672770003,
    "Overall Score": 18.12420306348228,
    "MMLU Score": 25.65196513002364,
    "BBH Score": 24.562854114562622,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.233562004627114
  },
  {
    "Model Name": "SicariusSicariiStuff/Impish_QWEN_14B-1M",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2022507114347665,
    "Overall Score": 40.23736559941774,
    "MMLU Score": 44.93388002364066,
    "BBH Score": 47.22031340500465,
    "Math Score": 39.65256797583081,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.565338952298777
  },
  {
    "Model Name": "SicariusSicariiStuff/Impish_QWEN_7B-1M",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2744692866465974,
    "Overall Score": 30.209083552218303,
    "MMLU Score": 36.28102836879432,
    "BBH Score": 34.55484768058619,
    "Math Score": 30.891238670694865,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.70326524831751
  },
  {
    "Model Name": "SicariusSicariiStuff/LLAMA-3_8B_Unaligned_BETA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.498746439946928,
    "Overall Score": 19.14075237978403,
    "MMLU Score": 27.38807624113475,
    "BBH Score": 24.998013753807424,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.771174542681031
  },
  {
    "Model Name": "SicariusSicariiStuff/Phi-Line_14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9368138642981236,
    "Overall Score": 37.56208119420943,
    "MMLU Score": 49.48655437352246,
    "BBH Score": 43.79406899090469,
    "Math Score": 38.59516616314199,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.0955650057032
  },
  {
    "Model Name": "SicariusSicariiStuff/Phi-lthy4",
    "Parameters (B)": 11.933,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.739112042377834,
    "Overall Score": 30.269040533700707,
    "MMLU Score": 37.038268321512994,
    "BBH Score": 40.15288217449905,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.95325038450284
  },
  {
    "Model Name": "SicariusSicariiStuff/Qwen2.5-14B_Uncencored",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.478390781463515,
    "Overall Score": 31.72493871859786,
    "MMLU Score": 47.399527186761226,
    "BBH Score": 46.7202351109504,
    "Math Score": 31.797583081570995,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.790922915893699
  },
  {
    "Model Name": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.841773402094493,
    "Overall Score": 31.750334298621823,
    "MMLU Score": 47.399527186761226,
    "BBH Score": 46.7202351109504,
    "Math Score": 31.797583081570995,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.557583691315874
  },
  {
    "Model Name": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored_Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.8103262425846,
    "Overall Score": 28.95879229174073,
    "MMLU Score": 45.85734338061466,
    "BBH Score": 42.113096716972805,
    "Math Score": 32.85498489425982,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.7077570631873704
  },
  {
    "Model Name": "SicariusSicariiStuff/Redemption_Wind_24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.965807175651332,
    "Overall Score": 28.370595438172284,
    "MMLU Score": 49.24645390070923,
    "BBH Score": 48.417358452350896,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.565893450892238
  },
  {
    "Model Name": "SicariusSicariiStuff/Winged_Imp_8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.299678580705405,
    "Overall Score": 26.911877977477257,
    "MMLU Score": 29.3181146572104,
    "BBH Score": 30.59287532329393,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.706564205182747
  },
  {
    "Model Name": "SicariusSicariiStuff/Wingless_Imp_8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2959258660149595,
    "Overall Score": 26.911877977477257,
    "MMLU Score": 29.3181146572104,
    "BBH Score": 30.59287532329393,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.766525835488338
  },
  {
    "Model Name": "SicariusSicariiStuff/Zion_Alpha",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.180954638110283,
    "Overall Score": 19.18649140147796,
    "MMLU Score": 23.684988179669027,
    "BBH Score": 29.16050119411573,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.246594731343304
  },
  {
    "Model Name": "SicariusSicariiStuff/dn_ep02",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3874595609327391,
    "Overall Score": 25.284440475555808,
    "MMLU Score": 33.30747635933806,
    "BBH Score": 32.6437741461978,
    "Math Score": 14.19939577039275,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.22355129295299
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.1-8B-lora",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.34628480084584,
    "Overall Score": 24.02231249174472,
    "MMLU Score": 30.860298463356976,
    "BBH Score": 29.191619249410262,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.843410604243658
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.1-8B-lora-epoch1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.36420275822784,
    "Overall Score": 24.02231249174472,
    "MMLU Score": 30.860298463356976,
    "BBH Score": 29.191619249410262,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.60904846941577
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-epoch3",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7414391903365065,
    "Overall Score": 7.679539302024469,
    "MMLU Score": 3.100989952718674,
    "BBH Score": 5.493123703086085,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.357611793543128
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-epoch5",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7261055632337824,
    "Overall Score": 12.134493116614278,
    "MMLU Score": 10.507166075650115,
    "BBH Score": 8.132119042373503,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.711747893201814
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-v2-epoch3",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6957441095320627,
    "Overall Score": 12.134493116614278,
    "MMLU Score": 10.507166075650115,
    "BBH Score": 8.132119042373503,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.44102889318831
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-v2-epoch5",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7083427535997535,
    "Overall Score": 11.804479423825526,
    "MMLU Score": 10.507166075650115,
    "BBH Score": 8.268548811534602,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.664925791696042
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-3B-lora-epoch1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8412479453539257,
    "Overall Score": 20.42021662043027,
    "MMLU Score": 22.27208924349881,
    "BBH Score": 20.806136629310423,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.090421945592496
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-3B-lora-epoch2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1445605695482872,
    "Overall Score": 20.42021662043027,
    "MMLU Score": 22.27208924349881,
    "BBH Score": 20.806136629310423,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.84109741653019
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Llama3.2-3B-lora-epoch3",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1332529970386,
    "Overall Score": 20.42021662043027,
    "MMLU Score": 22.27208924349881,
    "BBH Score": 20.806136629310423,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.01911547888431
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Qwen2.5-3B-Instruct",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4597928292182816,
    "Overall Score": 15.791201412428553,
    "MMLU Score": 20.12965425531915,
    "BBH Score": 19.15067903050948,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.817426347329528
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Qwen2.5-7B-Instruct-SFT-step-15000",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.286764843505913,
    "Overall Score": 24.13133339481089,
    "MMLU Score": 32.374778368794324,
    "BBH Score": 31.32761158066677,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.75349137536489
  },
  {
    "Model Name": "SkyOrbis/SKY-Ko-Qwen2.5-7B-Instruct-SFT-step-5000",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2356579907364422,
    "Overall Score": 24.667117533839868,
    "MMLU Score": 35.976285460992905,
    "BBH Score": 34.9514354427427,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.962738653224314
  },
  {
    "Model Name": "Skywork/Skywork-Reward-Gemma-2-27B-v0.2",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForSequenceClassification",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.857939726796388,
    "Overall Score": 34.66144843038861,
    "MMLU Score": 34.48027482269504,
    "BBH Score": 48.15990424972716,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.9130372862589415
  },
  {
    "Model Name": "Skywork/Skywork-o1-Open-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.396378069950861,
    "Overall Score": 20.75299470026652,
    "MMLU Score": 11.449098699763592,
    "BBH Score": 23.017598928073,
    "Math Score": 52.11480362537765,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.862017061752354
  },
  {
    "Model Name": "Solshine/Brimful-merged-replete",
    "Parameters (B)": 12.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.333446537317904,
    "Overall Score": 3.879827054900916,
    "MMLU Score": 0.9400856973995264,
    "BBH Score": 1.992138996736096,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.8953213156062734
  },
  {
    "Model Name": "Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2",
    "Parameters (B)": 18.5,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.762705392247006,
    "Overall Score": 6.928703193353647,
    "MMLU Score": 2.05747635933806,
    "BBH Score": 5.008442306492267,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.0245460642566135
  },
  {
    "Model Name": "Sorawiz/Gemma-9B-Base",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.064132863618642,
    "Overall Score": 20.84248400200344,
    "MMLU Score": 35.948581560283685,
    "BBH Score": 41.28135020153275,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.097452721848716
  },
  {
    "Model Name": "Sorawiz/Gemma-Creative-9B-Base",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.051281638551995,
    "Overall Score": 18.29960573109928,
    "MMLU Score": 33.41829196217494,
    "BBH Score": 34.6224221959871,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.921059588880743
  },
  {
    "Model Name": "Sourjayon/DeepSeek-R1-8b-Sify",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8653249275105314,
    "Overall Score": 13.313209574216849,
    "MMLU Score": 10.895020685579194,
    "BBH Score": 6.92682249570646,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.38521444484196
  },
  {
    "Model Name": "Sourjayon/DeepSeek-R1-ForumNXT",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2067745961926486,
    "Overall Score": 11.959695622199478,
    "MMLU Score": 7.201167257683213,
    "BBH Score": 6.957542087542088,
    "Math Score": 25.755287009063444,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.91046352809555
  },
  {
    "Model Name": "SpaceYL/ECE_Poirot",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6143529019539091,
    "Overall Score": 15.742560298806495,
    "MMLU Score": 20.923832742316783,
    "BBH Score": 18.61642605277272,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.62462104230047
  },
  {
    "Model Name": "Spestly/Athena-1-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4893610158375592,
    "Overall Score": 25.48204682938236,
    "MMLU Score": 27.988327423167853,
    "BBH Score": 26.30886959330041,
    "Math Score": 23.791540785498487,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.109382183642182
  },
  {
    "Model Name": "Spestly/Atlas-Pro-1.5B-Preview",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1789415089573965,
    "Overall Score": 13.9538569769866,
    "MMLU Score": 10.27630023640662,
    "BBH Score": 9.07740771263535,
    "Math Score": 31.948640483383684,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.835919654170775
  },
  {
    "Model Name": "Spestly/Atlas-Pro-7B-Preview",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.385866069632902,
    "Overall Score": 24.63755262041268,
    "MMLU Score": 21.89346926713948,
    "BBH Score": 25.274194951351465,
    "Math Score": 50.83081570996979,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.777729868903457
  },
  {
    "Model Name": "Stark2008/GutenLaserPi",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1399303674874357,
    "Overall Score": 21.40072462295752,
    "MMLU Score": 23.39871453900709,
    "BBH Score": 32.97771006701662,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 18.77371217869007
  },
  {
    "Model Name": "Stark2008/LayleleFlamPi",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2593159866249992,
    "Overall Score": 20.87109621657652,
    "MMLU Score": 23.26019503546099,
    "BBH Score": 31.20740955947399,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-07-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.573359219008744
  },
  {
    "Model Name": "Stark2008/VisFlamCat",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2204318533152774,
    "Overall Score": 21.340907115633893,
    "MMLU Score": 23.823507683215126,
    "BBH Score": 32.881396834037055,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-07-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.486357028179633
  },
  {
    "Model Name": "Steelskull/L3.3-MS-Nevoria-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 39.22482966970595,
    "Overall Score": 44.041818757700526,
    "MMLU Score": 50.39154846335697,
    "BBH Score": 56.60264873723427,
    "Math Score": 39.57703927492447,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.1228045890461782
  },
  {
    "Model Name": "Steelskull/L3.3-Nevoria-R1-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 39.62696233736567,
    "Overall Score": 43.61308347965567,
    "MMLU Score": 49.5881353427896,
    "BBH Score": 56.16728833047952,
    "Math Score": 46.299093655589125,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.1005911356099922
  },
  {
    "Model Name": "StelleX/Qwen2.5_Math_7B_Cot",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0559838993158137,
    "Overall Score": 17.801855998042843,
    "MMLU Score": 20.111184988179662,
    "BBH Score": 19.796911486609314,
    "Math Score": 32.62839879154079,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.658558077213986
  },
  {
    "Model Name": "StelleX/Vorisatex-7B-preview",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4981429762342664,
    "Overall Score": 5.954613231174487,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 4.133712426973548,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.383615864993664
  },
  {
    "Model Name": "SultanR/SmolTulu-1.7b-Instruct",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.614783493029297,
    "Overall Score": 16.331009858160883,
    "MMLU Score": 7.893764775413713,
    "BBH Score": 12.25982971199621,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 26.563839210599365
  },
  {
    "Model Name": "SultanR/SmolTulu-1.7b-Reinforced",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5792320587665617,
    "Overall Score": 16.5748337360141,
    "MMLU Score": 8.475546690307327,
    "BBH Score": 10.015214516485557,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 28.615187100156657
  },
  {
    "Model Name": "SultanR/SmolTulu-1.7b-it-v0",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.612902656162427,
    "Overall Score": 16.331009858160883,
    "MMLU Score": 7.893764775413713,
    "BBH Score": 12.25982971199621,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 26.64535663854744
  },
  {
    "Model Name": "Supichi/BBA-123",
    "Parameters (B)": 17.161,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4063001393023913,
    "Overall Score": 4.7970062398113145,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.218337253816706,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.4110828163544915
  },
  {
    "Model Name": "Supichi/BBA99",
    "Parameters (B)": 17.161,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4096340914337329,
    "Overall Score": 3.550455951739293,
    "MMLU Score": 1.2448286052009452,
    "BBH Score": 1.3050510001980589,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.51870749531046
  },
  {
    "Model Name": "Supichi/BBAIK29",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6412984065814576,
    "Overall Score": 30.240917048589704,
    "MMLU Score": 38.54351359338061,
    "BBH Score": 36.96354856971481,
    "Math Score": 36.78247734138973,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 47.15576514495597
  },
  {
    "Model Name": "Supichi/BBAI_135_Gemma",
    "Parameters (B)": 19.3,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.2168864661964816,
    "Overall Score": 5.349663435184209,
    "MMLU Score": 7.468971631205674,
    "BBH Score": 10.857975857833802,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.6629941688646035
  },
  {
    "Model Name": "Supichi/BBAI_250_Xia0_gZ",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6098356306802665,
    "Overall Score": 30.643171147465264,
    "MMLU Score": 38.49734042553191,
    "BBH Score": 36.654123211962506,
    "Math Score": 36.40483383685801,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 50.248246586187605
  },
  {
    "Model Name": "Supichi/BBAI_275_Tsunami_gZ",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6195082794233058,
    "Overall Score": 30.835431920268267,
    "MMLU Score": 38.802083333333336,
    "BBH Score": 36.25417674909635,
    "Math Score": 32.85498489425982,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 49.774043292807434
  },
  {
    "Model Name": "Supichi/BBAI_525_Tsu_gZ_Xia0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6500205335836085,
    "Overall Score": 30.93538839809629,
    "MMLU Score": 38.63585992907802,
    "BBH Score": 36.525252487756354,
    "Math Score": 34.29003021148036,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 47.591401809335686
  },
  {
    "Model Name": "Supichi/BBAI_78B_Calme_3_1_Ties",
    "Parameters (B)": 27.06,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.3646634423965374,
    "Overall Score": 3.942051462942828,
    "MMLU Score": 1.595744680851063,
    "BBH Score": 1.530417863838492,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.6670666075624023
  },
  {
    "Model Name": "Supichi/BBAI_QWEEN_V000000_LUMEN_14B",
    "Parameters (B)": 10.366,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9180784406772212,
    "Overall Score": 4.277816309763046,
    "MMLU Score": 1.7804373522458627,
    "BBH Score": 3.0068974054268174,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.659532475904251
  },
  {
    "Model Name": "Supichi/HF_TOKEN",
    "Parameters (B)": 17.161,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4168891762749531,
    "Overall Score": 3.4876527968358464,
    "MMLU Score": 1.2171247044917255,
    "BBH Score": 1.1476980590215882,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.4614859476906985
  },
  {
    "Model Name": "Supichi/NJS26",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4169590959348428,
    "Overall Score": 11.996375840759782,
    "MMLU Score": 22.63223995271868,
    "BBH Score": 26.847431929671945,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 28.771109582975562
  },
  {
    "Model Name": "Svak/MN-12B-Inferor-v0.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.494259584397854,
    "Overall Score": 25.41093424607308,
    "MMLU Score": 28.431589834515364,
    "BBH Score": 30.84642679217884,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.187766503945339
  },
  {
    "Model Name": "Svak/MN-12B-Inferor-v0.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.990764986078632,
    "Overall Score": 26.937535331905043,
    "MMLU Score": 29.57668439716312,
    "BBH Score": 30.85076497103817,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.531248299160639
  },
  {
    "Model Name": "Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.328476623843412,
    "Overall Score": 27.216374484698875,
    "MMLU Score": 31.783761820330973,
    "BBH Score": 39.148157776889455,
    "Math Score": 15.709969788519636,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.688489463886134
  },
  {
    "Model Name": "T145/KRONOS-8B-V1-P1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4941161225327542,
    "Overall Score": 28.907659501595617,
    "MMLU Score": 30.66637115839244,
    "BBH Score": 29.9732800557004,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.34766586454655
  },
  {
    "Model Name": "T145/KRONOS-8B-V1-P2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3284026293633946,
    "Overall Score": 24.505318597003576,
    "MMLU Score": 27.258791371158388,
    "BBH Score": 25.86433596064097,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.44720723621811
  },
  {
    "Model Name": "T145/KRONOS-8B-V1-P3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.492216135585029,
    "Overall Score": 25.821837809885533,
    "MMLU Score": 26.72318262411348,
    "BBH Score": 30.27003165149001,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.304355042215104
  },
  {
    "Model Name": "T145/KRONOS-8B-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3699907312036532,
    "Overall Score": 25.04979364610371,
    "MMLU Score": 30.41703605200945,
    "BBH Score": 30.67490713784655,
    "Math Score": 22.658610271903324,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.284644615146657
  },
  {
    "Model Name": "T145/KRONOS-8B-V3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4015645267678678,
    "Overall Score": 25.7368028097919,
    "MMLU Score": 30.4262706855792,
    "BBH Score": 30.29109898483549,
    "Math Score": 25.98187311178248,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.36290967576302
  },
  {
    "Model Name": "T145/KRONOS-8B-V4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3905189302327912,
    "Overall Score": 28.7502883448152,
    "MMLU Score": 30.952644799054376,
    "BBH Score": 30.14061947211616,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.675941707605535
  },
  {
    "Model Name": "T145/KRONOS-8B-V5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3808181462013638,
    "Overall Score": 26.264834996106643,
    "MMLU Score": 30.65713652482269,
    "BBH Score": 30.17368221664718,
    "Math Score": 26.888217522658607,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.02121221998806
  },
  {
    "Model Name": "T145/KRONOS-8B-V6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4396566160893274,
    "Overall Score": 27.898039972832333,
    "MMLU Score": 27.794400118203303,
    "BBH Score": 29.659286418525568,
    "Math Score": 25.98187311178248,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.37825983019087
  },
  {
    "Model Name": "T145/KRONOS-8B-V7",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.454147422885968,
    "Overall Score": 15.89983125272142,
    "MMLU Score": 18.85527482269504,
    "BBH Score": 23.89017313885566,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.934126074484167
  },
  {
    "Model Name": "T145/KRONOS-8B-V8",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4554374939342578,
    "Overall Score": 28.793303577270123,
    "MMLU Score": 30.915706264775416,
    "BBH Score": 30.05309399552845,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.78326358725146
  },
  {
    "Model Name": "T145/KRONOS-8B-V9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4379859323130169,
    "Overall Score": 28.92215319526741,
    "MMLU Score": 30.57402482269504,
    "BBH Score": 30.06801140755337,
    "Math Score": 19.86404833836858,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.112959762232023
  },
  {
    "Model Name": "T145/Llama-3.1-8B-Instruct-Zeus",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.389369408893887,
    "Overall Score": 29.649994293530643,
    "MMLU Score": 32.14391252955083,
    "BBH Score": 31.38899072847828,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.340612585630318
  },
  {
    "Model Name": "T145/Llama-3.1-8B-Zeus",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4634354982438125,
    "Overall Score": 9.076440481991645,
    "MMLU Score": 3.692006501182032,
    "BBH Score": 10.560807756832054,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.202145904540225
  },
  {
    "Model Name": "T145/Meta-Llama-3.1-8B-Instruct-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3694240258694423,
    "Overall Score": 24.976590554171448,
    "MMLU Score": 30.888002364066192,
    "BBH Score": 29.7742634799406,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.238755916608007
  },
  {
    "Model Name": "T145/ZEUS-8B-V10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3669331779670844,
    "Overall Score": 30.36969062022236,
    "MMLU Score": 32.263962765957444,
    "BBH Score": 32.69504767226082,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.21739226886602
  },
  {
    "Model Name": "T145/ZEUS-8B-V11",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.17199566710153,
    "Overall Score": 29.941073374653865,
    "MMLU Score": 32.042331560283685,
    "BBH Score": 31.20791313817828,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.785052073611835
  },
  {
    "Model Name": "T145/ZEUS-8B-V12",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.741877751881664,
    "Overall Score": 30.333680488372995,
    "MMLU Score": 32.35630910165484,
    "BBH Score": 32.44900193426873,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.063104643361998
  },
  {
    "Model Name": "T145/ZEUS-8B-V13",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3517701951939556,
    "Overall Score": 30.62136168037916,
    "MMLU Score": 32.347074468085104,
    "BBH Score": 32.72745832819285,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.65278653816267
  },
  {
    "Model Name": "T145/ZEUS-8B-V13-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.36719859751768,
    "Overall Score": 29.48866762435381,
    "MMLU Score": 31.91304669030733,
    "BBH Score": 31.784785148944987,
    "Math Score": 17.900302114803626,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.568678959950788
  },
  {
    "Model Name": "T145/ZEUS-8B-V14",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3481792126144727,
    "Overall Score": 30.191102257235432,
    "MMLU Score": 32.374778368794324,
    "BBH Score": 32.69344597105668,
    "Math Score": 21.299093655589125,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.393982917661944
  },
  {
    "Model Name": "T145/ZEUS-8B-V15",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3892912358486078,
    "Overall Score": 29.370031092616266,
    "MMLU Score": 33.99083924349882,
    "BBH Score": 36.18160301722815,
    "Math Score": 23.036253776435046,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.14029825767701
  },
  {
    "Model Name": "T145/ZEUS-8B-V16",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.331310957109588,
    "Overall Score": 30.579931119756704,
    "MMLU Score": 32.513297872340424,
    "BBH Score": 32.53218336552364,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.969788505420894
  },
  {
    "Model Name": "T145/ZEUS-8B-V17",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3446234519473816,
    "Overall Score": 31.006563519372005,
    "MMLU Score": 32.60564420803782,
    "BBH Score": 32.33848329071727,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.059662892586054
  },
  {
    "Model Name": "T145/ZEUS-8B-V17-abliterated",
    "Parameters (B)": 7.594,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3400490976803874,
    "Overall Score": 26.847962315480604,
    "MMLU Score": 29.1334219858156,
    "BBH Score": 31.52220415463321,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.035058686994514
  },
  {
    "Model Name": "T145/ZEUS-8B-V17-abliterated-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6694349225561051,
    "Overall Score": 22.60735726411397,
    "MMLU Score": 26.68624408983452,
    "BBH Score": 27.568611667990155,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.541921855509882
  },
  {
    "Model Name": "T145/ZEUS-8B-V17-abliterated-V4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3164047673296315,
    "Overall Score": 26.58716707472223,
    "MMLU Score": 30.82335992907802,
    "BBH Score": 30.971615423734274,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.196802483976974
  },
  {
    "Model Name": "T145/ZEUS-8B-V18",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3272917306684742,
    "Overall Score": 30.93292754557434,
    "MMLU Score": 32.68875591016548,
    "BBH Score": 32.52958987066048,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.305296666012794
  },
  {
    "Model Name": "T145/ZEUS-8B-V19",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3864482789696406,
    "Overall Score": 31.07371725651432,
    "MMLU Score": 32.59640957446809,
    "BBH Score": 32.64362847061702,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.412460477506748
  },
  {
    "Model Name": "T145/ZEUS-8B-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3914350329709466,
    "Overall Score": 30.143481455653376,
    "MMLU Score": 32.18085106382979,
    "BBH Score": 31.605592775073944,
    "Math Score": 21.6012084592145,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.663592436142707
  },
  {
    "Model Name": "T145/ZEUS-8B-V2-ORPO",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4149754480427466,
    "Overall Score": 27.882957614827564,
    "MMLU Score": 29.752142434988176,
    "BBH Score": 29.59149027379915,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.705612315320696
  },
  {
    "Model Name": "T145/ZEUS-8B-V2-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.055450230985255,
    "Overall Score": 29.79670590213997,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 30.98256419519066,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.496437545878832
  },
  {
    "Model Name": "T145/ZEUS-8B-V20",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3367754678837924,
    "Overall Score": 31.039974330291205,
    "MMLU Score": 32.55023640661938,
    "BBH Score": 32.22158697725198,
    "Math Score": 21.90332326283988,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.22003588188944
  },
  {
    "Model Name": "T145/ZEUS-8B-V21",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.440348362883099,
    "Overall Score": 12.085754641843304,
    "MMLU Score": 7.930703309692672,
    "BBH Score": 7.358048379917139,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.390855263411163
  },
  {
    "Model Name": "T145/ZEUS-8B-V22",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4125065320853716,
    "Overall Score": 31.143603587984483,
    "MMLU Score": 32.64258274231678,
    "BBH Score": 32.21395635996418,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.04846694903792
  },
  {
    "Model Name": "T145/ZEUS-8B-V23",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3324908358064511,
    "Overall Score": 28.43967386680849,
    "MMLU Score": 29.622857565011817,
    "BBH Score": 31.46730001602275,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.343241621317574
  },
  {
    "Model Name": "T145/ZEUS-8B-V24",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.524096689802697,
    "Overall Score": 22.06564517894393,
    "MMLU Score": 25.384160756501178,
    "BBH Score": 26.153953910062185,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.477851258767876
  },
  {
    "Model Name": "T145/ZEUS-8B-V25",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6179681370552723,
    "Overall Score": 16.8147475535603,
    "MMLU Score": 20.942302009456267,
    "BBH Score": 21.846212671079687,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.392508460743489
  },
  {
    "Model Name": "T145/ZEUS-8B-V26",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.434081544674218,
    "Overall Score": 26.628443632555204,
    "MMLU Score": 32.300901300236404,
    "BBH Score": 32.25100532809862,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.568291134800443
  },
  {
    "Model Name": "T145/ZEUS-8B-V27",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4555947946601695,
    "Overall Score": 26.817908661081884,
    "MMLU Score": 32.245493498817964,
    "BBH Score": 32.21930421807795,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.424020722980757
  },
  {
    "Model Name": "T145/ZEUS-8B-V28",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.454430589728298,
    "Overall Score": 26.17942932560065,
    "MMLU Score": 32.245493498817964,
    "BBH Score": 32.62174149720304,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.999779096018067
  },
  {
    "Model Name": "T145/ZEUS-8B-V29",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.408967476441205,
    "Overall Score": 29.116399573768543,
    "MMLU Score": 32.448655437352244,
    "BBH Score": 32.349726924866495,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.665061515338355
  },
  {
    "Model Name": "T145/ZEUS-8B-V2L1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.489273917381773,
    "Overall Score": 19.959332334959768,
    "MMLU Score": 29.308880023640665,
    "BBH Score": 28.694208206551323,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.402055929408467
  },
  {
    "Model Name": "T145/ZEUS-8B-V2L2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.408079108073052,
    "Overall Score": 29.93592636769453,
    "MMLU Score": 32.042331560283685,
    "BBH Score": 32.0175092945529,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.260116847171798
  },
  {
    "Model Name": "T145/ZEUS-8B-V3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2127011701204595,
    "Overall Score": 29.6049284530603,
    "MMLU Score": 31.15580673758865,
    "BBH Score": 32.108252109929126,
    "Math Score": 16.76737160120846,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.412385493220555
  },
  {
    "Model Name": "T145/ZEUS-8B-V30",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0650085806418934,
    "Overall Score": 29.0957713811746,
    "MMLU Score": 32.70722517730496,
    "BBH Score": 32.188253745585094,
    "Math Score": 15.861027190332328,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.089903380513016
  },
  {
    "Model Name": "T145/ZEUS-8B-V4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3011521967725297,
    "Overall Score": 29.65462225846948,
    "MMLU Score": 30.98034869976359,
    "BBH Score": 32.04614380654929,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.791048066495918
  },
  {
    "Model Name": "T145/ZEUS-8B-V6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2898547806439689,
    "Overall Score": 29.75703725188933,
    "MMLU Score": 30.65713652482269,
    "BBH Score": 32.07784842307126,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.07006780796899
  },
  {
    "Model Name": "T145/ZEUS-8B-V7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.311758942423652,
    "Overall Score": 28.470021765028548,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 29.556016390229985,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.703699394971405
  },
  {
    "Model Name": "T145/ZEUS-8B-V8",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3200279497215517,
    "Overall Score": 28.22354116902905,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 29.39403095675921,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.38101786025255
  },
  {
    "Model Name": "T145/ZEUS-8B-V9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.346419889879008,
    "Overall Score": 25.864889285845788,
    "MMLU Score": 32.23625886524823,
    "BBH Score": 31.85054952781809,
    "Math Score": 21.37462235649547,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.21012121127389
  },
  {
    "Model Name": "T145/qwen-2.5-3B-merge-test",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5679131730465117,
    "Overall Score": 25.975399259287943,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 27.88934131367608,
    "Math Score": 32.02416918429003,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.566860784017017
  },
  {
    "Model Name": "THUDM/glm-4-9b",
    "Parameters (B)": 9.0,
    "Architecture": "ChatGLMModelM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.3448936751023592,
    "Overall Score": 18.006731731716215,
    "MMLU Score": 34.94200650118203,
    "BBH Score": 35.811283581208905,
    "Math Score": 0.0,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.383349511450518
  },
  {
    "Model Name": "THUDM/glm-4-9b-chat",
    "Parameters (B)": 9.0,
    "Architecture": "ChatGLMModelM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.4942690169854622,
    "Overall Score": 10.973477297045166,
    "MMLU Score": 24.072842789598106,
    "BBH Score": 25.205183674440235,
    "Math Score": 0.0,
    "Date Submitted": "2024-07-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 22.201426591478878
  },
  {
    "Model Name": "THUDM/glm-4-9b-chat-1m",
    "Parameters (B)": 9.484,
    "Architecture": "ChatGLMModel",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.4113399099723327,
    "Overall Score": 8.922510186531982,
    "MMLU Score": 24.03590425531915,
    "BBH Score": 17.10802850816805,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 21.6913311113724
  },
  {
    "Model Name": "THUDM/glm-4-9b-chat-1m-hf",
    "Parameters (B)": 9.484,
    "Architecture": "GlmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.094131675191864,
    "Overall Score": 15.139213915838658,
    "MMLU Score": 9.048093971631204,
    "BBH Score": 14.405440654648933,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.229351475451803
  },
  {
    "Model Name": "THUDM/glm-4-9b-chat-hf",
    "Parameters (B)": 9.4,
    "Architecture": "GlmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9847880947215943,
    "Overall Score": 20.54431273192071,
    "MMLU Score": 19.714095744680847,
    "BBH Score": 20.668085640285003,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.350884704798904
  },
  {
    "Model Name": "TIGER-Lab/AceCodeRM-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalRM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6548936133746145,
    "Overall Score": 27.34471609415536,
    "MMLU Score": 26.23374704491725,
    "BBH Score": 26.27915814299532,
    "Math Score": 34.66767371601209,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 41.75444001240174
  },
  {
    "Model Name": "TIGER-Lab/AceCoder-Qwen2.5-7B-Ins-Rule",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6477565533827316,
    "Overall Score": 35.10989936210928,
    "MMLU Score": 36.90898345153664,
    "BBH Score": 35.040755991620735,
    "Math Score": 49.92447129909365,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 54.20230668259151
  },
  {
    "Model Name": "TIGER-Lab/AceCoder-Qwen2.5-Coder-7B-Base-Rule",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9756049775312156,
    "Overall Score": 21.333370512930014,
    "MMLU Score": 30.50014775413712,
    "BBH Score": 29.40535118246905,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.86681188006488
  },
  {
    "Model Name": "TIGER-Lab/AceCoder-Qwen2.5-Coder-7B-Ins-Rule",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6418509308278861,
    "Overall Score": 28.02995967932972,
    "MMLU Score": 26.981752364066192,
    "BBH Score": 30.54299135823097,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.670513405932915
  },
  {
    "Model Name": "TIGER-Lab/MAmmoTH2-7B-Plus",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1053267011114711,
    "Overall Score": 21.633507778259585,
    "MMLU Score": 22.410608747044915,
    "BBH Score": 18.92595322755573,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.572048478070617
  },
  {
    "Model Name": "TIGER-Lab/Qwen2.5-Math-7B-CFT",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1704517284970632,
    "Overall Score": 23.521464490408093,
    "MMLU Score": 21.607195626477537,
    "BBH Score": 24.585137970728173,
    "Math Score": 55.740181268882175,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.096056862260518
  },
  {
    "Model Name": "TTTXXX01/Mistral-7B-Base-SimPO2-5e-7",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0459922645345738,
    "Overall Score": 16.417452751929584,
    "MMLU Score": 19.62174940898345,
    "BBH Score": 20.692627382557507,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-09-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.695577595150493
  },
  {
    "Model Name": "Tarek07/Progenitor-V1.1-LLaMa-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 28.14517307312465,
    "Overall Score": 43.00294516350462,
    "MMLU Score": 49.61583924349882,
    "BBH Score": 56.24697023586278,
    "Math Score": 35.725075528700906,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.527897698542398
  },
  {
    "Model Name": "Tarek07/Thalassic-Alpha-LLaMa-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 28.772456313434247,
    "Overall Score": 42.2203763514307,
    "MMLU Score": 49.27415780141844,
    "BBH Score": 55.95412538254855,
    "Math Score": 31.49546827794562,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.467388668228421
  },
  {
    "Model Name": "TeeZee/DoubleBagel-57B-v1.0",
    "Parameters (B)": 56.703,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 18.737294956345185,
    "Overall Score": 8.707748481359532,
    "MMLU Score": 5.308067375886525,
    "BBH Score": 5.5227816982611495,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.4647281532178019
  },
  {
    "Model Name": "Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.410325791348669,
    "Overall Score": 6.657818235070503,
    "MMLU Score": 3.100989952718674,
    "BBH Score": 6.021054704987018,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.72076613496783
  },
  {
    "Model Name": "Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.861161435069849,
    "Overall Score": 13.004827801453324,
    "MMLU Score": 15.004432624113472,
    "BBH Score": 16.263180963543576,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.987479729809282
  },
  {
    "Model Name": "TencentARC/LLaMA-Pro-8B",
    "Parameters (B)": 8.357,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 95.615467102173,
    "Overall Score": 8.816698626146762,
    "MMLU Score": 9.011155437352246,
    "BBH Score": 9.2939499758607,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.09220996239787642
  },
  {
    "Model Name": "TencentARC/LLaMA-Pro-8B-Instruct",
    "Parameters (B)": 8.357,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.210406711645305,
    "Overall Score": 15.28346018029823,
    "MMLU Score": 10.507166075650115,
    "BBH Score": 19.485726056875954,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.460943524300879
  },
  {
    "Model Name": "TencentARC/MetaMath-Mistral-Pro",
    "Parameters (B)": 8.987,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2015045035813725,
    "Overall Score": 12.5165268741835,
    "MMLU Score": 16.35268912529551,
    "BBH Score": 22.37227879113455,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.4173782427573
  },
  {
    "Model Name": "TencentARC/Mistral_Pro_8B_v0.1",
    "Parameters (B)": 8.987,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2649645640770015,
    "Overall Score": 14.195345928021323,
    "MMLU Score": 19.61251477541371,
    "BBH Score": 22.89418875876804,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.22193168974591
  },
  {
    "Model Name": "TheDrummer/Cydonia-22B-v1.2",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2574085500617844,
    "Overall Score": 28.7900883355216,
    "MMLU Score": 34.895833333333336,
    "BBH Score": 39.93260406588619,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.83834124367836
  },
  {
    "Model Name": "TheDrummer/Gemmasutra-9B-v1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.807637484434085,
    "Overall Score": 22.74868519843542,
    "MMLU Score": 33.83385047281324,
    "BBH Score": 41.20039631726062,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.9170291292126214
  },
  {
    "Model Name": "TheDrummer/Gemmasutra-Mini-2B-v1",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7959093485129887,
    "Overall Score": 9.12929252128462,
    "MMLU Score": 11.71690307328605,
    "BBH Score": 9.81033614467704,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.265231945427722
  },
  {
    "Model Name": "TheDrummer/Llama-3SOME-8B-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4985057944870328,
    "Overall Score": 21.81296685668469,
    "MMLU Score": 30.59249408983452,
    "BBH Score": 31.69527340436814,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.556478151058258
  },
  {
    "Model Name": "TheDrummer/Ministrations-8B-v1",
    "Parameters (B)": 8.02,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.725111781761734,
    "Overall Score": 21.29045248198521,
    "MMLU Score": 29.37352245862884,
    "BBH Score": 26.98563733629608,
    "Math Score": 18.429003021148034,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.341491552647552
  },
  {
    "Model Name": "TheDrummer/Rocinante-12B-v1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.7288831901606856,
    "Overall Score": 24.62809312692346,
    "MMLU Score": 27.526595744680847,
    "BBH Score": 30.025654065607256,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.6046834590874335
  },
  {
    "Model Name": "TheDrummer/Tiger-Gemma-9B-v1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2408546620597902,
    "Overall Score": 30.896643595129223,
    "MMLU Score": 34.64649822695036,
    "BBH Score": 37.22054605408783,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.533486322861588
  },
  {
    "Model Name": "TheDrummer/Tiger-Gemma-9B-v2",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.3395979593481933,
    "Overall Score": 29.900202484538976,
    "MMLU Score": 34.58185579196217,
    "BBH Score": 35.46954056518246,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.953234146296687
  },
  {
    "Model Name": "TheDrummer/Tiger-Gemma-9B-v3",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.1435063282657105,
    "Overall Score": 29.47327542727632,
    "MMLU Score": 33.99083924349882,
    "BBH Score": 38.83602273195975,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.375923681864158
  },
  {
    "Model Name": "TheDrunkenSnail/Daughter-of-Rhodia-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6214507377709615,
    "Overall Score": 27.609503388815305,
    "MMLU Score": 29.34581855791962,
    "BBH Score": 31.47583343042707,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.027654769685203
  },
  {
    "Model Name": "TheDrunkenSnail/Mother-of-Rhodia-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.714810337183691,
    "Overall Score": 25.379307438403675,
    "MMLU Score": 28.34847813238771,
    "BBH Score": 28.50297888404884,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.800066740958208
  },
  {
    "Model Name": "TheDrunkenSnail/Son-of-Rhodia",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.912420039431329,
    "Overall Score": 27.21622497737153,
    "MMLU Score": 28.97643321513001,
    "BBH Score": 30.222057252119924,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.231300873350218
  },
  {
    "Model Name": "TheHierophant/Underground-Cognitive-V0.3-test",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1731624613051972,
    "Overall Score": 22.4060912466085,
    "MMLU Score": 25.75354609929078,
    "BBH Score": 33.665101982714994,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.098881856210003
  },
  {
    "Model Name": "TheTsar1209/nemo-carpmuscle-v0.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.616880770705841,
    "Overall Score": 16.794489017380517,
    "MMLU Score": 26.73241725768321,
    "BBH Score": 30.034995783434088,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.64336263263194
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-r-v0.3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.513992806284949,
    "Overall Score": 32.00049707280477,
    "MMLU Score": 45.58953900709219,
    "BBH Score": 46.37591354449345,
    "Math Score": 30.06042296072508,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.089177685052943
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-v0.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.352435104606311,
    "Overall Score": 33.445029423216624,
    "MMLU Score": 46.669991134751776,
    "BBH Score": 48.82559521217237,
    "Math Score": 26.28398791540785,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.684210934660636
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-v0.2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.496397782336827,
    "Overall Score": 33.666712709905646,
    "MMLU Score": 46.07897458628841,
    "BBH Score": 48.18244143380709,
    "Math Score": 28.32326283987916,
    "Date Submitted": "2024-10-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.4874853915635295
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-v0.3",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 8.461957749933813,
    "Overall Score": 31.794404327523267,
    "MMLU Score": 45.12780732860521,
    "BBH Score": 45.5433921378403,
    "Math Score": 31.344410876132933,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.757334327008659
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-v0.4",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.73924849680602,
    "Overall Score": 37.393960224042935,
    "MMLU Score": 46.04203605200946,
    "BBH Score": 49.38495588865565,
    "Math Score": 27.7190332326284,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.651174863340993
  },
  {
    "Model Name": "TheTsar1209/qwen-carpmuscle-v0.4.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.678118088869087,
    "Overall Score": 37.605164486042526,
    "MMLU Score": 46.56841016548463,
    "BBH Score": 50.003672744368544,
    "Math Score": 27.794561933534744,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.041637910717519
  },
  {
    "Model Name": "Tijmen2/cosmosage-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6617177615198897,
    "Overall Score": 17.354746679203608,
    "MMLU Score": 16.50967789598109,
    "BBH Score": 22.6871057550123,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.443859409271822
  },
  {
    "Model Name": "TinyLlama/TinyLlama-1.1B-Chat-v0.1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1821904194941174,
    "Overall Score": 3.9575773348190606,
    "MMLU Score": 1.087839834515365,
    "BBH Score": 3.3630106739393377,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.722203317868992
  },
  {
    "Model Name": "TinyLlama/TinyLlama-1.1B-Chat-v0.5",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.1899276635098133,
    "Overall Score": 4.126163903736939,
    "MMLU Score": 1.0693705673758855,
    "BBH Score": 3.407690937569705,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 21.724923202268243
  },
  {
    "Model Name": "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6476948448823974,
    "Overall Score": 4.2942762818616345,
    "MMLU Score": 1.6511524822695034,
    "BBH Score": 3.390370709512531,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.630091802940551
  },
  {
    "Model Name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.536882909624825,
    "Overall Score": 2.818859486124847,
    "MMLU Score": 1.124778368794326,
    "BBH Score": 4.013396848486799,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.250417615443696
  },
  {
    "Model Name": "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3315957588642627,
    "Overall Score": 5.230318100791095,
    "MMLU Score": 1.337174940898345,
    "BBH Score": 3.547093389508079,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.77317550352658
  },
  {
    "Model Name": "TinyLlama/TinyLlama_v1.1",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4978572372047257,
    "Overall Score": 4.824553844580785,
    "MMLU Score": 0.542996453900708,
    "BBH Score": 3.2103010497128146,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.69063716271109
  },
  {
    "Model Name": "ToastyPigeon/Sto-vo-kor-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7371561597927307,
    "Overall Score": 22.997938390529622,
    "MMLU Score": 26.640070921985814,
    "BBH Score": 29.579484369783785,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.238843417090164
  },
  {
    "Model Name": "Trappu/Magnum-Picaro-0.7-v2-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3499177102746382,
    "Overall Score": 21.73006413381809,
    "MMLU Score": 28.671690307328607,
    "BBH Score": 35.74623319855443,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.486745649652565
  },
  {
    "Model Name": "Trappu/Nemo-Picaro-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.682055727975601,
    "Overall Score": 21.362492548877267,
    "MMLU Score": 28.93949468085106,
    "BBH Score": 35.9731352844479,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.801784146439954
  },
  {
    "Model Name": "Tremontaine/L3-12B-Lunaris-v1",
    "Parameters (B)": 11.52,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.281927897434539,
    "Overall Score": 25.4772545981474,
    "MMLU Score": 30.83259456264776,
    "BBH Score": 32.1807456461844,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-07-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.164793868724004
  },
  {
    "Model Name": "Triangle104/Annunaki-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5733339060325435,
    "Overall Score": 23.36969772271661,
    "MMLU Score": 30.23234338061465,
    "BBH Score": 35.321144959632626,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.853616027158331
  },
  {
    "Model Name": "Triangle104/BigTalker-Lite-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3354162271484944,
    "Overall Score": 20.97899274764932,
    "MMLU Score": 27.00945626477541,
    "BBH Score": 32.683408496152815,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.709703327812353
  },
  {
    "Model Name": "Triangle104/Chatty-Harry_V2.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7168798861463483,
    "Overall Score": 21.833190818566663,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 32.763031539641695,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.716784088823314
  },
  {
    "Model Name": "Triangle104/Chatty-Harry_V3.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6679627320496089,
    "Overall Score": 23.114766630549312,
    "MMLU Score": 30.019946808510632,
    "BBH Score": 35.89470703139707,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.858083389036914
  },
  {
    "Model Name": "Triangle104/Chronos-Prism_V1.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6540336547935837,
    "Overall Score": 22.183415410600137,
    "MMLU Score": 29.696734633569736,
    "BBH Score": 36.57570887067551,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.411707401666222
  },
  {
    "Model Name": "Triangle104/DS-Distilled-Hermes-Llama-3.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4246801609287691,
    "Overall Score": 22.38500937029289,
    "MMLU Score": 23.444887706855795,
    "BBH Score": 30.312465517244533,
    "Math Score": 29.30513595166164,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.712305108326762
  },
  {
    "Model Name": "Triangle104/DS-Distilled-Hermes-Llama-3.1_TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5058492107836854,
    "Overall Score": 3.378416433125681,
    "MMLU Score": 1.1524822695035457,
    "BBH Score": 2.108592689290024,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.243529039250524
  },
  {
    "Model Name": "Triangle104/DS-R1-Distill-Q2.5-10B-Harmony",
    "Parameters (B)": 10.366,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.871262396789764,
    "Overall Score": 3.758424150861492,
    "MMLU Score": 1.9189568557919607,
    "BBH Score": 1.528324420677361,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.008496594229243
  },
  {
    "Model Name": "Triangle104/DS-R1-Distill-Q2.5-14B-Harmony_V0.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6793931311300994,
    "Overall Score": 38.40633267860269,
    "MMLU Score": 40.01182033096927,
    "BBH Score": 38.71536986302894,
    "Math Score": 55.51359516616314,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.438224813124673
  },
  {
    "Model Name": "Triangle104/DS-R1-Distill-Q2.5-7B-RP",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3332671182751854,
    "Overall Score": 23.29151402275458,
    "MMLU Score": 21.006944444444443,
    "BBH Score": 20.78137433344085,
    "Math Score": 46.82779456193353,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.46950307518739
  },
  {
    "Model Name": "Triangle104/DS-R1-Llama-8B-Harmony",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5553321228885983,
    "Overall Score": 21.179062178800105,
    "MMLU Score": 19.372414302600472,
    "BBH Score": 17.496342243581015,
    "Math Score": 42.82477341389728,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.617067292010832
  },
  {
    "Model Name": "Triangle104/DSR1-Distill-Llama-Lit-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4702000791170424,
    "Overall Score": 17.835032823738523,
    "MMLU Score": 19.97266548463357,
    "BBH Score": 19.22515965463957,
    "Math Score": 35.196374622356494,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.131024257902164
  },
  {
    "Model Name": "Triangle104/DSR1-Distill-Qwen-7B-RP",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6860882551271495,
    "Overall Score": 24.099711456809,
    "MMLU Score": 22.53065898345153,
    "BBH Score": 19.853297811659683,
    "Math Score": 48.036253776435046,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.126255662753934
  },
  {
    "Model Name": "Triangle104/Dark-Chivalry_V1.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4220577896339603,
    "Overall Score": 21.672950420599893,
    "MMLU Score": 27.15721040189125,
    "BBH Score": 28.02613873976541,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.240555326642907
  },
  {
    "Model Name": "Triangle104/Distilled-DarkPlanet-Allades-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4574056932536057,
    "Overall Score": 21.68305782960861,
    "MMLU Score": 21.12699468085106,
    "BBH Score": 23.038205707355587,
    "Math Score": 40.03021148036254,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.877846251033894
  },
  {
    "Model Name": "Triangle104/Distilled-DarkPlanet-Allades-8B_TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4457470456859252,
    "Overall Score": 20.21392622497977,
    "MMLU Score": 26.677009456264773,
    "BBH Score": 29.96179725766144,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.981647955150692
  },
  {
    "Model Name": "Triangle104/Distilled-Whiskey-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.478627218374972,
    "Overall Score": 22.93584846984364,
    "MMLU Score": 26.29838947990544,
    "BBH Score": 29.317662931896013,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.511582760562462
  },
  {
    "Model Name": "Triangle104/Dolphin3-Llama3.2-Smart",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2169451994944307,
    "Overall Score": 14.183463389792356,
    "MMLU Score": 13.277556146572104,
    "BBH Score": 15.349665999615956,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.654972956616907
  },
  {
    "Model Name": "Triangle104/Gemmadevi-Stock-10B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.862202785697742,
    "Overall Score": 22.723742034208243,
    "MMLU Score": 36.24408983451536,
    "BBH Score": 43.62183969257654,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.883622195695505
  },
  {
    "Model Name": "Triangle104/Hermes-Llama-3.2-CoT",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.179573613762454,
    "Overall Score": 17.621221154166122,
    "MMLU Score": 21.63489952718676,
    "BBH Score": 23.795788682714846,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.938636256842157
  },
  {
    "Model Name": "Triangle104/Hermes-Llama-3.2-CoT-Summary",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2115236264239686,
    "Overall Score": 16.766151353052297,
    "MMLU Score": 21.12699468085106,
    "BBH Score": 17.388422101012054,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.838897556245461
  },
  {
    "Model Name": "Triangle104/Hermes3-L3.1-DirtyHarry-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3222689806146606,
    "Overall Score": 18.55982177819895,
    "MMLU Score": 25.98441193853428,
    "BBH Score": 29.678775616931603,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.036343626219955
  },
  {
    "Model Name": "Triangle104/Herodotos-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.835056676380084,
    "Overall Score": 38.337259928842606,
    "MMLU Score": 47.667331560283685,
    "BBH Score": 48.9099032194971,
    "Math Score": 50.45317220543807,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.996530211654969
  },
  {
    "Model Name": "Triangle104/Herodotos-14B_V0.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.997502037756403,
    "Overall Score": 4.56388866448478,
    "MMLU Score": 1.8266105200945613,
    "BBH Score": 2.954726291928145,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.2847980018137783
  },
  {
    "Model Name": "Triangle104/L3.1-8B-Dusky-Ink",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.440204275039435,
    "Overall Score": 22.39149881570813,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 30.50903807196173,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.547446430885657
  },
  {
    "Model Name": "Triangle104/L3.1-8B-Dusky-Ink_v0.r1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.467098660298715,
    "Overall Score": 13.969324061974744,
    "MMLU Score": 24.506870567375884,
    "BBH Score": 20.17548881298811,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.521734590862797
  },
  {
    "Model Name": "Triangle104/LThreePointOne-8B-HermesBlackroot",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.477823540288118,
    "Overall Score": 15.16012857459314,
    "MMLU Score": 25.384160756501178,
    "BBH Score": 29.26724981597156,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.258415948386846
  },
  {
    "Model Name": "Triangle104/LThreePointOne-8B-HermesInk",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.072176001463124,
    "Overall Score": 22.69615504867416,
    "MMLU Score": 27.41578014184397,
    "BBH Score": 31.47994731255064,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.952812421651847
  },
  {
    "Model Name": "Triangle104/Llama3.1-Allades-Lit-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7720308187157303,
    "Overall Score": 11.875472634114065,
    "MMLU Score": 19.160017730496453,
    "BBH Score": 17.44690701770639,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.382122508877117
  },
  {
    "Model Name": "Triangle104/Llama3.1-cc-Lit-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5077341013865455,
    "Overall Score": 12.717562119702656,
    "MMLU Score": 22.27208924349881,
    "BBH Score": 13.866972220416004,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.434883914880817
  },
  {
    "Model Name": "Triangle104/Minerva-1.5b",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1307037261186643,
    "Overall Score": 14.46708051296632,
    "MMLU Score": 18.864509456264773,
    "BBH Score": 16.381923221385325,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.794757971327352
  },
  {
    "Model Name": "Triangle104/Minerva-1.5b_V0.2",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1413996689755057,
    "Overall Score": 15.021440291369975,
    "MMLU Score": 21.22857565011821,
    "BBH Score": 14.994536223857972,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.160543760147467
  },
  {
    "Model Name": "Triangle104/Minerva-10b",
    "Parameters (B)": 10.067,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.561337791741095,
    "Overall Score": 10.977971126497692,
    "MMLU Score": 14.644281914893616,
    "BBH Score": 22.69248262502312,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.03113136988494
  },
  {
    "Model Name": "Triangle104/Minerva-14b",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.038677185252144,
    "Overall Score": 32.40842006449074,
    "MMLU Score": 46.596114066193856,
    "BBH Score": 47.06222455163349,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.665305357798823
  },
  {
    "Model Name": "Triangle104/Minerva-14b-V0.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.809768634655589,
    "Overall Score": 27.042982226988133,
    "MMLU Score": 45.755762411347526,
    "BBH Score": 43.620098523083904,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.624629549010166
  },
  {
    "Model Name": "Triangle104/Minerva-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1637015534784922,
    "Overall Score": 26.50105069675505,
    "MMLU Score": 38.26647458628841,
    "BBH Score": 36.0758653251849,
    "Math Score": 28.3987915407855,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.773064638041536
  },
  {
    "Model Name": "Triangle104/Minerva-8b",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4768092091178562,
    "Overall Score": 14.317747008078769,
    "MMLU Score": 23.21402186761229,
    "BBH Score": 25.37530670020226,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.695055339363167
  },
  {
    "Model Name": "Triangle104/Mistral-Redemption-Arc",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.593036275501428,
    "Overall Score": 32.78693047639915,
    "MMLU Score": 38.99601063829786,
    "BBH Score": 46.27652867208423,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.581408584734866
  },
  {
    "Model Name": "Triangle104/Mistral-Small-24b-Harmony",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4399582166958405,
    "Overall Score": 27.168346239791443,
    "MMLU Score": 49.22798463356975,
    "BBH Score": 48.42115059678503,
    "Math Score": 19.10876132930513,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.86745457248928
  },
  {
    "Model Name": "Triangle104/Pans_Gutenbergum_V0.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.684474305877838,
    "Overall Score": 22.27617513692708,
    "MMLU Score": 29.9645390070922,
    "BBH Score": 36.08244913782136,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.224407792506037
  },
  {
    "Model Name": "Triangle104/Pans_Gutenbergum_V0.2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.681225758481351,
    "Overall Score": 21.71531814911191,
    "MMLU Score": 28.727098108747047,
    "BBH Score": 35.91445940350976,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.916360601521669
  },
  {
    "Model Name": "Triangle104/Pantheon_ChatWaifu_V0.2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7744480161185985,
    "Overall Score": 20.845639319611607,
    "MMLU Score": 27.13874113475177,
    "BBH Score": 36.74319895362526,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.74767540680569
  },
  {
    "Model Name": "Triangle104/Phi-4-AbliteratedRP",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7394770105593755,
    "Overall Score": 37.3749762449992,
    "MMLU Score": 47.86125886524823,
    "BBH Score": 52.64096935250796,
    "Math Score": 30.74018126888218,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.486329522101748
  },
  {
    "Model Name": "Triangle104/Phi4-RP-o1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.86396540106734,
    "Overall Score": 28.80908949124801,
    "MMLU Score": 45.67265070921986,
    "BBH Score": 51.5939185267128,
    "Math Score": 37.764350453172206,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.455806998751912
  },
  {
    "Model Name": "Triangle104/Phi4-RP-o1-Ablit",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9109735397136868,
    "Overall Score": 28.67748592577745,
    "MMLU Score": 45.60800827423168,
    "BBH Score": 51.22184133516779,
    "Math Score": 38.82175226586103,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.480042696729264
  },
  {
    "Model Name": "Triangle104/Porpoise-R1-Llama3.2-3b",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5946285747737013,
    "Overall Score": 13.62683633096472,
    "MMLU Score": 12.409500591016547,
    "BBH Score": 12.926570818614184,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.91655145592474
  },
  {
    "Model Name": "Triangle104/Q2.5-14B-Instruct-1M-Harmony",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7730342245263926,
    "Overall Score": 37.73826910663008,
    "MMLU Score": 45.27556146572104,
    "BBH Score": 47.259249197406746,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.002100924851046
  },
  {
    "Model Name": "Triangle104/Q2.5-AthensCOT",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2770496852895648,
    "Overall Score": 28.558050099748765,
    "MMLU Score": 37.54617316784869,
    "BBH Score": 36.446691868053854,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.362520760712115
  },
  {
    "Model Name": "Triangle104/Q2.5-CodeR1-3B",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7322141137207586,
    "Overall Score": 19.81078532589114,
    "MMLU Score": 21.98581560283688,
    "BBH Score": 25.312035348871195,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.056000362001072
  },
  {
    "Model Name": "Triangle104/Q2.5-EVACOT-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.309828209517811,
    "Overall Score": 30.447241223161303,
    "MMLU Score": 37.01056442080379,
    "BBH Score": 35.722592826715,
    "Math Score": 28.24773413897281,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.24521719865072
  },
  {
    "Model Name": "Triangle104/Q2.5-EvaHumane-RP",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2574226662136654,
    "Overall Score": 26.370822890124625,
    "MMLU Score": 37.9155585106383,
    "BBH Score": 33.757405524368195,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.972123056706224
  },
  {
    "Model Name": "Triangle104/Q2.5-Humane-RP",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.254656556269786,
    "Overall Score": 29.83187981671115,
    "MMLU Score": 38.802083333333336,
    "BBH Score": 37.653375376825046,
    "Math Score": 33.91238670694864,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.776928967241986
  },
  {
    "Model Name": "Triangle104/Q2.5-Instruct-1M_Harmony",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2756625564987696,
    "Overall Score": 32.07867587170479,
    "MMLU Score": 37.39841903073286,
    "BBH Score": 33.63146155668904,
    "Math Score": 33.23262839879154,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.146678256159767
  },
  {
    "Model Name": "Triangle104/Q2.5-R1-3B",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7877770482953435,
    "Overall Score": 24.667669563202328,
    "MMLU Score": 31.257387706855795,
    "BBH Score": 27.2034830328168,
    "Math Score": 26.73716012084592,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.313008695265054
  },
  {
    "Model Name": "Triangle104/Q2.5-R1-7B",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7005417943365251,
    "Overall Score": 3.783468006938507,
    "MMLU Score": 2.002068557919621,
    "BBH Score": 2.548887396663384,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.400774140137899
  },
  {
    "Model Name": "Triangle104/Robo-Gutenberg_V1.0",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8898383424955503,
    "Overall Score": 40.348593527637,
    "MMLU Score": 48.79395685579197,
    "BBH Score": 50.286291267237225,
    "Math Score": 45.61933534743202,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.372820147006703
  },
  {
    "Model Name": "Triangle104/Rocinante-Prism_V2.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6493639223611307,
    "Overall Score": 20.77491884064445,
    "MMLU Score": 29.33658392434988,
    "BBH Score": 33.22820642176426,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.595715571918367
  },
  {
    "Model Name": "Triangle104/Rocinante-Prism_V2.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7031501654301848,
    "Overall Score": 20.79146935600846,
    "MMLU Score": 29.4566341607565,
    "BBH Score": 32.982522799498575,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.20765483750337
  },
  {
    "Model Name": "Triangle104/RomboHermes3-R1-Llama3.2-3b",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5959179312218184,
    "Overall Score": 14.65828137567246,
    "MMLU Score": 21.74571513002364,
    "BBH Score": 19.092695935991667,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.59781894063566
  },
  {
    "Model Name": "Triangle104/Rombos-Novasky-7B_V1c",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6720768673852975,
    "Overall Score": 18.20981801856624,
    "MMLU Score": 19.30777186761229,
    "BBH Score": 20.42212501104689,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.094844209429787
  },
  {
    "Model Name": "Triangle104/Set-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 28.620895805508525,
    "Overall Score": 44.03469176472607,
    "MMLU Score": 49.3572695035461,
    "BBH Score": 56.88003115055037,
    "Math Score": 36.40483383685801,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.5385504375530736
  },
  {
    "Model Name": "Tsunami-th/Tsunami-0.5-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.1801055943223924,
    "Overall Score": 36.42709650938436,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 36.13825418700338,
    "Math Score": 50.45317220543807,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.708867957703866
  },
  {
    "Model Name": "Tsunami-th/Tsunami-0.5x-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.117126798710792,
    "Overall Score": 36.004746535208355,
    "MMLU Score": 38.423463356974,
    "BBH Score": 37.36306059795168,
    "Math Score": 42.06948640483384,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.0064195291152
  },
  {
    "Model Name": "Tsunami-th/Tsunami-1.0-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.307262617446699,
    "Overall Score": 41.84004532523768,
    "MMLU Score": 47.20559988179669,
    "BBH Score": 49.150255113097735,
    "Math Score": 45.84592145015105,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.650959468570836
  },
  {
    "Model Name": "Tsunami-th/Tsunami-1.0-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9684366489643583,
    "Overall Score": 35.74871261762576,
    "MMLU Score": 38.04484338061466,
    "BBH Score": 35.85724274977317,
    "Math Score": 43.353474320241695,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.042942749038602
  },
  {
    "Model Name": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.885316477033936,
    "Overall Score": 22.586154586899323,
    "MMLU Score": 32.300901300236404,
    "BBH Score": 41.80922962006354,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.8377128358409407
  },
  {
    "Model Name": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.432923596852596,
    "Overall Score": 22.56307298613433,
    "MMLU Score": 31.885342789598106,
    "BBH Score": 42.16983380174582,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.153026005962164
  },
  {
    "Model Name": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.630300298977712,
    "Overall Score": 22.65046295673854,
    "MMLU Score": 31.395907210401887,
    "BBH Score": 42.53675224107426,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.022958235611546
  },
  {
    "Model Name": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4024578249460675,
    "Overall Score": 24.76595847369129,
    "MMLU Score": 30.12152777777778,
    "BBH Score": 29.489353188071963,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.65896844323549
  },
  {
    "Model Name": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3135334475254834,
    "Overall Score": 24.04094254728852,
    "MMLU Score": 29.90913120567376,
    "BBH Score": 29.86944932809155,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 18.302497429797736
  },
  {
    "Model Name": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 9.13529851667579,
    "Overall Score": 23.69339630817469,
    "MMLU Score": 29.38275709219858,
    "BBH Score": 29.73968358044069,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.593609422278232
  },
  {
    "Model Name": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9104745048401184,
    "Overall Score": 23.05947024187678,
    "MMLU Score": 29.53051122931442,
    "BBH Score": 29.71670075746525,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 25.326870900054562
  },
  {
    "Model Name": "UCLA-AGI/Mistral7B-PairRM-SPPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0083177982388298,
    "Overall Score": 16.44469675653773,
    "MMLU Score": 18.005688534278956,
    "BBH Score": 22.08465647856181,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.309041440368034
  },
  {
    "Model Name": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0533470821859574,
    "Overall Score": 17.91774579525423,
    "MMLU Score": 18.83680555555556,
    "BBH Score": 22.93229237099634,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.010296129619924
  },
  {
    "Model Name": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0309688884634434,
    "Overall Score": 17.118139500757714,
    "MMLU Score": 18.63364361702128,
    "BBH Score": 22.47992425019784,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.603934117032956
  },
  {
    "Model Name": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0368151525905829,
    "Overall Score": 16.488657432502865,
    "MMLU Score": 18.42124704491726,
    "BBH Score": 21.81749598592864,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.903179454220322
  },
  {
    "Model Name": "UKzExecution/LlamaExecutor-8B-3.0.5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.614003500601508,
    "Overall Score": 24.541079195358947,
    "MMLU Score": 29.17036052009456,
    "BBH Score": 28.41381524085358,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.205096634680753
  },
  {
    "Model Name": "Unbabel/TowerInstruct-Mistral-7B-v0.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2077791222280865,
    "Overall Score": 11.902717149315622,
    "MMLU Score": 10.756501182033098,
    "BBH Score": 14.224326422972672,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.855044627164718
  },
  {
    "Model Name": "Undi95/MG-FinalMix-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 24.44404705336021,
    "Overall Score": 44.29736213992491,
    "MMLU Score": 49.19104609929077,
    "BBH Score": 57.502411706281976,
    "Math Score": 39.72809667673716,
    "Date Submitted": "2024-07-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.812194275490709
  },
  {
    "Model Name": "Undi95/Phi4-abliterated",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.910048602404521,
    "Overall Score": 37.42237137162351,
    "MMLU Score": 47.56575059101655,
    "BBH Score": 54.11724836063252,
    "Math Score": 37.00906344410876,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.592366039541222
  },
  {
    "Model Name": "V3N0M/Jenna-Tiny-2.0",
    "Parameters (B)": 0.631,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4935997564668777,
    "Overall Score": 5.519126028133118,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 4.829999905649889,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.181379155529367
  },
  {
    "Model Name": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 21.25238163230416,
    "Overall Score": 38.00558783767682,
    "MMLU Score": 48.8031914893617,
    "BBH Score": 52.02957975911792,
    "Math Score": 22.80966767371601,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.7882978244615821
  },
  {
    "Model Name": "VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5913870564135353,
    "Overall Score": 26.66765472658618,
    "MMLU Score": 31.746823286052013,
    "BBH Score": 28.0492424520597,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-07-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.757491283538734
  },
  {
    "Model Name": "VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 30.18323458840754,
    "Overall Score": 43.413769840000015,
    "MMLU Score": 48.16600177304965,
    "BBH Score": 57.24162100868165,
    "Math Score": 36.933534743202415,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.4383405367917035
  },
  {
    "Model Name": "VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4988715708140576,
    "Overall Score": 29.931073085077475,
    "MMLU Score": 32.116208628841605,
    "BBH Score": 30.99936066535637,
    "Math Score": 19.410876132930515,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.977835689781699
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-1.5b",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5524737369802986,
    "Overall Score": 10.27356265309496,
    "MMLU Score": 12.788120567375886,
    "BBH Score": 13.419518424915282,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.617543606939185
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-7b-HerO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.139537237641185,
    "Overall Score": 19.66931174717597,
    "MMLU Score": 22.733820921985814,
    "BBH Score": 27.99187353683021,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.260788939105648
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-7b-LaserChat",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2093577226572745,
    "Overall Score": 22.14731649128105,
    "MMLU Score": 25.60579196217494,
    "BBH Score": 22.99208011647468,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.31328818293533
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-Gemma-2b",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.832470509424899,
    "Overall Score": 7.716094956089698,
    "MMLU Score": 5.206486406619384,
    "BBH Score": 9.133870459903902,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.2107607824539075
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-Gemma-7b",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.026498864574828,
    "Overall Score": 14.801979415385231,
    "MMLU Score": 21.79188829787234,
    "BBH Score": 18.492651800030927,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.890792984805781
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.548780388067429,
    "Overall Score": 24.4874668003906,
    "MMLU Score": 29.44739952718675,
    "BBH Score": 33.94516253986293,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.243897098807992
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.761054538607155,
    "Overall Score": 26.219081516210625,
    "MMLU Score": 26.50155141843972,
    "BBH Score": 32.34378307249567,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2024-07-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.496038976990702
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-Phi-3-medium",
    "Parameters (B)": 13.96,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5654950210859602,
    "Overall Score": 30.407915004992635,
    "MMLU Score": 40.72288711583924,
    "BBH Score": 49.630350331717615,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.423833736564124
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-SOLAR-Instruct",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6314605938212952,
    "Overall Score": 21.221646172197712,
    "MMLU Score": 24.257535460992905,
    "BBH Score": 31.838919738784018,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.00775896921373
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-gemma-2-2b-it",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.744972801225721,
    "Overall Score": 10.817668945100197,
    "MMLU Score": 18.809101654846337,
    "BBH Score": 18.914195373183343,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.279816850015616
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-gemma-2-9b-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.812136404481569,
    "Overall Score": 23.14181422578697,
    "MMLU Score": 34.34175531914893,
    "BBH Score": 43.249988966600455,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.9816364612404813
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-v2-14b-DPO",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.983250828721228,
    "Overall Score": 37.583891756672784,
    "MMLU Score": 45.74652777777778,
    "BBH Score": 50.92613155208554,
    "Math Score": 31.64652567975831,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.598300952381916
  },
  {
    "Model Name": "VAGOsolutions/SauerkrautLM-v2-14b-SFT",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.037848790767508,
    "Overall Score": 36.22785641162885,
    "MMLU Score": 46.725398936170215,
    "BBH Score": 45.824351326219606,
    "Math Score": 32.85498489425982,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.925496924577322
  },
  {
    "Model Name": "VIRNECT/llama-3-Korean-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8126872040589411,
    "Overall Score": 20.245300698827084,
    "MMLU Score": 28.20995862884161,
    "BBH Score": 27.322411613379888,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-07-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 24.91155342143023
  },
  {
    "Model Name": "VIRNECT/llama-3-Korean-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6406132627587642,
    "Overall Score": 20.431609341892,
    "MMLU Score": 28.1822547281324,
    "BBH Score": 27.564318704783016,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-07-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.453641455717198
  },
  {
    "Model Name": "VIRNECT/llama-3-Korean-8B-r-v-0.1",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3989817615402846,
    "Overall Score": 18.749278536149728,
    "MMLU Score": 25.10712174940898,
    "BBH Score": 25.8849543311167,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-07-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.815515247648906
  },
  {
    "Model Name": "ValiantLabs/Llama3-70B-Fireplace",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 19.38434399045657,
    "Overall Score": 37.125226832822285,
    "MMLU Score": 43.25317671394799,
    "BBH Score": 49.55653001638277,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.9152170871039031
  },
  {
    "Model Name": "ValiantLabs/Llama3-70B-ShiningValiant2",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 22.43518747855869,
    "Overall Score": 32.730483450533846,
    "MMLU Score": 43.30858451536643,
    "BBH Score": 46.71026104076922,
    "Math Score": 20.77039274924472,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.4588905700839083
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-70B-ShiningValiant2",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 27.994570050184382,
    "Overall Score": 36.49318385410157,
    "MMLU Score": 46.36524822695035,
    "BBH Score": 52.390968518523096,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2024-10-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3035807940140596
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Cobalt",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.627762740519015,
    "Overall Score": 20.239393742398576,
    "MMLU Score": 29.38275709219858,
    "BBH Score": 27.41777700049443,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.702138945162549
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Cobalt",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9381708246723048,
    "Overall Score": 25.55866436932208,
    "MMLU Score": 29.58591903073286,
    "BBH Score": 27.23548304863836,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 27.243081640541856
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Enigma",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.275141104754986,
    "Overall Score": 16.62515745828593,
    "MMLU Score": 26.769355791962173,
    "BBH Score": 22.012915076928262,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.285200688055361
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Esper2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.753530232424242,
    "Overall Score": 13.94081009846365,
    "MMLU Score": 21.15469858156028,
    "BBH Score": 22.19568506792584,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.950139575974454
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Fireplace2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9162338472706588,
    "Overall Score": 18.312602016344886,
    "MMLU Score": 15.632387706855791,
    "BBH Score": 24.07027321429611,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 19.98682112748371
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-Fireplace2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8021953793743168,
    "Overall Score": 18.5705806084544,
    "MMLU Score": 15.817080378250589,
    "BBH Score": 24.08995379001348,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.304421385711077
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-ShiningValiant2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4452384103432947,
    "Overall Score": 23.15728097110788,
    "MMLU Score": 26.46461288416076,
    "BBH Score": 26.346118640067065,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.470357112481624
  },
  {
    "Model Name": "ValiantLabs/Llama3.1-8B-ShiningValiant2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.528982131474145,
    "Overall Score": 15.45803558114332,
    "MMLU Score": 21.413268321513,
    "BBH Score": 21.618149642278947,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.3676026783141357
  },
  {
    "Model Name": "ValiantLabs/Llama3.2-3B-Enigma",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.244792890969476,
    "Overall Score": 11.692730593705356,
    "MMLU Score": 15.86325354609929,
    "BBH Score": 12.434025970150064,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.208823780912602
  },
  {
    "Model Name": "ValiantLabs/Llama3.2-3B-Esper2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4777687000332602,
    "Overall Score": 10.944295126634552,
    "MMLU Score": 13.9701536643026,
    "BBH Score": 13.851732907913409,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.405959489051452
  },
  {
    "Model Name": "ValiantLabs/Llama3.2-3B-ShiningValiant2",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.463997135589956,
    "Overall Score": 14.39069569820728,
    "MMLU Score": 20.323581560283685,
    "BBH Score": 18.912708783001538,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.154361315820311
  },
  {
    "Model Name": "Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.713223400631936,
    "Overall Score": 25.354951361962605,
    "MMLU Score": 28.302304964539005,
    "BBH Score": 32.66941729424733,
    "Math Score": 21.75226586102719,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.799559329279667
  },
  {
    "Model Name": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.4415836238229383,
    "Overall Score": 25.01995412263689,
    "MMLU Score": 26.640070921985814,
    "BBH Score": 31.41440911337631,
    "Math Score": 17.14501510574018,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.269895739114578
  },
  {
    "Model Name": "Weyaxi/Bagel-Hermes-2x34B",
    "Parameters (B)": 60.814,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 19.630335820609552,
    "Overall Score": 25.611273447311103,
    "MMLU Score": 39.873300827423165,
    "BBH Score": 27.409031445428763,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.304678314286517
  },
  {
    "Model Name": "Weyaxi/Bagel-Hermes-34B-Slerp",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.042750996972115,
    "Overall Score": 27.24685762860255,
    "MMLU Score": 41.14768026004728,
    "BBH Score": 41.957047480557854,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.509015453765236
  },
  {
    "Model Name": "Weyaxi/Einstein-v4-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3355080217096282,
    "Overall Score": 16.755664054789627,
    "MMLU Score": 13.98862293144208,
    "BBH Score": 14.30445141720726,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.546284846226639
  },
  {
    "Model Name": "Weyaxi/Einstein-v6.1-Llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.719195518627926,
    "Overall Score": 20.169491366460083,
    "MMLU Score": 23.675753546099287,
    "BBH Score": 29.38377348658535,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.731935750133392
  },
  {
    "Model Name": "Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7434564581463543,
    "Overall Score": 19.31874270630133,
    "MMLU Score": 23.25096040189125,
    "BBH Score": 29.69444747698505,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.080714184764354
  },
  {
    "Model Name": "Weyaxi/Einstein-v7-Qwen2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6279427530533828,
    "Overall Score": 24.8064180500954,
    "MMLU Score": 34.39716312056737,
    "BBH Score": 32.84181889691276,
    "Math Score": 19.939577039274926,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.439481899395657
  },
  {
    "Model Name": "Weyaxi/Einstein-v8-Llama3.2-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7758492036245103,
    "Overall Score": 4.640409160461389,
    "MMLU Score": 1.7896719858156025,
    "BBH Score": 3.013774178282933,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.981070984906521
  },
  {
    "Model Name": "Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4920222032108486,
    "Overall Score": 20.476008390270348,
    "MMLU Score": 23.92508865248227,
    "BBH Score": 31.82468678354313,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.723661984523922
  },
  {
    "Model Name": "WizardLMTeam/WizardLM-13B-V1.0",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 141.95517416949244,
    "Overall Score": 4.546091523510591,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 2.147966883446335,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.032024838475296594
  },
  {
    "Model Name": "WizardLMTeam/WizardLM-13B-V1.2",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.038916260166667,
    "Overall Score": 15.177532740883724,
    "MMLU Score": 16.87906323877068,
    "BBH Score": 22.88865497804447,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.156231468013565
  },
  {
    "Model Name": "WizardLMTeam/WizardLM-70B-V1.0",
    "Parameters (B)": 70.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 58.19212658390846,
    "Overall Score": 22.3974420993294,
    "MMLU Score": 27.184914302600472,
    "BBH Score": 37.54335453368136,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.38488784332420045
  },
  {
    "Model Name": "Wladastic/Mini-Think-Base-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.3615004625377821,
    "Overall Score": 14.3485600949955,
    "MMLU Score": 8.577127659574469,
    "BBH Score": 9.377987524324114,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.69167838477071
  },
  {
    "Model Name": "Xclbr7/Arcanum-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.381021411270149,
    "Overall Score": 20.757225902526443,
    "MMLU Score": 28.736332742316783,
    "BBH Score": 31.879959562746524,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.139335833051874
  },
  {
    "Model Name": "Xclbr7/Hyena-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.719786792906344,
    "Overall Score": 20.76453411894911,
    "MMLU Score": 27.10180260047281,
    "BBH Score": 34.665648637656034,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.582183946280793
  },
  {
    "Model Name": "Xclbr7/caliburn-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.712440910761932,
    "Overall Score": 22.94686461976949,
    "MMLU Score": 29.724438534278963,
    "BBH Score": 35.63684056756332,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.181072014708493
  },
  {
    "Model Name": "Xclbr7/caliburn-v2-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2643874963426573,
    "Overall Score": 20.96611306962392,
    "MMLU Score": 30.9341755319149,
    "BBH Score": 30.387966946397217,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.422679015010889
  },
  {
    "Model Name": "Xiaojian9992024/Llama3.2-1B-THREADRIPPER",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7736472043193455,
    "Overall Score": 14.088097956146528,
    "MMLU Score": 8.475546690307327,
    "BBH Score": 9.115530357902744,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.209977206007267
  },
  {
    "Model Name": "Xiaojian9992024/Llama3.2-1B-THREADRIPPER-v0.2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6876423057880287,
    "Overall Score": 13.779234902412703,
    "MMLU Score": 8.281619385342788,
    "BBH Score": 8.329663069732538,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.038375746271004
  },
  {
    "Model Name": "Xiaojian9992024/Phi-4-Megatron-Empathetic",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.602237813494312,
    "Overall Score": 27.96788940888075,
    "MMLU Score": 45.35867316784871,
    "BBH Score": 51.91276449300776,
    "Math Score": 26.96374622356496,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.764031931515038
  },
  {
    "Model Name": "Xiaojian9992024/Phi-4-mini-UNOFFICAL",
    "Parameters (B)": 3.754,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4920230455777322,
    "Overall Score": 3.014260701114446,
    "MMLU Score": 1.6049793144208029,
    "BBH Score": 2.4789472756031983,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.126259182789109
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-7B-MS-Destroyer",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6893245788040062,
    "Overall Score": 35.4337301147896,
    "MMLU Score": 37.9155585106383,
    "BBH Score": 35.7596547015331,
    "Math Score": 45.9214501510574,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.403549509677894
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-Dyanka-7B-Preview",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.620859013831167,
    "Overall Score": 37.29594433542609,
    "MMLU Score": 37.50923463356973,
    "BBH Score": 36.61517249738159,
    "Math Score": 48.79154078549849,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 60.071519466685466
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-Dyanka-7B-Preview-v0.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6527470209395493,
    "Overall Score": 34.55453510407936,
    "MMLU Score": 37.4538268321513,
    "BBH Score": 34.35967522664527,
    "Math Score": 47.205438066465256,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 52.93710119786123
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-THREADRIPPER-Medium-Censored",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.593070184447759,
    "Overall Score": 41.54381790411528,
    "MMLU Score": 43.65026595744681,
    "BBH Score": 49.11232867574543,
    "Math Score": 53.398791540785496,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.077832797125964
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-THREADRIPPER-Small",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.291254759495219,
    "Overall Score": 36.55431800242105,
    "MMLU Score": 37.29683806146573,
    "BBH Score": 35.79468363096907,
    "Math Score": 47.35649546827795,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 28.30914483266723
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-THREADRIPPER-Small-AnniversaryEdition",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.044542113283342,
    "Overall Score": 34.25068817877398,
    "MMLU Score": 37.70316193853428,
    "BBH Score": 35.29192945032174,
    "Math Score": 50.75528700906344,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.752253698394405
  },
  {
    "Model Name": "Xiaojian9992024/Qwen2.5-Ultra-1.5B-25.02-Exp",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6000318406060409,
    "Overall Score": 14.446569781402497,
    "MMLU Score": 18.23655437352246,
    "BBH Score": 17.02637966475561,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.07633862698228
  },
  {
    "Model Name": "Xiaojian9992024/Reflection-L3.2-JametMiniMix-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5851620329780873,
    "Overall Score": 19.12592274423045,
    "MMLU Score": 22.087396572104016,
    "BBH Score": 20.235870672885177,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.684832006089266
  },
  {
    "Model Name": "Xkev/Llama-3.2V-11B-cot",
    "Parameters (B)": 10.67,
    "Architecture": "MllamaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 1.4232207220783888,
    "Overall Score": 21.7590291424644,
    "MMLU Score": 28.745567375886527,
    "BBH Score": 28.24676155300344,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.288583706600884
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-1M-YOYO-V3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.780762706451244,
    "Overall Score": 42.55942702673594,
    "MMLU Score": 46.74386820330969,
    "BBH Score": 49.46606980733037,
    "Math Score": 53.54984894259819,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.899549823541403
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-0505",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.857234023167,
    "Overall Score": 39.665305547250405,
    "MMLU Score": 48.56309101654846,
    "BBH Score": 50.35907329801012,
    "Math Score": 44.33534743202417,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.283354680845374
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-0510-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.639096152046373,
    "Overall Score": 39.98094603659342,
    "MMLU Score": 48.67390661938534,
    "BBH Score": 50.468800790349086,
    "Math Score": 44.41087613293052,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.61826199031405
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-0805",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.983396677583985,
    "Overall Score": 39.665305547250405,
    "MMLU Score": 48.56309101654846,
    "BBH Score": 50.35907329801012,
    "Math Score": 44.33534743202417,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.95765894229451
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-1005",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9308090122404535,
    "Overall Score": 40.08590414271186,
    "MMLU Score": 48.69237588652482,
    "BBH Score": 50.28689926796508,
    "Math Score": 45.2416918429003,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.197876319578294
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-1005-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.909489671257113,
    "Overall Score": 39.99172395122441,
    "MMLU Score": 48.5723256501182,
    "BBH Score": 50.51505544014052,
    "Math Score": 44.33534743202417,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.229397520921163
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-1010",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.886339525994916,
    "Overall Score": 40.00800921412039,
    "MMLU Score": 48.6184988179669,
    "BBH Score": 50.26771877763532,
    "Math Score": 45.090634441087616,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.294522376780296
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-1010",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.670591842952951,
    "Overall Score": 31.959648585770537,
    "MMLU Score": 43.82572399527187,
    "BBH Score": 48.6902938974714,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.13073424881473
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-1010-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9195075866457527,
    "Overall Score": 39.98094603659342,
    "MMLU Score": 48.67390661938534,
    "BBH Score": 50.468800790349086,
    "Math Score": 44.41087613293052,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.200502270441689
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-SCE",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.927547495329891,
    "Overall Score": 39.66921695193184,
    "MMLU Score": 48.67390661938534,
    "BBH Score": 49.4648829451977,
    "Math Score": 46.14803625377644,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.100251365286127
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-V4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.693343718287393,
    "Overall Score": 42.28551883596217,
    "MMLU Score": 46.3283096926714,
    "BBH Score": 49.67240339546996,
    "Math Score": 53.47432024169184,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 11.449115506522638
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-V4-p1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7656846963986237,
    "Overall Score": 42.45828532336958,
    "MMLU Score": 44.6660756501182,
    "BBH Score": 50.24542053284919,
    "Math Score": 53.32326283987915,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.046357432881173
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-V4-p2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.757040584464602,
    "Overall Score": 41.58466487593814,
    "MMLU Score": 44.08429373522459,
    "BBH Score": 47.02692591646044,
    "Math Score": 51.66163141993958,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.66744698080474
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-latest",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.953941577818676,
    "Overall Score": 40.078312739638136,
    "MMLU Score": 48.56309101654846,
    "BBH Score": 52.03543238956396,
    "Math Score": 44.18429003021148,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.136293607491458
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-YOYO-latest-V2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.697725501634185,
    "Overall Score": 41.84546724325599,
    "MMLU Score": 46.92856087470449,
    "BBH Score": 47.29890601305299,
    "Math Score": 51.58610271903324,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.31654235144352
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-14B-it-restore",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.670695198460566,
    "Overall Score": 41.50259115054908,
    "MMLU Score": 43.33628841607564,
    "BBH Score": 48.42592166972992,
    "Math Score": 53.70090634441088,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 24.8415098030993
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-7B-it-restore",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6688730982662607,
    "Overall Score": 35.33330306100891,
    "MMLU Score": 36.5303634751773,
    "BBH Score": 35.084321766131644,
    "Math Score": 50.0,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 52.825122063652884
  },
  {
    "Model Name": "YOYO-AI/Qwen2.5-Coder-14B-YOYO-1010",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.230074966484489,
    "Overall Score": 32.054639724074,
    "MMLU Score": 34.16629728132387,
    "BBH Score": 45.20119016827334,
    "Math Score": 32.17522658610272,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.92380674030029
  },
  {
    "Model Name": "YOYO-AI/ZYH-LLM-Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.941876074014728,
    "Overall Score": 39.82358869327943,
    "MMLU Score": 48.341459810874696,
    "BBH Score": 52.042745183320136,
    "Math Score": 41.1631419939577,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.102699310057163
  },
  {
    "Model Name": "YOYO-AI/ZYH-LLM-Qwen2.5-14B-V2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.015112458534472,
    "Overall Score": 36.56636248193895,
    "MMLU Score": 48.5723256501182,
    "BBH Score": 49.088647063990685,
    "Math Score": 35.422960725075534,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.14606541043001
  },
  {
    "Model Name": "YOYO-AI/ZYH-LLM-Qwen2.5-14B-V3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.863210504006676,
    "Overall Score": 41.62825190779884,
    "MMLU Score": 43.123891843971634,
    "BBH Score": 48.182465261630426,
    "Math Score": 52.7190332326284,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.342216200628336
  },
  {
    "Model Name": "YOYO-AI/ZYH-LLM-Qwen2.5-14B-V4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8018926490312424,
    "Overall Score": 43.137421470516735,
    "MMLU Score": 46.706929669030735,
    "BBH Score": 50.26935344231426,
    "Math Score": 53.92749244712991,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.940061853134733
  },
  {
    "Model Name": "Yash21/TinyYi-7B-Test",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5262181891545112,
    "Overall Score": 4.495167294967694,
    "MMLU Score": 1.0139627659574466,
    "BBH Score": 2.267966388832264,
    "Math Score": 0.0,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.9452979442329346
  },
  {
    "Model Name": "Youlln/1PARAMMYL-8B-ModelStock",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.785043690387826,
    "Overall Score": 26.30915159356537,
    "MMLU Score": 33.335180260047274,
    "BBH Score": 31.799951193327704,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.738659751151154
  },
  {
    "Model Name": "Youlln/2PRYMMAL-Yi1.5-6B-SLERP",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0788965592952984,
    "Overall Score": 18.991811258176195,
    "MMLU Score": 24.109781323877066,
    "BBH Score": 24.495644420709063,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.13552488855627
  },
  {
    "Model Name": "Youlln/3PRYMMAL-PHI3-3B-SLERP",
    "Parameters (B)": 3.0,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1568781105686563,
    "Overall Score": 25.13874099477812,
    "MMLU Score": 33.353649527186754,
    "BBH Score": 35.82766762143187,
    "Math Score": 17.14501510574018,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.655151430022324
  },
  {
    "Model Name": "Youlln/4PRYMMAL-GEMMA2-9B-SLERP",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.705320172540969,
    "Overall Score": 23.688707771567948,
    "MMLU Score": 35.662307919621746,
    "BBH Score": 42.06417191239567,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.1520382827205555
  },
  {
    "Model Name": "Youlln/ECE-MIRAGE-1-12B",
    "Parameters (B)": 15.21,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.26754454297524,
    "Overall Score": 4.785720345472222,
    "MMLU Score": 1.2171247044917255,
    "BBH Score": 2.6005529379115604,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.77558356587529
  },
  {
    "Model Name": "Youlln/ECE-MIRAGE-1-15B",
    "Parameters (B)": 15.21,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2881628575043904,
    "Overall Score": 4.785720345472222,
    "MMLU Score": 1.2171247044917255,
    "BBH Score": 2.6005529379115604,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.715151634432148
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-0.5B-FT-V3",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1462704150298528,
    "Overall Score": 4.392856379585042,
    "MMLU Score": 1.7896719858156025,
    "BBH Score": 3.616882510836621,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.8323037234374024
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-0.5B-FT-V3-MUSR",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0599692544226658,
    "Overall Score": 5.5387028579477615,
    "MMLU Score": 7.164228723404253,
    "BBH Score": 5.062185886531173,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.6887308371503136
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-0.5B-FT-V4-MUSR",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8973827349384207,
    "Overall Score": 4.211186680289756,
    "MMLU Score": 3.5719562647754137,
    "BBH Score": 4.949091743380625,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.2194713816801066
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-0.5B-SLERP-V2",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3099948071405385,
    "Overall Score": 4.6271949147226215,
    "MMLU Score": 1.0509013002364058,
    "BBH Score": 1.9175609031491383,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.532223860354744
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-0.5B-SLERP-V3",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.27539691314213,
    "Overall Score": 3.6630142582547953,
    "MMLU Score": 0.967789598108746,
    "BBH Score": 2.319604893286366,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.8720582749650965
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-YL-1B-SLERP-V1",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.190681575994079,
    "Overall Score": 16.681936382880597,
    "MMLU Score": 21.5056146572104,
    "BBH Score": 18.27951144620795,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.010409432054194
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-YL-1B-SLERP-V2",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.20925564708773,
    "Overall Score": 16.681936382880597,
    "MMLU Score": 21.5056146572104,
    "BBH Score": 18.27951144620795,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.795210651325858
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL-YL-7B-SLERP-V4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.540313926541391,
    "Overall Score": 10.869547461805958,
    "MMLU Score": 12.575723995271868,
    "BBH Score": 13.157437333845117,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.056709203566286
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL0.5-FT",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0067829764347855,
    "Overall Score": 5.585741676013818,
    "MMLU Score": 5.298832742316785,
    "BBH Score": 5.151599849335524,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.548108983520973
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL0.5B-Youri",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3116917717904806,
    "Overall Score": 3.505273892929676,
    "MMLU Score": 1.0601359338061456,
    "BBH Score": 1.5012962555992375,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.6723304729928437
  },
  {
    "Model Name": "Youlln/ECE-PRYMMAL1B-FT-V1",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.475191139732048,
    "Overall Score": 11.84779796618845,
    "MMLU Score": 19.36317966903073,
    "BBH Score": 16.18938601764277,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.031364646306423
  },
  {
    "Model Name": "Youlln/ECE-Qwen0.5B-FT-V2",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0465990255890534,
    "Overall Score": 7.574686962054336,
    "MMLU Score": 7.395094562647753,
    "BBH Score": 7.632147610946966,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.237429786246078
  },
  {
    "Model Name": "Youlln/ECE.EIFFEIL.ia-0.5B-SLERP",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2081187188905276,
    "Overall Score": 8.829965651830063,
    "MMLU Score": 10.03619976359338,
    "BBH Score": 8.405356119616796,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.308855920996769
  },
  {
    "Model Name": "YoungPanda/qwenqwen",
    "Parameters (B)": 14.316,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 14.245337780966572,
    "Overall Score": 4.783628186114581,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 8.194779944827593,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.3358030718307055
  },
  {
    "Model Name": "Yuma42/KangalKhan-RawRuby-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.307438889120352,
    "Overall Score": 20.49108954626372,
    "MMLU Score": 22.47525118203309,
    "BBH Score": 26.387283588738622,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.672693933748729
  },
  {
    "Model Name": "Yuma42/Llama3.1-IgneousIguana-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7070549834224411,
    "Overall Score": 31.47616691324721,
    "MMLU Score": 33.0396719858156,
    "BBH Score": 31.985926552081427,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.51728316925146
  },
  {
    "Model Name": "Yuma42/Llama3.1-SuperHawk-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7120080997921155,
    "Overall Score": 31.135471049209404,
    "MMLU Score": 32.72569444444445,
    "BBH Score": 31.966635202809908,
    "Math Score": 23.48942598187311,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.729096703113356
  },
  {
    "Model Name": "Z1-Coder/Z1-Coder-7B",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.170037262173062,
    "Overall Score": 21.53334869957601,
    "MMLU Score": 30.65713652482269,
    "BBH Score": 28.158145376480263,
    "Math Score": 32.477341389728096,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.403985407766424
  },
  {
    "Model Name": "ZHLiu627/zephyr-7b-gemma-dpo-avg",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8876135928862379,
    "Overall Score": 14.667993195924751,
    "MMLU Score": 20.563682033096924,
    "BBH Score": 18.40453524667128,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.525201183804644
  },
  {
    "Model Name": "ZHLiu627/zephyr-7b-gemma-rpo-avg",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8713301212278419,
    "Overall Score": 14.5883116384285,
    "MMLU Score": 20.342050827423165,
    "BBH Score": 19.01680125229881,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.74257699007497
  },
  {
    "Model Name": "ZeroXClem/L3-Aspire-Heart-Matrix-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5754026013900415,
    "Overall Score": 25.81522350685034,
    "MMLU Score": 30.94341016548463,
    "BBH Score": 34.30754710829408,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.386429401647884
  },
  {
    "Model Name": "ZeroXClem/Llama-3.1-8B-AthenaSky-MegaMix",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7384327295388944,
    "Overall Score": 26.791594885986022,
    "MMLU Score": 27.822104018912537,
    "BBH Score": 31.38528367305928,
    "Math Score": 27.94561933534744,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 36.281700166128495
  },
  {
    "Model Name": "ZeroXClem/Llama-3.1-8B-RainbowLight-EtherealMix",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7630019896475743,
    "Overall Score": 22.83097975490585,
    "MMLU Score": 29.225768321512994,
    "BBH Score": 31.072264304734336,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.922569095070557
  },
  {
    "Model Name": "ZeroXClem/Llama-3.1-8B-SpecialTitanFusion",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6858701462349897,
    "Overall Score": 29.23340398888008,
    "MMLU Score": 29.12418735224587,
    "BBH Score": 34.823135587389494,
    "Math Score": 23.338368580060425,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 42.622359566681396
  },
  {
    "Model Name": "ZeroXClem/Llama-3.1-8B-SuperNova-EtherealHermes",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7371906885752015,
    "Overall Score": 28.40553977440776,
    "MMLU Score": 30.50014775413712,
    "BBH Score": 32.07128887769491,
    "Math Score": 17.447129909365557,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.53214672218433
  },
  {
    "Model Name": "ZeroXClem/Llama-3.1-8B-SuperTulu-LexiNova",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.468249573248224,
    "Overall Score": 23.300170759550948,
    "MMLU Score": 26.30762411347517,
    "BBH Score": 30.50279668346708,
    "Math Score": 25.302114803625376,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.869352992900067
  },
  {
    "Model Name": "ZeroXClem/Qwen-2.5-Aether-SlerpFusion-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.352707431092865,
    "Overall Score": 30.11832980281197,
    "MMLU Score": 36.96439125295508,
    "BBH Score": 36.01120909918873,
    "Math Score": 27.34138972809668,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.265220926951727
  },
  {
    "Model Name": "ZeroXClem/Qwen2.5-7B-CelestialHarmony-1M",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.431678809760781,
    "Overall Score": 32.03891571870145,
    "MMLU Score": 37.62928486997636,
    "BBH Score": 34.50741633012333,
    "Math Score": 34.74320241691843,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.378563893150606
  },
  {
    "Model Name": "ZeroXClem/Qwen2.5-7B-HomerAnvita-NerdMix",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5683858790129577,
    "Overall Score": 35.64186520551805,
    "MMLU Score": 38.12795508274231,
    "BBH Score": 36.579205629985445,
    "Math Score": 38.36858006042296,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.725188795979708
  },
  {
    "Model Name": "ZeroXClem/Qwen2.5-7B-HomerCreative-Mix",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4591412814366411,
    "Overall Score": 34.907245009987854,
    "MMLU Score": 38.30341312056737,
    "BBH Score": 36.7707223822516,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.92314264155345
  },
  {
    "Model Name": "ZeroXClem/Qwen2.5-7B-Qandora-CySec",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3641605836632866,
    "Overall Score": 32.02349981666794,
    "MMLU Score": 38.71897163120567,
    "BBH Score": 36.264898165897854,
    "Math Score": 29.30513595166164,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.4748754656675
  },
  {
    "Model Name": "ZeusLabs/L3-Aethora-15B-V2",
    "Parameters (B)": 15.01,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.75533746778399,
    "Overall Score": 24.69871364353165,
    "MMLU Score": 27.77593085106383,
    "BBH Score": 28.968504695312703,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.193892927864354
  },
  {
    "Model Name": "ZhangShenao/SELM-Llama-3-8B-Instruct-iter-3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.311181864354396,
    "Overall Score": 24.042937650204056,
    "MMLU Score": 30.92494089834515,
    "BBH Score": 29.07853088402274,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 18.336844265339497
  },
  {
    "Model Name": "aaditya/Llama3-OpenBioLLM-70B",
    "Parameters (B)": 70.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 19.3140446459104,
    "Overall Score": 34.979020412011955,
    "MMLU Score": 42.96690307328605,
    "BBH Score": 47.14707467716792,
    "Math Score": 19.71299093655589,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.8110665608002772
  },
  {
    "Model Name": "abacusai/Dracarys-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 24.76692814545505,
    "Overall Score": 43.377212135916615,
    "MMLU Score": 49.51425827423168,
    "BBH Score": 56.93552010003367,
    "Math Score": 39.65256797583081,
    "Date Submitted": "2024-08-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.7514167231868323
  },
  {
    "Model Name": "abacusai/Liberated-Qwen1.5-14B",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.1071985770077655,
    "Overall Score": 20.50814223648692,
    "MMLU Score": 27.914450354609933,
    "BBH Score": 28.020905999685464,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3580277401975236
  },
  {
    "Model Name": "abacusai/Llama-3-Smaug-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.820436529300302,
    "Overall Score": 19.06776237652968,
    "MMLU Score": 24.27600472813239,
    "BBH Score": 27.880374189415942,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.474280245221465
  },
  {
    "Model Name": "abacusai/Smaug-34B-v0.1",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 23.57188137271181,
    "Overall Score": 24.95321808709686,
    "MMLU Score": 39.36539598108747,
    "BBH Score": 34.261660667279955,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.0586010379292068
  },
  {
    "Model Name": "abacusai/Smaug-72B-v0.1",
    "Parameters (B)": 72.289,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 58.47160296784014,
    "Overall Score": 29.737299261857203,
    "MMLU Score": 40.26115543735224,
    "BBH Score": 43.12510043134919,
    "Math Score": 19.10876132930513,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5085767749212033
  },
  {
    "Model Name": "abacusai/Smaug-Llama-3-70B-Instruct-32K",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.606826468263424,
    "Overall Score": 35.76489160177244,
    "MMLU Score": 41.83104314420804,
    "BBH Score": 49.07037043446443,
    "Math Score": 27.492447129909365,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.3441998294848407
  },
  {
    "Model Name": "abacusai/Smaug-Mixtral-v0.1",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.882831004615716,
    "Overall Score": 23.821471245327263,
    "MMLU Score": 26.13216607565012,
    "BBH Score": 31.919260543426763,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.0219436686361574
  },
  {
    "Model Name": "abacusai/Smaug-Qwen2-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 26.51466955627384,
    "Overall Score": 42.07422014151536,
    "MMLU Score": 46.559175531914896,
    "BBH Score": 56.26617189727526,
    "Math Score": 41.31419939577039,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.5868280029746724
  },
  {
    "Model Name": "abacusai/bigstral-12b-32k",
    "Parameters (B)": 12.476,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.930558858073448,
    "Overall Score": 18.135141503206025,
    "MMLU Score": 18.23655437352246,
    "BBH Score": 25.5569024540723,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.393726291931616
  },
  {
    "Model Name": "abacusai/bigyi-15b",
    "Parameters (B)": 15.058,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7422439356328927,
    "Overall Score": 13.051824492532411,
    "MMLU Score": 22.25361997635934,
    "BBH Score": 19.94022305425607,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.487700085036031
  },
  {
    "Model Name": "abhishek/autotrain-0tmgq-5tpbg",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3518284991076842,
    "Overall Score": 4.856618645954227,
    "MMLU Score": 1.6788563829787229,
    "BBH Score": 4.268752154086201,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.80393759536734
  },
  {
    "Model Name": "abhishek/autotrain-0tmgq-5tpbg",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6736077839783131,
    "Overall Score": 5.051545214400249,
    "MMLU Score": 1.595744680851063,
    "BBH Score": 4.419022545347729,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.499238183629546
  },
  {
    "Model Name": "abhishek/autotrain-llama3-70b-orpo-v1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 21.522055975877294,
    "Overall Score": 14.813377033004464,
    "MMLU Score": 1.3556442080378246,
    "BBH Score": 41.56536227340845,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.6882881937305543
  },
  {
    "Model Name": "abhishek/autotrain-llama3-70b-orpo-v2",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 25.054093177678148,
    "Overall Score": 28.867313366854955,
    "MMLU Score": 42.4220596926714,
    "BBH Score": 39.88219882979646,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.1521994894061534
  },
  {
    "Model Name": "abhishek/autotrain-llama3-orpo-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8118801946809,
    "Overall Score": 12.276280777825413,
    "MMLU Score": 13.536125886524822,
    "BBH Score": 4.380133995067516,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.7754373682457825
  },
  {
    "Model Name": "abhishek/autotrain-vr4a1-e5mms",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.745756095720281,
    "Overall Score": 18.65996836134808,
    "MMLU Score": 29.63209219858156,
    "BBH Score": 28.45661724854773,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.981629311814523
  },
  {
    "Model Name": "abideen/MedPhi-4-14B-v1",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8237211677219296,
    "Overall Score": 36.53594090222929,
    "MMLU Score": 48.2029403073286,
    "BBH Score": 55.57896973123449,
    "Math Score": 29.30513595166164,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.033731882307176
  },
  {
    "Model Name": "adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.0431489462132335,
    "Overall Score": 23.8273490799763,
    "MMLU Score": 39.03294917257684,
    "BBH Score": 35.2764249557812,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.9428697343140993
  },
  {
    "Model Name": "adriszmar/QAIMath-Qwen2.5-7B-TIES",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2834082223865078,
    "Overall Score": 5.469542016632626,
    "MMLU Score": 0.967789598108746,
    "BBH Score": 5.253690606033476,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.261732098351349
  },
  {
    "Model Name": "adriszmar/QAIMath-Qwen2.5-7B-TIES",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.6126317222798834,
    "Overall Score": 4.988441667082756,
    "MMLU Score": 0.7369237588652473,
    "BBH Score": 5.019151283406914,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.9093550861158683
  },
  {
    "Model Name": "aevalone/distill_qw_test",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6383736325002226,
    "Overall Score": 33.68409846940663,
    "MMLU Score": 34.35098995271868,
    "BBH Score": 33.097457229677104,
    "Math Score": 47.809667673716014,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 52.76549148416603
  },
  {
    "Model Name": "agentlans/Gemma2-9B-AdvancedFuse",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.959092552204823,
    "Overall Score": 20.43457994939628,
    "MMLU Score": 33.335180260047274,
    "BBH Score": 40.51673791578562,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.161430221684573
  },
  {
    "Model Name": "agentlans/Llama-3.2-1B-Instruct-CrashCourse12K",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7763331443373106,
    "Overall Score": 13.43796759000334,
    "MMLU Score": 8.992686170212766,
    "BBH Score": 9.387917708519003,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.309537391288618
  },
  {
    "Model Name": "agentlans/Llama3.1-8B-drill",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3829473293004872,
    "Overall Score": 26.72490725705725,
    "MMLU Score": 30.841829196217496,
    "BBH Score": 28.79168307535513,
    "Math Score": 17.14501510574018,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.324602384224608
  },
  {
    "Model Name": "agentlans/Llama3.1-Daredevilish",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.40154680146613,
    "Overall Score": 25.570843048894687,
    "MMLU Score": 29.9645390070922,
    "BBH Score": 29.2027295330145,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.244730052642936
  },
  {
    "Model Name": "agentlans/Llama3.1-Daredevilish-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.914256354585132,
    "Overall Score": 29.365203712781987,
    "MMLU Score": 31.96845449172577,
    "BBH Score": 32.21751239385498,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.076396905365026
  },
  {
    "Model Name": "agentlans/Llama3.1-LexiHermes-SuperStorm",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2385420258216011,
    "Overall Score": 29.43098725189088,
    "MMLU Score": 31.599069148936167,
    "BBH Score": 32.54749327279135,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.762606870257386
  },
  {
    "Model Name": "agentlans/Llama3.1-SuperDeepFuse",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3456045308937912,
    "Overall Score": 27.387201422763493,
    "MMLU Score": 30.83259456264776,
    "BBH Score": 29.218386755692325,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.353083535302968
  },
  {
    "Model Name": "agentlans/Llama3.1-SuperDeepFuse-CrashCourse12K",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4103921643817925,
    "Overall Score": 27.995793391642223,
    "MMLU Score": 29.235002955082745,
    "BBH Score": 31.82844411240522,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.849651819296252
  },
  {
    "Model Name": "agentlans/Qwen2.5-0.5B-Instruct-CrashCourse-dropout",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9185456354197432,
    "Overall Score": 8.433362269175692,
    "MMLU Score": 6.757904846335696,
    "BBH Score": 7.227868281254662,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.181212063918785
  },
  {
    "Model Name": "ahmeda335/13_outOf_32_pruned_layers_llama3.1-8b",
    "Parameters (B)": 5.195,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.992047384114175,
    "Overall Score": 4.404258622194578,
    "MMLU Score": 1.4295212765957446,
    "BBH Score": 1.6778452402411428,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.439564775554804
  },
  {
    "Model Name": "ai21labs/Jamba-v0.1",
    "Parameters (B)": 51.57,
    "Architecture": "JambaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 15.315294656239235,
    "Overall Score": 9.218365089520882,
    "MMLU Score": 16.574320330969268,
    "BBH Score": 10.722058918870276,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.6019058265892031
  },
  {
    "Model Name": "ai4bharat/Airavata",
    "Parameters (B)": 6.87,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0705537282993127,
    "Overall Score": 5.550973263891643,
    "MMLU Score": 7.053413120567376,
    "BBH Score": 11.57402914482553,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.185142153220043
  },
  {
    "Model Name": "aixonlab/Aether-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7328641016066255,
    "Overall Score": 18.045942870286208,
    "MMLU Score": 26.77859042553192,
    "BBH Score": 30.55113831130312,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.834342311716955
  },
  {
    "Model Name": "aixonlab/Grey-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9373873351076165,
    "Overall Score": 23.68155281704829,
    "MMLU Score": 30.87876773049646,
    "BBH Score": 38.74604345491756,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.06211442869882
  },
  {
    "Model Name": "aixonlab/Zara-14b-v1.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.940743717717448,
    "Overall Score": 37.99891251390576,
    "MMLU Score": 47.37182328605201,
    "BBH Score": 48.270462607206646,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.579562292025415
  },
  {
    "Model Name": "akhadangi/Llama3.2.1B.0.01-First",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3709194188135816,
    "Overall Score": 3.1098917488910103,
    "MMLU Score": 2.186761229314421,
    "BBH Score": 4.7662306392124005,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.384278609187604
  },
  {
    "Model Name": "akhadangi/Llama3.2.1B.0.01-Last",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3674257784086992,
    "Overall Score": 3.2621298672901786,
    "MMLU Score": 2.519208037825059,
    "BBH Score": 4.282945307374523,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.87833695669989
  },
  {
    "Model Name": "akhadangi/Llama3.2.1B.0.1-First",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3674638297033121,
    "Overall Score": 3.269240763959394,
    "MMLU Score": 1.8820183215130024,
    "BBH Score": 4.177000172360429,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.896768878174916
  },
  {
    "Model Name": "akhadangi/Llama3.2.1B.0.1-Last",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3729283586009589,
    "Overall Score": 3.2667219224258432,
    "MMLU Score": 1.9743646572104017,
    "BBH Score": 4.256105664488017,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.75965006973713
  },
  {
    "Model Name": "akhadangi/Llama3.2.1B.BaseFiT",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3724347268775617,
    "Overall Score": 3.318002610011419,
    "MMLU Score": 1.9097222222222217,
    "BBH Score": 4.548336087243887,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.908950671246659
  },
  {
    "Model Name": "akjindal53244/Llama-3.1-Storm-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7943914887773879,
    "Overall Score": 29.365249771767235,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 31.61569511385009,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 36.96571550251875
  },
  {
    "Model Name": "akjindal53244/Llama-3.1-Storm-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.941914822460576,
    "Overall Score": 29.94392423913393,
    "MMLU Score": 31.146572104018905,
    "BBH Score": 31.494363445102696,
    "Math Score": 17.220543806646525,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.419792821392836
  },
  {
    "Model Name": "alcholjung/llama3_medical_tuned",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8214421946937207,
    "Overall Score": 12.048770294336398,
    "MMLU Score": 21.625664893617017,
    "BBH Score": 23.26508902496949,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-08-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.614961665781781
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 73.18610096017416,
    "Overall Score": 42.33178738532094,
    "MMLU Score": 40.50125591016548,
    "BBH Score": 45.36556861740628,
    "Math Score": 45.01510574018127,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.578412934012658
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 38.02202622335404,
    "Overall Score": 41.45452740659843,
    "MMLU Score": 40.6213061465721,
    "BBH Score": 45.25948099520497,
    "Math Score": 38.29305135951662,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.0902766507781763
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-70B-DPO",
    "Parameters (B)": 70.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 73.6014980662589,
    "Overall Score": 42.22441492015548,
    "MMLU Score": 40.36273640661938,
    "BBH Score": 45.04718091950844,
    "Math Score": 44.93957703927492,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.573689612705212
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-70B-SFT",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 54.6766543790736,
    "Overall Score": 38.84849206812736,
    "MMLU Score": 40.270390070921984,
    "BBH Score": 42.02398394906459,
    "Math Score": 33.157099697885194,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.7105133353403542
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7037741489943292,
    "Overall Score": 26.034998081672143,
    "MMLU Score": 20.295877659574465,
    "BBH Score": 16.671812993247975,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 36.99339925866178
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.402464233166514,
    "Overall Score": 26.260868015453667,
    "MMLU Score": 20.231235224586285,
    "BBH Score": 16.858052069402785,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.72480409440554
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-8B-DPO",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3406751467289846,
    "Overall Score": 26.463980035063702,
    "MMLU Score": 21.0900561465721,
    "BBH Score": 17.42601622698448,
    "Math Score": 23.6404833836858,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.73929336993472
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-8B-RM",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForSequenceClassification",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4737981352541207,
    "Overall Score": 4.235057018188027,
    "MMLU Score": 0.912381796690307,
    "BBH Score": 2.6496699813735507,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.873566546790205
  },
  {
    "Model Name": "allenai/Llama-3.1-Tulu-3-8B-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3664925590347663,
    "Overall Score": 22.596940551752763,
    "MMLU Score": 20.12965425531915,
    "BBH Score": 13.931208168262556,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.536453420364253
  },
  {
    "Model Name": "allenai/OLMo-1.7-7B-hf",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 0.6542927552804128,
    "Overall Score": 3.8002319134201135,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 2.7703163925041445,
    "Math Score": 0.2265861027190332,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 5.808152211300939
  },
  {
    "Model Name": "allenai/OLMo-1B-hf",
    "Parameters (B)": 1.177,
    "Architecture": "OlmoForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4977474999034887,
    "Overall Score": 6.633923959022838,
    "MMLU Score": 1.9281914893617007,
    "BBH Score": 3.1965463124303173,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.32789006536272
  },
  {
    "Model Name": "allenai/OLMo-2-1124-7B-Instruct",
    "Parameters (B)": 7.299,
    "Architecture": "Olmo2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.635889893155562,
    "Overall Score": 21.78585700041552,
    "MMLU Score": 18.578235815602834,
    "BBH Score": 16.326772949551835,
    "Math Score": 14.879154078549847,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.317434805096525
  },
  {
    "Model Name": "allenai/OLMo-7B-Instruct-hf",
    "Parameters (B)": 7.0,
    "Architecture": "OlmoForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7905993674604468,
    "Overall Score": 10.84897342143646,
    "MMLU Score": 8.724881796690305,
    "BBH Score": 13.159933415267032,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.058850247905109
  },
  {
    "Model Name": "allenai/OLMo-7B-hf",
    "Parameters (B)": 6.888,
    "Architecture": "OlmoForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1811283168501223,
    "Overall Score": 6.864268027495356,
    "MMLU Score": 1.9189568557919607,
    "BBH Score": 5.761987041080832,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.811619220002485
  },
  {
    "Model Name": "allenai/OLMoE-1B-7B-0125-Instruct",
    "Parameters (B)": 6.919,
    "Architecture": "OlmoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.6083486455591163,
    "Overall Score": 17.50987629325843,
    "MMLU Score": 10.16548463356974,
    "BBH Score": 14.007956498913387,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.713012205277901
  },
  {
    "Model Name": "allenai/OLMoE-1B-7B-0924",
    "Parameters (B)": 6.919,
    "Architecture": "OlmoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 6.152814233849351,
    "Overall Score": 7.266580603765461,
    "MMLU Score": 8.216976950354608,
    "BBH Score": 8.308106894895777,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.181017389374246
  },
  {
    "Model Name": "allenai/OLMoE-1B-7B-0924-Instruct",
    "Parameters (B)": 6.919,
    "Architecture": "OlmoeForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 8.245768180804477,
    "Overall Score": 13.698377341715071,
    "MMLU Score": 9.73145685579196,
    "BBH Score": 14.571562821337196,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.6612615151616625
  },
  {
    "Model Name": "allknowingroger/Chocolatine-24B",
    "Parameters (B)": 24.184,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 12.369920157785502,
    "Overall Score": 21.34573359059476,
    "MMLU Score": 39.623965721040186,
    "BBH Score": 45.78594021531884,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.72561611702562
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp1-2.6B",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.388526979326512,
    "Overall Score": 20.670220538987987,
    "MMLU Score": 18.76292848699764,
    "BBH Score": 19.770254818005952,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.653961507613502
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp1-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.179935475644573,
    "Overall Score": 36.50763943363299,
    "MMLU Score": 38.40499408983452,
    "BBH Score": 48.37766577055401,
    "Math Score": 25.83081570996979,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.463071810570268
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp2-2.6B",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.4000228880452505,
    "Overall Score": 21.29404813373446,
    "MMLU Score": 18.846040189125294,
    "BBH Score": 19.719838751468483,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.872435442096075
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp2-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.823042133825854,
    "Overall Score": 37.93170029272168,
    "MMLU Score": 40.2519208037825,
    "BBH Score": 51.09023389049588,
    "Math Score": 27.870090634441087,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.299163453759197
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp3-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.693278122014503,
    "Overall Score": 37.53145642523688,
    "MMLU Score": 40.45508274231678,
    "BBH Score": 49.95152147746908,
    "Math Score": 27.416918429003022,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.317296179699319
  },
  {
    "Model Name": "allknowingroger/Gemma2Slerp4-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.813366715220036,
    "Overall Score": 37.36755448762331,
    "MMLU Score": 40.54742907801418,
    "BBH Score": 50.77376164739926,
    "Math Score": 27.19033232628399,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.2398728766263964
  },
  {
    "Model Name": "allknowingroger/GemmaSlerp-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.215339927007747,
    "Overall Score": 33.18611821246378,
    "MMLU Score": 35.117464539007095,
    "BBH Score": 41.55603152984087,
    "Math Score": 21.6012084592145,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.321184996246222
  },
  {
    "Model Name": "allknowingroger/GemmaSlerp2-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.570006589254344,
    "Overall Score": 34.25757823554644,
    "MMLU Score": 35.985520094562645,
    "BBH Score": 42.541032642532,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.595942578554654
  },
  {
    "Model Name": "allknowingroger/GemmaSlerp4-10B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.837357026917442,
    "Overall Score": 34.06301244708342,
    "MMLU Score": 36.114804964539005,
    "BBH Score": 43.328658430206815,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.876685752236696
  },
  {
    "Model Name": "allknowingroger/GemmaSlerp5-10B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.645721806493785,
    "Overall Score": 34.382403041414115,
    "MMLU Score": 36.98286052009456,
    "BBH Score": 43.53846364760333,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.4008742825182585
  },
  {
    "Model Name": "allknowingroger/GemmaStock1-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.305481153593714,
    "Overall Score": 37.51365913910503,
    "MMLU Score": 41.44318853427896,
    "BBH Score": 50.9901358512802,
    "Math Score": 26.3595166163142,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.51673520719184
  },
  {
    "Model Name": "allknowingroger/HomerSlerp1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3665644049358667,
    "Overall Score": 28.48374237557012,
    "MMLU Score": 38.93136820330969,
    "BBH Score": 36.25986284709981,
    "Math Score": 27.19033232628399,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.843322329112524
  },
  {
    "Model Name": "allknowingroger/HomerSlerp2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2499731109344432,
    "Overall Score": 28.948900169100085,
    "MMLU Score": 39.05141843971632,
    "BBH Score": 37.96030019842789,
    "Math Score": 29.68277945619335,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.159618327676455
  },
  {
    "Model Name": "allknowingroger/HomerSlerp3-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2344683203092297,
    "Overall Score": 28.95365293492869,
    "MMLU Score": 39.27304964539008,
    "BBH Score": 37.29001802552013,
    "Math Score": 30.211480362537763,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.45435071810989
  },
  {
    "Model Name": "allknowingroger/HomerSlerp4-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3581398652442602,
    "Overall Score": 29.144845188798246,
    "MMLU Score": 38.58045212765956,
    "BBH Score": 36.7868341584624,
    "Math Score": 32.703927492447136,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.459384217071467
  },
  {
    "Model Name": "allknowingroger/LimyQstar-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2606481806550056,
    "Overall Score": 18.67252497281834,
    "MMLU Score": 23.371010638297868,
    "BBH Score": 30.194567331120084,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.811844620373385
  },
  {
    "Model Name": "allknowingroger/Llama3.1-60B",
    "Parameters (B)": 61.997,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 26.983717435413205,
    "Overall Score": 9.951594488947729,
    "MMLU Score": 25.67043439716312,
    "BBH Score": 7.784282802508024,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.36879998142462533
  },
  {
    "Model Name": "allknowingroger/Marco-01-slerp1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2746476604123598,
    "Overall Score": 29.48531675671586,
    "MMLU Score": 38.70050236406619,
    "BBH Score": 36.23184676022296,
    "Math Score": 31.57099697885196,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.13213107626707
  },
  {
    "Model Name": "allknowingroger/Meme-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9649009171513736,
    "Overall Score": 19.276080557709445,
    "MMLU Score": 20.111184988179662,
    "BBH Score": 24.52948594942413,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.97726420927986
  },
  {
    "Model Name": "allknowingroger/Ministral-8B-slerp",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.250196562256689,
    "Overall Score": 14.900965366835123,
    "MMLU Score": 23.54646867612293,
    "BBH Score": 25.19556465134829,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.622072763230588
  },
  {
    "Model Name": "allknowingroger/MistralPhi3-11B",
    "Parameters (B)": 11.234,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4140754682898875,
    "Overall Score": 21.627095011873774,
    "MMLU Score": 40.97222222222222,
    "BBH Score": 46.16462900339792,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.294158973020377
  },
  {
    "Model Name": "allknowingroger/Mistralmash1-7B-s",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3223769966212695,
    "Overall Score": 20.91386580967448,
    "MMLU Score": 25.47650709219858,
    "BBH Score": 33.44855374433827,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.81535814908329
  },
  {
    "Model Name": "allknowingroger/Mistralmash2-7B-s",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3310737440025664,
    "Overall Score": 21.389680975325334,
    "MMLU Score": 26.0582890070922,
    "BBH Score": 33.29836428588566,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.069493573666414
  },
  {
    "Model Name": "allknowingroger/MixTAO-19B-pass",
    "Parameters (B)": 19.188,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.510264608639344,
    "Overall Score": 20.627592394280352,
    "MMLU Score": 23.389479905437348,
    "BBH Score": 31.577918110916897,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.217298018419369
  },
  {
    "Model Name": "allknowingroger/MixTaoTruthful-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6162171190429424,
    "Overall Score": 20.25297596808001,
    "MMLU Score": 23.33407210401891,
    "BBH Score": 32.70636246605644,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.531098532153274
  },
  {
    "Model Name": "allknowingroger/MultiCalm-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2331468527800262,
    "Overall Score": 19.472289426361296,
    "MMLU Score": 22.586066784869978,
    "BBH Score": 31.46648332199455,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.790730343642894
  },
  {
    "Model Name": "allknowingroger/MultiMash-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6839596369648564,
    "Overall Score": 20.179903850442244,
    "MMLU Score": 22.973921394799056,
    "BBH Score": 31.92567710646836,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.983603055245553
  },
  {
    "Model Name": "allknowingroger/MultiMash10-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7587183017329835,
    "Overall Score": 20.4264364824254,
    "MMLU Score": 23.51876477541371,
    "BBH Score": 32.45250184104656,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.614387854096849
  },
  {
    "Model Name": "allknowingroger/MultiMash11-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9714771309533337,
    "Overall Score": 20.614675908435512,
    "MMLU Score": 23.167848699763592,
    "BBH Score": 32.59670310684399,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.456462103857636
  },
  {
    "Model Name": "allknowingroger/MultiMash2-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6402793394565462,
    "Overall Score": 19.84014306475432,
    "MMLU Score": 22.696882387706854,
    "BBH Score": 31.617950213580304,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.095587981573743
  },
  {
    "Model Name": "allknowingroger/MultiMash5-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.608333288442236,
    "Overall Score": 19.590305453838365,
    "MMLU Score": 22.53065898345153,
    "BBH Score": 31.85636425596493,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.180501140290835
  },
  {
    "Model Name": "allknowingroger/MultiMash6-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6491453052321292,
    "Overall Score": 20.27642710504546,
    "MMLU Score": 23.23249113475177,
    "BBH Score": 32.403879619181005,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.295112529330098
  },
  {
    "Model Name": "allknowingroger/MultiMash7-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.643542693275669,
    "Overall Score": 19.79229351182464,
    "MMLU Score": 22.549128250591018,
    "BBH Score": 31.298150090327656,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.042457791210483
  },
  {
    "Model Name": "allknowingroger/MultiMash8-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.598432099419344,
    "Overall Score": 21.07486448648852,
    "MMLU Score": 23.620345744680847,
    "BBH Score": 32.27299661531551,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.110608120642441
  },
  {
    "Model Name": "allknowingroger/MultiMash9-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7314619662186004,
    "Overall Score": 20.642969652890788,
    "MMLU Score": 23.33407210401891,
    "BBH Score": 32.55261171624742,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.922277275297985
  },
  {
    "Model Name": "allknowingroger/MultiMerge-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2263444868106883,
    "Overall Score": 19.542246727772383,
    "MMLU Score": 22.63223995271868,
    "BBH Score": 31.803983321994554,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.935364767362577
  },
  {
    "Model Name": "allknowingroger/Multimash3-12B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.689315902139885,
    "Overall Score": 20.47073324126141,
    "MMLU Score": 22.973921394799056,
    "BBH Score": 32.1508911391619,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.117765075987734
  },
  {
    "Model Name": "allknowingroger/Multimerge-19B-pass",
    "Parameters (B)": 19.188,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.930757831495271,
    "Overall Score": 4.536203105914491,
    "MMLU Score": 1.8727836879432624,
    "BBH Score": 2.0803742908537424,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.1540276202130995
  },
  {
    "Model Name": "allknowingroger/MultiverseEx26-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2109854289342996,
    "Overall Score": 19.69589878762239,
    "MMLU Score": 22.6137706855792,
    "BBH Score": 31.66377531246577,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.264356545524517
  },
  {
    "Model Name": "allknowingroger/NeuralWestSeverus-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.168092565997147,
    "Overall Score": 20.675370567029702,
    "MMLU Score": 23.749630614657207,
    "BBH Score": 33.41446681662389,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.700113132198634
  },
  {
    "Model Name": "allknowingroger/Neuralcoven-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2638224311243544,
    "Overall Score": 20.36367045149513,
    "MMLU Score": 25.48574172576832,
    "BBH Score": 33.79913505465432,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.11276232324716
  },
  {
    "Model Name": "allknowingroger/Neuralmultiverse-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.234319028287148,
    "Overall Score": 19.36103031824635,
    "MMLU Score": 22.68764775413712,
    "BBH Score": 32.10018047347172,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.685596571506684
  },
  {
    "Model Name": "allknowingroger/Ph3della5-14B",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0918496924067207,
    "Overall Score": 30.46973875649518,
    "MMLU Score": 42.08037825059102,
    "BBH Score": 48.41436428305058,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.565931226845965
  },
  {
    "Model Name": "allknowingroger/Ph3merge-14B",
    "Parameters (B)": 13.619,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.024664867271926,
    "Overall Score": 23.68333279737927,
    "MMLU Score": 40.12263593380615,
    "BBH Score": 48.88242371785896,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.884547801723613
  },
  {
    "Model Name": "allknowingroger/Ph3merge2-14B",
    "Parameters (B)": 13.619,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.122009189633371,
    "Overall Score": 7.962730746600417,
    "MMLU Score": 8.03228427895981,
    "BBH Score": 10.549967885447565,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.931759581377512
  },
  {
    "Model Name": "allknowingroger/Ph3merge3-14B",
    "Parameters (B)": 13.619,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9785131756969263,
    "Overall Score": 7.931823747573229,
    "MMLU Score": 7.191932624113473,
    "BBH Score": 10.391379646236162,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.993665321011232
  },
  {
    "Model Name": "allknowingroger/Ph3task1-14B",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.017696993674693,
    "Overall Score": 30.54839802644553,
    "MMLU Score": 41.48936170212765,
    "BBH Score": 47.92690847304542,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.140230729496121
  },
  {
    "Model Name": "allknowingroger/Ph3task2-14B",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8701316050849537,
    "Overall Score": 28.611110586227724,
    "MMLU Score": 38.44193262411347,
    "BBH Score": 44.08179620906436,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.298982439756168
  },
  {
    "Model Name": "allknowingroger/Ph3task3-14B",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0752301196035647,
    "Overall Score": 30.710221507611795,
    "MMLU Score": 41.89568557919622,
    "BBH Score": 47.99849937558212,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.798465585820637
  },
  {
    "Model Name": "allknowingroger/Ph3unsloth-3B-slerp",
    "Parameters (B)": 3.821,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.058083765671333,
    "Overall Score": 20.153514887760053,
    "MMLU Score": 30.010712174940902,
    "BBH Score": 36.45877270267158,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.047182786112447
  },
  {
    "Model Name": "allknowingroger/Phi3mash1-17B-pass",
    "Parameters (B)": 16.687,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.916252902936439,
    "Overall Score": 21.34996880563698,
    "MMLU Score": 39.882535460992905,
    "BBH Score": 45.25041934691859,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.321027879351351
  },
  {
    "Model Name": "allknowingroger/Quen2-65B",
    "Parameters (B)": 63.923,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 26.63484711957512,
    "Overall Score": 3.5313443657802126,
    "MMLU Score": 1.263297872340425,
    "BBH Score": 1.23986036838978,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.13258361686577402
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-42B-AGI",
    "Parameters (B)": 42.516,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 17.7139622556385,
    "Overall Score": 4.47082956616707,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 2.2358856564144527,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.25239014860969167
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-7B-task2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3837787587187609,
    "Overall Score": 29.87793414236696,
    "MMLU Score": 39.079122340425535,
    "BBH Score": 37.52854979009311,
    "Math Score": 35.49848942598187,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.591554252524375
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-7B-task3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2464163421179026,
    "Overall Score": 28.738760798626867,
    "MMLU Score": 38.90366430260047,
    "BBH Score": 34.385984193445104,
    "Math Score": 26.057401812688823,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.057111678906704
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-7B-task4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.324198591253045,
    "Overall Score": 30.06180942847573,
    "MMLU Score": 39.56855791962175,
    "BBH Score": 37.02526862429277,
    "Math Score": 31.1178247734139,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.7018889968983
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-7B-task7",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3565170555703252,
    "Overall Score": 24.01693955924644,
    "MMLU Score": 34.81272163120568,
    "BBH Score": 37.51817009438029,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.704856316125646
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-7B-task8",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3955516221737765,
    "Overall Score": 30.109425461585875,
    "MMLU Score": 38.14642434988179,
    "BBH Score": 36.09273684636751,
    "Math Score": 35.27190332326284,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.57528606121071
  },
  {
    "Model Name": "allknowingroger/Qwen2.5-slerp-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.733763744815111,
    "Overall Score": 38.16277613953164,
    "MMLU Score": 48.65543735224587,
    "BBH Score": 49.78953727809471,
    "Math Score": 46.22356495468278,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.061825261417262
  },
  {
    "Model Name": "allknowingroger/QwenSlerp12-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3660681974403914,
    "Overall Score": 29.989027415795302,
    "MMLU Score": 38.45116725768321,
    "BBH Score": 36.41130337400265,
    "Math Score": 29.45619335347432,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.952804019584004
  },
  {
    "Model Name": "allknowingroger/QwenSlerp4-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.758323525776358,
    "Overall Score": 38.79874440145977,
    "MMLU Score": 49.28339243498819,
    "BBH Score": 49.38124012444703,
    "Math Score": 36.933534743202415,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.32341791103391
  },
  {
    "Model Name": "allknowingroger/QwenSlerp5-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.723624981332687,
    "Overall Score": 39.3582576505929,
    "MMLU Score": 48.78472222222222,
    "BBH Score": 47.38764037444587,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.569876893592694
  },
  {
    "Model Name": "allknowingroger/QwenSlerp6-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.48165447545322,
    "Overall Score": 39.53457080924675,
    "MMLU Score": 48.95094562647754,
    "BBH Score": 47.588316576052456,
    "Math Score": 37.235649546827794,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.355110361461238
  },
  {
    "Model Name": "allknowingroger/QwenStock1-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.08054899462919,
    "Overall Score": 38.14564924678278,
    "MMLU Score": 49.08946513002365,
    "BBH Score": 50.07629311887721,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.348165969086514
  },
  {
    "Model Name": "allknowingroger/QwenStock2-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.042087995274873,
    "Overall Score": 38.41917529577626,
    "MMLU Score": 48.95094562647754,
    "BBH Score": 50.5982763137811,
    "Math Score": 38.82175226586103,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.504784492739292
  },
  {
    "Model Name": "allknowingroger/QwenStock3-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.2992838879816615,
    "Overall Score": 38.32000426856688,
    "MMLU Score": 49.20028073286053,
    "BBH Score": 50.57667411796288,
    "Math Score": 37.764350453172206,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.913113268860355
  },
  {
    "Model Name": "allknowingroger/Qwenslerp2-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.528886847953466,
    "Overall Score": 38.08598326949303,
    "MMLU Score": 48.92324172576833,
    "BBH Score": 50.30369191199753,
    "Math Score": 44.5619335347432,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.40956829970338
  },
  {
    "Model Name": "allknowingroger/Qwenslerp2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.292309915901357,
    "Overall Score": 30.81046927051673,
    "MMLU Score": 39.06065307328605,
    "BBH Score": 37.43724534081928,
    "Math Score": 34.21450151057402,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.841393532159913
  },
  {
    "Model Name": "allknowingroger/Qwenslerp3-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.439262164468745,
    "Overall Score": 38.08092336696463,
    "MMLU Score": 48.83089539007093,
    "BBH Score": 49.80982854016478,
    "Math Score": 44.63746223564954,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.578210061969127
  },
  {
    "Model Name": "allknowingroger/Qwenslerp3-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2188906930043304,
    "Overall Score": 30.63274991183272,
    "MMLU Score": 39.35616134751773,
    "BBH Score": 37.15398413723134,
    "Math Score": 32.17522658610272,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.131662820665976
  },
  {
    "Model Name": "allknowingroger/ROGERphi-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.232698875974477,
    "Overall Score": 20.70747082131683,
    "MMLU Score": 22.807697990543733,
    "BBH Score": 32.81903240379116,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.798482764046568
  },
  {
    "Model Name": "allknowingroger/RogerMerge-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2357162254144245,
    "Overall Score": 19.61773581081775,
    "MMLU Score": 22.55836288416076,
    "BBH Score": 31.98716596760703,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.875599435654017
  },
  {
    "Model Name": "allknowingroger/Rombos-LLM-V2.5-Qwen-42b",
    "Parameters (B)": 42.516,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 16.89576539452686,
    "Overall Score": 4.559640996200532,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 2.607639713842668,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.26986886298016194
  },
  {
    "Model Name": "allknowingroger/Strangecoven-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2649379377675427,
    "Overall Score": 20.311977055139792,
    "MMLU Score": 26.27068557919622,
    "BBH Score": 34.832235357083775,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.05768666483977
  },
  {
    "Model Name": "allknowingroger/Weirdslerp2-25B",
    "Parameters (B)": 25.204,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4154245881450267,
    "Overall Score": 4.039649477594208,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 1.5659917737677609,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.182766409662761
  },
  {
    "Model Name": "allknowingroger/WestlakeMaziyar-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2633411170478208,
    "Overall Score": 22.18341722963105,
    "MMLU Score": 23.084736997635936,
    "BBH Score": 33.34281144377223,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.559324975877715
  },
  {
    "Model Name": "allknowingroger/YamMaths-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.225247122036009,
    "Overall Score": 20.55230690685158,
    "MMLU Score": 23.675753546099287,
    "BBH Score": 32.1333222251701,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.774009534255867
  },
  {
    "Model Name": "allknowingroger/Yi-1.5-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.504515486676762,
    "Overall Score": 4.25273291237777,
    "MMLU Score": 1.0601359338061456,
    "BBH Score": 1.3390433749257278,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.4048480786926019
  },
  {
    "Model Name": "allknowingroger/Yi-blossom-40B",
    "Parameters (B)": 18.769,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9769146319373168,
    "Overall Score": 5.827458303350088,
    "MMLU Score": 0.8939125295508273,
    "BBH Score": 5.539183494900659,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.9477541463888883
  },
  {
    "Model Name": "allknowingroger/Yibuddy-35B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.760124957451268,
    "Overall Score": 28.283170568255755,
    "MMLU Score": 38.765144799054376,
    "BBH Score": 42.80824233844326,
    "Math Score": 15.709969788519636,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.6285169252304987
  },
  {
    "Model Name": "allknowingroger/Yillama-40B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.048132234928361,
    "Overall Score": 8.31148742313468,
    "MMLU Score": 10.904255319148934,
    "BBH Score": 15.875797412234048,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1792468055502028
  },
  {
    "Model Name": "allknowingroger/Yislerp-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.977555745763449,
    "Overall Score": 29.39892579588029,
    "MMLU Score": 41.68328900709219,
    "BBH Score": 45.9816957285586,
    "Math Score": 21.6012084592145,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.918218590720224
  },
  {
    "Model Name": "allknowingroger/Yislerp2-34B",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.10231048295783,
    "Overall Score": 30.43386510728805,
    "MMLU Score": 41.37854609929077,
    "BBH Score": 47.20230580445542,
    "Math Score": 22.9607250755287,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.343531860868632
  },
  {
    "Model Name": "allknowingroger/Yunconglong-13B-slerp",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5992629681499602,
    "Overall Score": 19.60010418064844,
    "MMLU Score": 22.623005319148938,
    "BBH Score": 32.14072892807635,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.255710643586022
  },
  {
    "Model Name": "allknowingroger/limyClown-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.220100793295194,
    "Overall Score": 19.70388869479609,
    "MMLU Score": 22.64147458628841,
    "BBH Score": 31.9314661071385,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.149394216506245
  },
  {
    "Model Name": "allknowingroger/llama3-Jallabi-40B-s",
    "Parameters (B)": 18.769,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9591494795974127,
    "Overall Score": 5.029701636906855,
    "MMLU Score": 0.9770242316784856,
    "BBH Score": 5.957911562958214,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.5672883510350686
  },
  {
    "Model Name": "allknowingroger/llama3AnFeng-40B",
    "Parameters (B)": 39.971,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.126936202511224,
    "Overall Score": 9.237994378100716,
    "MMLU Score": 10.885786052009454,
    "BBH Score": 12.476996185725282,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1367130426403709
  },
  {
    "Model Name": "allura-org/L3.1-8b-RP-Ink",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.668821031483859,
    "Overall Score": 25.096017377265284,
    "MMLU Score": 26.972517730496453,
    "BBH Score": 26.318228573463205,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 37.52276946433157
  },
  {
    "Model Name": "allura-org/MN-12b-RP-Ink",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8294158149047763,
    "Overall Score": 24.976661361688898,
    "MMLU Score": 27.932919621749413,
    "BBH Score": 26.61059786167285,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 30.113558136766926
  },
  {
    "Model Name": "allura-org/MS-Meadowlark-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.3438523756957625,
    "Overall Score": 27.09796440696345,
    "MMLU Score": 31.36820330969267,
    "BBH Score": 30.29658044666958,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.238233269293163
  },
  {
    "Model Name": "allura-org/Mistral-Small-24b-Sertraline-0304",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4705426325981037,
    "Overall Score": 35.369805475643055,
    "MMLU Score": 45.61724290780142,
    "BBH Score": 49.28145843642874,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 24.05221357857059
  },
  {
    "Model Name": "allura-org/Mistral-Small-Sisyphus-24b-2503",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.743696289599396,
    "Overall Score": 32.50290014221418,
    "MMLU Score": 45.85734338061466,
    "BBH Score": 46.42097750457095,
    "Math Score": 25.0,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 11.846391404698766
  },
  {
    "Model Name": "allura-org/MoE-Girl-1BA-7BT",
    "Parameters (B)": 6.919,
    "Architecture": "OlmoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.402309294204105,
    "Overall Score": 6.402799107780404,
    "MMLU Score": 2.41762706855792,
    "BBH Score": 4.8423440285205,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.000076505765934
  },
  {
    "Model Name": "allura-org/TQ2.5-14B-Aletheia-v1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.825806465586459,
    "Overall Score": 39.48247192029189,
    "MMLU Score": 47.12248817966904,
    "BBH Score": 50.881441812823226,
    "Math Score": 33.987915407854985,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.97210757393388
  },
  {
    "Model Name": "allura-org/TQ2.5-14B-Neon-v1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4839621477769045,
    "Overall Score": 39.14031038134542,
    "MMLU Score": 47.251773049645394,
    "BBH Score": 50.51009292921976,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.375544982721276
  },
  {
    "Model Name": "allura-org/Teleut-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.10019685565601,
    "Overall Score": 30.22949441247033,
    "MMLU Score": 34.785017730496456,
    "BBH Score": 30.859919035029737,
    "Math Score": 24.093655589123863,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.393648067351265
  },
  {
    "Model Name": "aloobun/Meta-Llama-3-7B-28Layers",
    "Parameters (B)": 7.158,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.618716589671752,
    "Overall Score": 13.375690297994408,
    "MMLU Score": 23.99896572104019,
    "BBH Score": 22.09653025134352,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.263145249352618
  },
  {
    "Model Name": "aloobun/d-SmolLM2-360M",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7402465552245907,
    "Overall Score": 6.184070904256285,
    "MMLU Score": 1.8820183215130024,
    "BBH Score": 4.762820747165694,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.354069141706495
  },
  {
    "Model Name": "alpindale/WizardLM-2-8x22B",
    "Parameters (B)": 140.621,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 186.61044332743728,
    "Overall Score": 33.059051837739325,
    "MMLU Score": 39.95641252955083,
    "BBH Score": 48.57616817936264,
    "Math Score": 25.0,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.1771554220024655
  },
  {
    "Model Name": "alpindale/magnum-72b-v1",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.03024541005665,
    "Overall Score": 42.9290547455837,
    "MMLU Score": 49.64354314420804,
    "BBH Score": 57.65318485514271,
    "Math Score": 39.80362537764351,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.7150872491380234
  },
  {
    "Model Name": "altomek/YiSM-34B-0rn",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.9212482883245645,
    "Overall Score": 30.51201240834246,
    "MMLU Score": 41.06456855791962,
    "BBH Score": 45.38292724900714,
    "Math Score": 22.80966767371601,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.152969597391419
  },
  {
    "Model Name": "amazon/MegaBeam-Mistral-7B-300k",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.299219876736505,
    "Overall Score": 17.022470504123003,
    "MMLU Score": 17.211510047281322,
    "BBH Score": 19.291805959592,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.10207056474655
  },
  {
    "Model Name": "amd/AMD-Llama-135m",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1287191757663833,
    "Overall Score": 4.759627159992882,
    "MMLU Score": 1.8727836879432624,
    "BBH Score": 2.4854950529752244,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 36.976830621035724
  },
  {
    "Model Name": "amd/AMD-Llama-135m",
    "Parameters (B)": 0.134,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7086780315506144,
    "Overall Score": 5.228976558960189,
    "MMLU Score": 1.8727836879432624,
    "BBH Score": 2.537952680477511,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.3784939368290985
  },
  {
    "Model Name": "anakin87/gemma-2b-orpo",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5798531310408666,
    "Overall Score": 7.284706228625474,
    "MMLU Score": 3.3964982269503543,
    "BBH Score": 7.94944502776896,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-07-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.611002178301242
  },
  {
    "Model Name": "anthracite-org/magnum-v1-72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.78211241796205,
    "Overall Score": 42.96291506867274,
    "MMLU Score": 49.84670508274232,
    "BBH Score": 57.65318485514271,
    "Math Score": 39.80362537764351,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.666384599220856
  },
  {
    "Model Name": "anthracite-org/magnum-v2-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.2976707757776453,
    "Overall Score": 18.795821563358565,
    "MMLU Score": 24.08207742316785,
    "BBH Score": 28.78555159536588,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.699726516491386
  },
  {
    "Model Name": "anthracite-org/magnum-v2-72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.268433710248942,
    "Overall Score": 41.78287226692161,
    "MMLU Score": 49.51425827423168,
    "BBH Score": 57.85470432085098,
    "Math Score": 35.422960725075534,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.7216962893355594
  },
  {
    "Model Name": "anthracite-org/magnum-v2.5-12b-kto",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.218126101776261,
    "Overall Score": 18.98278998956064,
    "MMLU Score": 24.608451536643024,
    "BBH Score": 29.625059445981027,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.898709183298626
  },
  {
    "Model Name": "anthracite-org/magnum-v3-27b-kto",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.87506792297306,
    "Overall Score": 29.33708001780754,
    "MMLU Score": 35.976285460992905,
    "BBH Score": 41.1601029248443,
    "Math Score": 18.12688821752266,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.725311362994818
  },
  {
    "Model Name": "anthracite-org/magnum-v3-34b",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 9.225748511595937,
    "Overall Score": 29.66608133452966,
    "MMLU Score": 41.692523640661946,
    "BBH Score": 44.32790341462959,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.2155744650140923
  },
  {
    "Model Name": "anthracite-org/magnum-v3-9b-chatml",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.779930609974818,
    "Overall Score": 19.50411636926871,
    "MMLU Score": 36.022458628841605,
    "BBH Score": 35.31787541238543,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3744551077497604
  },
  {
    "Model Name": "anthracite-org/magnum-v3-9b-customgemma2",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.803650034123516,
    "Overall Score": 19.20026712602973,
    "MMLU Score": 35.606900118203306,
    "BBH Score": 34.11678334094384,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3083089113124666
  },
  {
    "Model Name": "anthracite-org/magnum-v4-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.398031457956096,
    "Overall Score": 20.27642686776778,
    "MMLU Score": 28.93026004728133,
    "BBH Score": 30.50390226648477,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.9671098159768
  },
  {
    "Model Name": "anthracite-org/magnum-v4-22b",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.300580071468586,
    "Overall Score": 27.854369713005507,
    "MMLU Score": 31.44208037825059,
    "BBH Score": 35.549148532773465,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.439234652656607
  },
  {
    "Model Name": "anthracite-org/magnum-v4-27b",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 11.472707787132371,
    "Overall Score": 26.63300380472101,
    "MMLU Score": 37.50923463356973,
    "BBH Score": 40.96038433350091,
    "Math Score": 17.97583081570997,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.321422657917969
  },
  {
    "Model Name": "anthracite-org/magnum-v4-9b",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.112652302122218,
    "Overall Score": 23.798994622099844,
    "MMLU Score": 32.8088061465721,
    "BBH Score": 33.27040443647636,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.65492140199346
  },
  {
    "Model Name": "apple/DCLM-7B",
    "Parameters (B)": 7.0,
    "Architecture": "OpenLMModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.2599111030184245,
    "Overall Score": 14.112858289728544,
    "MMLU Score": 23.45412234042553,
    "BBH Score": 19.760934974772244,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-08-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.201471481533696
  },
  {
    "Model Name": "appvoid/arco-2",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3162940489756324,
    "Overall Score": 5.137100838868086,
    "MMLU Score": 1.291001773049644,
    "BBH Score": 4.059150069582826,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.241534911913103
  },
  {
    "Model Name": "appvoid/arco-2-instruct",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3375334700786766,
    "Overall Score": 5.382510586018164,
    "MMLU Score": 1.2540632387706852,
    "BBH Score": 3.913002236158603,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.94659808037271
  },
  {
    "Model Name": "arcee-ai/Arcee-Blitz",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4446652668107918,
    "Overall Score": 40.01232729285768,
    "MMLU Score": 57.2621158392435,
    "BBH Score": 50.72663255795833,
    "Math Score": 34.818731117824775,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.696607797035174
  },
  {
    "Model Name": "arcee-ai/Arcee-Maestro-7B-Preview",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6903426140888346,
    "Overall Score": 23.793130973366363,
    "MMLU Score": 22.659943853427897,
    "BBH Score": 25.37555578678192,
    "Math Score": 49.92447129909365,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 34.46568484660374
  },
  {
    "Model Name": "arcee-ai/Arcee-Nova",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 22.986587129501515,
    "Overall Score": 44.05339262826514,
    "MMLU Score": 49.46808510638298,
    "BBH Score": 56.74098753952074,
    "Math Score": 43.80664652567976,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.9164825287058815
  },
  {
    "Model Name": "arcee-ai/Arcee-Spark",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.197065655544504,
    "Overall Score": 28.406546265844867,
    "MMLU Score": 31.358968676122927,
    "BBH Score": 37.13852245584468,
    "Math Score": 29.531722054380666,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.929311508810967
  },
  {
    "Model Name": "arcee-ai/Arcee-Spark",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1360401936497302,
    "Overall Score": 25.443168747377587,
    "MMLU Score": 31.257387706855795,
    "BBH Score": 36.92439043586489,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 22.396363165318036
  },
  {
    "Model Name": "arcee-ai/Llama-3.1-SuperNova-Lite",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7119867700237617,
    "Overall Score": 30.193463980461605,
    "MMLU Score": 31.96845449172577,
    "BBH Score": 31.572340212980667,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.636505438673765
  },
  {
    "Model Name": "arcee-ai/Llama-Spark",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6614282034914647,
    "Overall Score": 27.037236901530367,
    "MMLU Score": 30.23234338061465,
    "BBH Score": 29.77025370020864,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.273490990890878
  },
  {
    "Model Name": "arcee-ai/SuperNova-Medius",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.687530654788435,
    "Overall Score": 39.15430388277812,
    "MMLU Score": 44.83229905437352,
    "BBH Score": 48.00501462716327,
    "Math Score": 46.90332326283988,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.093222471690511
  },
  {
    "Model Name": "arcee-ai/Virtuoso-Lite",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.586021987364553,
    "Overall Score": 36.41610644523877,
    "MMLU Score": 38.22953605200946,
    "BBH Score": 43.89855735433509,
    "Math Score": 25.302114803625376,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.081901323024278
  },
  {
    "Model Name": "arcee-ai/Virtuoso-Small",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.0286282432128417,
    "Overall Score": 40.53607757653,
    "MMLU Score": 46.56841016548463,
    "BBH Score": 50.399846311899886,
    "Math Score": 40.93655589123867,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.384302833261685
  },
  {
    "Model Name": "arcee-ai/Virtuoso-Small-v2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.114543153921314,
    "Overall Score": 42.475701925930025,
    "MMLU Score": 46.53147163120567,
    "BBH Score": 50.94799062781783,
    "Math Score": 46.6012084592145,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.637859495525593
  },
  {
    "Model Name": "arcee-ai/raspberry-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0730530354701697,
    "Overall Score": 15.852706041886336,
    "MMLU Score": 20.600620567375884,
    "BBH Score": 19.528234400992485,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.647033515614294
  },
  {
    "Model Name": "argilla/notus-7b-v1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.335816262311418,
    "Overall Score": 18.47426177294325,
    "MMLU Score": 22.26285460992908,
    "BBH Score": 22.74711196116141,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.829942256412176
  },
  {
    "Model Name": "argilla/notux-8x7b-v1",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 30.70977222678072,
    "Overall Score": 24.47858356291764,
    "MMLU Score": 29.558215130023648,
    "BBH Score": 34.75806168290175,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7970942728637654
  },
  {
    "Model Name": "argilla-warehouse/Llama-3.1-8B-MagPie-Ultra",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.931354103983328,
    "Overall Score": 19.84899133862277,
    "MMLU Score": 23.823507683215126,
    "BBH Score": 23.51631036482765,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.27724087348102
  },
  {
    "Model Name": "arisin/orca-platypus-13B-slerp",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.878126628161279,
    "Overall Score": 14.79190764445101,
    "MMLU Score": 17.691710992907797,
    "BBH Score": 24.40376595176109,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.8758840978324045
  },
  {
    "Model Name": "arshiaafshani/Arsh-V1",
    "Parameters (B)": 13.96,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8986704685080669,
    "Overall Score": 37.54445092721804,
    "MMLU Score": 47.29794621749409,
    "BBH Score": 53.51427176415471,
    "Math Score": 26.20845921450152,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.774074306174697
  },
  {
    "Model Name": "asharsha30/LLAMA_Harsha_8_B_ORDP_10k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4822389187294722,
    "Overall Score": 16.221361486666726,
    "MMLU Score": 20.111184988179662,
    "BBH Score": 25.72567833858325,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.943823753171424
  },
  {
    "Model Name": "ashercn97/a1-v0.0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.164092573836315,
    "Overall Score": 21.57499066409029,
    "MMLU Score": 35.163637706855795,
    "BBH Score": 32.75543224003656,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.969532230242823
  },
  {
    "Model Name": "ashercn97/a1-v002",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.077839372853315,
    "Overall Score": 22.8816161973256,
    "MMLU Score": 35.274453309692674,
    "BBH Score": 33.526527072476405,
    "Math Score": 23.413897280966765,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.012216101143698
  },
  {
    "Model Name": "assskelad/smollm2-360M-sft_SmallThoughts",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.416623155019007,
    "Overall Score": 5.0424666628422985,
    "MMLU Score": 2.020537825059101,
    "BBH Score": 4.164356769946658,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.10318390155788
  },
  {
    "Model Name": "athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7730546115919343,
    "Overall Score": 20.968535229566395,
    "MMLU Score": 28.496232269503547,
    "BBH Score": 28.01590901759341,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-08-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.826220744966129
  },
  {
    "Model Name": "automerger/YamshadowExperiment28-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.168848141905,
    "Overall Score": 19.88427002958577,
    "MMLU Score": 22.89080969267139,
    "BBH Score": 31.980235156677427,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.011850655961343
  },
  {
    "Model Name": "avemio/GRAG-NEMO-12B-ORPO-HESSIAN-AI",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.962404566531638,
    "Overall Score": 0.7378506308720487,
    "MMLU Score": 0.6722813238770686,
    "BBH Score": 0.4410640720934837,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.37599312774538074
  },
  {
    "Model Name": "awnr/Mistral-7B-v0.1-signtensors-1-over-2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.2138826548654063,
    "Overall Score": 14.370486963136566,
    "MMLU Score": 22.21668144208038,
    "BBH Score": 22.40015255970937,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.471378860513619
  },
  {
    "Model Name": "awnr/Mistral-7B-v0.1-signtensors-1-over-4",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.9320716524596728,
    "Overall Score": 8.747197547964134,
    "MMLU Score": 14.561170212765957,
    "BBH Score": 9.22769372478478,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.527367055372037
  },
  {
    "Model Name": "awnr/Mistral-7B-v0.1-signtensors-3-over-8",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.9055370006724817,
    "Overall Score": 13.813468900343905,
    "MMLU Score": 22.23515070921986,
    "BBH Score": 20.435230589690025,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.249121321427505
  },
  {
    "Model Name": "awnr/Mistral-7B-v0.1-signtensors-5-over-16",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.299469117048102,
    "Overall Score": 12.28452908669469,
    "MMLU Score": 21.75494976359338,
    "BBH Score": 17.543031293477835,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.453498298290036
  },
  {
    "Model Name": "awnr/Mistral-7B-v0.1-signtensors-7-over-16",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.9556216383299223,
    "Overall Score": 14.246704735704872,
    "MMLU Score": 22.55836288416076,
    "BBH Score": 21.040436509874464,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.285000562722035
  },
  {
    "Model Name": "aws-prototyping/MegaBeam-Mistral-7B-512k",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2943758144129205,
    "Overall Score": 17.582481722488744,
    "MMLU Score": 17.65477245862884,
    "BBH Score": 12.361177501580404,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.583753286106854
  },
  {
    "Model Name": "axolotl-ai-co/romulus-mistral-nemo-12b-simpo",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.080012998109583,
    "Overall Score": 25.176086393973254,
    "MMLU Score": 27.43424940898345,
    "BBH Score": 34.64240096637378,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.1705897519537904
  },
  {
    "Model Name": "baconnier/Napoleon_24B_V0.0",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2766561543186024,
    "Overall Score": 27.30083551864148,
    "MMLU Score": 44.88770685579197,
    "BBH Score": 47.26497234848218,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.384642549436442
  },
  {
    "Model Name": "baconnier/Napoleon_24B_V0.2",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.28884764797119,
    "Overall Score": 24.007932141039515,
    "MMLU Score": 37.29683806146573,
    "BBH Score": 41.20548669811284,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.627439929638737
  },
  {
    "Model Name": "baebee/7B-Cetacea",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4541996112195244,
    "Overall Score": 19.942170906921103,
    "MMLU Score": 21.71801122931442,
    "BBH Score": 25.75266015070167,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.9061822474406
  },
  {
    "Model Name": "baebee/mergekit-model_stock-nzjnheg",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6334827799574804,
    "Overall Score": 22.99798497246768,
    "MMLU Score": 29.99224290780142,
    "BBH Score": 32.742095397153456,
    "Math Score": 16.76737160120846,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.30404124641133
  },
  {
    "Model Name": "baebee/mergekit-ties-fnjenli",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6871999168055457,
    "Overall Score": 5.4674729843638685,
    "MMLU Score": 1.4295212765957446,
    "BBH Score": 2.9252946060117697,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.9561607192554105
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.2301884718146217,
    "Overall Score": 22.61927817846981,
    "MMLU Score": 29.6875,
    "BBH Score": 34.07162735574622,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.142316877849046
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.1v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.262393562761689,
    "Overall Score": 22.61107627651725,
    "MMLU Score": 29.70596926713948,
    "BBH Score": 34.35759228302058,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.994316041509618
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.2v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.265824284170919,
    "Overall Score": 22.454256608568887,
    "MMLU Score": 29.58591903073286,
    "BBH Score": 34.41027746820577,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.90997261589729
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.3v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.2595164768217573,
    "Overall Score": 22.795688006734604,
    "MMLU Score": 29.595153664302604,
    "BBH Score": 34.38744334527327,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.0887460837635
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.4v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1081866673732383,
    "Overall Score": 26.6539064273152,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 30.596484949495864,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.64304856861915
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.5v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.3089564542816,
    "Overall Score": 22.635396518839368,
    "MMLU Score": 29.56744976359338,
    "BBH Score": 34.1770041493929,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.80330160703791
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_0.6v",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1307047035446205,
    "Overall Score": 23.874344518139583,
    "MMLU Score": 29.57668439716312,
    "BBH Score": 34.72779363865639,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.204905343486804
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_III_IV_V",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.188830563510498,
    "Overall Score": 23.23673015528421,
    "MMLU Score": 29.604388297872337,
    "BBH Score": 34.85070126040164,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.616047921962764
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_III_ex_V",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.159004792865925,
    "Overall Score": 23.80784193287211,
    "MMLU Score": 29.42893026004728,
    "BBH Score": 34.868634894350585,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.02722977343135
  },
  {
    "Model Name": "bamec66557/MISCHIEVOUS-12B-Mix_Neo",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0109002685634336,
    "Overall Score": 26.077670184051115,
    "MMLU Score": 29.83525413711584,
    "BBH Score": 30.36068974252419,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.968156895558392
  },
  {
    "Model Name": "bamec66557/Mistral-Nemo-VICIOUS_MESH-12B-2407",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9388037027739964,
    "Overall Score": 27.48211728638603,
    "MMLU Score": 29.74290780141844,
    "BBH Score": 31.356607393533825,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.351464087392126
  },
  {
    "Model Name": "bamec66557/NameLess-12B-prob",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.922932883417949,
    "Overall Score": 27.18904881817572,
    "MMLU Score": 29.82601950354609,
    "BBH Score": 31.35572805903409,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.139364432651488
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3601327747126493,
    "Overall Score": 22.780363902289253,
    "MMLU Score": 29.76137706855792,
    "BBH Score": 34.37251603029727,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.7796023043278035
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-0.1v",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1489175293330742,
    "Overall Score": 22.44945344518881,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 34.13023813457423,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.446865986595629
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-0.X.ver",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.37598261326679,
    "Overall Score": 22.653126146717884,
    "MMLU Score": 29.678265366430256,
    "BBH Score": 34.08924738532064,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.71008377166891
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-ALPHA",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9053541901705389,
    "Overall Score": 26.45551197855697,
    "MMLU Score": 29.9645390070922,
    "BBH Score": 30.51014607050993,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.884826304231167
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-BETA",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.913221440632584,
    "Overall Score": 27.466293297388987,
    "MMLU Score": 29.76137706855792,
    "BBH Score": 31.356607393533825,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.356045104903059
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-DELTA",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.169281582832776,
    "Overall Score": 25.939275726783706,
    "MMLU Score": 29.4566341607565,
    "BBH Score": 29.792447042456303,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.957542041596401
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-DIGAMMA",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.988230357090947,
    "Overall Score": 25.971654466957943,
    "MMLU Score": 29.539745862884164,
    "BBH Score": 29.83322953136833,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.062698884126299
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-EPSILON",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.092368777812442,
    "Overall Score": 25.50473024902234,
    "MMLU Score": 29.419695626477544,
    "BBH Score": 29.596444965473506,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.189404907717735
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-GAMMA",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.80363916459474,
    "Overall Score": 26.91684881897208,
    "MMLU Score": 29.622857565011817,
    "BBH Score": 31.485974649070176,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.923632923562087
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-NEMO",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.954810932917596,
    "Overall Score": 23.316444114380342,
    "MMLU Score": 30.17693557919622,
    "BBH Score": 34.4014166333088,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.891010505825347
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-OMEGA",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9947289317766943,
    "Overall Score": 27.49554497317065,
    "MMLU Score": 29.74290780141844,
    "BBH Score": 31.52371165532988,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.784100954850299
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B-UNION",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0332475815456683,
    "Overall Score": 26.67624004599591,
    "MMLU Score": 29.6875,
    "BBH Score": 30.46389197050985,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.12001562825749
  },
  {
    "Model Name": "bamec66557/VICIOUS_MESH-12B_Razor",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.141617222178077,
    "Overall Score": 22.64068156588953,
    "MMLU Score": 29.650561465721044,
    "BBH Score": 34.56221200969913,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.571768536145504
  },
  {
    "Model Name": "bamec66557/mergekit-model_stock-zdaysvi",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9319840894221847,
    "Overall Score": 26.24451582006411,
    "MMLU Score": 29.8721926713948,
    "BBH Score": 30.16636018648764,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.584229789342253
  },
  {
    "Model Name": "bamec66557/mergekit-ties-sinbkow",
    "Parameters (B)": 6.124,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8004765207173132,
    "Overall Score": 26.284691171067987,
    "MMLU Score": 28.92102541371157,
    "BBH Score": 30.62203788717879,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.598741426850774
  },
  {
    "Model Name": "belztjti/dffghgjh",
    "Parameters (B)": 9.543,
    "Architecture": "GlmForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3218651318125167,
    "Overall Score": 16.671219751518176,
    "MMLU Score": 26.90787529550828,
    "BBH Score": 9.713638961998791,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.180098242185207
  },
  {
    "Model Name": "belztjti/dtfgv",
    "Parameters (B)": 9.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8656283220337087,
    "Overall Score": 9.007600725168578,
    "MMLU Score": 5.603575650118202,
    "BBH Score": 5.520450164271318,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.143324853369669
  },
  {
    "Model Name": "benhaotang/phi4-qwq-sky-t1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.90146160689232,
    "Overall Score": 31.01825262068425,
    "MMLU Score": 47.15942671394799,
    "BBH Score": 52.61239992936087,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.312847184634645
  },
  {
    "Model Name": "beomi/gemma-mling-7b",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 3.287011197266699,
    "Overall Score": 11.392173694644192,
    "MMLU Score": 18.144208037825056,
    "BBH Score": 17.631391012223656,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-07-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 3.4658152987483914
  },
  {
    "Model Name": "beowolx/CodeNinja-1.0-OpenChat-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2721452017893264,
    "Overall Score": 20.460682433184903,
    "MMLU Score": 22.392139479905435,
    "BBH Score": 21.713423267203808,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.083606183009678
  },
  {
    "Model Name": "berkeley-nest/Starling-LM-7B-alpha",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1032577733840974,
    "Overall Score": 20.83936104726783,
    "MMLU Score": 24.128250591016545,
    "BBH Score": 21.95402808715926,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.888931988528704
  },
  {
    "Model Name": "bfuzzy1/Gunny",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6675725586964267,
    "Overall Score": 23.34108004405445,
    "MMLU Score": 22.65070921985816,
    "BBH Score": 22.99177882913372,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.997040142169656
  },
  {
    "Model Name": "bfuzzy1/acheron",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3253645856268118,
    "Overall Score": 4.974672842034184,
    "MMLU Score": 1.0693705673758855,
    "BBH Score": 3.737588062186813,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.289533839248433
  },
  {
    "Model Name": "bfuzzy1/acheron-c",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4982063432651979,
    "Overall Score": 4.2908204733904265,
    "MMLU Score": 1.9097222222222217,
    "BBH Score": 2.769027258890272,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.612536816108742
  },
  {
    "Model Name": "bfuzzy1/acheron-d",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3274728033873796,
    "Overall Score": 4.988234616217907,
    "MMLU Score": 1.4941637115839237,
    "BBH Score": 4.1222474820638,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.232515691744762
  },
  {
    "Model Name": "bfuzzy1/acheron-m",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3736255718512762,
    "Overall Score": 4.225197951458999,
    "MMLU Score": 1.2540632387706852,
    "BBH Score": 2.1820409575204094,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.30864231407818
  },
  {
    "Model Name": "bfuzzy1/acheron-m1a-llama",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0738704727547566,
    "Overall Score": 3.348613471275291,
    "MMLU Score": 1.6234485815602824,
    "BBH Score": 2.545408537429085,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.1182657091643726
  },
  {
    "Model Name": "bfuzzy1/llambses-1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9365833927550146,
    "Overall Score": 19.83707295838704,
    "MMLU Score": 23.777334515366427,
    "BBH Score": 31.077833088739435,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.180252726919633
  },
  {
    "Model Name": "bhuvneshsaini/merged_model",
    "Parameters (B)": 4.715,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7164317669572453,
    "Overall Score": 5.795748828202385,
    "MMLU Score": 4.947916666666666,
    "BBH Score": 7.617386883057352,
    "Math Score": 0.0,
    "Date Submitted": "2024-12-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.089742939257828
  },
  {
    "Model Name": "bigcode/starcoder2-15b",
    "Parameters (B)": 15.958,
    "Architecture": "Starcoder2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 67.68626903353528,
    "Overall Score": 12.539175421645837,
    "MMLU Score": 15.032136524822691,
    "BBH Score": 20.373540752678547,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.18525434479825265
  },
  {
    "Model Name": "bigcode/starcoder2-3b",
    "Parameters (B)": 3.03,
    "Architecture": "Starcoder2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.893257836653058,
    "Overall Score": 6.549147626379535,
    "MMLU Score": 7.071882387706856,
    "BBH Score": 8.909299421083569,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.331755018146265
  },
  {
    "Model Name": "bigcode/starcoder2-7b",
    "Parameters (B)": 7.174,
    "Architecture": "Starcoder2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.0128027570551226,
    "Overall Score": 8.2934383764798,
    "MMLU Score": 7.1365248226950335,
    "BBH Score": 11.395110106503443,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.188601698315107
  },
  {
    "Model Name": "bigscience/bloom-1b1",
    "Parameters (B)": 1.065,
    "Architecture": "BloomForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.4340427150874084,
    "Overall Score": 4.025155876068456,
    "MMLU Score": 1.198655437352245,
    "BBH Score": 4.042705269260129,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.8068591219217014
  },
  {
    "Model Name": "bigscience/bloom-1b7",
    "Parameters (B)": 1.722,
    "Architecture": "BloomForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.6367191975791189,
    "Overall Score": 4.046754480742192,
    "MMLU Score": 0.958554964539006,
    "BBH Score": 4.39745292760164,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.4724793884789587
  },
  {
    "Model Name": "bigscience/bloom-3b",
    "Parameters (B)": 3.003,
    "Architecture": "BloomForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.992112381322494,
    "Overall Score": 4.387894128649155,
    "MMLU Score": 1.4756944444444438,
    "BBH Score": 3.4200982840077354,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.2026338322018684
  },
  {
    "Model Name": "bigscience/bloom-560m",
    "Parameters (B)": 0.559,
    "Architecture": "BloomForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.525432280306906,
    "Overall Score": 3.50724359916236,
    "MMLU Score": 1.8266105200945613,
    "BBH Score": 2.885363608028119,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.2991801369620473
  },
  {
    "Model Name": "bigscience/bloom-7b1",
    "Parameters (B)": 7.069,
    "Architecture": "BloomForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.011550037199904,
    "Overall Score": 3.795510241848182,
    "MMLU Score": 1.1617169030732852,
    "BBH Score": 4.038808518979752,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": 433.0,
    "Reported CO2 (t)": 25.0,
    "Cloud Provider": "Hugging Face",
    "Water Use (Million Liters)": 3960.0,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.8868584781174853
  },
  {
    "Model Name": "bluuwhale/L3-SthenoMaid-8B-V1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.205450782943445,
    "Overall Score": 25.83976001225683,
    "MMLU Score": 29.51204196217494,
    "BBH Score": 32.398152503800446,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.43576525717776
  },
  {
    "Model Name": "bond005/meno-tiny-0.1",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.73337552432176,
    "Overall Score": 18.850916827026232,
    "MMLU Score": 19.843380614657207,
    "BBH Score": 19.64270876311028,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.049295658638805
  },
  {
    "Model Name": "bosonai/Higgs-Llama-3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 27.45369405239353,
    "Overall Score": 33.525397972968115,
    "MMLU Score": 43.35475768321512,
    "BBH Score": 45.89740563396065,
    "Math Score": 25.22658610271904,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.2211616370819587
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-1.5B-Blunt",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6036575615550887,
    "Overall Score": 7.552804605341624,
    "MMLU Score": 2.039007092198581,
    "BBH Score": 1.1023633058943698,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.51173692893826
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-1.5B-Reflective",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6228340036068769,
    "Overall Score": 8.705956789781306,
    "MMLU Score": 1.4479905437352243,
    "BBH Score": 1.7477599117687752,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.977972845677144
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8978922751786207,
    "Overall Score": 13.942561374741304,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 3.271232992020663,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.346339703832292
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-ABUB-ST",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8912967101766145,
    "Overall Score": 29.311295170279617,
    "MMLU Score": 36.03169326241135,
    "BBH Score": 27.634826732270326,
    "Math Score": 50.15105740181269,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.497988767475013
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.936471661494304,
    "Overall Score": 17.9179987350434,
    "MMLU Score": 4.966385933806146,
    "BBH Score": 6.126852862495489,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.252910378877809
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9544725353046577,
    "Overall Score": 16.62442618013144,
    "MMLU Score": 4.790927895981086,
    "BBH Score": 4.607187867121389,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.5058377029279
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Blunt",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9292949587001595,
    "Overall Score": 17.9423472074527,
    "MMLU Score": 5.372709810874704,
    "BBH Score": 5.067571369076204,
    "Math Score": 25.075528700906347,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.299950288338051
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Blunt-Reflective",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.887683133323476,
    "Overall Score": 17.874122056267588,
    "MMLU Score": 5.603575650118202,
    "BBH Score": 6.901046016164872,
    "Math Score": 23.716012084592144,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.468814834827818
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Reflective",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.929412472558116,
    "Overall Score": 15.258010678110056,
    "MMLU Score": 3.2118055555555545,
    "BBH Score": 2.698522439001891,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.908112389198037
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-14B-Reflective",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.992266633258429,
    "Overall Score": 14.389854199470006,
    "MMLU Score": 1.4387559101654843,
    "BBH Score": 3.035855458967868,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.222855595355148
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6814255563649841,
    "Overall Score": 11.398600284940263,
    "MMLU Score": 1.5680407801418434,
    "BBH Score": 1.9766705871500392,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 16.727579672452087
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-7B-Blunt",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6726927587157503,
    "Overall Score": 12.850779949168643,
    "MMLU Score": 1.8820183215130024,
    "BBH Score": 2.149818735298187,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.10349083243039
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-7B-ORPO-Uncensored",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6785234959047466,
    "Overall Score": 10.72103457820772,
    "MMLU Score": 1.4756944444444438,
    "BBH Score": 2.744263179742631,
    "Math Score": 17.371601208459214,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.80053549053926
  },
  {
    "Model Name": "braindao/DeepSeek-R1-Distill-Qwen-7B-Reflective",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6684679781246362,
    "Overall Score": 11.718078328507309,
    "MMLU Score": 1.725029550827422,
    "BBH Score": 2.0813002167796686,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.529752676234352
  },
  {
    "Model Name": "braindao/Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.2515694930214387,
    "Overall Score": 32.436238941896505,
    "MMLU Score": 43.15159574468085,
    "BBH Score": 41.26351364432166,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 14.40605721583547
  },
  {
    "Model Name": "braindao/Qwen2.5-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.755065293649155,
    "Overall Score": 41.60549009199536,
    "MMLU Score": 43.21623817966904,
    "BBH Score": 48.57308952738765,
    "Math Score": 55.2870090634441,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 8.749720040135616
  },
  {
    "Model Name": "braindao/iq-code-evmind-0.5b",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5073626971520605,
    "Overall Score": 7.0224136272788416,
    "MMLU Score": 2.103649527186761,
    "BBH Score": 4.260915277471788,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.841012882297434
  },
  {
    "Model Name": "brgx53/3Bgeneral-ECE-PRYMMAL-Martial",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.307303661929017,
    "Overall Score": 23.281187153244208,
    "MMLU Score": 32.59640957446809,
    "BBH Score": 36.673582111407946,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.80855346101548
  },
  {
    "Model Name": "brgx53/3Bgeneralv2-ECE-PRYMMAL-Martial",
    "Parameters (B)": 3.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0068195482674844,
    "Overall Score": 31.48239660410299,
    "MMLU Score": 38.949837470449175,
    "BBH Score": 37.250632564299146,
    "Math Score": 34.96978851963746,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.687706765305425
  },
  {
    "Model Name": "brgx53/3Blareneg-ECE-PRYMMAL-Martial",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.615068915069678,
    "Overall Score": 22.75631720130753,
    "MMLU Score": 33.51063829787233,
    "BBH Score": 35.45258577949333,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.089997639714197
  },
  {
    "Model Name": "brgx53/3Blarenegv2-ECE-PRYMMAL-Martial",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3737919280859543,
    "Overall Score": 31.457001024079023,
    "MMLU Score": 38.949837470449175,
    "BBH Score": 37.250632564299146,
    "Math Score": 34.96978851963746,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.89793700266293
  },
  {
    "Model Name": "brgx53/Barracuda-PRYMMAL-ECE-TW3",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6295401721453008,
    "Overall Score": 3.9169280688644776,
    "MMLU Score": 1.032432033096926,
    "BBH Score": 2.753426597884674,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.221887406353526
  },
  {
    "Model Name": "brgx53/LaConfiance-PRYMMAL-ECE-TW3",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6074110120256099,
    "Overall Score": 4.255168913434492,
    "MMLU Score": 1.6234485815602824,
    "BBH Score": 1.9868050366680503,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.0054194428320375
  },
  {
    "Model Name": "bunnycore/Best-Mix-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8100050452288448,
    "Overall Score": 9.644596419047586,
    "MMLU Score": 6.277703900709218,
    "BBH Score": 7.255275858385576,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.328491456126405
  },
  {
    "Model Name": "bunnycore/Blabbertron-1.0",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6719606311601921,
    "Overall Score": 36.2247146459169,
    "MMLU Score": 37.2691341607565,
    "BBH Score": 36.054612445029626,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 53.90898360127456
  },
  {
    "Model Name": "bunnycore/Blabbertron-1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6637390108814308,
    "Overall Score": 36.19288822858115,
    "MMLU Score": 38.11872044917258,
    "BBH Score": 36.60739009385717,
    "Math Score": 48.036253776435046,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 54.528794654570305
  },
  {
    "Model Name": "bunnycore/CyberCore-Qwen-2.1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3453683327965331,
    "Overall Score": 30.98421070085202,
    "MMLU Score": 38.27570921985816,
    "BBH Score": 36.96653253167443,
    "Math Score": 35.87613293051359,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.030280961383323
  },
  {
    "Model Name": "bunnycore/DeepQwen-3B-LCoT-SCE",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7734388198390433,
    "Overall Score": 20.33845959063539,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 23.559546324044987,
    "Math Score": 24.69788519637462,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.296145304508936
  },
  {
    "Model Name": "bunnycore/DeepSeek-R1-Distill-Qwen-7B-RRP-Ex",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3365016987234717,
    "Overall Score": 14.616489832350064,
    "MMLU Score": 16.759013002364064,
    "BBH Score": 8.396453841395422,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.936379539442907
  },
  {
    "Model Name": "bunnycore/DeepThinker-7B-Sce-v1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4259256537840237,
    "Overall Score": 4.766577429203108,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 2.5205978669314697,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.3427951987215403
  },
  {
    "Model Name": "bunnycore/DeepThinker-7B-Sce-v2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4249684990843643,
    "Overall Score": 5.521537075022995,
    "MMLU Score": 1.6234485815602824,
    "BBH Score": 3.256507303765563,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.8748485167012077
  },
  {
    "Model Name": "bunnycore/FuseCyberMix-Qwen-2.5-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.302794593476737,
    "Overall Score": 34.50574650183828,
    "MMLU Score": 37.07520685579196,
    "BBH Score": 36.36861871726955,
    "Math Score": 48.413897280966765,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 26.48594542425419
  },
  {
    "Model Name": "bunnycore/FuseQwQen-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4317790858062496,
    "Overall Score": 34.67786732785649,
    "MMLU Score": 37.85091607565011,
    "BBH Score": 35.909588839820735,
    "Math Score": 43.65558912386707,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.220124229799755
  },
  {
    "Model Name": "bunnycore/FwF-Qwen-7B-0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.642909230556383,
    "Overall Score": 22.055184230946704,
    "MMLU Score": 34.0093085106383,
    "BBH Score": 30.502106087142987,
    "Math Score": 27.64350453172205,
    "Date Submitted": "2025-01-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.424469119013688
  },
  {
    "Model Name": "bunnycore/FwF-Qwen-7B-0.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.550554917300331,
    "Overall Score": 30.049606790844468,
    "MMLU Score": 37.58311170212765,
    "BBH Score": 37.66718042893359,
    "Math Score": 42.59818731117825,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.37990486861555
  },
  {
    "Model Name": "bunnycore/Gemma-2-2B-Smart",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.481796983463691,
    "Overall Score": 10.674608537656132,
    "MMLU Score": 15.844784278959809,
    "BBH Score": 15.07045874494903,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.301161057403752
  },
  {
    "Model Name": "bunnycore/Gemma2-9B-TitanFusion",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0467130344261024,
    "Overall Score": 19.47150093470061,
    "MMLU Score": 32.89191784869976,
    "BBH Score": 39.05056413790993,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.513547139821881
  },
  {
    "Model Name": "bunnycore/HyperLlama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.789089037076908,
    "Overall Score": 28.44897570570595,
    "MMLU Score": 30.92494089834515,
    "BBH Score": 29.80665561261375,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.901375010484182
  },
  {
    "Model Name": "bunnycore/Llama-3.1-8B-TitanFusion-Mix",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8661696080057093,
    "Overall Score": 25.01224783778518,
    "MMLU Score": 29.94606973995272,
    "BBH Score": 39.53548333481336,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.402987451132393
  },
  {
    "Model Name": "bunnycore/Llama-3.1-8B-TitanFusion-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7756484366333043,
    "Overall Score": 24.219132767586814,
    "MMLU Score": 31.174276004728128,
    "BBH Score": 32.072941144614084,
    "Math Score": 14.19939577039275,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.639599071484664
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-All-Mix",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4806189654910051,
    "Overall Score": 22.94517856311552,
    "MMLU Score": 23.99896572104019,
    "BBH Score": 22.51631119233452,
    "Math Score": 15.030211480362537,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.497017867460858
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Bespoke-Thought",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2235100982970288,
    "Overall Score": 18.009908616281866,
    "MMLU Score": 23.444887706855795,
    "BBH Score": 22.51656576646296,
    "Math Score": 16.46525679758308,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.719869203653797
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Booval",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3104814708176846,
    "Overall Score": 21.56545090409925,
    "MMLU Score": 22.86310579196217,
    "BBH Score": 22.515991469149508,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.456128060050577
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Deep-Test",
    "Parameters (B)": 1.803,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5965275921771368,
    "Overall Score": 3.9736733260966406,
    "MMLU Score": 0.542996453900708,
    "BBH Score": 2.5723233888621087,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.661340360793692
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Deep-Test",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7395749165213583,
    "Overall Score": 18.441056902448857,
    "MMLU Score": 23.91585401891253,
    "BBH Score": 22.914432093725296,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.60089837310691
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Della",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2548360029719627,
    "Overall Score": 12.217685988950697,
    "MMLU Score": 12.538785460992909,
    "BBH Score": 11.46745923572203,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.736480273130704
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Long-Think",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.071543124319194,
    "Overall Score": 19.82599007647469,
    "MMLU Score": 22.752290189125294,
    "BBH Score": 24.22680316567029,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.570638353469198
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-Mix-Skill",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.370133583615858,
    "Overall Score": 21.73956606363181,
    "MMLU Score": 23.56493794326241,
    "BBH Score": 23.784246657651128,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.866749288970713
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-ProdigyPlus",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4278795718496495,
    "Overall Score": 16.356007600580043,
    "MMLU Score": 20.19429669030733,
    "BBH Score": 20.62298869714629,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.454752853836801
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-ProdigyPlusPlus",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3431514349940856,
    "Overall Score": 6.708176427584118,
    "MMLU Score": 5.557402482269504,
    "BBH Score": 11.56197768121448,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.994355999488365
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-RP-DeepThink",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3272197823874436,
    "Overall Score": 23.21103861527769,
    "MMLU Score": 24.913194444444443,
    "BBH Score": 23.757462281904537,
    "Math Score": 16.08761329305136,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.488466434342143
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-RRStock",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.14466366206302,
    "Overall Score": 22.67468863966219,
    "MMLU Score": 24.839317375886523,
    "BBH Score": 23.921831246946,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.809040324382924
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3B-ToxicKod",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.210684779049432,
    "Overall Score": 21.26912427486916,
    "MMLU Score": 20.886894208037827,
    "BBH Score": 22.983327840830786,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.567846431148325
  },
  {
    "Model Name": "bunnycore/Llama-3.2-3b-RP-Toxic-Fuse",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5789514823163004,
    "Overall Score": 25.27738174853081,
    "MMLU Score": 23.39871453900709,
    "BBH Score": 24.36603090543824,
    "Math Score": 24.018126888217523,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.66062186661945
  },
  {
    "Model Name": "bunnycore/Maestro-S1k-7B-Sce",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7234155444945778,
    "Overall Score": 6.835617935266296,
    "MMLU Score": 1.891252955082742,
    "BBH Score": 4.8440468816556645,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.449089098634278
  },
  {
    "Model Name": "bunnycore/Phi-3.5-mini-TitanFusion-0.1",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.593770933170724,
    "Overall Score": 26.23579178503736,
    "MMLU Score": 31.183510638297868,
    "BBH Score": 35.446219076522446,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.46145706324473
  },
  {
    "Model Name": "bunnycore/Phi-4-Model-Stock",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.919819940670153,
    "Overall Score": 40.7857160927999,
    "MMLU Score": 48.53538711583924,
    "BBH Score": 55.31567822091236,
    "Math Score": 42.97583081570997,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.244552798301907
  },
  {
    "Model Name": "bunnycore/Phi-4-Model-Stock-v2",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8849691486581048,
    "Overall Score": 39.1446195362203,
    "MMLU Score": 48.119828605200944,
    "BBH Score": 54.68637369280513,
    "Math Score": 37.53776435045317,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.76671629564179
  },
  {
    "Model Name": "bunnycore/Phi-4-Model-Stock-v3",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.861207931804194,
    "Overall Score": 37.67299066187767,
    "MMLU Score": 48.68314125295508,
    "BBH Score": 52.78361125759003,
    "Math Score": 49.01812688821752,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.241150931136804
  },
  {
    "Model Name": "bunnycore/Phi-4-Model-Stock-v4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8868426755694208,
    "Overall Score": 41.216841837982095,
    "MMLU Score": 48.82166075650118,
    "BBH Score": 55.90173559155676,
    "Math Score": 38.29305135951662,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.844344720231362
  },
  {
    "Model Name": "bunnycore/Phi-4-RP-v0",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.846903331156068,
    "Overall Score": 38.21180801915013,
    "MMLU Score": 48.48921394799055,
    "BBH Score": 54.8449853466199,
    "Math Score": 33.157099697885194,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.689663272864138
  },
  {
    "Model Name": "bunnycore/Phi-4-RR-Shoup",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8697275952784915,
    "Overall Score": 41.27997062998439,
    "MMLU Score": 49.20951536643025,
    "BBH Score": 56.10839417299811,
    "Math Score": 49.92447129909365,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.07806673775697
  },
  {
    "Model Name": "bunnycore/Phi-4-RStock-v0.1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.788147565338876,
    "Overall Score": 41.10230758798472,
    "MMLU Score": 48.8955378250591,
    "BBH Score": 55.97629172237362,
    "Math Score": 39.50151057401813,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.741797779626873
  },
  {
    "Model Name": "bunnycore/Phi-4-ReasoningRP",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8747088099962927,
    "Overall Score": 40.9538705823328,
    "MMLU Score": 49.11716903073285,
    "BBH Score": 55.88446363760437,
    "Math Score": 45.69486404833837,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.84545693921062
  },
  {
    "Model Name": "bunnycore/Phi-4-Sce-exp-v0.1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8583181603957728,
    "Overall Score": 41.33228109882298,
    "MMLU Score": 49.14487293144209,
    "BBH Score": 56.074961973018425,
    "Math Score": 50.30211480362537,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.24176784131534
  },
  {
    "Model Name": "bunnycore/Phi-4-Stock-Ex",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.84229568684912,
    "Overall Score": 40.217464671520766,
    "MMLU Score": 48.60926418439716,
    "BBH Score": 55.20355070082317,
    "Math Score": 40.86102719033233,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.830081326578327
  },
  {
    "Model Name": "bunnycore/Phi-4-Stock-RP",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3111459529240057,
    "Overall Score": 39.044084455528825,
    "MMLU Score": 47.96283983451538,
    "BBH Score": 55.20594989405504,
    "Math Score": 34.13897280966767,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.8938203172029
  },
  {
    "Model Name": "bunnycore/Phi-4-Trim-Exp1",
    "Parameters (B)": 7.503,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5123423469545572,
    "Overall Score": 4.501547812787733,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 1.4066196276490397,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.786210703732836
  },
  {
    "Model Name": "bunnycore/Phi-Seek-4-Sce-V1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9464034254665368,
    "Overall Score": 26.22214709074268,
    "MMLU Score": 45.81117021276596,
    "BBH Score": 49.2526730890894,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.47210282701668
  },
  {
    "Model Name": "bunnycore/Qandora-2.5-7B-Creative",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.419590012322623,
    "Overall Score": 32.10182633953863,
    "MMLU Score": 38.66356382978723,
    "BBH Score": 36.424651784758105,
    "Math Score": 30.589123867069485,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.61344899645787
  },
  {
    "Model Name": "bunnycore/QandoraExp-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3410551587069948,
    "Overall Score": 36.26500037492428,
    "MMLU Score": 37.88785460992907,
    "BBH Score": 35.92474216004687,
    "Math Score": 47.43202416918429,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 27.04213927329425
  },
  {
    "Model Name": "bunnycore/QandoraExp-7B-Persona",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3759415732833142,
    "Overall Score": 31.693541037557907,
    "MMLU Score": 37.86015070921986,
    "BBH Score": 36.8327094432999,
    "Math Score": 31.04229607250756,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.034074740491924
  },
  {
    "Model Name": "bunnycore/QandoraExp-7B-v2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3872989562354536,
    "Overall Score": 31.12963867958909,
    "MMLU Score": 32.319370567375884,
    "BBH Score": 34.94496675271275,
    "Math Score": 47.12990936555892,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.439026959309366
  },
  {
    "Model Name": "bunnycore/QwQen-3B-LCoT",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4554590235335287,
    "Overall Score": 27.986056265747138,
    "MMLU Score": 29.99224290780142,
    "BBH Score": 28.499814171968943,
    "Math Score": 36.17824773413897,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.228336774334778
  },
  {
    "Model Name": "bunnycore/QwQen-3B-LCoT-R1",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8102690770869923,
    "Overall Score": 25.965028531766123,
    "MMLU Score": 30.26004728132387,
    "BBH Score": 26.982869231919675,
    "Math Score": 33.53474320241692,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.04494564338219
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Deep-Sky-T1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7107938132268742,
    "Overall Score": 15.009116031308366,
    "MMLU Score": 12.26174645390071,
    "BBH Score": 17.866965310070587,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.115991377541285
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Deep-Stock-v1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.406862713775246,
    "Overall Score": 27.53059115286298,
    "MMLU Score": 34.06471631205674,
    "BBH Score": 34.07986228320928,
    "Math Score": 26.435045317220546,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.568782997301852
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Deep-Stock-v4",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3293361270213009,
    "Overall Score": 36.10174991287545,
    "MMLU Score": 37.1306146572104,
    "BBH Score": 35.91001360257288,
    "Math Score": 48.94259818731118,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.157728718146064
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Deep-Stock-v5",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6894965582474849,
    "Overall Score": 18.50794443275282,
    "MMLU Score": 20.351285460992905,
    "BBH Score": 24.990385055835603,
    "Math Score": 14.72809667673716,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.842692992978883
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Exp-Sce",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7166903469215072,
    "Overall Score": 33.8635495431104,
    "MMLU Score": 36.2071513002364,
    "BBH Score": 36.2390009919108,
    "Math Score": 32.55287009063444,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 47.24990323724728
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-R1-Stock",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3544243143784895,
    "Overall Score": 35.319380127136064,
    "MMLU Score": 36.60424054373522,
    "BBH Score": 34.8504410029365,
    "Math Score": 50.07552870090635,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.077042291833944
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7B-Stock-Deep-Bespoke",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4266904813280454,
    "Overall Score": 23.4734154687315,
    "MMLU Score": 28.662455673758863,
    "BBH Score": 28.17803739186357,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.453053956651548
  },
  {
    "Model Name": "bunnycore/Qwen-2.5-7b-S1k",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6942319849156767,
    "Overall Score": 34.59275371596473,
    "MMLU Score": 37.58311170212765,
    "BBH Score": 36.69420283560647,
    "Math Score": 47.809667673716014,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 49.828810062916446
  },
  {
    "Model Name": "bunnycore/Qwen2.5-1.5B-Model-Stock",
    "Parameters (B)": 1.776,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6066806636378542,
    "Overall Score": 4.199522746745044,
    "MMLU Score": 1.1155437352245865,
    "BBH Score": 1.430207460042271,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.922130534972621
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-Model-Stock",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5158120396985344,
    "Overall Score": 27.52421014331389,
    "MMLU Score": 24.9963061465721,
    "BBH Score": 26.00226442713036,
    "Math Score": 37.99093655589124,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.158062756110528
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-Model-Stock-v2",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5142603427826242,
    "Overall Score": 27.68767938120949,
    "MMLU Score": 25.217937352245865,
    "BBH Score": 25.64854657456816,
    "Math Score": 38.670694864048336,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.28462292707888
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-Model-Stock-v3.1",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7668845276681562,
    "Overall Score": 27.97276368199932,
    "MMLU Score": 25.439568557919618,
    "BBH Score": 26.396631614914487,
    "Math Score": 38.97280966767372,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.47584828325498
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-Model-Stock-v3.2",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7636616572248317,
    "Overall Score": 27.386758745448905,
    "MMLU Score": 25.48574172576832,
    "BBH Score": 26.32693751443641,
    "Math Score": 37.53776435045317,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.86242478766469
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-Model-Stock-v4.1",
    "Parameters (B)": 3.396,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7750401326792976,
    "Overall Score": 27.743273848475656,
    "MMLU Score": 26.5200206855792,
    "BBH Score": 27.39995114531432,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.79591904817591
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-RP-Mix",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8394020332907,
    "Overall Score": 25.50520681111248,
    "MMLU Score": 30.30622044917257,
    "BBH Score": 28.305922895366823,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.86603165023338
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-RP-Thinker",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.440127196860825,
    "Overall Score": 22.90612225635052,
    "MMLU Score": 23.88815011820331,
    "BBH Score": 17.412964272966242,
    "Math Score": 33.53474320241692,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.90562438254139
  },
  {
    "Model Name": "bunnycore/Qwen2.5-3B-RP-Thinker-V2",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4404737026994847,
    "Overall Score": 27.670372197700004,
    "MMLU Score": 25.236406619385345,
    "BBH Score": 25.629506719785628,
    "Math Score": 38.29305135951662,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.209217180324096
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-CyberRombos",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.420210820498877,
    "Overall Score": 35.95055187781517,
    "MMLU Score": 37.67545803782505,
    "BBH Score": 35.8840250776346,
    "Math Score": 49.62235649546828,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.31353187774392
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-Fuse-Exp",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6754423000288923,
    "Overall Score": 26.92529775716781,
    "MMLU Score": 25.65196513002364,
    "BBH Score": 29.967150522844417,
    "Math Score": 31.41993957703928,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 39.86320927193348
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-Instruct-Fusion",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.328964770541402,
    "Overall Score": 33.10123026617861,
    "MMLU Score": 38.52504432624112,
    "BBH Score": 36.17985917773406,
    "Math Score": 34.06344410876133,
    "Date Submitted": "2024-11-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.907530282156106
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-Instruct-Merge-Stock-v0.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6805329882548932,
    "Overall Score": 36.14483066079348,
    "MMLU Score": 37.5923463356974,
    "BBH Score": 36.39523146749664,
    "Math Score": 48.94259818731118,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 53.11253280091613
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-MixStock-Sce-V0.3",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7264664530340607,
    "Overall Score": 11.636394077198473,
    "MMLU Score": 8.660239361702127,
    "BBH Score": 9.507336377473363,
    "Math Score": 25.755287009063444,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.017799622542096
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-MixStock-V0.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.128944701196448,
    "Overall Score": 33.68659688810528,
    "MMLU Score": 36.179447399527184,
    "BBH Score": 35.86925790573909,
    "Math Score": 31.72205438066465,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.823143207605959
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-R1-Bespoke-Stock",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.433775879745251,
    "Overall Score": 20.435991032043965,
    "MMLU Score": 27.46195330969267,
    "BBH Score": 26.63869755860018,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.25326741838827
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-R1-Bespoke-Task",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.405181067340548,
    "Overall Score": 15.746098824658986,
    "MMLU Score": 18.753693853427897,
    "BBH Score": 17.906937974221723,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.205743651570913
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-RRP-1M",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.361352956624342,
    "Overall Score": 33.67928553393096,
    "MMLU Score": 36.290263002364064,
    "BBH Score": 35.648526152494235,
    "Math Score": 32.477341389728096,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.73956909561741
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-RRP-1M-Thinker",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7101215693816563,
    "Overall Score": 12.275362824338156,
    "MMLU Score": 8.540189125295509,
    "BBH Score": 9.209373414510402,
    "Math Score": 27.19033232628399,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.286283579622882
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-RRP-ID",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5030598082994553,
    "Overall Score": 35.463219597116336,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 36.09918880152282,
    "Math Score": 48.6404833836858,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.594017617461954
  },
  {
    "Model Name": "bunnycore/Qwen2.5-7B-Sky-R1-Mini",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6655915571196371,
    "Overall Score": 7.371821186629208,
    "MMLU Score": 2.8147163120567367,
    "BBH Score": 8.89516742838758,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.07559299359345
  },
  {
    "Model Name": "bunnycore/QwenMosaic-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5005744720068477,
    "Overall Score": 31.300371581101075,
    "MMLU Score": 36.77969858156028,
    "BBH Score": 36.750519941741935,
    "Math Score": 44.41087613293052,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.858925808087612
  },
  {
    "Model Name": "bunnycore/Smol-Llama-3.2-3B",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1314095821066952,
    "Overall Score": 22.52219334493714,
    "MMLU Score": 24.756205673758867,
    "BBH Score": 23.04076448114923,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.90631306392209
  },
  {
    "Model Name": "bunnycore/SmolLM2-1.7-Persona",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6626648013774251,
    "Overall Score": 14.527349011570474,
    "MMLU Score": 10.821143617021276,
    "BBH Score": 11.203752907058009,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.922620578871406
  },
  {
    "Model Name": "bunnycore/SmolLM2-1.7B-roleplay-lora",
    "Parameters (B)": 3.423,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4000513949062356,
    "Overall Score": 14.47905997638928,
    "MMLU Score": 10.738031914893616,
    "BBH Score": 10.90723801954026,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.341806043026708
  },
  {
    "Model Name": "bunnycore/Tulu-3.1-8B-SuperNova",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3878481612472198,
    "Overall Score": 30.991375681506,
    "MMLU Score": 31.26662234042553,
    "BBH Score": 32.499170772496946,
    "Math Score": 24.62235649546828,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.330523285526372
  },
  {
    "Model Name": "byroneverson/Mistral-Small-Instruct-2409-abliterated",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.804572923392441,
    "Overall Score": 28.80584571864184,
    "MMLU Score": 32.476359338061464,
    "BBH Score": 31.255700427788582,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.271027534487493
  },
  {
    "Model Name": "byroneverson/Yi-1.5-9B-Chat-16K-abliterated",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.180206419702791,
    "Overall Score": 26.948135419447976,
    "MMLU Score": 31.36820330969267,
    "BBH Score": 32.843258967002555,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.360359631966219
  },
  {
    "Model Name": "byroneverson/Yi-1.5-9B-Chat-abliterated",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.689144676280076,
    "Overall Score": 26.270006043497983,
    "MMLU Score": 30.167700945626475,
    "BBH Score": 34.35218727198406,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.552253405167866
  },
  {
    "Model Name": "c10x/Q-Pluse",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.6233823800199807,
    "Overall Score": 3.634370763516103,
    "MMLU Score": 1.5033983451536632,
    "BBH Score": 1.9479450969539605,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3853759143904985
  },
  {
    "Model Name": "c10x/longthinker",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8895488764718007,
    "Overall Score": 20.73088769949013,
    "MMLU Score": 28.08067375886525,
    "BBH Score": 28.4247368611983,
    "Math Score": 23.187311178247736,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.971342396921328
  },
  {
    "Model Name": "carsenk/flippa-v6",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.129600623223738,
    "Overall Score": 20.776367026140395,
    "MMLU Score": 29.6413268321513,
    "BBH Score": 29.993501279427136,
    "Math Score": 14.04833836858006,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.755992179740083
  },
  {
    "Model Name": "carsenk/phi3.5_mini_exp_825_uncensored",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.975636967913453,
    "Overall Score": 3.6431087408611895,
    "MMLU Score": 1.9466607565011809,
    "BBH Score": 1.827812730226084,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.7340823079434227
  },
  {
    "Model Name": "cat-searcher/gemma-2-9b-it-sppo-iter-1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.536078704562463,
    "Overall Score": 21.93864090281541,
    "MMLU Score": 31.709884751773053,
    "BBH Score": 41.67630770023723,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-08-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.9628484480784314
  },
  {
    "Model Name": "cat-searcher/gemma-2-9b-it-sppo-iter-1-evol-1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.575624815994469,
    "Overall Score": 21.52546311795015,
    "MMLU Score": 31.109633569739948,
    "BBH Score": 41.10464026733791,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-08-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.860636938160063
  },
  {
    "Model Name": "cckm/tinymistral_950m",
    "Parameters (B)": 0.955,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7365668642980026,
    "Overall Score": 5.219822920055284,
    "MMLU Score": 1.0693705673758855,
    "BBH Score": 2.371788472964944,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.0866925639264595
  },
  {
    "Model Name": "cgato/TheSalt-L3-8b-v0.3.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.880588171001616,
    "Overall Score": 7.39988938907955,
    "MMLU Score": 1.549571513002364,
    "BBH Score": 2.612714473502145,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.9348803226483717
  },
  {
    "Model Name": "chargoddard/prometheus-2-llama-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8902292652132209,
    "Overall Score": 19.318861828334345,
    "MMLU Score": 23.186317966903072,
    "BBH Score": 27.80383919259717,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.220380238454908
  },
  {
    "Model Name": "chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4409627658318651,
    "Overall Score": 23.054922214082467,
    "MMLU Score": 26.677009456264773,
    "BBH Score": 25.86828225174116,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.999665474196277
  },
  {
    "Model Name": "chujiezheng/Mistral7B-PairRM-SPPO-ExPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.018067970306855,
    "Overall Score": 13.61714888899552,
    "MMLU Score": 17.239213947990542,
    "BBH Score": 13.678635807519433,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.37548109375368
  },
  {
    "Model Name": "cjvt/GaMS-1B",
    "Parameters (B)": 1.54,
    "Architecture": "OPTForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.5078824355043933,
    "Overall Score": 4.621759796234088,
    "MMLU Score": 1.6511524822695034,
    "BBH Score": 3.861742268465667,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.100058346463744
  },
  {
    "Model Name": "cloudyu/Llama-3-70Bx2-MOE",
    "Parameters (B)": 126.926,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 43.07910960388615,
    "Overall Score": 35.66646489034437,
    "MMLU Score": 46.02356678486997,
    "BBH Score": 51.42213772529595,
    "Math Score": 21.75226586102719,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.827929481790564
  },
  {
    "Model Name": "cloudyu/Llama-3.2-3Bx4",
    "Parameters (B)": 9.949,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.534152258686576,
    "Overall Score": 18.997310704369745,
    "MMLU Score": 22.0596926713948,
    "BBH Score": 19.7933281387424,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.496515112401276
  },
  {
    "Model Name": "cloudyu/Mixtral_11Bx2_MoE_19B",
    "Parameters (B)": 19.188,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1164466475132806,
    "Overall Score": 20.407079261242234,
    "MMLU Score": 25.67966903073286,
    "BBH Score": 32.78564048528819,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.27859782345711
  },
  {
    "Model Name": "cloudyu/Mixtral_34Bx2_MoE_60B",
    "Parameters (B)": 60.814,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 14.66517696022586,
    "Overall Score": 27.61116919285104,
    "MMLU Score": 41.84951241134751,
    "BBH Score": 41.20912905359096,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2024-08-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.8827709524226428
  },
  {
    "Model Name": "cloudyu/Mixtral_7Bx2_MoE",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5676300529098277,
    "Overall Score": 21.447315990602657,
    "MMLU Score": 22.7061170212766,
    "BBH Score": 32.2766407313606,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.6813631193101
  },
  {
    "Model Name": "cloudyu/S1-Llama-3.2-3Bx4-MoE",
    "Parameters (B)": 9.555,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.711205931650744,
    "Overall Score": 19.960751542556377,
    "MMLU Score": 22.7061170212766,
    "BBH Score": 20.04155472353695,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.362314794879148
  },
  {
    "Model Name": "cloudyu/Yi-34Bx2-MoE-60B-DPO",
    "Parameters (B)": 60.814,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 14.678493278722105,
    "Overall Score": 26.04350240565636,
    "MMLU Score": 40.8521719858156,
    "BBH Score": 31.259298004231464,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.774262651563082
  },
  {
    "Model Name": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-apty-ipo",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.439661779649258,
    "Overall Score": 10.051762435192131,
    "MMLU Score": 17.673241725768317,
    "BBH Score": 12.669478223003605,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.982030486105579
  },
  {
    "Model Name": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-apty-sigmoid",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4471203294708117,
    "Overall Score": 10.070699081571052,
    "MMLU Score": 17.359264184397162,
    "BBH Score": 12.757325206130604,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.95913040296638
  },
  {
    "Model Name": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-etpc",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4830543361353572,
    "Overall Score": 9.681788175038944,
    "MMLU Score": 17.28538711583924,
    "BBH Score": 12.69457911779628,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.5282760982772885
  },
  {
    "Model Name": "cognitivecomputations/Dolphin3.0-Llama3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2386505265987682,
    "Overall Score": 25.26984394173985,
    "MMLU Score": 22.13356973995272,
    "BBH Score": 27.6317028058839,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.4011086251493
  },
  {
    "Model Name": "cognitivecomputations/Dolphin3.0-Llama3.2-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.008096300085214,
    "Overall Score": 11.140988411587436,
    "MMLU Score": 4.172207446808509,
    "BBH Score": 4.657279069612183,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.5480349279636965
  },
  {
    "Model Name": "cognitivecomputations/Dolphin3.0-Qwen2.5-0.5B",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8245174133202131,
    "Overall Score": 10.626273337296174,
    "MMLU Score": 4.587765957446806,
    "BBH Score": 5.096928104575164,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.887870123331536
  },
  {
    "Model Name": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9536720384896045,
    "Overall Score": 23.513141611997387,
    "MMLU Score": 22.281323877068555,
    "BBH Score": 33.763678263545195,
    "Math Score": 31.19335347432024,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.960647392667574
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9-llama3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4782402798649394,
    "Overall Score": 18.415461238797384,
    "MMLU Score": 19.67715721040189,
    "BBH Score": 27.858929260905125,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.457691411628918
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 24.29817613920845,
    "Overall Score": 25.53438611403665,
    "MMLU Score": 34.77578309692671,
    "BBH Score": 31.101151872569243,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.0508766570686514
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.1-yi-1.5-34b",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.985306700006266,
    "Overall Score": 28.3072040459155,
    "MMLU Score": 39.09759160756501,
    "BBH Score": 44.17408874277273,
    "Math Score": 18.65558912386707,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.729449210327997
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.1-yi-1.5-9b",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.101731428783443,
    "Overall Score": 25.63972412430824,
    "MMLU Score": 32.96579491725768,
    "BBH Score": 35.7760897255686,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2024-08-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.199334212340073
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium",
    "Parameters (B)": -1.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.68096358537964,
    "Overall Score": 28.614516488633864,
    "MMLU Score": 39.50391548463357,
    "BBH Score": 49.72194030508101,
    "Math Score": 18.27794561933535,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.022686712259368
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated",
    "Parameters (B)": 13.96,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8439536564991926,
    "Overall Score": 25.590063720348784,
    "MMLU Score": 38.820552600472816,
    "BBH Score": 45.44126655093765,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 30.32164565350546
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated",
    "Parameters (B)": 13.96,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6415931932373822,
    "Overall Score": 28.53887227810586,
    "MMLU Score": 39.1622340425532,
    "BBH Score": 48.38534691270737,
    "Math Score": 18.202416918429005,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.384862702692143
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.2-qwen2-72b",
    "Parameters (B)": 72.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 37.74700133322834,
    "Overall Score": 36.97892776605849,
    "MMLU Score": 49.680481678487006,
    "BBH Score": 47.69617372826186,
    "Math Score": 28.02114803625378,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.9796520640039896
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.2-qwen2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.558394539648611,
    "Overall Score": 21.27208217477453,
    "MMLU Score": 33.89849290780142,
    "BBH Score": 27.91487495325553,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-07-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.314621472611568
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.3-Yi-1.5-34B-32k",
    "Parameters (B)": 34.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.490521054223584,
    "Overall Score": 27.09838264797317,
    "MMLU Score": 40.33503250591017,
    "BBH Score": 43.40647565235176,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.175070448363989
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.3-mistral-7B-32k",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2001651608405095,
    "Overall Score": 19.348695949526363,
    "MMLU Score": 20.231235224586285,
    "BBH Score": 26.906353891780515,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.121694397441036
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.750284963315723,
    "Overall Score": 24.9724308416491,
    "MMLU Score": 26.409205082742314,
    "BBH Score": 36.08275865915292,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-07-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.079943051262049
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.4-gemma2-2b",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.022496022461491,
    "Overall Score": 9.835205324051351,
    "MMLU Score": 12.28021572104019,
    "BBH Score": 17.3676325443774,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-08-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.2540010808820377
  },
  {
    "Model Name": "cognitivecomputations/dolphin-2.9.4-llama3.1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.637555731042925,
    "Overall Score": 7.1318611826224165,
    "MMLU Score": 2.6300236406619386,
    "BBH Score": 8.972088688921525,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.7039660617151706
  },
  {
    "Model Name": "collaiborateorg/Collaiborator-MEDLLM-Llama-3-8B-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4115782694310812,
    "Overall Score": 17.93904722141172,
    "MMLU Score": 27.56353427895981,
    "BBH Score": 23.64850317610825,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.70850338935993
  },
  {
    "Model Name": "cpayne1303/cp2024",
    "Parameters (B)": 0.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.0952261152563516,
    "Overall Score": 3.702132658945494,
    "MMLU Score": 1.124778368794326,
    "BBH Score": 2.7391414141414145,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 38.87728328493964
  },
  {
    "Model Name": "cpayne1303/cp2024-instruct",
    "Parameters (B)": 0.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.0643237910282734,
    "Overall Score": 4.319731373654743,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.481300216779669,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 67.15604451478944
  },
  {
    "Model Name": "cpayne1303/llama-43m-beta",
    "Parameters (B)": 0.043,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.0583918477434125,
    "Overall Score": 5.288331692594867,
    "MMLU Score": 1.466459810874704,
    "BBH Score": 2.482040957520409,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 90.56626732952584
  },
  {
    "Model Name": "cpayne1303/llama-43m-beta",
    "Parameters (B)": 0.043,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.1198317508245459,
    "Overall Score": 5.422628758277313,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 2.496047806835478,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 45.252019777437496
  },
  {
    "Model Name": "cpayne1303/smallcp2024",
    "Parameters (B)": 0.002,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.0946158897718687,
    "Overall Score": 3.543848434170488,
    "MMLU Score": 1.263297872340425,
    "BBH Score": 3.118177558861132,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 37.45510867905138
  },
  {
    "Model Name": "crestf411/MN-Slush",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.12421819670568,
    "Overall Score": 22.136982895446007,
    "MMLU Score": 27.868277186761222,
    "BBH Score": 33.156422079931886,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.42123776633535
  },
  {
    "Model Name": "cstr/llama3.1-8b-spaetzle-v90",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5578157861662771,
    "Overall Score": 27.855367438578327,
    "MMLU Score": 30.34315898345153,
    "BBH Score": 32.76366579584106,
    "Math Score": 14.954682779456194,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.88104067627231
  },
  {
    "Model Name": "cyberagent/calm3-22b-chat",
    "Parameters (B)": 22.543,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.548496236264388,
    "Overall Score": 21.451118364125847,
    "MMLU Score": 21.66260342789598,
    "BBH Score": 29.52088396885831,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.045129242326069
  },
  {
    "Model Name": "darkc0de/BuddyGlassNeverSleeps",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.708297548316883,
    "Overall Score": 19.82064159432298,
    "MMLU Score": 27.249556737588648,
    "BBH Score": 28.477953494418696,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.318487441175305
  },
  {
    "Model Name": "darkc0de/BuddyGlassUncensored2025.2",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.790304478851306,
    "Overall Score": 33.625792878130945,
    "MMLU Score": 37.06597222222223,
    "BBH Score": 43.57124516402332,
    "Math Score": 24.018126888217523,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.78216430520573
  },
  {
    "Model Name": "darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp",
    "Parameters (B)": 0.007,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7963640925218531,
    "Overall Score": 22.32825544058106,
    "MMLU Score": 29.696734633569736,
    "BBH Score": 31.869311081858005,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.429693698249778
  },
  {
    "Model Name": "databricks/dbrx-base",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 10.453409663307854,
    "Overall Score": 16.35943247356884,
    "MMLU Score": 27.77777777777777,
    "BBH Score": 32.60853758169935,
    "Math Score": 10.0,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 1.564985301493685
  },
  {
    "Model Name": "databricks/dbrx-instruct",
    "Parameters (B)": 131.597,
    "Architecture": "DbrxForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 47.958027273119946,
    "Overall Score": 25.19901027244322,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 35.96381960359357,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5254388411127796
  },
  {
    "Model Name": "databricks/dolly-v1-6b",
    "Parameters (B)": 6.0,
    "Architecture": "GPTJForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.3215598245524656,
    "Overall Score": 6.981231710564127,
    "MMLU Score": 2.953235815602837,
    "BBH Score": 4.7813091701327,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.282569567312822
  },
  {
    "Model Name": "databricks/dolly-v2-12b",
    "Parameters (B)": 12.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.794238924559327,
    "Overall Score": 6.370435703496376,
    "MMLU Score": 1.4295212765957446,
    "BBH Score": 6.377894137452961,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.279846453896581
  },
  {
    "Model Name": "databricks/dolly-v2-3b",
    "Parameters (B)": 3.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5161689681554578,
    "Overall Score": 5.59965824307081,
    "MMLU Score": 1.6142139479905429,
    "BBH Score": 3.3247689565453875,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.6932943231803828
  },
  {
    "Model Name": "databricks/dolly-v2-7b",
    "Parameters (B)": 7.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6604119870933625,
    "Overall Score": 5.647360474812998,
    "MMLU Score": 1.6603871158392434,
    "BBH Score": 5.449892512817211,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.401180260508114
  },
  {
    "Model Name": "davidkim205/Rhea-72b-v0.5",
    "Parameters (B)": 72.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 17.377381849100434,
    "Overall Score": 5.99895584588256,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 3.6707473002836015,
    "Math Score": 17.371601208459214,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.345216321881832
  },
  {
    "Model Name": "davidkim205/nox-solar-10.7b-v4",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.69795251189026,
    "Overall Score": 18.514321082123697,
    "MMLU Score": 25.919769503546096,
    "BBH Score": 26.63108814569961,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.903909828145
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 118.54646560023332,
    "Overall Score": 27.809426360756188,
    "MMLU Score": 41.64635047281324,
    "BBH Score": 35.81986234433108,
    "Math Score": 30.74018126888218,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.23458671854913113
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4798056329536695,
    "Overall Score": 13.059950104920146,
    "MMLU Score": 12.10475768321513,
    "BBH Score": 5.325247153240706,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.825449649662898
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2364111786043857,
    "Overall Score": 10.351036796154286,
    "MMLU Score": 2.0759456264775418,
    "BBH Score": 4.729119207646243,
    "Math Score": 16.91842900302115,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.371840189796849
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.9921899783219374,
    "Overall Score": 38.22146462032291,
    "MMLU Score": 40.74135638297872,
    "BBH Score": 40.69076685552542,
    "Math Score": 57.02416918429003,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.574059558254987
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 47.27590504446936,
    "Overall Score": 22.96226839270608,
    "MMLU Score": 40.96298758865248,
    "BBH Score": 17.149673765590364,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.4857076426375544
  },
  {
    "Model Name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3699315191987256,
    "Overall Score": 14.99492256865316,
    "MMLU Score": 14.681220449172578,
    "BBH Score": 7.882702983365756,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.945746089135687
  },
  {
    "Model Name": "deepseek-ai/deepseek-llm-67b-chat",
    "Parameters (B)": 67.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 119.64361733739256,
    "Overall Score": 27.31063187473676,
    "MMLU Score": 32.70722517730496,
    "BBH Score": 33.22524192534525,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.2282665175336628
  },
  {
    "Model Name": "deepseek-ai/deepseek-llm-7b-base",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.6450711788946506,
    "Overall Score": 8.227098434870664,
    "MMLU Score": 8.955747635933804,
    "BBH Score": 9.76792479590425,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.001059249240863
  },
  {
    "Model Name": "deepseek-ai/deepseek-llm-7b-chat",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5489650952313605,
    "Overall Score": 14.823156850686358,
    "MMLU Score": 12.594193262411348,
    "BBH Score": 11.258949371501748,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.56971651351014
  },
  {
    "Model Name": "deepseek-ai/deepseek-moe-16b-base",
    "Parameters (B)": 16.376,
    "Architecture": "DeepseekForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 14.004930861807704,
    "Overall Score": 7.466333791660237,
    "MMLU Score": 5.612810283687943,
    "BBH Score": 8.355555779389382,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5331217886995345
  },
  {
    "Model Name": "deepseek-ai/deepseek-moe-16b-chat",
    "Parameters (B)": 16.376,
    "Architecture": "DeepseekForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.18695614589026,
    "Overall Score": 10.290615224333424,
    "MMLU Score": 10.710328014184398,
    "BBH Score": 6.573749026890635,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.1201332694874004
  },
  {
    "Model Name": "dfurman/CalmeRys-78B-Orpo-v0.1",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.99353475607352,
    "Overall Score": 51.23132307602696,
    "MMLU Score": 66.80149231678487,
    "BBH Score": 61.92476379259157,
    "Math Score": 40.6344410876133,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.9709255996457544
  },
  {
    "Model Name": "dfurman/Llama-3-70B-Orpo-v0.1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 28.880685434073776,
    "Overall Score": 18.30006146936084,
    "MMLU Score": 32.14391252955083,
    "BBH Score": 24.09381654636037,
    "Math Score": 15.78549848942598,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.6336435993229652
  },
  {
    "Model Name": "dfurman/Llama-3-8B-Orpo-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8561587817168912,
    "Overall Score": 10.89448042775765,
    "MMLU Score": 14.42265070921986,
    "BBH Score": 13.68074574746978,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.869368792728272
  },
  {
    "Model Name": "dfurman/Llama-3-8B-Orpo-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9498608388033823,
    "Overall Score": 11.076157946218345,
    "MMLU Score": 14.22872340425532,
    "BBH Score": 13.773376256003464,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.660821768557055
  },
  {
    "Model Name": "dfurman/Qwen2-72B-Orpo-v0.1",
    "Parameters (B)": 72.699,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 25.25066324234519,
    "Overall Score": 44.17229985056738,
    "MMLU Score": 49.49578900709219,
    "BBH Score": 57.41436351018751,
    "Math Score": 40.55891238670695,
    "Date Submitted": "2024-08-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.7493520636119662
  },
  {
    "Model Name": "dicta-il/dictalm2.0",
    "Parameters (B)": 7.251,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.3480768887398813,
    "Overall Score": 11.895185345587594,
    "MMLU Score": 17.830230496453904,
    "BBH Score": 16.48984561578202,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.823818170124296
  },
  {
    "Model Name": "dicta-il/dictalm2.0-instruct",
    "Parameters (B)": 7.251,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2967896079037098,
    "Overall Score": 16.7792214696191,
    "MMLU Score": 17.830230496453904,
    "BBH Score": 19.68807585119424,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.939046833312535
  },
  {
    "Model Name": "distilbert/distilgpt2",
    "Parameters (B)": 0.088,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2461630808282443,
    "Overall Score": 4.002273827220365,
    "MMLU Score": 2.0759456264775418,
    "BBH Score": 2.835219845513963,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.258627466613795
  },
  {
    "Model Name": "divyanshukunwar/SASTRI_1_9B",
    "Parameters (B)": 5.211,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.792430844020681,
    "Overall Score": 19.42175962571148,
    "MMLU Score": 24.30370862884161,
    "BBH Score": 23.534216256795457,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.4923878074085524
  },
  {
    "Model Name": "djuna/G2-BigGSHT-27B-2",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.050857950074226,
    "Overall Score": 36.04705290996797,
    "MMLU Score": 39.19917257683216,
    "BBH Score": 48.814372082405725,
    "Math Score": 23.48942598187311,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.586465263863545
  },
  {
    "Model Name": "djuna/G2-GSHT",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.303383940005492,
    "Overall Score": 24.632233584017342,
    "MMLU Score": 23.00162529550828,
    "BBH Score": 30.99205901512568,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.723921901327239
  },
  {
    "Model Name": "djuna/Gemma-2-gemmama-9b",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.528194430150129,
    "Overall Score": 28.75247693758838,
    "MMLU Score": 23.43565307328605,
    "BBH Score": 32.916050576064585,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.20106108800655
  },
  {
    "Model Name": "djuna/L3.1-ForStHS",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6873286473063,
    "Overall Score": 28.348156412970027,
    "MMLU Score": 30.38933215130024,
    "BBH Score": 31.3912168031268,
    "Math Score": 15.030211480362537,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.800613477537905
  },
  {
    "Model Name": "djuna/L3.1-Promissum_Mane-8B-Della-1.5-calc",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4883060783272883,
    "Overall Score": 29.587663022160967,
    "MMLU Score": 32.263962765957444,
    "BBH Score": 34.87957646776231,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 19.88009284717471
  },
  {
    "Model Name": "djuna/L3.1-Promissum_Mane-8B-Della-calc",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6454390620277746,
    "Overall Score": 26.488800069760984,
    "MMLU Score": 31.128102836879428,
    "BBH Score": 35.553825960108405,
    "Math Score": 18.429003021148034,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.098317270478084
  },
  {
    "Model Name": "djuna/L3.1-Purosani-2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7299035958162357,
    "Overall Score": 23.11337398214292,
    "MMLU Score": 30.57402482269504,
    "BBH Score": 31.391342665184258,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.36107632705228
  },
  {
    "Model Name": "djuna/L3.1-Suze-Vume-calc",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6090376998225064,
    "Overall Score": 26.000783959950287,
    "MMLU Score": 27.942154255319146,
    "BBH Score": 31.13663819998828,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.159213648517024
  },
  {
    "Model Name": "djuna/MN-Chinofun",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.8929861685466323,
    "Overall Score": 24.68383401895207,
    "MMLU Score": 28.92102541371157,
    "BBH Score": 28.48357519092637,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.532302811303326
  },
  {
    "Model Name": "djuna/MN-Chinofun-12B-2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.955393100722868,
    "Overall Score": 25.682587776893183,
    "MMLU Score": 29.05954491725768,
    "BBH Score": 29.526083526964456,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.134232583411931
  },
  {
    "Model Name": "djuna/MN-Chinofun-12B-3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.4154788495638067,
    "Overall Score": 18.389453278031425,
    "MMLU Score": 22.51218971631205,
    "BBH Score": 34.219196465449734,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.613170896260275
  },
  {
    "Model Name": "djuna/MN-Chinofun-12B-4",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6917923335509382,
    "Overall Score": 24.40291180354787,
    "MMLU Score": 27.74822695035461,
    "BBH Score": 34.17304204588476,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.424295062460821
  },
  {
    "Model Name": "djuna/Q2.5-Partron-7B",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.002153106358169,
    "Overall Score": 35.108466039072106,
    "MMLU Score": 36.47495567375886,
    "BBH Score": 35.25726531667357,
    "Math Score": 48.26283987915408,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.535355277066152
  },
  {
    "Model Name": "djuna/Q2.5-Veltha-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.213489909455477,
    "Overall Score": 42.519512261718894,
    "MMLU Score": 47.759677895981085,
    "BBH Score": 49.75243239928858,
    "Math Score": 47.88519637462236,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.231568624693079
  },
  {
    "Model Name": "djuna/Q2.5-Veltha-14B-0.5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9429227973111853,
    "Overall Score": 41.61227861539469,
    "MMLU Score": 47.722739361702125,
    "BBH Score": 50.31812598570336,
    "Math Score": 43.73111782477341,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.139779219969324
  },
  {
    "Model Name": "djuna-test-lab/TEST-L3.2-ReWish-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2812618019241586,
    "Overall Score": 22.57139360581495,
    "MMLU Score": 23.620345744680847,
    "BBH Score": 22.06670043242225,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.61653517799246
  },
  {
    "Model Name": "djuna-test-lab/TEST-L3.2-ReWish-3B-ties-w-base",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.92206090899317,
    "Overall Score": 22.545998025790983,
    "MMLU Score": 23.620345744680847,
    "BBH Score": 22.06670043242225,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.730116314368631
  },
  {
    "Model Name": "dnhkng/RYS-Medium",
    "Parameters (B)": 18.731,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 4.2727567000988005,
    "Overall Score": 26.44775194883569,
    "MMLU Score": 36.95515661938535,
    "BBH Score": 47.73420132486152,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-07-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.189856761145358
  },
  {
    "Model Name": "dnhkng/RYS-Llama-3-8B-Instruct",
    "Parameters (B)": 8.248,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6103746555589764,
    "Overall Score": 21.92277473665084,
    "MMLU Score": 28.413120567375884,
    "BBH Score": 25.373015462245583,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.613462346152756
  },
  {
    "Model Name": "dnhkng/RYS-Llama-3-Huge-Instruct",
    "Parameters (B)": 99.646,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 29.473976290050448,
    "Overall Score": 34.64400590559008,
    "MMLU Score": 45.66341607565011,
    "BBH Score": 49.07372077223325,
    "Math Score": 22.88519637462236,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.175409980813647
  },
  {
    "Model Name": "dnhkng/RYS-Llama-3-Large-Instruct",
    "Parameters (B)": 73.976,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 19.62303388320932,
    "Overall Score": 35.981216135127745,
    "MMLU Score": 45.96815898345154,
    "BBH Score": 49.66553902889135,
    "Math Score": 23.036253776435046,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.8336214649211555
  },
  {
    "Model Name": "dnhkng/RYS-Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.685,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9433438965319416,
    "Overall Score": 26.763955214988574,
    "MMLU Score": 29.32734929078014,
    "BBH Score": 31.08544529601897,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 13.772114787686869
  },
  {
    "Model Name": "dnhkng/RYS-Llama3.1-Large",
    "Parameters (B)": 81.677,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 30.81265784726752,
    "Overall Score": 42.70529151024601,
    "MMLU Score": 47.20559988179669,
    "BBH Score": 55.41486404819653,
    "Math Score": 35.04531722054381,
    "Date Submitted": "2024-08-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.3859658495520903
  },
  {
    "Model Name": "dnhkng/RYS-Phi-3-medium-4k-instruct",
    "Parameters (B)": 17.709,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 4.6210930733664615,
    "Overall Score": 29.093689949569903,
    "MMLU Score": 42.73603723404255,
    "BBH Score": 46.748970518349154,
    "Math Score": 16.08761329305136,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.29584591516898
  },
  {
    "Model Name": "dnhkng/RYS-XLarge",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 27.1521657518909,
    "Overall Score": 45.345219749056206,
    "MMLU Score": 49.20028073286053,
    "BBH Score": 58.77356748233938,
    "Math Score": 42.522658610271904,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6700406208259215
  },
  {
    "Model Name": "dnhkng/RYS-XLarge-base",
    "Parameters (B)": 77.972,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 27.17504732334226,
    "Overall Score": 44.096835700317605,
    "MMLU Score": 49.22798463356975,
    "BBH Score": 58.69214607657639,
    "Math Score": 37.91540785498489,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6226958200157473
  },
  {
    "Model Name": "dnhkng/RYS-XLarge2",
    "Parameters (B)": 77.965,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 26.751769110437625,
    "Overall Score": 35.05222800806562,
    "MMLU Score": 48.64620271867612,
    "BBH Score": 51.54993579817892,
    "Math Score": 27.492447129909365,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3102770087227404
  },
  {
    "Model Name": "dreamgen/WizardLM-2-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1334500041434057,
    "Overall Score": 14.877542593987686,
    "MMLU Score": 18.44895094562648,
    "BBH Score": 9.213113542615597,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.125892222508085
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7822831510467891,
    "Overall Score": 17.353238785134156,
    "MMLU Score": 26.492316784869978,
    "BBH Score": 24.10995815732617,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.736521817502494
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.880739450076765,
    "Overall Score": 18.27663380631257,
    "MMLU Score": 26.41843971631205,
    "BBH Score": 24.89219630627393,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.7177914811999
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7829341776091412,
    "Overall Score": 20.52544148779317,
    "MMLU Score": 28.311539598108748,
    "BBH Score": 24.168293247720744,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.512170076473122
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7705395097616592,
    "Overall Score": 18.53093853220701,
    "MMLU Score": 26.55695921985816,
    "BBH Score": 24.33177003879756,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.466266598423182
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8261926105455653,
    "Overall Score": 18.53626973812641,
    "MMLU Score": 24.63615543735224,
    "BBH Score": 25.195784260224865,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.150227106980134
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7984057478075823,
    "Overall Score": 20.34489241107629,
    "MMLU Score": 27.54506501182033,
    "BBH Score": 26.11610264109281,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.312737648819537
  },
  {
    "Model Name": "dustinwloring1988/Reflexis-8b-chat-v7",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8042220303022205,
    "Overall Score": 19.0955010758327,
    "MMLU Score": 29.364287825059105,
    "BBH Score": 25.98749682684877,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.583786670997506
  },
  {
    "Model Name": "duyhv1411/Llama-3.2-1B-en-vi",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3794542423150936,
    "Overall Score": 10.858146203302624,
    "MMLU Score": 3.793587470449173,
    "BBH Score": 6.09240023176899,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 28.615166184612498
  },
  {
    "Model Name": "duyhv1411/Llama-3.2-3B-en-vi",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3683193365720268,
    "Overall Score": 10.861408814252767,
    "MMLU Score": 3.987514775413712,
    "BBH Score": 5.946254874082537,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.489108324696282
  },
  {
    "Model Name": "dwikitheduck/gemma-2-2b-id",
    "Parameters (B)": 2.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.048664020510734,
    "Overall Score": 14.849648233221265,
    "MMLU Score": 13.037455673758863,
    "BBH Score": 15.415129369168447,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.4550294383795843
  },
  {
    "Model Name": "dwikitheduck/gemma-2-2b-id-inst",
    "Parameters (B)": 2.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.820792959479685,
    "Overall Score": 14.849648233221265,
    "MMLU Score": 13.037455673758863,
    "BBH Score": 15.415129369168447,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.264352416690797
  },
  {
    "Model Name": "dwikitheduck/gemma-2-2b-id-instruct",
    "Parameters (B)": 2.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8338148685218054,
    "Overall Score": 14.849648233221265,
    "MMLU Score": 13.037455673758863,
    "BBH Score": 15.415129369168447,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.240161733277673
  },
  {
    "Model Name": "dwikitheduck/gen-inst-1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.0597448187122507,
    "Overall Score": 40.88019801465988,
    "MMLU Score": 45.43255023640663,
    "BBH Score": 48.31674208220422,
    "Math Score": 45.54380664652568,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.360656014400918
  },
  {
    "Model Name": "dwikitheduck/gen-try1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.166161110753483,
    "Overall Score": 39.412127202941626,
    "MMLU Score": 45.67265070921986,
    "BBH Score": 47.41312903142858,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.447922207459092
  },
  {
    "Model Name": "dwikitheduck/gen-try1-notemp",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.7912117591585552,
    "Overall Score": 30.399295492837265,
    "MMLU Score": 46.780806737588655,
    "BBH Score": 45.749092669505465,
    "Math Score": 31.797583081570995,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.018358620934503
  },
  {
    "Model Name": "dzakwan/dzakwan-MoE-4x7b-Beta",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.9120566130342462,
    "Overall Score": 20.76930305324143,
    "MMLU Score": 23.41718380614657,
    "BBH Score": 32.074208465442545,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.132176950227849
  },
  {
    "Model Name": "ehristoforu/Falcon3-8B-Franken-Basestruct",
    "Parameters (B)": 8.406,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.593017293500535,
    "Overall Score": 16.43874726421677,
    "MMLU Score": 32.74416371158392,
    "BBH Score": 34.8564190624812,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.319252233661485
  },
  {
    "Model Name": "ehristoforu/Falcon3-MoE-2x7B-Insruct",
    "Parameters (B)": 13.401,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.272421412705328,
    "Overall Score": 36.66765115739224,
    "MMLU Score": 34.38792848699764,
    "BBH Score": 38.0671542210182,
    "Math Score": 41.23867069486405,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.20505171339742
  },
  {
    "Model Name": "ehristoforu/Gemma2-9B-it-psy10k-mental_health",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.553660365839716,
    "Overall Score": 27.19248947734485,
    "MMLU Score": 31.432845744680847,
    "BBH Score": 35.56600949863266,
    "Math Score": 16.314199395770395,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.971567331049827
  },
  {
    "Model Name": "ehristoforu/Gemma2-9b-it-train6",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.987366948792421,
    "Overall Score": 30.5339867395368,
    "MMLU Score": 32.68875591016548,
    "BBH Score": 40.98762530159646,
    "Math Score": 19.10876132930513,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.65768165600712
  },
  {
    "Model Name": "ehristoforu/HappyLlama1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4287212848324906,
    "Overall Score": 26.735379379762943,
    "MMLU Score": 28.283835697399525,
    "BBH Score": 28.49977340708129,
    "Math Score": 14.274924471299094,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.71280260439146
  },
  {
    "Model Name": "ehristoforu/QwenQwen2.5-7B-IT",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3084646956722368,
    "Overall Score": 35.58121845476433,
    "MMLU Score": 36.54883274231678,
    "BBH Score": 34.96965415936291,
    "Math Score": 50.90634441087614,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.19310545592071
  },
  {
    "Model Name": "ehristoforu/QwenQwen2.5-7B-IT-Dare",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3336692145681672,
    "Overall Score": 35.56581488113525,
    "MMLU Score": 36.54883274231678,
    "BBH Score": 34.96965415936291,
    "Math Score": 50.90634441087614,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.66764329013264
  },
  {
    "Model Name": "ehristoforu/RQwen-v0.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4178277548538123,
    "Overall Score": 39.73075710536471,
    "MMLU Score": 46.68846040189125,
    "BBH Score": 48.49085165760342,
    "Math Score": 46.45015105740181,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.624563891185346
  },
  {
    "Model Name": "ehristoforu/RQwen-v0.2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.588486659159132,
    "Overall Score": 37.702469412365296,
    "MMLU Score": 46.208259456264784,
    "BBH Score": 48.68383680717029,
    "Math Score": 32.703927492447136,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.56544861027521
  },
  {
    "Model Name": "ehristoforu/SoRu-0009",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0238624057573298,
    "Overall Score": 6.300240741893716,
    "MMLU Score": 2.657727541371158,
    "BBH Score": 5.137457620795654,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.153405678796809
  },
  {
    "Model Name": "ehristoforu/coolqwen-3b-it",
    "Parameters (B)": 3.085,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4458912752828572,
    "Overall Score": 28.654353578279625,
    "MMLU Score": 28.9025561465721,
    "BBH Score": 27.463695565892305,
    "Math Score": 36.70694864048338,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.817778880140228
  },
  {
    "Model Name": "ehristoforu/della-70b-test-v1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 112.55540311381245,
    "Overall Score": 12.869435105716944,
    "MMLU Score": 6.3885195035461,
    "BBH Score": 3.35845623845221,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 0.11433867010989938
  },
  {
    "Model Name": "ehristoforu/falcon3-ultraset",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2365822010385132,
    "Overall Score": 32.53688653155465,
    "MMLU Score": 33.132018321512994,
    "BBH Score": 37.555134459501744,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.31194796773667
  },
  {
    "Model Name": "ehristoforu/fd-lora-merged-16x32",
    "Parameters (B)": 1.776,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2609660637995952,
    "Overall Score": 10.454537831938053,
    "MMLU Score": 2.279107565011819,
    "BBH Score": 6.527180121800353,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.290895474566545
  },
  {
    "Model Name": "ehristoforu/fd-lora-merged-64x128",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.274784777113842,
    "Overall Score": 11.210864438231852,
    "MMLU Score": 5.963726359338062,
    "BBH Score": 7.819061072049554,
    "Math Score": 18.731117824773413,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.794319354529511
  },
  {
    "Model Name": "ehristoforu/fp4-14b-it-v1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.927937797337822,
    "Overall Score": 18.698030773782747,
    "MMLU Score": 35.606900118203306,
    "BBH Score": 38.77952167023901,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.698461641035193
  },
  {
    "Model Name": "ehristoforu/fp4-14b-v1-fix",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9345584896659,
    "Overall Score": 40.37357596138752,
    "MMLU Score": 48.36916371158392,
    "BBH Score": 54.33377964212988,
    "Math Score": 42.06948640483384,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.869658982686058
  },
  {
    "Model Name": "ehristoforu/fq2.5-7b-it-normalize_false",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.375597854684785,
    "Overall Score": 36.49631491468131,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 36.35831249255221,
    "Math Score": 46.22356495468278,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.53123861046174
  },
  {
    "Model Name": "ehristoforu/fq2.5-7b-it-normalize_true",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.370156364188565,
    "Overall Score": 36.49631491468131,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 36.35831249255221,
    "Math Score": 46.22356495468278,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.636605768930014
  },
  {
    "Model Name": "ehristoforu/frqwen2.5-from7b-duable4layers-it",
    "Parameters (B)": 8.545,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5642098098613515,
    "Overall Score": 34.62610373964922,
    "MMLU Score": 34.73884456264776,
    "BBH Score": 33.95977783040959,
    "Math Score": 45.090634441087616,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.136482920228207
  },
  {
    "Model Name": "ehristoforu/frqwen2.5-from7b-it",
    "Parameters (B)": 13.206,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.930741844722849,
    "Overall Score": 28.8464894172487,
    "MMLU Score": 33.076610520094555,
    "BBH Score": 30.71074009126445,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.338688358782979
  },
  {
    "Model Name": "ehristoforu/mllama-3.1-8b-instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4892374312599972,
    "Overall Score": 20.35306209343201,
    "MMLU Score": 17.036052009456267,
    "BBH Score": 26.370934099251983,
    "Math Score": 37.764350453172206,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.666767747176433
  },
  {
    "Model Name": "ehristoforu/mllama-3.1-8b-it",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4676052297594384,
    "Overall Score": 22.17760204557689,
    "MMLU Score": 18.02415780141844,
    "BBH Score": 28.024833549561222,
    "Math Score": 37.99093655589124,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.11142206083043
  },
  {
    "Model Name": "ehristoforu/moremerge",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4287547139447274,
    "Overall Score": 4.5589162639696825,
    "MMLU Score": 0.7276891252955076,
    "BBH Score": 1.987596513075965,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.1908320017945697
  },
  {
    "Model Name": "ehristoforu/moremerge-upscaled",
    "Parameters (B)": 8.545,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8812689359615675,
    "Overall Score": 3.918261338977189,
    "MMLU Score": 0.4598847517730496,
    "BBH Score": 1.0147625530079194,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.082775760592921
  },
  {
    "Model Name": "ehristoforu/phi-4-25b",
    "Parameters (B)": 24.883,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.66303403496976,
    "Overall Score": 39.11615849607893,
    "MMLU Score": 48.341459810874696,
    "BBH Score": 55.67261468233141,
    "Math Score": 45.2416918429003,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.388563798319478
  },
  {
    "Model Name": "ehristoforu/qwen2.5-test-32b-it",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 29.54403370563684,
    "Overall Score": 47.36835680458376,
    "MMLU Score": 52.94954196217494,
    "BBH Score": 58.28330738049858,
    "Math Score": 59.74320241691843,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.603313795148634
  },
  {
    "Model Name": "ehristoforu/qwen2.5-with-lora-think-3b-it",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5346905766211627,
    "Overall Score": 24.256524060080704,
    "MMLU Score": 26.695478723404253,
    "BBH Score": 25.07946347199629,
    "Math Score": 23.6404833836858,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.805481853863244
  },
  {
    "Model Name": "ehristoforu/rmoe-v1",
    "Parameters (B)": 11.026,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.069017817120963,
    "Overall Score": 5.841232027005013,
    "MMLU Score": 1.383348108747044,
    "BBH Score": 2.067320668865772,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.9624674375689989
  },
  {
    "Model Name": "ehristoforu/rufalcon3-3b-it",
    "Parameters (B)": 3.228,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9813632832027144,
    "Overall Score": 20.64141899254107,
    "MMLU Score": 14.976728723404252,
    "BBH Score": 18.21435758381163,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.033412749228866
  },
  {
    "Model Name": "ehristoforu/ruphi-4b",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1001005886744497,
    "Overall Score": 4.080739303536478,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 2.400631279750579,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.7094237977397193
  },
  {
    "Model Name": "ehristoforu/testq-32b",
    "Parameters (B)": 56.165,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 94.46409363188756,
    "Overall Score": 4.53854409737458,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 1.9328254204684496,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.04804517698608963
  },
  {
    "Model Name": "ehristoforu/tmoe",
    "Parameters (B)": 11.026,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.344954699169198,
    "Overall Score": 3.652324770801055,
    "MMLU Score": 2.1221187943262403,
    "BBH Score": 3.201360903411308,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.4972562691522355
  },
  {
    "Model Name": "ehristoforu/tmoe-v2",
    "Parameters (B)": 11.026,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.7213718338413955,
    "Overall Score": 5.712206463926581,
    "MMLU Score": 1.1155437352245865,
    "BBH Score": 2.062356861659844,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.7397916570849494
  },
  {
    "Model Name": "ehristoforu/trd-7b-it",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.421301667057972,
    "Overall Score": 6.323081412830128,
    "MMLU Score": 1.9835992907801416,
    "BBH Score": 2.722591215675422,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.448796170005633
  },
  {
    "Model Name": "ehristoforu/ud-14b",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.938748812040152,
    "Overall Score": 16.222391948468367,
    "MMLU Score": 15.724734042553193,
    "BBH Score": 6.295264416110146,
    "Math Score": 19.033232628398792,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.118666287852376
  },
  {
    "Model Name": "elinas/Chronos-Gold-12B-1.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.00506212983133,
    "Overall Score": 21.82816794846716,
    "MMLU Score": 27.979092789598106,
    "BBH Score": 35.90894700063131,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.263799217919114
  },
  {
    "Model Name": "ell44ot/gemma-2b-def",
    "Parameters (B)": 1.546,
    "Architecture": "GemmaModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8945953968520545,
    "Overall Score": 8.12291928068411,
    "MMLU Score": 6.3608156028368805,
    "BBH Score": 4.586419628734295,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.079992261605002
  },
  {
    "Model Name": "euclaise/ReMask-3B",
    "Parameters (B)": 2.795,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8936806068910378,
    "Overall Score": 7.294404589328096,
    "MMLU Score": 3.969045508274229,
    "BBH Score": 8.742082990875964,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.162205303642073
  },
  {
    "Model Name": "eworojoshua/vas-01",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3466237713459364,
    "Overall Score": 36.46642217879174,
    "MMLU Score": 37.19525709219858,
    "BBH Score": 34.808538150886584,
    "Math Score": 47.35649546827795,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.079888945034686
  },
  {
    "Model Name": "ewre324/Thinker-Llama-3.2-3B-Instruct-Reasoning",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1903661259480065,
    "Overall Score": 17.331991514504523,
    "MMLU Score": 20.960771276595743,
    "BBH Score": 19.41258301552284,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.560219025639142
  },
  {
    "Model Name": "ewre324/Thinker-Qwen2.5-0.5B-Instruct-Reasoning",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0242398933317165,
    "Overall Score": 8.066116427700267,
    "MMLU Score": 7.191932624113473,
    "BBH Score": 7.39460963380786,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.875221889143822
  },
  {
    "Model Name": "ewre324/Thinker-SmolLM2-135M-Instruct-Reasoning",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6681034901288193,
    "Overall Score": 5.843149272359046,
    "MMLU Score": 1.041666666666666,
    "BBH Score": 3.9733526107072055,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.745874492037766
  },
  {
    "Model Name": "ewre324/ewre324-R1-SmolLM2-135M-Distill",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7058207649530425,
    "Overall Score": 4.164698963034765,
    "MMLU Score": 1.4849290780141835,
    "BBH Score": 3.3830043659713684,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.900505014629087
  },
  {
    "Model Name": "experiment-llm/exp-3-q-r",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4673112319684305,
    "Overall Score": 29.50441044971987,
    "MMLU Score": 36.844341016548455,
    "BBH Score": 33.9949174008218,
    "Math Score": 27.870090634441087,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.107806583160308
  },
  {
    "Model Name": "facebook/opt-1.3b",
    "Parameters (B)": 1.3,
    "Architecture": "OPTForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8060095556904593,
    "Overall Score": 5.276689334204645,
    "MMLU Score": 1.1894208037825047,
    "BBH Score": 3.6480520895226793,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.546683345068318
  },
  {
    "Model Name": "facebook/opt-30b",
    "Parameters (B)": 30.0,
    "Architecture": "OPTForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.999689572535679,
    "Overall Score": 6.276874107966858,
    "MMLU Score": 1.8173758865248213,
    "BBH Score": 3.4984293851759607,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.0461998128536558
  },
  {
    "Model Name": "failspy/Llama-3-8B-Instruct-MopeyMule",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.646271822481612,
    "Overall Score": 15.63813259258844,
    "MMLU Score": 8.494015957446807,
    "BBH Score": 13.620495859752507,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.49911939148379
  },
  {
    "Model Name": "failspy/Llama-3-8B-Instruct-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4838118499630564,
    "Overall Score": 19.190256107675243,
    "MMLU Score": 19.35394503546099,
    "BBH Score": 18.86459884908717,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.933079155657799
  },
  {
    "Model Name": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 18.409422221815564,
    "Overall Score": 30.12935413704135,
    "MMLU Score": 38.35882092198581,
    "BBH Score": 37.87133313079306,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.6366268193543527
  },
  {
    "Model Name": "failspy/Meta-Llama-3-8B-Instruct-abliterated-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6525271459553947,
    "Overall Score": 23.933089775002568,
    "MMLU Score": 29.484338061465724,
    "BBH Score": 27.3350514750733,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.67753889374371
  },
  {
    "Model Name": "failspy/Phi-3-medium-4k-instruct-abliterated-v3",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.041962386455618,
    "Overall Score": 31.85112078051007,
    "MMLU Score": 37.77703900709219,
    "BBH Score": 46.73283933573803,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.470583371552406
  },
  {
    "Model Name": "failspy/llama-3-70B-Instruct-abliterated",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 18.748257920537103,
    "Overall Score": 35.89001866123902,
    "MMLU Score": 46.06050531914893,
    "BBH Score": 48.93981832466943,
    "Math Score": 24.3202416918429,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.9143121890767565
  },
  {
    "Model Name": "fblgit/TheBeagle-v2beta-32B-MGS",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 43.4101607790295,
    "Overall Score": 42.642045426579536,
    "MMLU Score": 54.61177600472813,
    "BBH Score": 58.0279762011676,
    "Math Score": 49.47129909365559,
    "Date Submitted": "2024-10-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.9823056321684709
  },
  {
    "Model Name": "fblgit/TheBeagle-v2beta-32B-MGS",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 11.366068492834712,
    "Overall Score": 40.28666965781717,
    "MMLU Score": 54.56560283687944,
    "BBH Score": 58.06602977613295,
    "Math Score": 39.42598187311178,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.5444683166579813
  },
  {
    "Model Name": "fblgit/UNA-SimpleSmaug-34b-v1beta",
    "Parameters (B)": 34.389,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.328932494608793,
    "Overall Score": 24.2920916316972,
    "MMLU Score": 39.328457446808514,
    "BBH Score": 32.775788922324494,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.8382605048149996
  },
  {
    "Model Name": "fblgit/UNA-TheBeagle-7b-v1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1212776454447984,
    "Overall Score": 19.64617077795868,
    "MMLU Score": 22.43831264775413,
    "BBH Score": 30.173396964633465,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.521236473206656
  },
  {
    "Model Name": "fblgit/UNA-ThePitbull-21.4B-v2",
    "Parameters (B)": 21.421,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.596827555203435,
    "Overall Score": 23.0265687976468,
    "MMLU Score": 27.95138888888889,
    "BBH Score": 46.78807384004312,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.009230501061889
  },
  {
    "Model Name": "fblgit/cybertron-v4-qw7B-MGS",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.493477162325461,
    "Overall Score": 32.40351871985633,
    "MMLU Score": 38.58968676122932,
    "BBH Score": 37.04162311029608,
    "Math Score": 34.894259818731115,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.995314017488829
  },
  {
    "Model Name": "fblgit/cybertron-v4-qw7B-UNAMGS",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9906577828823064,
    "Overall Score": 33.05949412905735,
    "MMLU Score": 38.894429669030735,
    "BBH Score": 37.70717271699329,
    "Math Score": 37.31117824773414,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.607321666906483
  },
  {
    "Model Name": "fblgit/juanako-7b-UNA",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2635809849796131,
    "Overall Score": 20.86306801598857,
    "MMLU Score": 19.67715721040189,
    "BBH Score": 30.415072015961297,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.51106519011536
  },
  {
    "Model Name": "fblgit/miniclaus-qw1.5B-UNAMGS",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.168255560000145,
    "Overall Score": 17.04510204797917,
    "MMLU Score": 21.52408392434988,
    "BBH Score": 18.562863710456668,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-11-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.5902169282011
  },
  {
    "Model Name": "fblgit/miniclaus-qw1.5B-UNAMGS-GRPO",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7445232139324949,
    "Overall Score": 17.440457138521808,
    "MMLU Score": 21.61643026004728,
    "BBH Score": 18.62661642012632,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.997262861987158
  },
  {
    "Model Name": "fblgit/pancho-v1-qw25-3B-UNAMGS",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.353076156225762,
    "Overall Score": 23.860634894188152,
    "MMLU Score": 30.73101359338061,
    "BBH Score": 28.66965021792132,
    "Math Score": 15.709969788519636,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.14018812398305
  },
  {
    "Model Name": "fblgit/una-cybertron-7b-v2-bf16",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2684111497211332,
    "Overall Score": 17.217324719799368,
    "MMLU Score": 16.02947695035461,
    "BBH Score": 14.966964848379982,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.573930443283068
  },
  {
    "Model Name": "fhai50032/RolePlayLake-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8652534422583942,
    "Overall Score": 22.754717527935792,
    "MMLU Score": 23.99896572104019,
    "BBH Score": 33.47958591100428,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.298326497891537
  },
  {
    "Model Name": "fhai50032/Unaligned-Thinker-PHI-4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.804351802825741,
    "Overall Score": 28.89926817829444,
    "MMLU Score": 46.07897458628841,
    "BBH Score": 51.92504876544175,
    "Math Score": 33.53474320241692,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.01642658213114
  },
  {
    "Model Name": "flammenai/Llama3.1-Flammades-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 20.569665756617702,
    "Overall Score": 36.99412053300816,
    "MMLU Score": 41.692523640661946,
    "BBH Score": 52.54794346693766,
    "Math Score": 20.921450151057403,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7984794196816911
  },
  {
    "Model Name": "flammenai/Mahou-1.2a-llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.864824470117286,
    "Overall Score": 21.791261651208817,
    "MMLU Score": 31.303560874704488,
    "BBH Score": 28.97258765529244,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.685422408597137
  },
  {
    "Model Name": "flammenai/Mahou-1.2a-mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.414893302171176,
    "Overall Score": 19.578990668864712,
    "MMLU Score": 24.03590425531915,
    "BBH Score": 31.166750037107487,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.107600717291188
  },
  {
    "Model Name": "flammenai/Mahou-1.5-llama3.1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 20.51998453529889,
    "Overall Score": 37.34491319969544,
    "MMLU Score": 41.65558510638298,
    "BBH Score": 52.36957740630965,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.819928915416772
  },
  {
    "Model Name": "flammenai/Mahou-1.5-mistral-nemo-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9652639935554133,
    "Overall Score": 26.88532589921436,
    "MMLU Score": 28.911790780141843,
    "BBH Score": 36.260510188013406,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.066756267787913
  },
  {
    "Model Name": "flammenai/flammen15-gutenberg-DPO-v1-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2550592138285477,
    "Overall Score": 21.61269842919876,
    "MMLU Score": 24.28523936170213,
    "BBH Score": 32.66511308584827,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-07-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.22046114722301
  },
  {
    "Model Name": "fluently-lm/FluentlyLM-Prinum",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 21.252760892194704,
    "Overall Score": 47.21693789116021,
    "MMLU Score": 53.42050827423167,
    "BBH Score": 59.48220341842799,
    "Math Score": 54.003021148036254,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.2216848968785565
  },
  {
    "Model Name": "fluently-lm/Llama-TI-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3607848501476378,
    "Overall Score": 21.06211976017516,
    "MMLU Score": 27.111037234042552,
    "BBH Score": 31.984332678202136,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.477920523505265
  },
  {
    "Model Name": "fluently-lm/Llama-TI-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.394032195701821,
    "Overall Score": 29.67161684095501,
    "MMLU Score": 30.28775118203309,
    "BBH Score": 32.26686716202457,
    "Math Score": 23.036253776435046,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.284742872109156
  },
  {
    "Model Name": "fluently-sets/FalconThink3-10B-IT",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7468140421406724,
    "Overall Score": 34.620674425220905,
    "MMLU Score": 38.16489361702128,
    "BBH Score": 44.975804333935,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.819324547445373
  },
  {
    "Model Name": "fluently-sets/reasoning-1-1k-demo",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.287029190192277,
    "Overall Score": 38.341663670523,
    "MMLU Score": 41.93262411347518,
    "BBH Score": 48.94403407214196,
    "Math Score": 42.82477341389728,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.664533976432432
  },
  {
    "Model Name": "formulae/mita-elite-sce-gen1.1-v1-7b-2-26-2025-exp",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6999443901946086,
    "Overall Score": 5.330152301711151,
    "MMLU Score": 1.9281914893617007,
    "BBH Score": 1.972761926273208,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.615108251998684
  },
  {
    "Model Name": "formulae/mita-elite-v1.1-7b-2-25-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6972605249137397,
    "Overall Score": 2.7660245822572627,
    "MMLU Score": 1.087839834515365,
    "BBH Score": 1.2532101774016815,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.9669886411531134
  },
  {
    "Model Name": "formulae/mita-elite-v1.1-gen2-7b-2-25-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6845783503955575,
    "Overall Score": 3.177509781551489,
    "MMLU Score": 1.124778368794326,
    "BBH Score": 1.9012033109847029,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.6415575072093445
  },
  {
    "Model Name": "formulae/mita-elite-v1.2-7b-2-26-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6878110636727482,
    "Overall Score": 5.726216814779033,
    "MMLU Score": 2.0667109929078,
    "BBH Score": 1.73642630312822,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.325275816591828
  },
  {
    "Model Name": "formulae/mita-gen3-7b-2-26-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6890507058814883,
    "Overall Score": 5.370051339073015,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 2.4970370370370367,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.793405177929858
  },
  {
    "Model Name": "formulae/mita-gen3-v1.2-7b-2-26-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6893794297608428,
    "Overall Score": 5.48428689826696,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 2.9759798497580423,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.955396783697986
  },
  {
    "Model Name": "formulae/mita-math-v2.3-2-25-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6780721044617208,
    "Overall Score": 3.592857717077292,
    "MMLU Score": 1.309471040189124,
    "BBH Score": 2.483286518149532,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.2986366692218345
  },
  {
    "Model Name": "formulae/mita-v1-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6772915173741988,
    "Overall Score": 5.852620472389429,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 2.731523677549061,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.641213306612103
  },
  {
    "Model Name": "formulae/mita-v1.1-7b-2-24-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.666018893029639,
    "Overall Score": 29.48261068378812,
    "MMLU Score": 39.15299940898345,
    "BBH Score": 35.44089953030106,
    "Math Score": 43.50453172205438,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 44.266928449544885
  },
  {
    "Model Name": "formulae/mita-v1.2-7b-2-24-2025",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.637930641049308,
    "Overall Score": 24.86325007402709,
    "MMLU Score": 26.206043144208035,
    "BBH Score": 28.413176799944807,
    "Math Score": 48.79154078549849,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.974848477462174
  },
  {
    "Model Name": "frameai/Loxa-4B",
    "Parameters (B)": 4.018,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5449268287887865,
    "Overall Score": 17.545787467583636,
    "MMLU Score": 20.01883865248227,
    "BBH Score": 18.307902854016177,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.357034612014234
  },
  {
    "Model Name": "freewheelin/free-evo-qwen72b-v0.8-re",
    "Parameters (B)": 72.288,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 23.57958120720033,
    "Overall Score": 32.4749309635116,
    "MMLU Score": 43.00384160756501,
    "BBH Score": 45.31740264996691,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.377247995973523
  },
  {
    "Model Name": "freewheelin/free-solar-evo-v0.1",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6022221103142726,
    "Overall Score": 16.42145204334013,
    "MMLU Score": 26.824763593380613,
    "BBH Score": 22.63518273833165,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.249173281049712
  },
  {
    "Model Name": "freewheelin/free-solar-evo-v0.11",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.627003957376557,
    "Overall Score": 16.77976316256584,
    "MMLU Score": 27.41578014184397,
    "BBH Score": 23.18242496978891,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.313289704360749
  },
  {
    "Model Name": "freewheelin/free-solar-evo-v0.13",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.631911769440353,
    "Overall Score": 17.40590132423633,
    "MMLU Score": 27.44348404255319,
    "BBH Score": 23.35420388572778,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.665957345356667
  },
  {
    "Model Name": "fulim/FineLlama-3.1-8B",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.591880040179111,
    "Overall Score": 13.250843761720356,
    "MMLU Score": 24.08207742316785,
    "BBH Score": 22.46259684566392,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.324021551416294
  },
  {
    "Model Name": "gabrielmbmb/SmolLM-1.7B-Instruct-IFEval",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.2694907682513625,
    "Overall Score": 5.399069361603981,
    "MMLU Score": 1.7342641843971618,
    "BBH Score": 4.50167515878636,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 20.03433882591518
  },
  {
    "Model Name": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.691347914392641,
    "Overall Score": 12.108403733798744,
    "MMLU Score": 7.265809692671395,
    "BBH Score": 15.276579446085892,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.499010948768865
  },
  {
    "Model Name": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9227136711196464,
    "Overall Score": 20.99904174519205,
    "MMLU Score": 29.76137706855792,
    "BBH Score": 28.91423515333936,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.921564692970513
  },
  {
    "Model Name": "gbueno86/Brinebreath-Llama-3.1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 21.119508800657457,
    "Overall Score": 36.25499179659365,
    "MMLU Score": 46.62381796690308,
    "BBH Score": 55.46361848802468,
    "Math Score": 29.75830815709969,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.716658855032889
  },
  {
    "Model Name": "gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 21.804586425941253,
    "Overall Score": 38.69613307300818,
    "MMLU Score": 45.27556146572104,
    "BBH Score": 51.50838639894525,
    "Math Score": 29.38066465256798,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.7746786073855907
  },
  {
    "Model Name": "ghost-x/ghost-8b-beta-1608",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6978621748692648,
    "Overall Score": 16.04724368250191,
    "MMLU Score": 20.44363179669031,
    "BBH Score": 23.46396385965484,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.451440711751262
  },
  {
    "Model Name": "glaiveai/Reflection-Llama-3.1-70B",
    "Parameters (B)": 69.5,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 50.48755279544398,
    "Overall Score": 34.5194783867829,
    "MMLU Score": 59.349143026004725,
    "BBH Score": 37.96048632437056,
    "Math Score": 27.567975830815712,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.6837225509155189
  },
  {
    "Model Name": "gmonsoon/SahabatAI-Llama-11B-Test",
    "Parameters (B)": 11.52,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.09994373573564,
    "Overall Score": 16.26561908313948,
    "MMLU Score": 24.248300827423165,
    "BBH Score": 24.457264432236546,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.745740424536376
  },
  {
    "Model Name": "gmonsoon/SahabatAI-MediChatIndo-8B-v1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3534438936956568,
    "Overall Score": 17.29986493129456,
    "MMLU Score": 23.41718380614657,
    "BBH Score": 23.64009974170933,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.782107194747674
  },
  {
    "Model Name": "gmonsoon/SahabatAI-Rebase-8B-Test",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3043100372014074,
    "Overall Score": 23.51679147976689,
    "MMLU Score": 29.595153664302604,
    "BBH Score": 32.00222111760954,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.030062492063383
  },
  {
    "Model Name": "gmonsoon/StockSeaLLMs-7B-v1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.393780624954565,
    "Overall Score": 25.09345053151665,
    "MMLU Score": 32.79957151300236,
    "BBH Score": 34.01262496222566,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.003873839424806
  },
  {
    "Model Name": "gmonsoon/gemma2-9b-sahabatai-v1-instruct-BaseTIES",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5629694373942296,
    "Overall Score": 33.8045690236527,
    "MMLU Score": 37.186022458628834,
    "BBH Score": 43.401341987357206,
    "Math Score": 19.939577039274926,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.48775161214282
  },
  {
    "Model Name": "godlikehhd/alpaca_data_full_2",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4734952780887614,
    "Overall Score": 16.073236944099644,
    "MMLU Score": 20.600620567375884,
    "BBH Score": 18.446949715094675,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.908237836328794
  },
  {
    "Model Name": "godlikehhd/alpaca_data_full_3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6983988550920976,
    "Overall Score": 21.16254856881883,
    "MMLU Score": 26.18757387706856,
    "BBH Score": 25.1691372567158,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.460293708612555
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ifd_max_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9333451087343216,
    "Overall Score": 15.169551135723683,
    "MMLU Score": 21.293218085106385,
    "BBH Score": 15.966392816231314,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.846271763479693
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ifd_max_2600_3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3536223757152306,
    "Overall Score": 18.603034635124093,
    "MMLU Score": 25.42109929078014,
    "BBH Score": 24.47251859261156,
    "Math Score": 15.93655589123867,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.904001435009688
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ifd_me_max_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.754302786120011,
    "Overall Score": 16.250397979625767,
    "MMLU Score": 22.02275413711584,
    "BBH Score": 16.82395652793481,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.263166032795713
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ifd_min_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7676294938866262,
    "Overall Score": 16.51777329215277,
    "MMLU Score": 21.034648345153663,
    "BBH Score": 18.61162063219574,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.344590226220905
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ins_ans_max_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7716212707932837,
    "Overall Score": 15.92444135220606,
    "MMLU Score": 21.11776004728132,
    "BBH Score": 16.26868941225307,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.988626189318403
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ins_max_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1128275845725115,
    "Overall Score": 15.68373909505621,
    "MMLU Score": 21.28398345153665,
    "BBH Score": 17.540671840924308,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.4231040949938665
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ins_min_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.120538562004114,
    "Overall Score": 16.228325384264654,
    "MMLU Score": 20.886894208037827,
    "BBH Score": 17.53633236067362,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.652926324964973
  },
  {
    "Model Name": "godlikehhd/alpaca_data_ins_min_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9986224648680768,
    "Overall Score": 16.38323586874574,
    "MMLU Score": 21.65336879432624,
    "BBH Score": 18.69127786761616,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.197263943907059
  },
  {
    "Model Name": "godlikehhd/alpaca_data_sampled_ifd_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7249114740707934,
    "Overall Score": 15.703649205002767,
    "MMLU Score": 21.071586879432623,
    "BBH Score": 15.96825358073914,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.104031969792707
  },
  {
    "Model Name": "godlikehhd/alpaca_data_sampled_ifd_new_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7552255359802686,
    "Overall Score": 16.53778065653717,
    "MMLU Score": 21.38556442080378,
    "BBH Score": 17.561425245080894,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.422026011774637
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_0.1_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.044420604704493,
    "Overall Score": 15.917241105745404,
    "MMLU Score": 21.3670951536643,
    "BBH Score": 18.621496831589138,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.785697849609638
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_0.3_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.066964020498706,
    "Overall Score": 15.960793093536113,
    "MMLU Score": 21.256279550827426,
    "BBH Score": 16.924620676581448,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.721853372989617
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_0.7_2600",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.723766199098803,
    "Overall Score": 16.630379005915092,
    "MMLU Score": 22.031988770685576,
    "BBH Score": 18.14398633190028,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.647699911165198
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_2500",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.116895052230952,
    "Overall Score": 16.49115247845423,
    "MMLU Score": 21.551787825059098,
    "BBH Score": 17.930587543977595,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.790255100778163
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_2600_3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.060019494476361,
    "Overall Score": 19.567090626055247,
    "MMLU Score": 26.021350472813243,
    "BBH Score": 26.00926717613288,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.498497795055592
  },
  {
    "Model Name": "godlikehhd/alpaca_data_score_max_5200",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.117059548061321,
    "Overall Score": 16.366037527264833,
    "MMLU Score": 21.607195626477537,
    "BBH Score": 18.575115132209195,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.730551340538291
  },
  {
    "Model Name": "godlikehhd/ifd_2500_qwen",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7273969106070146,
    "Overall Score": 16.206918147182165,
    "MMLU Score": 21.34862588652482,
    "BBH Score": 19.136234077656635,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.38227806687867
  },
  {
    "Model Name": "godlikehhd/ifd_new_correct_all_sample_2500_qwen",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7822922819233824,
    "Overall Score": 15.324012443597336,
    "MMLU Score": 20.988475177304963,
    "BBH Score": 15.682840817827374,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.597923359158713
  },
  {
    "Model Name": "godlikehhd/ifd_new_correct_sample_2500_qwen",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8353397447837017,
    "Overall Score": 16.393782607601025,
    "MMLU Score": 21.46867612293144,
    "BBH Score": 16.877004154041817,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.932287689074736
  },
  {
    "Model Name": "godlikehhd/ifd_new_qwen_2500",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.001242073281229,
    "Overall Score": 15.886984394789131,
    "MMLU Score": 21.22857565011821,
    "BBH Score": 17.63795023834911,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.938562059481835
  },
  {
    "Model Name": "godlikehhd/qwen-2.5-1.5b-cherry",
    "Parameters (B)": 0.772,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8943105830699527,
    "Overall Score": 14.683674027867731,
    "MMLU Score": 21.3670951536643,
    "BBH Score": 16.323588748077068,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.751460694513522
  },
  {
    "Model Name": "godlikehhd/qwen_2.5-1.5b-cherry_new",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7826744384672384,
    "Overall Score": 15.370243206890224,
    "MMLU Score": 21.043882978723403,
    "BBH Score": 17.59708505979556,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.62201357422599
  },
  {
    "Model Name": "godlikehhd/qwen_full_data_alpaca",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6464101240149864,
    "Overall Score": 15.856124752105812,
    "MMLU Score": 20.563682033096924,
    "BBH Score": 18.614215673166097,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.630725978189794
  },
  {
    "Model Name": "godlikehhd/qwen_ins_ans_2500",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.385132610918049,
    "Overall Score": 14.783348090526234,
    "MMLU Score": 20.10195035460993,
    "BBH Score": 17.695311631481697,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.367140017748665
  },
  {
    "Model Name": "google/codegemma-1.1-2b",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.8997663921053336,
    "Overall Score": 7.133867903047553,
    "MMLU Score": 3.0917553191489344,
    "BBH Score": 7.551225280004151,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-08-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.7551290162269653
  },
  {
    "Model Name": "google/flan-t5-base",
    "Parameters (B)": 0.248,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3132428808489122,
    "Overall Score": 6.415642124982084,
    "MMLU Score": 3.969045508274229,
    "BBH Score": 11.33769367730488,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-08-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 20.481366113078778
  },
  {
    "Model Name": "google/flan-t5-large",
    "Parameters (B)": 0.783,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4669827432706164,
    "Overall Score": 9.658122925542836,
    "MMLU Score": 7.87529550827423,
    "BBH Score": 17.510018280067285,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-08-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 20.6819696545959
  },
  {
    "Model Name": "google/flan-t5-small",
    "Parameters (B)": 0.077,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2862604845502776,
    "Overall Score": 6.129661810537869,
    "MMLU Score": 2.5930851063829774,
    "BBH Score": 6.36311196167965,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 21.41288141871108
  },
  {
    "Model Name": "google/flan-t5-xl",
    "Parameters (B)": 2.85,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6978586885867614,
    "Overall Score": 11.70507257989283,
    "MMLU Score": 12.741947399527188,
    "BBH Score": 22.6950558112154,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.772840650013052
  },
  {
    "Model Name": "google/flan-t5-xl",
    "Parameters (B)": 2.85,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2853517301787843,
    "Overall Score": 11.58716743755607,
    "MMLU Score": 12.686539598108748,
    "BBH Score": 22.837587663523298,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 40.60661356528747
  },
  {
    "Model Name": "google/flan-t5-xxl",
    "Parameters (B)": 11.267,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4129536546292594,
    "Overall Score": 13.662077060970686,
    "MMLU Score": 14.921320921985814,
    "BBH Score": 30.11925560010588,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.669161487505008
  },
  {
    "Model Name": "google/flan-ul2",
    "Parameters (B)": 19.46,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1199325668968465,
    "Overall Score": 13.675998692966036,
    "MMLU Score": 16.592789598108748,
    "BBH Score": 30.02029012567709,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.211448347162575
  },
  {
    "Model Name": "google/gemma-1.1-2b-it",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6584295628455202,
    "Overall Score": 8.053373854341979,
    "MMLU Score": 5.372709810874704,
    "BBH Score": 5.862826722774347,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.231185093721939
  },
  {
    "Model Name": "google/gemma-1.1-7b-it",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.156598379926708,
    "Overall Score": 17.693584228972615,
    "MMLU Score": 17.5993646572104,
    "BBH Score": 15.93420938501317,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.297950036981575
  },
  {
    "Model Name": "google/gemma-2-27b",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 11.22849855677268,
    "Overall Score": 23.926167340782825,
    "MMLU Score": 37.4538268321513,
    "BBH Score": 37.390737454186464,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2024-08-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.1308429813486782
  },
  {
    "Model Name": "google/gemma-2-27b-it",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.652422373385471,
    "Overall Score": 36.17428251510342,
    "MMLU Score": 38.34958628841608,
    "BBH Score": 49.27284215130387,
    "Math Score": 23.86706948640484,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.7476895556131495
  },
  {
    "Model Name": "google/gemma-2-2b",
    "Parameters (B)": 2.614,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5187957227139828,
    "Overall Score": 10.129463155055184,
    "MMLU Score": 13.111332742316788,
    "BBH Score": 11.755807532236112,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.669404583886064
  },
  {
    "Model Name": "google/gemma-2-2b",
    "Parameters (B)": 2.614,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.8365147022631594,
    "Overall Score": 10.359615568466916,
    "MMLU Score": 13.51765661938534,
    "BBH Score": 12.497306228573644,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 3.652234046310893
  },
  {
    "Model Name": "google/gemma-2-2b-it",
    "Parameters (B)": 2.614,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2347432742058528,
    "Overall Score": 17.046939294966545,
    "MMLU Score": 17.22074468085106,
    "BBH Score": 17.980792881523424,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.806059649063963
  },
  {
    "Model Name": "google/gemma-2-2b-jpn-it",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.011437210514093,
    "Overall Score": 17.11540570593849,
    "MMLU Score": 17.53472222222222,
    "BBH Score": 18.52562644983273,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.92186675358629
  },
  {
    "Model Name": "google/gemma-2-2b-jpn-it",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.708800498080021,
    "Overall Score": 16.678630066922224,
    "MMLU Score": 16.297281323877066,
    "BBH Score": 17.848086390818036,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.760431417044908
  },
  {
    "Model Name": "google/gemma-2-9b",
    "Parameters (B)": 9.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 8.61623967949076,
    "Overall Score": 21.20528677610069,
    "MMLU Score": 34.48027482269504,
    "BBH Score": 34.09681853589784,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.461083670475839
  },
  {
    "Model Name": "google/gemma-2-9b-it",
    "Parameters (B)": 9.0,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.544268073096287,
    "Overall Score": 32.07276025267082,
    "MMLU Score": 31.949985224586293,
    "BBH Score": 42.136619683664655,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.251275265130876
  },
  {
    "Model Name": "google/gemma-2b",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.2959887261338292,
    "Overall Score": 7.321959810488082,
    "MMLU Score": 4.061391843971631,
    "BBH Score": 8.246263426638125,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.6497094942568085
  },
  {
    "Model Name": "google/gemma-2b-it",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7059006620955186,
    "Overall Score": 7.485804130315127,
    "MMLU Score": 3.9228723404255295,
    "BBH Score": 5.214303022163619,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.604614122464428
  },
  {
    "Model Name": "google/gemma-7b",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.509828115639864,
    "Overall Score": 15.442818570272308,
    "MMLU Score": 21.644134160756497,
    "BBH Score": 21.11609932329174,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-06-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.152938710838875
  },
  {
    "Model Name": "google/gemma-7b-it",
    "Parameters (B)": 8.538,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1990245623069615,
    "Overall Score": 13.067087110466217,
    "MMLU Score": 7.7183067375886525,
    "BBH Score": 11.940832085290182,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.898097938314727
  },
  {
    "Model Name": "google/mt5-base",
    "Parameters (B)": 0.39,
    "Architecture": "MT5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4000796363289305,
    "Overall Score": 3.716339524462038,
    "MMLU Score": 0.7738622931442081,
    "BBH Score": 1.29855138817669,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.28899945661469
  },
  {
    "Model Name": "google/mt5-small",
    "Parameters (B)": 0.17,
    "Architecture": "MT5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3609873487215465,
    "Overall Score": 4.255928173277352,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.070971479500891,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.78968788892442
  },
  {
    "Model Name": "google/mt5-xl",
    "Parameters (B)": 3.23,
    "Architecture": "MT5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.807534449154364,
    "Overall Score": 5.191420153031625,
    "MMLU Score": 1.3279403073286051,
    "BBH Score": 3.2824619143354035,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.872100255383999
  },
  {
    "Model Name": "google/mt5-xxl",
    "Parameters (B)": 11.9,
    "Architecture": "T5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.563877005244583,
    "Overall Score": 5.10307678308611,
    "MMLU Score": 0.9862588652482256,
    "BBH Score": 2.504710800447747,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1181451159226914
  },
  {
    "Model Name": "google/recurrentgemma-2b",
    "Parameters (B)": 2.683,
    "Architecture": "RecurrentGemmaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.5350494252772,
    "Overall Score": 7.01512699699078,
    "MMLU Score": 1.9558953900709208,
    "BBH Score": 4.8203622310347365,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.267400967542301
  },
  {
    "Model Name": "google/recurrentgemma-2b-it",
    "Parameters (B)": 2.683,
    "Architecture": "RecurrentGemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.059051279422074,
    "Overall Score": 7.995905374047496,
    "MMLU Score": 4.467715721040189,
    "BBH Score": 7.978763840391559,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.613851368832924
  },
  {
    "Model Name": "google/recurrentgemma-9b",
    "Parameters (B)": 9.0,
    "Architecture": "RecurrentGemmaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 26.08737700441429,
    "Overall Score": 13.709460856107864,
    "MMLU Score": 17.830230496453904,
    "BBH Score": 15.323368888997411,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 0.5255208622081117
  },
  {
    "Model Name": "google/recurrentgemma-9b-it",
    "Parameters (B)": 9.0,
    "Architecture": "RecurrentGemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 15.127758447638216,
    "Overall Score": 19.218115006306835,
    "MMLU Score": 20.480570330969268,
    "BBH Score": 21.62158008474012,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-07-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.2703874848892247
  },
  {
    "Model Name": "google/switch-base-8",
    "Parameters (B)": 0.62,
    "Architecture": "SwitchTransformersForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.2934058677548048,
    "Overall Score": 3.2959502683966075,
    "MMLU Score": 1.087839834515365,
    "BBH Score": 1.7024781049821334,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.233416337641165
  },
  {
    "Model Name": "google/umt5-base",
    "Parameters (B)": -1.0,
    "Architecture": "UMT5ForConditionalGeneration",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3360920891163983,
    "Overall Score": 3.516574726407488,
    "MMLU Score": 0.8662086288416063,
    "BBH Score": 0.8135531788472962,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.631985291323081
  },
  {
    "Model Name": "goulue5/merging_LLM",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.102930181856804,
    "Overall Score": 16.712100078199907,
    "MMLU Score": 21.75494976359338,
    "BBH Score": 18.28283029131199,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.152455117389904
  },
  {
    "Model Name": "gpt2",
    "Parameters (B)": 0.137,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3239280124164491,
    "Overall Score": 6.39102973137443,
    "MMLU Score": 1.6603871158392434,
    "BBH Score": 2.714297847387736,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.72978404583911
  },
  {
    "Model Name": "gpt2",
    "Parameters (B)": 0.137,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.0392451730685468,
    "Overall Score": 5.977736928104574,
    "MMLU Score": 0.0,
    "BBH Score": 9.199754901960786,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 152.3177619235792
  },
  {
    "Model Name": "gradientai/Llama-3-8B-Instruct-Gradient-1048k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7743289735325676,
    "Overall Score": 18.283333977044872,
    "MMLU Score": 21.56102245862884,
    "BBH Score": 21.01052898715872,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.304365340235641
  },
  {
    "Model Name": "grimjim/DeepSauerHuatuoSkywork-R1-o1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3692639052605395,
    "Overall Score": 26.940480296007976,
    "MMLU Score": 32.8549793144208,
    "BBH Score": 32.76923482357123,
    "Math Score": 22.20543806646526,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.67515552882541
  },
  {
    "Model Name": "grimjim/Gigantes-v1-gemma2-9b-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.995648654632423,
    "Overall Score": 33.23742832143159,
    "MMLU Score": 35.83776595744681,
    "BBH Score": 42.79787696550411,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.09523584150423
  },
  {
    "Model Name": "grimjim/Gigantes-v2-gemma2-9b-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.03773168323378,
    "Overall Score": 33.876785775265446,
    "MMLU Score": 36.21638593380615,
    "BBH Score": 42.70163259850296,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.152000672818584
  },
  {
    "Model Name": "grimjim/Gigantes-v3-gemma2-9b-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.035863590801693,
    "Overall Score": 33.49043715511172,
    "MMLU Score": 35.847000591016545,
    "BBH Score": 42.795367767587656,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.031601438412377
  },
  {
    "Model Name": "grimjim/HuatuoSkywork-o1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3971466462844655,
    "Overall Score": 24.47799926837126,
    "MMLU Score": 23.278664302600472,
    "BBH Score": 28.33277757558808,
    "Math Score": 38.82175226586103,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.51999286078337
  },
  {
    "Model Name": "grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0950967078398597,
    "Overall Score": 20.83668391168813,
    "MMLU Score": 29.17036052009456,
    "BBH Score": 28.258014912987704,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.027254636523992
  },
  {
    "Model Name": "grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.233883346225575,
    "Overall Score": 24.04094205100742,
    "MMLU Score": 29.82601950354609,
    "BBH Score": 29.07328591447649,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.48396671739528
  },
  {
    "Model Name": "grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8038294368260208,
    "Overall Score": 23.21730172505012,
    "MMLU Score": 29.4566341607565,
    "BBH Score": 29.415990262794168,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.871118106323168
  },
  {
    "Model Name": "grimjim/Llama-3.1-Bonsaikraft-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3560108759332417,
    "Overall Score": 22.8566402455144,
    "MMLU Score": 30.71254432624113,
    "BBH Score": 32.58754251798589,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.855794191019204
  },
  {
    "Model Name": "grimjim/Llama-Nephilim-Metamorphosis-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3459978060195088,
    "Overall Score": 23.00221313012307,
    "MMLU Score": 31.21121453900709,
    "BBH Score": 28.18246234355982,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.089339245022273
  },
  {
    "Model Name": "grimjim/Llama3.1-SuperNovaLite-HuatuoSkywork-o1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3439985673215311,
    "Overall Score": 25.96166505323568,
    "MMLU Score": 29.81678486997636,
    "BBH Score": 32.95297252204676,
    "Math Score": 30.06042296072508,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.31673566064505
  },
  {
    "Model Name": "grimjim/Magnolia-v1-Gemma2-8k-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.0740254212442935,
    "Overall Score": 25.51284798552607,
    "MMLU Score": 36.022458628841605,
    "BBH Score": 36.79001219814328,
    "Math Score": 16.842900302114806,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.26231929051977
  },
  {
    "Model Name": "grimjim/Magnolia-v2-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.002732247053589,
    "Overall Score": 21.577222272679126,
    "MMLU Score": 28.9025561465721,
    "BBH Score": 32.50462527039537,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.773892668090525
  },
  {
    "Model Name": "grimjim/Magnolia-v2-Gemma2-8k-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3294433701942467,
    "Overall Score": 34.30134506171324,
    "MMLU Score": 37.01979905437352,
    "BBH Score": 42.84461695501066,
    "Math Score": 22.80966767371601,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.302426336121172
  },
  {
    "Model Name": "grimjim/Magnolia-v3-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0001082476739587,
    "Overall Score": 22.786766373418164,
    "MMLU Score": 29.05954491725768,
    "BBH Score": 32.92491590836766,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.392766566468694
  },
  {
    "Model Name": "grimjim/Magnolia-v3-Gemma2-8k-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.41703063359954,
    "Overall Score": 34.353725481327054,
    "MMLU Score": 37.07520685579196,
    "BBH Score": 42.86822994504556,
    "Math Score": 23.187311178247736,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.053677934147883
  },
  {
    "Model Name": "grimjim/Magnolia-v4-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.823437390007458,
    "Overall Score": 22.59384028115097,
    "MMLU Score": 29.6875,
    "BBH Score": 34.57748311994204,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.43844347527908
  },
  {
    "Model Name": "grimjim/Magnolia-v5a-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8485829512595052,
    "Overall Score": 22.851795395693376,
    "MMLU Score": 28.9025561465721,
    "BBH Score": 32.694922623458645,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.92935954201732
  },
  {
    "Model Name": "grimjim/Magot-v1-Gemma2-8k-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.908073960813349,
    "Overall Score": 24.587402832733005,
    "MMLU Score": 37.07520685579196,
    "BBH Score": 42.81812817526611,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.161661312267682
  },
  {
    "Model Name": "grimjim/Magot-v2-Gemma2-8k-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.096882421506472,
    "Overall Score": 32.97995555494225,
    "MMLU Score": 35.810062056737586,
    "BBH Score": 41.45929075390556,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.649405132694454
  },
  {
    "Model Name": "grimjim/SauerHuatuoSkywork-o1-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.399417526016181,
    "Overall Score": 26.68447204012895,
    "MMLU Score": 33.23359929078014,
    "BBH Score": 32.08877158243549,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.06827057975577
  },
  {
    "Model Name": "grimjim/llama-3-Nephilim-v1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7137452405943856,
    "Overall Score": 21.729737138539548,
    "MMLU Score": 31.06346040189125,
    "BBH Score": 29.90753748907924,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.679677599573044
  },
  {
    "Model Name": "grimjim/llama-3-Nephilim-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4017468314255033,
    "Overall Score": 20.60024991305908,
    "MMLU Score": 29.34581855791962,
    "BBH Score": 29.8962638406202,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.696127325723792
  },
  {
    "Model Name": "grimjim/llama-3-Nephilim-v2.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.426316661154474,
    "Overall Score": 20.43496712781404,
    "MMLU Score": 29.38275709219858,
    "BBH Score": 29.81966445991054,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.327089968418225
  },
  {
    "Model Name": "grimjim/llama-3-Nephilim-v3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1281793692381223,
    "Overall Score": 20.600988872221105,
    "MMLU Score": 29.02260638297872,
    "BBH Score": 28.955635498374203,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 18.26038432712458
  },
  {
    "Model Name": "gupta-tanish/llama-7b-dpo-baseline",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5626329206994063,
    "Overall Score": 11.857290104453796,
    "MMLU Score": 11.421394799054372,
    "BBH Score": 14.380522116367189,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.588020159684519
  },
  {
    "Model Name": "gz987/qwen2.5-7b-cabs-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6224453856348778,
    "Overall Score": 36.56161315485646,
    "MMLU Score": 37.84168144208039,
    "BBH Score": 35.838183211484505,
    "Math Score": 47.9607250755287,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 58.738668481837294
  },
  {
    "Model Name": "gz987/qwen2.5-7b-cabs-v0.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6512716382261822,
    "Overall Score": 36.614018827547945,
    "MMLU Score": 37.74933510638298,
    "BBH Score": 36.27590658422937,
    "Math Score": 49.01812688821752,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 56.219274229829345
  },
  {
    "Model Name": "gz987/qwen2.5-7b-cabs-v0.3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6308176980387323,
    "Overall Score": 36.93504663341147,
    "MMLU Score": 37.79550827423168,
    "BBH Score": 35.95665199827286,
    "Math Score": 49.320241691842895,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 58.551062768602996
  },
  {
    "Model Name": "gz987/qwen2.5-7b-cabs-v0.4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6297121050369008,
    "Overall Score": 36.88194596713293,
    "MMLU Score": 37.73086583924351,
    "BBH Score": 36.35843837533925,
    "Math Score": 48.48942598187311,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 58.569536256527364
  },
  {
    "Model Name": "h2oai/h2o-danube-1.8b-chat",
    "Parameters (B)": 1.831,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.2625451227687596,
    "Overall Score": 6.953761979021041,
    "MMLU Score": 3.4888445626477527,
    "BBH Score": 5.269859154260847,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.485968985779515
  },
  {
    "Model Name": "h2oai/h2o-danube3-4b-base",
    "Parameters (B)": 3.962,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.8890039292136087,
    "Overall Score": 10.0908487494014,
    "MMLU Score": 12.326388888888888,
    "BBH Score": 10.564444044561542,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.35073582669935
  },
  {
    "Model Name": "h2oai/h2o-danube3-4b-chat",
    "Parameters (B)": 3.962,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9252426738721852,
    "Overall Score": 11.571247407067569,
    "MMLU Score": 13.6469414893617,
    "BBH Score": 8.839702966263845,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-07-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.506175659453039
  },
  {
    "Model Name": "h2oai/h2o-danube3-500m-chat",
    "Parameters (B)": 0.514,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.4378067021827259,
    "Overall Score": 5.204440277019856,
    "MMLU Score": 1.595744680851063,
    "BBH Score": 3.065370444981646,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.887529932896497
  },
  {
    "Model Name": "h2oai/h2o-danube3.1-4b-chat",
    "Parameters (B)": 3.962,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5982811536989042,
    "Overall Score": 16.41212819519095,
    "MMLU Score": 19.09537529550828,
    "BBH Score": 10.942062527495288,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 27.4321330259563
  },
  {
    "Model Name": "haoranxu/ALMA-13B-R",
    "Parameters (B)": 13.0,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9252597252610324,
    "Overall Score": 3.877301978282112,
    "MMLU Score": 9.075797872340424,
    "BBH Score": 8.819669166822672,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.013911124514079
  },
  {
    "Model Name": "haoranxu/Llama-3-Instruct-8B-CPO-SimPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.490670077540168,
    "Overall Score": 24.910737255485603,
    "MMLU Score": 29.84448877068557,
    "BBH Score": 29.762188091412483,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2024-07-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 16.71110035065043
  },
  {
    "Model Name": "haoranxu/Llama-3-Instruct-8B-SimPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1591559961402582,
    "Overall Score": 24.990729234610715,
    "MMLU Score": 30.37086288416076,
    "BBH Score": 28.2263760762505,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-07-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 21.55941850607209
  },
  {
    "Model Name": "hatemmahmoud/qwen2.5-1.5b-sft-raft-grpo-hra-doc",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6156239180882589,
    "Overall Score": 18.16435302663075,
    "MMLU Score": 19.73256501182033,
    "BBH Score": 19.805226737644773,
    "Math Score": 21.75226586102719,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.505599917296614
  },
  {
    "Model Name": "hon9kon9ize/CantoneseLLMChat-v0.5",
    "Parameters (B)": 6.069,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.6672683498631755,
    "Overall Score": 15.959800818271107,
    "MMLU Score": 16.712839834515364,
    "BBH Score": 20.761385180655164,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-07-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 9.572424750689263
  },
  {
    "Model Name": "hon9kon9ize/CantoneseLLMChat-v1.0-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.662792912775296,
    "Overall Score": 23.503869934977185,
    "MMLU Score": 30.94341016548463,
    "BBH Score": 28.53613616746739,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.416925688864107
  },
  {
    "Model Name": "hongbai12/li-0.4-pre",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.969251663521824,
    "Overall Score": 36.49263658043271,
    "MMLU Score": 44.61066784869976,
    "BBH Score": 46.72554509961223,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.531220390170454
  },
  {
    "Model Name": "hotmailuser/Deepseek-qwen-modelstock-2B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1776806671769675,
    "Overall Score": 13.734549593045678,
    "MMLU Score": 10.11931146572104,
    "BBH Score": 10.02016891992718,
    "Math Score": 33.987915407854985,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.662371622325203
  },
  {
    "Model Name": "hotmailuser/Falcon3Slerp1-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6440682251388408,
    "Overall Score": 31.776680017785,
    "MMLU Score": 37.79550827423168,
    "BBH Score": 44.74398729818869,
    "Math Score": 25.98187311178248,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.32807868426596
  },
  {
    "Model Name": "hotmailuser/Falcon3Slerp2-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5033467329832644,
    "Overall Score": 31.30860573299493,
    "MMLU Score": 37.43535756501182,
    "BBH Score": 44.5423501026709,
    "Math Score": 23.187311178247736,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.825937919767618
  },
  {
    "Model Name": "hotmailuser/Falcon3Slerp4-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6148316233690154,
    "Overall Score": 30.717492522295817,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 43.75873169992713,
    "Math Score": 22.88519637462236,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.022102414745916
  },
  {
    "Model Name": "hotmailuser/FalconSlerp-3B",
    "Parameters (B)": 3.228,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.922140828783185,
    "Overall Score": 22.47273640583823,
    "MMLU Score": 21.86576536643026,
    "BBH Score": 24.39400805864265,
    "Math Score": 17.598187311178247,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.370178289895513
  },
  {
    "Model Name": "hotmailuser/FalconSlerp1-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2278224733096967,
    "Overall Score": 28.681197911346505,
    "MMLU Score": 34.766548463356976,
    "BBH Score": 35.04308988047655,
    "Math Score": 23.791540785498487,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.359401326181928
  },
  {
    "Model Name": "hotmailuser/FalconSlerp2-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2316635207541564,
    "Overall Score": 31.286856255059003,
    "MMLU Score": 34.895833333333336,
    "BBH Score": 36.81735294513948,
    "Math Score": 29.83383685800604,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 25.40211326215283
  },
  {
    "Model Name": "hotmailuser/FalconSlerp3-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5993031087557148,
    "Overall Score": 30.415115815404064,
    "MMLU Score": 36.92745271867612,
    "BBH Score": 42.818643189920245,
    "Math Score": 22.734138972809667,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.017730690880445
  },
  {
    "Model Name": "hotmailuser/FalconSlerp3-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2133243870772683,
    "Overall Score": 31.531501918893497,
    "MMLU Score": 34.748079196217496,
    "BBH Score": 36.83401609166295,
    "Math Score": 31.57099697885196,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 25.98769319625113
  },
  {
    "Model Name": "hotmailuser/FalconSlerp4-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2299334634956316,
    "Overall Score": 30.51227574563949,
    "MMLU Score": 33.6860963356974,
    "BBH Score": 36.46810457203872,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.8080702340756
  },
  {
    "Model Name": "hotmailuser/FalconSlerp6-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.184894649891033,
    "Overall Score": 28.79520632630417,
    "MMLU Score": 33.279772458628834,
    "BBH Score": 34.47834539078978,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.30191268814681
  },
  {
    "Model Name": "hotmailuser/Gemma2Crono-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.775827925027047,
    "Overall Score": 36.28874920037128,
    "MMLU Score": 40.36273640661938,
    "BBH Score": 50.10341199129857,
    "Math Score": 24.24471299093656,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.666866287456465
  },
  {
    "Model Name": "hotmailuser/Gemma2SimPO-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.929292486388974,
    "Overall Score": 36.43283421130692,
    "MMLU Score": 40.46431737588653,
    "BBH Score": 49.15921945509655,
    "Math Score": 28.172205438066467,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.080147925139861
  },
  {
    "Model Name": "hotmailuser/Gemma2atlas-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.530740587560782,
    "Overall Score": 35.809591577124344,
    "MMLU Score": 41.66481973995272,
    "BBH Score": 50.71327914306504,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.197711934804418
  },
  {
    "Model Name": "hotmailuser/Gemma2magnum-27b",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.436378201254655,
    "Overall Score": 32.46719676338319,
    "MMLU Score": 39.95641252955083,
    "BBH Score": 46.10114598574725,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.8484757308005326
  },
  {
    "Model Name": "hotmailuser/Llama-Hermes-slerp-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4214525678925432,
    "Overall Score": 19.59642323585999,
    "MMLU Score": 25.901300236406616,
    "BBH Score": 33.30931089323399,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.786195669486041
  },
  {
    "Model Name": "hotmailuser/Llama-Hermes-slerp2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.437970914055651,
    "Overall Score": 20.611252287971684,
    "MMLU Score": 26.43690898345154,
    "BBH Score": 32.315975836753644,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.333566893811323
  },
  {
    "Model Name": "hotmailuser/LlamaStock-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2753957210387332,
    "Overall Score": 24.411960823539555,
    "MMLU Score": 31.183510638297868,
    "BBH Score": 33.09114622817674,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.14069525312307
  },
  {
    "Model Name": "hotmailuser/Mistral-modelstock-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.71543130172185,
    "Overall Score": 29.725473787931804,
    "MMLU Score": 45.2201536643026,
    "BBH Score": 48.712773019346535,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.32827992476009
  },
  {
    "Model Name": "hotmailuser/Mistral-modelstock2-24B",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4917658879570694,
    "Overall Score": 33.81477606165948,
    "MMLU Score": 47.98130910165485,
    "BBH Score": 52.38720934510872,
    "Math Score": 24.018126888217523,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.667615833452153
  },
  {
    "Model Name": "hotmailuser/Phi4-Slerp4-14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8446649148433256,
    "Overall Score": 30.881045458267863,
    "MMLU Score": 47.52881205673759,
    "BBH Score": 52.76034640932895,
    "Math Score": 34.74320241691843,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.74073443354383
  },
  {
    "Model Name": "hotmailuser/Qwen2.5-HomerSlerp-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2001042958753323,
    "Overall Score": 29.43258692955959,
    "MMLU Score": 39.43003841607564,
    "BBH Score": 37.40411935244851,
    "Math Score": 33.157099697885194,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.525024225575365
  },
  {
    "Model Name": "hotmailuser/QwenModelStock-1.8B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0588223432600736,
    "Overall Score": 16.665220644656603,
    "MMLU Score": 21.76418439716312,
    "BBH Score": 17.724176359806876,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.739392685410307
  },
  {
    "Model Name": "hotmailuser/QwenSlerp-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.791800683805432,
    "Overall Score": 40.34991665759889,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 49.421941687333,
    "Math Score": 38.36858006042296,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.641360140560952
  },
  {
    "Model Name": "hotmailuser/QwenSlerp-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4724753956167291,
    "Overall Score": 24.511060317673625,
    "MMLU Score": 29.92760047281324,
    "BBH Score": 28.28933436034725,
    "Math Score": 27.492447129909365,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.646159515220596
  },
  {
    "Model Name": "hotmailuser/QwenSlerp-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2683967687951827,
    "Overall Score": 30.08674999761204,
    "MMLU Score": 38.98677600472813,
    "BBH Score": 37.61925634545651,
    "Math Score": 34.44108761329305,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.720298519989658
  },
  {
    "Model Name": "hotmailuser/QwenSlerp2-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.701076932485308,
    "Overall Score": 40.85962754388034,
    "MMLU Score": 48.65543735224587,
    "BBH Score": 49.68432710491516,
    "Math Score": 39.65256797583081,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.03992926632917
  },
  {
    "Model Name": "hotmailuser/QwenSlerp2-3B",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.46318111692393,
    "Overall Score": 24.03431047768953,
    "MMLU Score": 30.46320921985816,
    "BBH Score": 26.901296704943547,
    "Math Score": 26.057401812688823,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.42606660221071
  },
  {
    "Model Name": "hotmailuser/QwenSlerp3-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.705657276969295,
    "Overall Score": 39.791587426588,
    "MMLU Score": 47.362588652482266,
    "BBH Score": 46.50024294429596,
    "Math Score": 43.05135951661632,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.738064654249923
  },
  {
    "Model Name": "hotmailuser/QwenSparse-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4819065821862699,
    "Overall Score": 3.4771858660491386,
    "MMLU Score": 1.3556442080378246,
    "BBH Score": 1.88717525781587,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.215477012731717
  },
  {
    "Model Name": "hotmailuser/QwenStock-0.5B",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0069252525386143,
    "Overall Score": 5.093186530380667,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.058157512228396
  },
  {
    "Model Name": "hotmailuser/QwenStock-1.7B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0975954025989914,
    "Overall Score": 16.75925374781586,
    "MMLU Score": 21.71801122931442,
    "BBH Score": 17.74065871627513,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.26906336171935
  },
  {
    "Model Name": "hotmailuser/QwenStock1-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.727170708681339,
    "Overall Score": 39.99889430195756,
    "MMLU Score": 49.07099586288417,
    "BBH Score": 49.56243886958751,
    "Math Score": 37.00906344410876,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.731704402160062
  },
  {
    "Model Name": "hotmailuser/RombosBeagle-v2beta-MGS-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.391246244145718,
    "Overall Score": 42.65614620168921,
    "MMLU Score": 54.52866430260048,
    "BBH Score": 58.117898971791085,
    "Math Score": 49.92447129909365,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.105007734343808
  },
  {
    "Model Name": "huggyllama/llama-13b",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.212281197143199,
    "Overall Score": 9.39218439885523,
    "MMLU Score": 10.581043144208037,
    "BBH Score": 16.145707376925767,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.245474947300418
  },
  {
    "Model Name": "huggyllama/llama-65b",
    "Parameters (B)": 65.286,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 18.660216163901705,
    "Overall Score": 13.688031554930518,
    "MMLU Score": 23.084736997635936,
    "BBH Score": 25.254277114598622,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7335408890605508
  },
  {
    "Model Name": "huggyllama/llama-7b",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1272084313543247,
    "Overall Score": 6.414999925920792,
    "MMLU Score": 3.4796099290780127,
    "BBH Score": 7.076660678102023,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-07-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.691050339477378
  },
  {
    "Model Name": "huihui-ai/DeepSeek-R1-Distill-Qwen-14B-abliterated-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.710507681662543,
    "Overall Score": 17.525034419590085,
    "MMLU Score": 10.16548463356974,
    "BBH Score": 8.72537349779457,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.723082640739274
  },
  {
    "Model Name": "huihui-ai/QwQ-32B-Coder-Fusion-7030",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.99417036842794,
    "Overall Score": 26.71967034395213,
    "MMLU Score": 37.41688829787233,
    "BBH Score": 44.95662557932721,
    "Math Score": 27.94561933534744,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.4303489438987826
  },
  {
    "Model Name": "huihui-ai/QwQ-32B-Coder-Fusion-8020",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.202812113959975,
    "Overall Score": 38.81040369162885,
    "MMLU Score": 48.52615248226951,
    "BBH Score": 51.79260416831474,
    "Math Score": 45.9214501510574,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.21723308169645
  },
  {
    "Model Name": "huihui-ai/QwQ-32B-Coder-Fusion-9010",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 22.30195359070872,
    "Overall Score": 41.58193870807085,
    "MMLU Score": 51.1118498817967,
    "BBH Score": 53.02341820461157,
    "Math Score": 53.17220543806647,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.8644975893678848
  },
  {
    "Model Name": "huihui-ai/Qwen2.5-14B-Instruct-abliterated-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.247965447579133,
    "Overall Score": 41.74807839195605,
    "MMLU Score": 44.0196513002364,
    "BBH Score": 47.40618824926219,
    "Math Score": 53.02114803625378,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.853609148789722
  },
  {
    "Model Name": "huihui-ai/Qwen2.5-72B-Instruct-abliterated",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 76.77142501291785,
    "Overall Score": 48.10647092442315,
    "MMLU Score": 50.410017730496456,
    "BBH Score": 60.48786941269388,
    "Math Score": 60.12084592145015,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.6266194865645464
  },
  {
    "Model Name": "huihui-ai/Qwen2.5-7B-Instruct-abliterated",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.297569060075492,
    "Overall Score": 34.27590445973728,
    "MMLU Score": 35.32986111111111,
    "BBH Score": 32.886673214320496,
    "Math Score": 45.77039274924472,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.394294656243712
  },
  {
    "Model Name": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.334388792887168,
    "Overall Score": 34.729008711870584,
    "MMLU Score": 35.643838652482266,
    "BBH Score": 34.369626512494015,
    "Math Score": 46.37462235649547,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.415404702041227
  },
  {
    "Model Name": "huu-ontocord/wide_3b_orpo_stage1.1-ss1-orpo3",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2789537936045549,
    "Overall Score": 4.271382904426972,
    "MMLU Score": 1.8266105200945613,
    "BBH Score": 2.6258625470390182,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.312152056559187
  },
  {
    "Model Name": "iFaz/llama31_8B_en_emo_v4",
    "Parameters (B)": 4.777,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7973431451023771,
    "Overall Score": 17.153620627087744,
    "MMLU Score": 22.76152482269504,
    "BBH Score": 27.93118385237936,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.543876289750264
  },
  {
    "Model Name": "iFaz/llama32_1B_en_emo_v1",
    "Parameters (B)": 0.765,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.754094765188556,
    "Overall Score": 10.934841101081998,
    "MMLU Score": 8.457077423167847,
    "BBH Score": 7.2810483160822015,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.23389415332219
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_1000_stp",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.902401058418344,
    "Overall Score": 23.648597853327,
    "MMLU Score": 23.592641843971627,
    "BBH Score": 23.111523420944195,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.206305536450014
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_2000_stp",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.902237538757954,
    "Overall Score": 23.911624360048616,
    "MMLU Score": 23.30636820330969,
    "BBH Score": 23.416054848493687,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.502582006248645
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_300_stp",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8700878633076544,
    "Overall Score": 23.75197000352155,
    "MMLU Score": 23.86968085106384,
    "BBH Score": 22.93979639383205,
    "Math Score": 16.012084592145015,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.298358022404788
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_5000_stp",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9237204039607672,
    "Overall Score": 23.22281886664426,
    "MMLU Score": 22.96468676122932,
    "BBH Score": 23.46226189636773,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 25.140528202114496
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_v2",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1775976581044354,
    "Overall Score": 19.3032163999358,
    "MMLU Score": 22.26285460992908,
    "BBH Score": 19.02916278101205,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.864454977756978
  },
  {
    "Model Name": "iFaz/llama32_3B_en_emo_v3",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9326067547081006,
    "Overall Score": 18.26359573830477,
    "MMLU Score": 19.00302895981088,
    "BBH Score": 20.09714960563635,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.583383506611153
  },
  {
    "Model Name": "iRyanBell/ARC1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.849328996764956,
    "Overall Score": 19.66167494214361,
    "MMLU Score": 26.34456264775413,
    "BBH Score": 26.56449513263172,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.631788598209358
  },
  {
    "Model Name": "iRyanBell/ARC1-II",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.790552524437696,
    "Overall Score": 9.559430625313343,
    "MMLU Score": 7.616725768321511,
    "BBH Score": 7.246229410679451,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.338816088802187
  },
  {
    "Model Name": "ibivibiv/colossus_120b",
    "Parameters (B)": 117.749,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 27.50486346616086,
    "Overall Score": 25.415203305397444,
    "MMLU Score": 32.901152482269495,
    "BBH Score": 44.07149752747837,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.924025794080588
  },
  {
    "Model Name": "ibivibiv/multimaster-7b-v6",
    "Parameters (B)": 35.428,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.149361008754831,
    "Overall Score": 21.08976867338016,
    "MMLU Score": 23.278664302600472,
    "BBH Score": 32.40128043389345,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.095608879921954
  },
  {
    "Model Name": "ibm/PowerLM-3b",
    "Parameters (B)": 3.512,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.121176518130097,
    "Overall Score": 11.5240792202122,
    "MMLU Score": 11.292109929078013,
    "BBH Score": 12.02206036323482,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.27855920442582
  },
  {
    "Model Name": "ibm/merlinite-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1007936688970816,
    "Overall Score": 16.751033885892248,
    "MMLU Score": 22.9831560283688,
    "BBH Score": 29.97724776968684,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.217233128416893
  },
  {
    "Model Name": "ibm-granite/granite-3.0-1b-a400m-base",
    "Parameters (B)": 1.335,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.706138660642777,
    "Overall Score": 6.030789973010188,
    "MMLU Score": 1.6880910165484628,
    "BBH Score": 6.055007672005359,
    "Math Score": 2.643504531722054,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 1.6272434804056235
  },
  {
    "Model Name": "ibm-granite/granite-3.0-1b-a400m-instruct",
    "Parameters (B)": 1.335,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.268125585439224,
    "Overall Score": 8.0692284950461,
    "MMLU Score": 2.713135342789597,
    "BBH Score": 5.453219408698861,
    "Math Score": 2.794561933534743,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 2.4690692827098397
  },
  {
    "Model Name": "ibm-granite/granite-3.0-2b-base",
    "Parameters (B)": 2.634,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5711600010720157,
    "Overall Score": 14.095784874796747,
    "MMLU Score": 15.346114066193852,
    "BBH Score": 17.563749725828334,
    "Math Score": 5.438066465256798,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 8.971578238485625
  },
  {
    "Model Name": "ibm-granite/granite-3.0-2b-instruct",
    "Parameters (B)": 2.634,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.525689769456262,
    "Overall Score": 18.396095114284226,
    "MMLU Score": 20.15735815602837,
    "BBH Score": 21.73789141090241,
    "Math Score": 9.214501510574015,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 12.05755946101702
  },
  {
    "Model Name": "ibm-granite/granite-3.0-3b-a800m-base",
    "Parameters (B)": 3.374,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.293744935580685,
    "Overall Score": 9.489841451458394,
    "MMLU Score": 9.89768026004728,
    "BBH Score": 11.3484424218006,
    "Math Score": 4.833836858006042,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 1.7926518120800674
  },
  {
    "Model Name": "ibm-granite/granite-3.0-3b-a800m-instruct",
    "Parameters (B)": 3.374,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.625489402223453,
    "Overall Score": 13.698124325974996,
    "MMLU Score": 12.797355200945626,
    "BBH Score": 13.16300959501,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.9614432408796283
  },
  {
    "Model Name": "ibm-granite/granite-3.0-8b-base",
    "Parameters (B)": 8.171,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.820031779871169,
    "Overall Score": 21.690924398799496,
    "MMLU Score": 25.69813829787234,
    "BBH Score": 27.974358298982427,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.691730481062319
  },
  {
    "Model Name": "ibm-granite/granite-3.0-8b-instruct",
    "Parameters (B)": 8.171,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.5676637463760468,
    "Overall Score": 24.027678753483297,
    "MMLU Score": 27.295729905437348,
    "BBH Score": 31.588159064715125,
    "Math Score": 14.19939577039275,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.357798032314596
  },
  {
    "Model Name": "ibm-granite/granite-3.1-1b-a400m-base",
    "Parameters (B)": 1.335,
    "Architecture": "GraniteMoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.246823674730084,
    "Overall Score": 6.312391508281799,
    "MMLU Score": 1.549571513002364,
    "BBH Score": 6.429845005402345,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 2.8094734710502465
  },
  {
    "Model Name": "ibm-granite/granite-3.1-1b-a400m-instruct",
    "Parameters (B)": 1.335,
    "Architecture": "GraniteMoeForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.096168213768369,
    "Overall Score": 10.127255876383268,
    "MMLU Score": 2.40839243498818,
    "BBH Score": 6.178183215904788,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.831318312081967
  },
  {
    "Model Name": "ibm-granite/granite-3.1-2b-base",
    "Parameters (B)": 2.534,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.9884427131625634,
    "Overall Score": 13.202826259598206,
    "MMLU Score": 13.89627659574468,
    "BBH Score": 16.843689846888516,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.357199242589605
  },
  {
    "Model Name": "ibm-granite/granite-3.1-2b-instruct",
    "Parameters (B)": 2.534,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0112838075919377,
    "Overall Score": 21.712212822028288,
    "MMLU Score": 20.212765957446805,
    "BBH Score": 21.822956140794503,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.46995003680447
  },
  {
    "Model Name": "ibm-granite/granite-3.1-3b-a800m-base",
    "Parameters (B)": 3.299,
    "Architecture": "GraniteMoeForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.245621007056488,
    "Overall Score": 10.00105158723934,
    "MMLU Score": 8.807993498817966,
    "BBH Score": 11.905605199489822,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.081398464421905
  },
  {
    "Model Name": "ibm-granite/granite-3.1-3b-a800m-instruct",
    "Parameters (B)": 3.299,
    "Architecture": "GraniteMoeForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.2727272082111534,
    "Overall Score": 17.277676062054883,
    "MMLU Score": 12.751182033096924,
    "BBH Score": 16.687236366660443,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.279290011922113
  },
  {
    "Model Name": "ibm-granite/granite-3.1-8b-base",
    "Parameters (B)": 8.171,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1973851147577552,
    "Overall Score": 20.05719991900457,
    "MMLU Score": 24.802378841607563,
    "BBH Score": 26.01958867101177,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.750834524164244
  },
  {
    "Model Name": "ibm-granite/granite-3.1-8b-instruct",
    "Parameters (B)": 8.171,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2356666876371007,
    "Overall Score": 30.6030430081627,
    "MMLU Score": 28.191489361702125,
    "BBH Score": 34.089655299414055,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.766422300080986
  },
  {
    "Model Name": "ibm-granite/granite-3.2-2b-instruct",
    "Parameters (B)": 2.534,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5072217436302251,
    "Overall Score": 21.25014812377563,
    "MMLU Score": 19.815676713947987,
    "BBH Score": 21.66826841603661,
    "Math Score": 14.425981873111782,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.895183695570076
  },
  {
    "Model Name": "ibm-granite/granite-3.2-8b-instruct",
    "Parameters (B)": 8.171,
    "Architecture": "GraniteForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6149577544719722,
    "Overall Score": 30.7704488980163,
    "MMLU Score": 27.914450354609933,
    "BBH Score": 34.65536965519957,
    "Math Score": 23.791540785498487,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 50.03668735657633
  },
  {
    "Model Name": "ibm-granite/granite-7b-base",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.3052476771223376,
    "Overall Score": 7.908701929835419,
    "MMLU Score": 9.269725177304965,
    "BBH Score": 9.050800002899097,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.0591580191673895
  },
  {
    "Model Name": "ibm-granite/granite-7b-instruct",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4229038379301109,
    "Overall Score": 12.03495955436329,
    "MMLU Score": 14.293365839243496,
    "BBH Score": 12.639328702465264,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.458027333646431
  },
  {
    "Model Name": "icefog72/Ice0.15-02.10-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.185644320842549,
    "Overall Score": 21.49132746100335,
    "MMLU Score": 22.95545212765957,
    "BBH Score": 30.130104071068587,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.126285499964332
  },
  {
    "Model Name": "icefog72/Ice0.16-02.10-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1935116607722032,
    "Overall Score": 21.076418616812266,
    "MMLU Score": 22.973921394799056,
    "BBH Score": 29.58232083302582,
    "Math Score": 5.8912386706948645,
    "Date Submitted": "2024-10-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.659164388201958
  },
  {
    "Model Name": "icefog72/Ice0.17-03.10-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2204125060394582,
    "Overall Score": 21.41440427176671,
    "MMLU Score": 23.167848699763592,
    "BBH Score": 30.37626243817209,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.546857448439113
  },
  {
    "Model Name": "icefog72/Ice0.27-06.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8287012653892059,
    "Overall Score": 21.83125244134635,
    "MMLU Score": 23.93432328605201,
    "BBH Score": 31.364751797095256,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.343935206968865
  },
  {
    "Model Name": "icefog72/Ice0.29-06.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8596332192143764,
    "Overall Score": 21.71623231324205,
    "MMLU Score": 23.25096040189125,
    "BBH Score": 31.359453902395284,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.26220698298355
  },
  {
    "Model Name": "icefog72/Ice0.31-08.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9269387673132792,
    "Overall Score": 21.886899252180523,
    "MMLU Score": 23.675753546099287,
    "BBH Score": 30.460341897671253,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.612022739775398
  },
  {
    "Model Name": "icefog72/Ice0.32-10.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8480647893442718,
    "Overall Score": 21.63483115225961,
    "MMLU Score": 23.33407210401891,
    "BBH Score": 30.430940035916453,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.51082349378964
  },
  {
    "Model Name": "icefog72/Ice0.34b-14.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8596460466015595,
    "Overall Score": 21.681833980913552,
    "MMLU Score": 23.61111111111111,
    "BBH Score": 30.80635727588579,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.22181549793475
  },
  {
    "Model Name": "icefog72/Ice0.34n-14.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8970969375770342,
    "Overall Score": 21.87840965107064,
    "MMLU Score": 23.60187647754137,
    "BBH Score": 31.206252799751898,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.388010631450772
  },
  {
    "Model Name": "icefog72/Ice0.37-18.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8290256218099152,
    "Overall Score": 21.91394124972764,
    "MMLU Score": 23.814273049645383,
    "BBH Score": 31.042850362735788,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.433370300287557
  },
  {
    "Model Name": "icefog72/Ice0.38-19.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8454755064784819,
    "Overall Score": 20.813765464787064,
    "MMLU Score": 23.777334515366427,
    "BBH Score": 31.3306289411177,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.61782193014576
  },
  {
    "Model Name": "icefog72/Ice0.39-19.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.850586712637743,
    "Overall Score": 21.33876534002405,
    "MMLU Score": 23.62958037825059,
    "BBH Score": 31.2636273781982,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.08711342768416
  },
  {
    "Model Name": "icefog72/Ice0.40-20.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3714913254279848,
    "Overall Score": 21.79272576511275,
    "MMLU Score": 23.324837470449168,
    "BBH Score": 31.50523985734019,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.889802116183386
  },
  {
    "Model Name": "icefog72/Ice0.41-22.11-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8546209986058674,
    "Overall Score": 19.03517499742875,
    "MMLU Score": 17.977984633569736,
    "BBH Score": 25.412777425832047,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.27323577174045
  },
  {
    "Model Name": "icefog72/Ice0.50-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8047468824222894,
    "Overall Score": 20.162878876154817,
    "MMLU Score": 22.992390661938536,
    "BBH Score": 30.030386129201485,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.054932571424843
  },
  {
    "Model Name": "icefog72/Ice0.50.1-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8045758406128498,
    "Overall Score": 21.64515420732792,
    "MMLU Score": 23.69422281323877,
    "BBH Score": 31.56631239449821,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.90256544472015
  },
  {
    "Model Name": "icefog72/Ice0.51-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8545865350107835,
    "Overall Score": 20.84509564746615,
    "MMLU Score": 22.89080969267139,
    "BBH Score": 31.042011224203208,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.3920244392841
  },
  {
    "Model Name": "icefog72/Ice0.51.1-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8168791417026133,
    "Overall Score": 21.35322617351512,
    "MMLU Score": 23.380245271867608,
    "BBH Score": 31.8691535648048,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.140006622043007
  },
  {
    "Model Name": "icefog72/Ice0.52-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7951320775446538,
    "Overall Score": 20.94727593446016,
    "MMLU Score": 23.11244089834516,
    "BBH Score": 30.96644092952937,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.344398026482313
  },
  {
    "Model Name": "icefog72/Ice0.52.1-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.825747444848155,
    "Overall Score": 21.2113364576448,
    "MMLU Score": 23.389479905437348,
    "BBH Score": 31.801683327768355,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.687438199152176
  },
  {
    "Model Name": "icefog72/Ice0.53-16.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8283239344189874,
    "Overall Score": 21.48687520926336,
    "MMLU Score": 23.66651891252955,
    "BBH Score": 31.40639773638384,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.940183926153157
  },
  {
    "Model Name": "icefog72/Ice0.54-17.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8264819307094243,
    "Overall Score": 19.92119268564771,
    "MMLU Score": 14.736628250591016,
    "BBH Score": 27.720691580598487,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.103603412778824
  },
  {
    "Model Name": "icefog72/Ice0.55-17.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8075650561519988,
    "Overall Score": 21.460984298912976,
    "MMLU Score": 18.42124704491726,
    "BBH Score": 30.94478559005843,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.574929332843272
  },
  {
    "Model Name": "icefog72/Ice0.57-17.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8483639070260532,
    "Overall Score": 21.771237145846925,
    "MMLU Score": 18.34736997635934,
    "BBH Score": 30.954927188616967,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.66261596649742
  },
  {
    "Model Name": "icefog72/Ice0.60-18.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8687066808695614,
    "Overall Score": 22.63934600501626,
    "MMLU Score": 20.40669326241135,
    "BBH Score": 31.50598646501167,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.060978352733102
  },
  {
    "Model Name": "icefog72/Ice0.60.1-18.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.831775152380986,
    "Overall Score": 21.823113618523887,
    "MMLU Score": 21.26551418439716,
    "BBH Score": 31.83208746983884,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.236794350077
  },
  {
    "Model Name": "icefog72/Ice0.61-18.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8564151296309443,
    "Overall Score": 22.37634566318344,
    "MMLU Score": 18.98455969267139,
    "BBH Score": 31.77285517916415,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.127919613968164
  },
  {
    "Model Name": "icefog72/Ice0.62-18.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8312003066913778,
    "Overall Score": 22.248597707539464,
    "MMLU Score": 20.859190307328607,
    "BBH Score": 31.62165712541642,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.766830484099305
  },
  {
    "Model Name": "icefog72/Ice0.62.1-24.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8559000893897843,
    "Overall Score": 22.004775451212502,
    "MMLU Score": 20.78531323877068,
    "BBH Score": 31.63738531804965,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.70951414072272
  },
  {
    "Model Name": "icefog72/Ice0.64-24.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8319368893469683,
    "Overall Score": 22.875703285300133,
    "MMLU Score": 21.47791075650118,
    "BBH Score": 31.22157004117841,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.496921435058006
  },
  {
    "Model Name": "icefog72/Ice0.64.1-24.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8267874263763786,
    "Overall Score": 22.88569529169502,
    "MMLU Score": 21.47791075650118,
    "BBH Score": 31.22157004117841,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.68026527930864
  },
  {
    "Model Name": "icefog72/Ice0.65-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8236528476522945,
    "Overall Score": 21.728992372015465,
    "MMLU Score": 22.18897754137116,
    "BBH Score": 31.94702464783097,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.38125083152553
  },
  {
    "Model Name": "icefog72/Ice0.66-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8119911365270718,
    "Overall Score": 22.685149861181817,
    "MMLU Score": 22.659943853427897,
    "BBH Score": 32.189358928643664,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.937681633087006
  },
  {
    "Model Name": "icefog72/Ice0.67-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8446217784171618,
    "Overall Score": 22.200117322014464,
    "MMLU Score": 23.29713356973995,
    "BBH Score": 32.095819566371766,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.28409293875648
  },
  {
    "Model Name": "icefog72/Ice0.68-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8313689642507519,
    "Overall Score": 23.242050794562672,
    "MMLU Score": 22.355200945626475,
    "BBH Score": 32.485197545735645,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.956360886659898
  },
  {
    "Model Name": "icefog72/Ice0.69-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2529375653887906,
    "Overall Score": 22.81762296294448,
    "MMLU Score": 21.83806146572104,
    "BBH Score": 31.8015030192188,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.211300860681032
  },
  {
    "Model Name": "icefog72/Ice0.7-29.09-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1737084628394303,
    "Overall Score": 21.550046416942568,
    "MMLU Score": 23.62958037825059,
    "BBH Score": 30.72587571429055,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.360646701659448
  },
  {
    "Model Name": "icefog72/Ice0.70-25.01-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8120544366643394,
    "Overall Score": 23.100001948439864,
    "MMLU Score": 22.17974290780142,
    "BBH Score": 32.48918739061522,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 28.446371210441633
  },
  {
    "Model Name": "icefog72/Ice0.70.1-01.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7903627100350105,
    "Overall Score": 21.38965688648672,
    "MMLU Score": 19.42782210401891,
    "BBH Score": 30.98341832479747,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.063089661124355
  },
  {
    "Model Name": "icefog72/Ice0.73-01.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8115800990167161,
    "Overall Score": 21.85097004562225,
    "MMLU Score": 18.91068262411348,
    "BBH Score": 31.51289324486128,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.92398454828571
  },
  {
    "Model Name": "icefog72/Ice0.74-02.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8577043786899584,
    "Overall Score": 14.163954352130537,
    "MMLU Score": 12.705008865248226,
    "BBH Score": 24.816877383693065,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.51379508376102
  },
  {
    "Model Name": "icefog72/Ice0.76-02.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7440540496769722,
    "Overall Score": 19.18268973168048,
    "MMLU Score": 18.35660460992908,
    "BBH Score": 31.0716806557854,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.781312177534094
  },
  {
    "Model Name": "icefog72/Ice0.77-02.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5639793499337524,
    "Overall Score": 22.480867406637245,
    "MMLU Score": 22.20744680851064,
    "BBH Score": 31.860105340069964,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.307799568775594
  },
  {
    "Model Name": "icefog72/Ice0.78-02.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8631772807841601,
    "Overall Score": 19.9371141589126,
    "MMLU Score": 21.71801122931442,
    "BBH Score": 29.33342240128623,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.097357405886047
  },
  {
    "Model Name": "icefog72/Ice0.80-03.02-RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.903662825508276,
    "Overall Score": 22.887791167207023,
    "MMLU Score": 21.24704491725769,
    "BBH Score": 30.5837538790623,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.327799839872256
  },
  {
    "Model Name": "icefog72/IceCocoaRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1698831456217178,
    "Overall Score": 20.9218542806483,
    "MMLU Score": 23.315602836879428,
    "BBH Score": 29.63689549472275,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.883712881024266
  },
  {
    "Model Name": "icefog72/IceCoffeeRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1434890928451789,
    "Overall Score": 20.34382476557608,
    "MMLU Score": 21.939642434988176,
    "BBH Score": 29.39810739240589,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.79100902043366
  },
  {
    "Model Name": "icefog72/IceDrinkByFrankensteinV3RP",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.342835251712049,
    "Overall Score": 19.8053456963892,
    "MMLU Score": 21.413268321513,
    "BBH Score": 28.84588139816073,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.453580200279237
  },
  {
    "Model Name": "icefog72/IceDrinkNameGoesHereRP-7b-Model_Stock",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.238757405567536,
    "Overall Score": 18.6570669982101,
    "MMLU Score": 20.18506205673759,
    "BBH Score": 26.22465405632467,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.333670701350709
  },
  {
    "Model Name": "icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2028972154551574,
    "Overall Score": 21.38126177033122,
    "MMLU Score": 22.936982860520093,
    "BBH Score": 30.6682514458964,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.7748036121614
  },
  {
    "Model Name": "icefog72/IceDrunkCherryRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0898596002548293,
    "Overall Score": 20.271642861184223,
    "MMLU Score": 22.32749704491725,
    "BBH Score": 28.24109020120596,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.600233329544775
  },
  {
    "Model Name": "icefog72/IceDrunkenCherryRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8331698129169264,
    "Overall Score": 21.79272576511275,
    "MMLU Score": 23.324837470449168,
    "BBH Score": 31.50523985734019,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.156403445315004
  },
  {
    "Model Name": "icefog72/IceEspressoRPv2-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1450676211289978,
    "Overall Score": 21.365276481870684,
    "MMLU Score": 22.90004432624113,
    "BBH Score": 31.30323855841809,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-09-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.658528184392505
  },
  {
    "Model Name": "icefog72/IceLemonTeaRP-32k-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1428701039081552,
    "Overall Score": 21.37243582498176,
    "MMLU Score": 22.973921394799056,
    "BBH Score": 30.135779642023177,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 18.70066926407178
  },
  {
    "Model Name": "icefog72/IceMartiniRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1388752444259926,
    "Overall Score": 21.14600270384616,
    "MMLU Score": 23.03856382978724,
    "BBH Score": 29.685367916429147,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.567444333645174
  },
  {
    "Model Name": "icefog72/IceNalyvkaRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8293532808410896,
    "Overall Score": 23.100001948439864,
    "MMLU Score": 22.17974290780142,
    "BBH Score": 32.48918739061522,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.853030164675985
  },
  {
    "Model Name": "icefog72/IceSakeRP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.868673697892017,
    "Overall Score": 21.56363636347618,
    "MMLU Score": 24.183658392434985,
    "BBH Score": 31.6512550721568,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-08-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.539540791846825
  },
  {
    "Model Name": "icefog72/IceSakeV4RP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.09615726584972,
    "Overall Score": 20.05225099073927,
    "MMLU Score": 23.361776004728128,
    "BBH Score": 29.234193217077536,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.293224535801578
  },
  {
    "Model Name": "icefog72/IceSakeV6RP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1108855330334666,
    "Overall Score": 21.214466273348467,
    "MMLU Score": 23.26019503546099,
    "BBH Score": 30.391494717552195,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 19.096896703136164
  },
  {
    "Model Name": "icefog72/IceSakeV8RP-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2965708194682928,
    "Overall Score": 21.68948669810957,
    "MMLU Score": 22.336731678486995,
    "BBH Score": 28.966258233266576,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.72834709252839
  },
  {
    "Model Name": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1598840944021205,
    "Overall Score": 21.67167061111473,
    "MMLU Score": 22.844636524822693,
    "BBH Score": 30.6127340167025,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.68434157835893
  },
  {
    "Model Name": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3.5",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0014573988569522,
    "Overall Score": 17.321387609280592,
    "MMLU Score": 16.648197399527188,
    "BBH Score": 22.57322577923665,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.29618017606236
  },
  {
    "Model Name": "ifable/gemma-2-Ifable-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 8.635208842924055,
    "Overall Score": 23.56844886390901,
    "MMLU Score": 35.847000591016545,
    "BBH Score": 41.03264464626528,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.729343237971794
  },
  {
    "Model Name": "ilsp/Llama-Krikri-8B-Instruct",
    "Parameters (B)": 8.202,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7570021231420504,
    "Overall Score": 24.18078391296001,
    "MMLU Score": 25.69813829787234,
    "BBH Score": 29.305557163927727,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 31.942821788390834
  },
  {
    "Model Name": "inflatebot/MN-12B-Mag-Mell-R1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.23511126535229,
    "Overall Score": 23.14682361352939,
    "MMLU Score": 27.09256796690307,
    "BBH Score": 32.53583283307959,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.356005077841647
  },
  {
    "Model Name": "informatiker/Qwen2-7B-Instruct-abliterated",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.121210091367628,
    "Overall Score": 27.991694247930223,
    "MMLU Score": 31.922281323877066,
    "BBH Score": 37.79572344136589,
    "Math Score": 26.3595166163142,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.196097058864579
  },
  {
    "Model Name": "insightfactory/Llama-3.2-3B-Instruct-unsloth-bnb-4bitlora_model",
    "Parameters (B)": 1.933,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.721413675707368,
    "Overall Score": 17.182396518039905,
    "MMLU Score": 21.7826536643026,
    "BBH Score": 17.41910908101376,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.981561527318103
  },
  {
    "Model Name": "instruction-pretrain/InstructLM-500M",
    "Parameters (B)": 0.5,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.491584290133651,
    "Overall Score": 2.8543503197666724,
    "MMLU Score": 1.5680407801418434,
    "BBH Score": 2.317053716048478,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.806431118843601
  },
  {
    "Model Name": "internlm/internlm2-1_8b",
    "Parameters (B)": 8.0,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.3272910338245865,
    "Overall Score": 8.748129853272754,
    "MMLU Score": 6.536273640661936,
    "BBH Score": 13.63385796590672,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.590965832161945
  },
  {
    "Model Name": "internlm/internlm2-7b",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 1.0395424089601004,
    "Overall Score": 17.92336611649886,
    "MMLU Score": 10.0,
    "BBH Score": 40.27619825708061,
    "Math Score": 8.571428571428571,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 17.2415920331989
  },
  {
    "Model Name": "internlm/internlm2-chat-1_8b",
    "Parameters (B)": 1.889,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.192845124564106,
    "Overall Score": 10.641800452239108,
    "MMLU Score": 9.325132978723405,
    "BBH Score": 20.67235743256185,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.921359724824189
  },
  {
    "Model Name": "internlm/internlm2_5-1_8b-chat",
    "Parameters (B)": 1.89,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.543331294717085,
    "Overall Score": 14.749842142996677,
    "MMLU Score": 3.322621158392436,
    "BBH Score": 21.03092693656956,
    "Math Score": 15.861027190332328,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.557145762213379
  },
  {
    "Model Name": "internlm/internlm2_5-20b-chat",
    "Parameters (B)": 19.86,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.465415742664814,
    "Overall Score": 38.87959582082076,
    "MMLU Score": 33.30747635933806,
    "BBH Score": 62.83245915287989,
    "Math Score": 40.78549848942598,
    "Date Submitted": "2024-08-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.207961239000269
  },
  {
    "Model Name": "internlm/internlm2_5-7b-chat",
    "Parameters (B)": 7.738,
    "Architecture": "InternLM2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.003415538760828,
    "Overall Score": 32.974747665791206,
    "MMLU Score": 30.85106382978724,
    "BBH Score": 57.04314320825679,
    "Math Score": 25.302114803625376,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.97908272772544
  },
  {
    "Model Name": "intervitens/mini-magnum-12b-v1.1",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.46189669686465,
    "Overall Score": 21.028735164842907,
    "MMLU Score": 25.458037825059098,
    "BBH Score": 29.73118686868688,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.712958769220203
  },
  {
    "Model Name": "inumulaisk/eval_model",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5949305874819794,
    "Overall Score": 12.24174390101748,
    "MMLU Score": 7.376625295508273,
    "BBH Score": 9.506916615277104,
    "Math Score": 29.75830815709969,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.57675997603382
  },
  {
    "Model Name": "invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5285014726940187,
    "Overall Score": 20.34807895630956,
    "MMLU Score": 23.841976950354614,
    "BBH Score": 31.635374808026484,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.312436605275629
  },
  {
    "Model Name": "invisietch/EtherealRainbow-v0.2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7428330849303162,
    "Overall Score": 20.106576639387253,
    "MMLU Score": 29.47510342789598,
    "BBH Score": 30.28379136654109,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.53671961660699
  },
  {
    "Model Name": "invisietch/EtherealRainbow-v0.3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.562534394436687,
    "Overall Score": 19.791231655800487,
    "MMLU Score": 29.179595153664305,
    "BBH Score": 30.080258475101616,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.723303811557669
  },
  {
    "Model Name": "invisietch/MiS-Firefly-v0.2-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0505555920788168,
    "Overall Score": 26.75418615052289,
    "MMLU Score": 29.11495271867612,
    "BBH Score": 36.08265621771957,
    "Math Score": 16.540785498489427,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.047286430015767
  },
  {
    "Model Name": "invisietch/Nimbus-Miqu-v0.1-70B",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 14.287354737481978,
    "Overall Score": 24.80805215493564,
    "MMLU Score": 31.700650118203303,
    "BBH Score": 43.4509951550532,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.7363642613179662
  },
  {
    "Model Name": "irahulpandey/mistralai-7B-slerp-v0.1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9083935593251266,
    "Overall Score": 21.352696815222927,
    "MMLU Score": 21.681072695035464,
    "BBH Score": 29.60624854675679,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.505997588849596
  },
  {
    "Model Name": "jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model",
    "Parameters (B)": 0.407,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.4661274932737139,
    "Overall Score": 3.81661033477558,
    "MMLU Score": 1.8727836879432624,
    "BBH Score": 1.8203742908537424,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.1879107966164
  },
  {
    "Model Name": "jaspionjader/Auro-Kosmos-EVAA-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3376660491774912,
    "Overall Score": 24.86988279003332,
    "MMLU Score": 31.756057919621743,
    "BBH Score": 35.142095643012475,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.59199671347374
  },
  {
    "Model Name": "jaspionjader/Auro-Kosmos-EVAA-v2.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4314973009726266,
    "Overall Score": 24.75324595698377,
    "MMLU Score": 31.395907210401887,
    "BBH Score": 35.195114448894905,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.29185653383017
  },
  {
    "Model Name": "jaspionjader/Auro-Kosmos-EVAA-v2.2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4419073388687802,
    "Overall Score": 23.794317671805487,
    "MMLU Score": 31.091164302600465,
    "BBH Score": 34.91772620301955,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.501974177115187
  },
  {
    "Model Name": "jaspionjader/Auro-Kosmos-EVAA-v2.3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4606882955697402,
    "Overall Score": 23.827726018728324,
    "MMLU Score": 30.9341755319149,
    "BBH Score": 35.02426114679496,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.31266991800899
  },
  {
    "Model Name": "jaspionjader/Kosmos-Aurora_faustus-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2817270535415657,
    "Overall Score": 22.772496063013904,
    "MMLU Score": 31.257387706855795,
    "BBH Score": 32.36435397107119,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.76704018229994
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3041788434603263,
    "Overall Score": 23.04291967518942,
    "MMLU Score": 31.31279550827423,
    "BBH Score": 33.09134006202049,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.668527434512395
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-Franken-Immersive-v39-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.198589077745552,
    "Overall Score": 23.3817043439325,
    "MMLU Score": 32.227024231678485,
    "BBH Score": 31.18947290052941,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.507690148413147
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-Franken-v38-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.880158808239308,
    "Overall Score": 23.287509583046784,
    "MMLU Score": 32.116208628841605,
    "BBH Score": 31.76216941291032,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.38592691266042
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-Fusion-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2934264055292035,
    "Overall Score": 23.94142651600792,
    "MMLU Score": 31.774527186761222,
    "BBH Score": 34.45875710784809,
    "Math Score": 13.51963746223565,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.51008021303873
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-Fusion-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2600241220012325,
    "Overall Score": 23.78962658485408,
    "MMLU Score": 31.709884751773053,
    "BBH Score": 34.61065709067911,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.88029456695656
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1931663358566724,
    "Overall Score": 20.648962768096755,
    "MMLU Score": 29.4104609929078,
    "BBH Score": 31.507446723357827,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.306021924655763
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-light-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.200579467339432,
    "Overall Score": 21.99624515951864,
    "MMLU Score": 30.906471631205672,
    "BBH Score": 32.28113826534745,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.321357109549652
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v23-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.26161333149737,
    "Overall Score": 22.73397243488874,
    "MMLU Score": 30.06611997635934,
    "BBH Score": 33.03704089860875,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.019762368796854
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v24-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2478613312692373,
    "Overall Score": 22.97857683964308,
    "MMLU Score": 30.87876773049646,
    "BBH Score": 32.86201554441706,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.41436725687371
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v25-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2829483889600175,
    "Overall Score": 23.4868995275574,
    "MMLU Score": 30.17693557919622,
    "BBH Score": 33.05901994218396,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.306971449253957
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v26-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2432433319287717,
    "Overall Score": 23.11497640393616,
    "MMLU Score": 31.03575650118203,
    "BBH Score": 32.71975634899274,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.592479694281177
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v27-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2828938423829248,
    "Overall Score": 23.4077778762187,
    "MMLU Score": 30.610963356974,
    "BBH Score": 32.99647631508889,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.246075476315074
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v28-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2058860911125209,
    "Overall Score": 23.264906845014234,
    "MMLU Score": 30.55555555555556,
    "BBH Score": 33.073754773711705,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.292789772167122
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v29-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.247893929420119,
    "Overall Score": 23.401854796574032,
    "MMLU Score": 30.72177895981088,
    "BBH Score": 32.92843632608228,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.753080085459334
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v30-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8727119754433248,
    "Overall Score": 23.26356365601452,
    "MMLU Score": 32.64258274231678,
    "BBH Score": 32.980026204409654,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.422392744355342
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v31-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2069281446666016,
    "Overall Score": 23.539317547208807,
    "MMLU Score": 32.60564420803782,
    "BBH Score": 32.91395767598818,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.503495424502873
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v32-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2725725342025458,
    "Overall Score": 23.43128878858796,
    "MMLU Score": 30.85106382978724,
    "BBH Score": 33.04697938500372,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.412536935091968
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v33-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2709855867345825,
    "Overall Score": 23.234915401488184,
    "MMLU Score": 32.319370567375884,
    "BBH Score": 32.935042544278936,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.281021943909963
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-PRP-v34-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.209066915792569,
    "Overall Score": 23.742486352642512,
    "MMLU Score": 32.52253250591017,
    "BBH Score": 33.1218626050209,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.637032526920816
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.313415133694842,
    "Overall Score": 23.87846732227049,
    "MMLU Score": 31.29432624113476,
    "BBH Score": 31.425048235694074,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.180441742814878
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-light-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.324997241130934,
    "Overall Score": 23.67584400376476,
    "MMLU Score": 31.174276004728128,
    "BBH Score": 32.31709224526529,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.868598717652084
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-v19-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.297936022832137,
    "Overall Score": 23.5328956860039,
    "MMLU Score": 30.99881796690307,
    "BBH Score": 33.429515483219056,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.131013603162337
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-v20-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2045490521318007,
    "Overall Score": 23.53649410669648,
    "MMLU Score": 32.6241134751773,
    "BBH Score": 32.00472858026129,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.53967259784215
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-v21-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2729876389623414,
    "Overall Score": 23.968398200512283,
    "MMLU Score": 31.29432624113476,
    "BBH Score": 32.386295261036274,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.828461068207858
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-TSN-v22-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2996115083833455,
    "Overall Score": 23.654432566783058,
    "MMLU Score": 31.23891843971632,
    "BBH Score": 32.32633123685557,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.20115658733127
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3506866639843,
    "Overall Score": 23.98708989579214,
    "MMLU Score": 32.23625886524823,
    "BBH Score": 33.103487394032555,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.75918170764656
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-alt-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3044490161906677,
    "Overall Score": 24.0523306996218,
    "MMLU Score": 32.18085106382979,
    "BBH Score": 32.85116982530719,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.438689746465442
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-light-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1781725368622369,
    "Overall Score": 24.11044721388785,
    "MMLU Score": 32.69799054373522,
    "BBH Score": 33.68753243090729,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.464275358259407
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-light-alt-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.258765389845097,
    "Overall Score": 23.801281271469463,
    "MMLU Score": 32.476359338061464,
    "BBH Score": 33.05767050932263,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.908433186583274
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-ultra-light-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4131181642035988,
    "Overall Score": 23.80223995423945,
    "MMLU Score": 32.384013002364064,
    "BBH Score": 32.78464802043255,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.843771849506904
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v13-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2773691783087238,
    "Overall Score": 23.7210916104417,
    "MMLU Score": 32.55023640661938,
    "BBH Score": 33.47406748343683,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.570270845151562
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v14-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.20918414931387,
    "Overall Score": 23.62429735133503,
    "MMLU Score": 32.56870567375886,
    "BBH Score": 33.65958954546506,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.537385901676117
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v15-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2007018233163582,
    "Overall Score": 24.02365934041546,
    "MMLU Score": 32.67952127659574,
    "BBH Score": 33.2170748468152,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.008014374511163
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v16-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1915594994137388,
    "Overall Score": 23.98392902504385,
    "MMLU Score": 32.41171690307328,
    "BBH Score": 33.29159037553265,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.128184145940025
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v17-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2210254561964191,
    "Overall Score": 23.702369090863083,
    "MMLU Score": 32.476359338061464,
    "BBH Score": 33.346731824868634,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.411854986789255
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-gamma-v18-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2339950249160372,
    "Overall Score": 23.49671429886148,
    "MMLU Score": 32.273197399527184,
    "BBH Score": 33.23387233410255,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.041174254701904
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-immersive-sof-v44-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3308076685501458,
    "Overall Score": 23.12092179330857,
    "MMLU Score": 32.08850472813239,
    "BBH Score": 31.258884400704403,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.37360126463485
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v10-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3959809536797354,
    "Overall Score": 23.09067680338188,
    "MMLU Score": 31.46054964539008,
    "BBH Score": 34.01111082889911,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.540825104035996
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v11-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2774191774778267,
    "Overall Score": 23.769168519505644,
    "MMLU Score": 31.506722813238763,
    "BBH Score": 33.83221649338713,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.607179959859515
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v12-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3129275432231455,
    "Overall Score": 23.67369216786618,
    "MMLU Score": 31.506722813238763,
    "BBH Score": 33.64435993303794,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.031225173134015
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2935494946640862,
    "Overall Score": 23.34429925313133,
    "MMLU Score": 31.405141843971634,
    "BBH Score": 33.60889502995319,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.04669968132411
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.226024618265807,
    "Overall Score": 23.56106225267956,
    "MMLU Score": 31.349734042553195,
    "BBH Score": 33.468587339989305,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.21744629076561
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v4-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2324701395863638,
    "Overall Score": 23.08362197891132,
    "MMLU Score": 31.303560874704488,
    "BBH Score": 33.55721455326533,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.729558824572045
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v5-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2738241090305913,
    "Overall Score": 23.4526279237508,
    "MMLU Score": 31.340499408983447,
    "BBH Score": 33.50776477750613,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.4111980276451
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v6-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.25514859695207,
    "Overall Score": 23.384013675258704,
    "MMLU Score": 31.340499408983447,
    "BBH Score": 34.084081768333256,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.630474297659326
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v7-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2459507125099003,
    "Overall Score": 23.26623532579292,
    "MMLU Score": 31.506722813238763,
    "BBH Score": 33.50209397496653,
    "Math Score": 13.36858006042296,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.67347969080121
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v8-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.90801426512072,
    "Overall Score": 23.53344449915876,
    "MMLU Score": 31.414376477541367,
    "BBH Score": 33.79805527334356,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.333998193493487
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v9-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.227281518781336,
    "Overall Score": 23.37731521074004,
    "MMLU Score": 31.331264775413715,
    "BBH Score": 33.7544160404883,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.048046314551538
  },
  {
    "Model Name": "jaspionjader/Kosmos-EVAA-v9-TitanFusion-Mix-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.516953826809074,
    "Overall Score": 23.357229970545784,
    "MMLU Score": 31.51595744680852,
    "BBH Score": 36.24517494591178,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.397456110894243
  },
  {
    "Model Name": "jaspionjader/Kosmos-Elusive-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.802080473067022,
    "Overall Score": 22.72148946873371,
    "MMLU Score": 30.66637115839244,
    "BBH Score": 33.53558413403654,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.608476595977558
  },
  {
    "Model Name": "jaspionjader/Kosmos-Elusive-VENN-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.23513328622024,
    "Overall Score": 22.81033720971873,
    "MMLU Score": 31.08192966903073,
    "BBH Score": 33.79747989824394,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.46791553932047
  },
  {
    "Model Name": "jaspionjader/Kosmos-Elusive-VENN-Asymmetric-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.286053014145634,
    "Overall Score": 23.56177185056856,
    "MMLU Score": 31.580599881796683,
    "BBH Score": 33.16698443913645,
    "Math Score": 13.444108761329304,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.32099578431562
  },
  {
    "Model Name": "jaspionjader/Kosmos-Elusive-VENN-Aurora_faustus-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3093567484866826,
    "Overall Score": 22.711557989116244,
    "MMLU Score": 31.05422576832151,
    "BBH Score": 33.008333200343884,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.345584398878014
  },
  {
    "Model Name": "jaspionjader/Kosmos-VENN-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2884897990741933,
    "Overall Score": 23.14475508223022,
    "MMLU Score": 31.11886820330969,
    "BBH Score": 33.39577047946897,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.9626995098139
  },
  {
    "Model Name": "jaspionjader/PRP-Kosmos-EVAA-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.194688710788678,
    "Overall Score": 21.355970519226545,
    "MMLU Score": 30.73101359338061,
    "BBH Score": 32.11810849839039,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.875761548904503
  },
  {
    "Model Name": "jaspionjader/PRP-Kosmos-EVAA-light-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2956604777136125,
    "Overall Score": 22.818510021314523,
    "MMLU Score": 29.235002955082745,
    "BBH Score": 32.67446090823398,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.611488822736348
  },
  {
    "Model Name": "jaspionjader/TSN-Kosmos-EVAA-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4479009137598755,
    "Overall Score": 24.896257217110144,
    "MMLU Score": 31.451315011820324,
    "BBH Score": 33.73244759125691,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.19472443211609
  },
  {
    "Model Name": "jaspionjader/TSN-Kosmos-EVAA-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4678468493711292,
    "Overall Score": 23.89651047859336,
    "MMLU Score": 30.69407505910165,
    "BBH Score": 33.53146314936159,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.27997531815486
  },
  {
    "Model Name": "jaspionjader/bbb-1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.330856716977883,
    "Overall Score": 24.60960304612495,
    "MMLU Score": 32.190085697399525,
    "BBH Score": 33.68952047615377,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.491549640301304
  },
  {
    "Model Name": "jaspionjader/bbb-2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3060917369107468,
    "Overall Score": 21.656531650464387,
    "MMLU Score": 29.281176122931434,
    "BBH Score": 29.187787519922125,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.581171933364978
  },
  {
    "Model Name": "jaspionjader/bbb-3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9345593718263656,
    "Overall Score": 23.067128829993425,
    "MMLU Score": 31.73758865248227,
    "BBH Score": 30.42347738232735,
    "Math Score": 14.04833836858006,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.923712017282968
  },
  {
    "Model Name": "jaspionjader/bbb-4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0964247692210245,
    "Overall Score": 23.306922027984893,
    "MMLU Score": 30.81412529550828,
    "BBH Score": 31.42180070448896,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.117461675786783
  },
  {
    "Model Name": "jaspionjader/bbb-5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2991299609398377,
    "Overall Score": 23.45290117457669,
    "MMLU Score": 31.488253546099287,
    "BBH Score": 31.2789023752389,
    "Math Score": 13.972809667673715,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.052775226282993
  },
  {
    "Model Name": "jaspionjader/bbb-6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3092681125293013,
    "Overall Score": 24.0711353691946,
    "MMLU Score": 31.903812056737586,
    "BBH Score": 31.296750246994566,
    "Math Score": 13.897280966767372,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.385184164222046
  },
  {
    "Model Name": "jaspionjader/bbb-7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.247956538258571,
    "Overall Score": 23.85265999247541,
    "MMLU Score": 31.774527186761222,
    "BBH Score": 31.125508104842208,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.113373952717932
  },
  {
    "Model Name": "jaspionjader/bh-1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.830374517106328,
    "Overall Score": 22.935035677562382,
    "MMLU Score": 27.21261820330969,
    "BBH Score": 41.45130060035327,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.103180529271556
  },
  {
    "Model Name": "jaspionjader/bh-10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4701216774772474,
    "Overall Score": 24.28628220700425,
    "MMLU Score": 30.084589243498822,
    "BBH Score": 40.86149871302791,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.519912997051986
  },
  {
    "Model Name": "jaspionjader/bh-11",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.361182274376617,
    "Overall Score": 24.42026599244475,
    "MMLU Score": 30.4262706855792,
    "BBH Score": 40.73264327719791,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.94048192673427
  },
  {
    "Model Name": "jaspionjader/bh-12",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3662580036416,
    "Overall Score": 24.40788717366816,
    "MMLU Score": 30.40780141843972,
    "BBH Score": 40.253624510427336,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.86477159409995
  },
  {
    "Model Name": "jaspionjader/bh-13",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3237689917031747,
    "Overall Score": 24.405271709903644,
    "MMLU Score": 30.33392434988179,
    "BBH Score": 40.01032313106834,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.436201378688867
  },
  {
    "Model Name": "jaspionjader/bh-15",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3222540136225729,
    "Overall Score": 24.4983726655142,
    "MMLU Score": 30.74024822695036,
    "BBH Score": 40.33141780064374,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.527735528210748
  },
  {
    "Model Name": "jaspionjader/bh-16",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.36752509458533,
    "Overall Score": 24.57710023673242,
    "MMLU Score": 30.841829196217496,
    "BBH Score": 39.952339093735326,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.97195556706391
  },
  {
    "Model Name": "jaspionjader/bh-17",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3579540781836985,
    "Overall Score": 24.253816929185927,
    "MMLU Score": 30.62943262411348,
    "BBH Score": 39.75841395740856,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.860557524615327
  },
  {
    "Model Name": "jaspionjader/bh-18",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2912412954439991,
    "Overall Score": 24.597830822803832,
    "MMLU Score": 30.62943262411348,
    "BBH Score": 40.464076641342125,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.049755386227606
  },
  {
    "Model Name": "jaspionjader/bh-19",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3182863656471857,
    "Overall Score": 24.18004103008259,
    "MMLU Score": 30.83259456264776,
    "BBH Score": 39.56714484667162,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.34202466185099
  },
  {
    "Model Name": "jaspionjader/bh-2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.8217813681439265,
    "Overall Score": 24.25166292008038,
    "MMLU Score": 29.94606973995272,
    "BBH Score": 41.94562264778238,
    "Math Score": 10.27190332326284,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.594451431945032
  },
  {
    "Model Name": "jaspionjader/bh-20",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.01052450867003,
    "Overall Score": 23.98580950014192,
    "MMLU Score": 30.75871749408984,
    "BBH Score": 39.32473656427744,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.930125395988647
  },
  {
    "Model Name": "jaspionjader/bh-21",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.652223645039114,
    "Overall Score": 24.388213730278952,
    "MMLU Score": 30.841829196217496,
    "BBH Score": 39.30946768551373,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 37.39240966772431
  },
  {
    "Model Name": "jaspionjader/bh-22",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.5978900160791345,
    "Overall Score": 24.20438229027608,
    "MMLU Score": 30.71254432624113,
    "BBH Score": 39.959361669826855,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.316938800514174
  },
  {
    "Model Name": "jaspionjader/bh-23",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3146741406993705,
    "Overall Score": 24.18046602127528,
    "MMLU Score": 31.06346040189125,
    "BBH Score": 38.53896512438835,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.39274484277293
  },
  {
    "Model Name": "jaspionjader/bh-24",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.313076663865094,
    "Overall Score": 24.42300670299736,
    "MMLU Score": 31.21121453900709,
    "BBH Score": 38.79538568907879,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.599833029632297
  },
  {
    "Model Name": "jaspionjader/bh-25",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3318180601928693,
    "Overall Score": 24.01355078586454,
    "MMLU Score": 30.915706264775416,
    "BBH Score": 38.72954410110149,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.030654113811146
  },
  {
    "Model Name": "jaspionjader/bh-26",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3453299226519777,
    "Overall Score": 24.518295926434583,
    "MMLU Score": 30.7956560283688,
    "BBH Score": 38.97859481521599,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.224745851265215
  },
  {
    "Model Name": "jaspionjader/bh-27",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3224764064490586,
    "Overall Score": 24.50292304430969,
    "MMLU Score": 31.10039893617021,
    "BBH Score": 38.70545276461525,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.528060632931627
  },
  {
    "Model Name": "jaspionjader/bh-28",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3363114008274333,
    "Overall Score": 24.48580651508801,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 38.64315088483485,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.32342858103777
  },
  {
    "Model Name": "jaspionjader/bh-29",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3587236809252874,
    "Overall Score": 24.37706592662716,
    "MMLU Score": 31.32203014184397,
    "BBH Score": 38.27176858208672,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.94115041111703
  },
  {
    "Model Name": "jaspionjader/bh-3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5736644333791383,
    "Overall Score": 24.48183645734593,
    "MMLU Score": 30.019946808510632,
    "BBH Score": 41.325395042772,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.850625433288576
  },
  {
    "Model Name": "jaspionjader/bh-30",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2817456204588766,
    "Overall Score": 24.17349100843053,
    "MMLU Score": 30.906471631205672,
    "BBH Score": 38.65102840424575,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.859819470088144
  },
  {
    "Model Name": "jaspionjader/bh-31",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3225714348331734,
    "Overall Score": 24.19175854920456,
    "MMLU Score": 31.331264775413715,
    "BBH Score": 37.88578885449606,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.29145701476311
  },
  {
    "Model Name": "jaspionjader/bh-32",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3191519612253972,
    "Overall Score": 24.181944671595648,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 38.0583806332999,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.331432149130386
  },
  {
    "Model Name": "jaspionjader/bh-33",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3091935598049491,
    "Overall Score": 24.17521279562777,
    "MMLU Score": 31.201979905437344,
    "BBH Score": 37.93177398115369,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.465728474275053
  },
  {
    "Model Name": "jaspionjader/bh-34",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6563342824599672,
    "Overall Score": 24.07521933828956,
    "MMLU Score": 31.15580673758865,
    "BBH Score": 38.20458432336169,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.68133751608201
  },
  {
    "Model Name": "jaspionjader/bh-35",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9903752487611488,
    "Overall Score": 24.218719337673107,
    "MMLU Score": 31.44208037825059,
    "BBH Score": 37.76624487883907,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.167916252348569
  },
  {
    "Model Name": "jaspionjader/bh-36",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.293844683482796,
    "Overall Score": 24.50064612361553,
    "MMLU Score": 31.451315011820324,
    "BBH Score": 38.11710705968076,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.936311627191778
  },
  {
    "Model Name": "jaspionjader/bh-37",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3306327517230658,
    "Overall Score": 24.412457780567525,
    "MMLU Score": 31.42361111111111,
    "BBH Score": 37.51076292376271,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.34650300690051
  },
  {
    "Model Name": "jaspionjader/bh-38",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.271061424375078,
    "Overall Score": 24.065232926604608,
    "MMLU Score": 31.229683806146568,
    "BBH Score": 38.05344075657449,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.933178574305618
  },
  {
    "Model Name": "jaspionjader/bh-39",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.365749840940557,
    "Overall Score": 24.313151042679937,
    "MMLU Score": 31.46054964539008,
    "BBH Score": 37.62931792742345,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.802052992322583
  },
  {
    "Model Name": "jaspionjader/bh-4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.441372809462604,
    "Overall Score": 24.27326191997518,
    "MMLU Score": 30.056885342789595,
    "BBH Score": 41.322953178368685,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.84037728519739
  },
  {
    "Model Name": "jaspionjader/bh-40",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.929656917369135,
    "Overall Score": 24.13085106647801,
    "MMLU Score": 31.49748817966903,
    "BBH Score": 37.62940413720817,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.505254612502645
  },
  {
    "Model Name": "jaspionjader/bh-41",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3416012935225354,
    "Overall Score": 24.2479389953904,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 37.37607576190458,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.07387866459529
  },
  {
    "Model Name": "jaspionjader/bh-42",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9993257286925663,
    "Overall Score": 24.232844116751995,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 37.81206560286688,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.120508313869774
  },
  {
    "Model Name": "jaspionjader/bh-43",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3654369302798086,
    "Overall Score": 24.020973802572843,
    "MMLU Score": 31.331264775413715,
    "BBH Score": 37.6625467846229,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.592151837910528
  },
  {
    "Model Name": "jaspionjader/bh-44",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3557483523937854,
    "Overall Score": 24.3932540087341,
    "MMLU Score": 31.488253546099287,
    "BBH Score": 37.82162994785929,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.99246443166536
  },
  {
    "Model Name": "jaspionjader/bh-46",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.337495322713837,
    "Overall Score": 24.45744275031464,
    "MMLU Score": 31.358968676122927,
    "BBH Score": 37.61558589155505,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.286002451724023
  },
  {
    "Model Name": "jaspionjader/bh-47",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3369329958007805,
    "Overall Score": 24.05418330216361,
    "MMLU Score": 31.719119385342783,
    "BBH Score": 36.31256652223936,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.992063459961145
  },
  {
    "Model Name": "jaspionjader/bh-48",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3058294734706812,
    "Overall Score": 24.04574868881624,
    "MMLU Score": 31.774527186761222,
    "BBH Score": 36.33510481146546,
    "Math Score": 12.537764350453172,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.41415680786142
  },
  {
    "Model Name": "jaspionjader/bh-49",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.36467462653606,
    "Overall Score": 23.89820118999216,
    "MMLU Score": 31.201979905437344,
    "BBH Score": 36.290275257532365,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.51201401806138
  },
  {
    "Model Name": "jaspionjader/bh-5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1091891409697805,
    "Overall Score": 24.28473590988246,
    "MMLU Score": 30.019946808510632,
    "BBH Score": 41.30461071540461,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.513778180517573
  },
  {
    "Model Name": "jaspionjader/bh-50",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2878958881775615,
    "Overall Score": 23.95066016776602,
    "MMLU Score": 31.580599881796683,
    "BBH Score": 36.63331018684279,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.596736263874114
  },
  {
    "Model Name": "jaspionjader/bh-51",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3122423717127931,
    "Overall Score": 23.94353537817681,
    "MMLU Score": 31.46054964539008,
    "BBH Score": 36.60322305451519,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.24627515031748
  },
  {
    "Model Name": "jaspionjader/bh-52",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.29026814085776,
    "Overall Score": 23.45560997649567,
    "MMLU Score": 31.589834515366427,
    "BBH Score": 34.932557534743474,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.178864713270038
  },
  {
    "Model Name": "jaspionjader/bh-53",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.318827514819002,
    "Overall Score": 24.32024154454693,
    "MMLU Score": 31.756057919621743,
    "BBH Score": 35.57594881398253,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.440805390600815
  },
  {
    "Model Name": "jaspionjader/bh-54",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.320474900714138,
    "Overall Score": 24.26650310289129,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 36.353920099875154,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.377102881522017
  },
  {
    "Model Name": "jaspionjader/bh-55",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3167506366817785,
    "Overall Score": 24.48915917092739,
    "MMLU Score": 31.62677304964539,
    "BBH Score": 36.47069849338268,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.598175302683167
  },
  {
    "Model Name": "jaspionjader/bh-56",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2553204749529787,
    "Overall Score": 23.70813110478299,
    "MMLU Score": 31.599069148936167,
    "BBH Score": 35.076883829070766,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.886118387952717
  },
  {
    "Model Name": "jaspionjader/bh-57",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8547357831923847,
    "Overall Score": 23.7518441675172,
    "MMLU Score": 32.18085106382979,
    "BBH Score": 34.57783861568968,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.806052691039017
  },
  {
    "Model Name": "jaspionjader/bh-58",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.346408408874782,
    "Overall Score": 24.27018122084656,
    "MMLU Score": 32.18085106382979,
    "BBH Score": 34.86550097653127,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.025868719231774
  },
  {
    "Model Name": "jaspionjader/bh-59",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.280590894222326,
    "Overall Score": 24.333977051688347,
    "MMLU Score": 31.534426713947987,
    "BBH Score": 35.897385616875816,
    "Math Score": 15.40785498489426,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.002147494158017
  },
  {
    "Model Name": "jaspionjader/bh-6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.2109803566019988,
    "Overall Score": 24.345390925830227,
    "MMLU Score": 29.973773640661943,
    "BBH Score": 41.49290582070984,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.011129453563331
  },
  {
    "Model Name": "jaspionjader/bh-60",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.081683890277799,
    "Overall Score": 24.367675846211625,
    "MMLU Score": 29.88142730496453,
    "BBH Score": 33.68824984560268,
    "Math Score": 15.78549848942598,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.705752232611927
  },
  {
    "Model Name": "jaspionjader/bh-61",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3660730955623497,
    "Overall Score": 24.55820931591465,
    "MMLU Score": 29.770611702127653,
    "BBH Score": 32.55596453531747,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.977229326667295
  },
  {
    "Model Name": "jaspionjader/bh-62",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3805567706646085,
    "Overall Score": 24.43322080140432,
    "MMLU Score": 30.21387411347517,
    "BBH Score": 34.005745917802976,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.698092045604195
  },
  {
    "Model Name": "jaspionjader/bh-63",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4170756790767831,
    "Overall Score": 21.68160361165873,
    "MMLU Score": 24.977836879432623,
    "BBH Score": 27.8107207255612,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.300243968469047
  },
  {
    "Model Name": "jaspionjader/bh-64",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4000885095336175,
    "Overall Score": 24.325275625065377,
    "MMLU Score": 29.918365839243503,
    "BBH Score": 33.698327780013834,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.374098465509405
  },
  {
    "Model Name": "jaspionjader/bh-7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3820944572691356,
    "Overall Score": 24.27717239337679,
    "MMLU Score": 30.167700945626475,
    "BBH Score": 41.169212894944,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.56549435944181
  },
  {
    "Model Name": "jaspionjader/bh-8",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.409182488764274,
    "Overall Score": 24.723236409499417,
    "MMLU Score": 30.223108747044915,
    "BBH Score": 41.42820621241066,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.54438236823356
  },
  {
    "Model Name": "jaspionjader/bh-9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3725313775411982,
    "Overall Score": 24.07777357950316,
    "MMLU Score": 30.029181442080382,
    "BBH Score": 40.93804479430806,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.542603377590495
  },
  {
    "Model Name": "jaspionjader/dp-6-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2714995115249983,
    "Overall Score": 24.73540941734236,
    "MMLU Score": 32.190085697399525,
    "BBH Score": 32.66331333979792,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.453730963431873
  },
  {
    "Model Name": "jaspionjader/dp-7-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3018850832262412,
    "Overall Score": 24.05857973112694,
    "MMLU Score": 32.59640957446809,
    "BBH Score": 32.60386262129972,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.479802895895112
  },
  {
    "Model Name": "jaspionjader/ek-6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3746079267365563,
    "Overall Score": 23.66051017385812,
    "MMLU Score": 31.792996453900702,
    "BBH Score": 31.302615174659127,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.21255182198048
  },
  {
    "Model Name": "jaspionjader/ek-7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2607618925710955,
    "Overall Score": 24.05190462596363,
    "MMLU Score": 32.079270094562645,
    "BBH Score": 30.932091410213463,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.07727761101196
  },
  {
    "Model Name": "jaspionjader/f-1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3471122729437774,
    "Overall Score": 24.950601941148005,
    "MMLU Score": 32.300901300236404,
    "BBH Score": 30.92034478861048,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.521546007909716
  },
  {
    "Model Name": "jaspionjader/f-2-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2418458334556366,
    "Overall Score": 24.65845169680976,
    "MMLU Score": 32.91038711583924,
    "BBH Score": 32.7394137680834,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.8562905575756
  },
  {
    "Model Name": "jaspionjader/f-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2717586051192296,
    "Overall Score": 24.704183722506134,
    "MMLU Score": 32.827275413711575,
    "BBH Score": 32.37894525683091,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.425214520321703
  },
  {
    "Model Name": "jaspionjader/f-4-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3060924340979272,
    "Overall Score": 24.76687133257254,
    "MMLU Score": 32.845744680851055,
    "BBH Score": 32.54745293621357,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.962571626623163
  },
  {
    "Model Name": "jaspionjader/f-5-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.272994814836517,
    "Overall Score": 25.236685497779423,
    "MMLU Score": 32.7626329787234,
    "BBH Score": 32.98155315144156,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.8246569456926
  },
  {
    "Model Name": "jaspionjader/f-6-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2474840432667238,
    "Overall Score": 24.64630433978021,
    "MMLU Score": 32.661052009456256,
    "BBH Score": 32.05231759151268,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.756809293720643
  },
  {
    "Model Name": "jaspionjader/f-7-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.282092306482512,
    "Overall Score": 23.808814144149792,
    "MMLU Score": 32.6241134751773,
    "BBH Score": 32.323956862199424,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.570280800974878
  },
  {
    "Model Name": "jaspionjader/f-8-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2441897490485316,
    "Overall Score": 24.24099112237977,
    "MMLU Score": 32.67028664302601,
    "BBH Score": 32.106937481055674,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.4833554455159
  },
  {
    "Model Name": "jaspionjader/f-9-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.308281193697638,
    "Overall Score": 24.48334046224257,
    "MMLU Score": 32.70722517730496,
    "BBH Score": 32.629822943023534,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.714127039497146
  },
  {
    "Model Name": "jaspionjader/fct-14-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3011536994911783,
    "Overall Score": 22.80635574585233,
    "MMLU Score": 31.949985224586293,
    "BBH Score": 31.53726552564611,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.527795336377903
  },
  {
    "Model Name": "jaspionjader/fct-9-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4732704881335137,
    "Overall Score": 23.25010065000295,
    "MMLU Score": 32.5779403073286,
    "BBH Score": 31.232275252624323,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.78128445337862
  },
  {
    "Model Name": "jaspionjader/fr-1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2811561102040658,
    "Overall Score": 22.0650738987078,
    "MMLU Score": 29.00413711583924,
    "BBH Score": 31.05532835820168,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.22278317448232
  },
  {
    "Model Name": "jaspionjader/fr-10-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2102327181157422,
    "Overall Score": 22.98290735666885,
    "MMLU Score": 31.811465721040182,
    "BBH Score": 31.101142245733232,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.990485889731872
  },
  {
    "Model Name": "jaspionjader/fr-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3036556633338388,
    "Overall Score": 22.896518178840868,
    "MMLU Score": 31.811465721040182,
    "BBH Score": 32.054254099420874,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.563317387267432
  },
  {
    "Model Name": "jaspionjader/gamma-Kosmos-EVAA-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2357917815442745,
    "Overall Score": 22.91189753415071,
    "MMLU Score": 30.841829196217496,
    "BBH Score": 32.36253555048168,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.54025724747859
  },
  {
    "Model Name": "jaspionjader/gamma-Kosmos-EVAA-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2220187804593092,
    "Overall Score": 23.10243444820793,
    "MMLU Score": 30.62019799054373,
    "BBH Score": 32.46635236533594,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.905138626040284
  },
  {
    "Model Name": "jaspionjader/gamma-Kosmos-EVAA-v3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1916567657175103,
    "Overall Score": 23.195991097275467,
    "MMLU Score": 32.19932033096927,
    "BBH Score": 32.436623618170984,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.46532908182575
  },
  {
    "Model Name": "jaspionjader/knf-2-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3370901305776082,
    "Overall Score": 22.8072765120901,
    "MMLU Score": 31.940750591016545,
    "BBH Score": 31.22492769679673,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.057396498946268
  },
  {
    "Model Name": "jaspionjader/knfp-2-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3830640815292654,
    "Overall Score": 24.67250799856437,
    "MMLU Score": 30.28775118203309,
    "BBH Score": 33.05584007121163,
    "Math Score": 14.274924471299094,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.83902013512185
  },
  {
    "Model Name": "jaspionjader/knfp-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.29315344644979,
    "Overall Score": 23.99800729357214,
    "MMLU Score": 32.014627659574465,
    "BBH Score": 31.233992064698388,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.557741433900222
  },
  {
    "Model Name": "jaspionjader/kstc-1-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.353302886543091,
    "Overall Score": 23.579746063684382,
    "MMLU Score": 32.134677895981085,
    "BBH Score": 31.351649338559994,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.42384967781828
  },
  {
    "Model Name": "jaspionjader/kstc-11-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2441986131850935,
    "Overall Score": 23.422736110402607,
    "MMLU Score": 31.98692375886525,
    "BBH Score": 31.11662570042764,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.82556037451403
  },
  {
    "Model Name": "jaspionjader/kstc-4-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.252027183144063,
    "Overall Score": 23.58399542404481,
    "MMLU Score": 31.876108156028373,
    "BBH Score": 31.476699762140168,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.83664807086792
  },
  {
    "Model Name": "jaspionjader/kstc-5-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.231027975432848,
    "Overall Score": 24.077626579224447,
    "MMLU Score": 32.134677895981085,
    "BBH Score": 31.373760830790683,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.558959714752536
  },
  {
    "Model Name": "jaspionjader/kstc-6-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2622968203867957,
    "Overall Score": 23.838631190941225,
    "MMLU Score": 31.746823286052013,
    "BBH Score": 31.50593464386095,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.885123376636994
  },
  {
    "Model Name": "jaspionjader/kstc-8-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.25132188164988,
    "Overall Score": 24.19535866879385,
    "MMLU Score": 32.097739361702125,
    "BBH Score": 31.820932114012862,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.33583918223506
  },
  {
    "Model Name": "jaspionjader/kstc-9-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3353232700936393,
    "Overall Score": 23.936405590737944,
    "MMLU Score": 31.91304669030733,
    "BBH Score": 31.77207937089541,
    "Math Score": 13.595166163141997,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.92555115815469
  },
  {
    "Model Name": "jaspionjader/slu-10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.318348783847079,
    "Overall Score": 21.55040710616896,
    "MMLU Score": 29.595153664302604,
    "BBH Score": 29.96246024103085,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.34651419276364
  },
  {
    "Model Name": "jaspionjader/slu-11",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1244251961237677,
    "Overall Score": 18.804382344048094,
    "MMLU Score": 26.46461288416076,
    "BBH Score": 28.134961733027723,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.723551205426972
  },
  {
    "Model Name": "jaspionjader/slu-13",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2858861333071645,
    "Overall Score": 20.904970185551083,
    "MMLU Score": 28.671690307328607,
    "BBH Score": 29.865275873551703,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.257248323990932
  },
  {
    "Model Name": "jaspionjader/slu-14",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2612141100902652,
    "Overall Score": 20.889513928235285,
    "MMLU Score": 29.18882978723404,
    "BBH Score": 29.879580354102824,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.563019523100817
  },
  {
    "Model Name": "jaspionjader/slu-17",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2847611084904456,
    "Overall Score": 20.804993679674656,
    "MMLU Score": 29.09648345153664,
    "BBH Score": 29.787844658593286,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.193667088911088
  },
  {
    "Model Name": "jaspionjader/slu-2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2531850930850796,
    "Overall Score": 19.75671748019524,
    "MMLU Score": 27.849807919621743,
    "BBH Score": 28.879825492610465,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.765203072722747
  },
  {
    "Model Name": "jaspionjader/slu-20",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3226731418683069,
    "Overall Score": 21.37957338953326,
    "MMLU Score": 29.613622931442084,
    "BBH Score": 29.24863516444493,
    "Math Score": 8.685800604229605,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.16391284647552
  },
  {
    "Model Name": "jaspionjader/slu-22",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2822667377774175,
    "Overall Score": 21.18897829376361,
    "MMLU Score": 29.44739952718675,
    "BBH Score": 29.539288054181537,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.52462601540375
  },
  {
    "Model Name": "jaspionjader/slu-23",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3414044761902386,
    "Overall Score": 22.05300469060442,
    "MMLU Score": 30.27851654846335,
    "BBH Score": 30.2907431370659,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.440234904566438
  },
  {
    "Model Name": "jaspionjader/slu-25",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2431247679452595,
    "Overall Score": 21.53675810500795,
    "MMLU Score": 29.82601950354609,
    "BBH Score": 29.95100639270016,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.324695525619447
  },
  {
    "Model Name": "jaspionjader/slu-29",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3989189692021649,
    "Overall Score": 21.424562623311605,
    "MMLU Score": 29.659796099290777,
    "BBH Score": 29.95867809359305,
    "Math Score": 8.685800604229605,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.315084786884059
  },
  {
    "Model Name": "jaspionjader/slu-32",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.389078085306773,
    "Overall Score": 22.29921319060769,
    "MMLU Score": 30.73101359338061,
    "BBH Score": 30.52574044435336,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.053246701162223
  },
  {
    "Model Name": "jaspionjader/slu-33",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2767204967176065,
    "Overall Score": 21.668822088893943,
    "MMLU Score": 29.770611702127653,
    "BBH Score": 29.520426724137007,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.97225206660624
  },
  {
    "Model Name": "jaspionjader/slu-34",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3281678288401984,
    "Overall Score": 21.49692767091205,
    "MMLU Score": 30.223108747044915,
    "BBH Score": 29.5585553986661,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.18540007077562
  },
  {
    "Model Name": "jaspionjader/slu-35",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.317880945938176,
    "Overall Score": 21.56133130196117,
    "MMLU Score": 29.733673167848696,
    "BBH Score": 29.95432730687622,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.360606296354064
  },
  {
    "Model Name": "jaspionjader/slu-36",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2942129275204786,
    "Overall Score": 21.82465906451858,
    "MMLU Score": 30.12152777777778,
    "BBH Score": 29.705289242535667,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.863267705362375
  },
  {
    "Model Name": "jaspionjader/slu-37",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3346887529396667,
    "Overall Score": 21.805877912918163,
    "MMLU Score": 29.94606973995272,
    "BBH Score": 29.87373618872132,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.33780000385144
  },
  {
    "Model Name": "jaspionjader/slu-6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.286933360341945,
    "Overall Score": 20.953096684197828,
    "MMLU Score": 29.01337174940898,
    "BBH Score": 29.920194960710266,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.28141544068022
  },
  {
    "Model Name": "jaspionjader/slu-mix-1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.384987916328368,
    "Overall Score": 23.420400006262994,
    "MMLU Score": 32.55947104018913,
    "BBH Score": 31.758280422355,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.910183641421916
  },
  {
    "Model Name": "jaspionjader/sof-1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2627230607158582,
    "Overall Score": 21.57226411594584,
    "MMLU Score": 29.715203900709213,
    "BBH Score": 28.67139572134592,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.083923456435627
  },
  {
    "Model Name": "jaspionjader/sof-10",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.310298600597568,
    "Overall Score": 23.315168787914505,
    "MMLU Score": 31.93151595744681,
    "BBH Score": 30.894575246850525,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.793782865433503
  },
  {
    "Model Name": "jaspionjader/sof-3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2059052768508982,
    "Overall Score": 23.121574249978817,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 30.909590596424703,
    "Math Score": 12.764350453172204,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.173623910460456
  },
  {
    "Model Name": "jaspionjader/sof-6",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2643305811944732,
    "Overall Score": 22.79773077631505,
    "MMLU Score": 31.599069148936167,
    "BBH Score": 31.091426922196035,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.031463539208985
  },
  {
    "Model Name": "jaspionjader/test-10",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.239113202739934,
    "Overall Score": 23.988062713940256,
    "MMLU Score": 32.6241134751773,
    "BBH Score": 32.89618100381385,
    "Math Score": 11.404833836858003,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.35905667125305
  },
  {
    "Model Name": "jaspionjader/test-11",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.215754502587888,
    "Overall Score": 24.29911024681541,
    "MMLU Score": 32.661052009456256,
    "BBH Score": 33.37675179363524,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.986856059419615
  },
  {
    "Model Name": "jaspionjader/test-12",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2049300158577163,
    "Overall Score": 23.56243386883551,
    "MMLU Score": 32.61487884160757,
    "BBH Score": 33.309634149213345,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.555022747161665
  },
  {
    "Model Name": "jaspionjader/test-13",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.252774550092542,
    "Overall Score": 23.805351597197618,
    "MMLU Score": 32.61487884160757,
    "BBH Score": 32.89714888833163,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.00210344745519
  },
  {
    "Model Name": "jaspionjader/test-14",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.237467605060922,
    "Overall Score": 23.77110330101908,
    "MMLU Score": 32.55023640661938,
    "BBH Score": 33.002110558637106,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.20947522488785
  },
  {
    "Model Name": "jaspionjader/test-15",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2513938577310617,
    "Overall Score": 23.48260697104523,
    "MMLU Score": 32.55023640661938,
    "BBH Score": 33.10384984912975,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.765160805265754
  },
  {
    "Model Name": "jaspionjader/test-16",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.216782641676609,
    "Overall Score": 23.76530715829608,
    "MMLU Score": 32.55947104018913,
    "BBH Score": 33.07756163805877,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.531267413175602
  },
  {
    "Model Name": "jaspionjader/test-17",
    "Parameters (B)": 4.015,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2887432946876372,
    "Overall Score": 23.3665977153968,
    "MMLU Score": 32.54100177304965,
    "BBH Score": 33.14214119658744,
    "Math Score": 11.027190332326285,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.13130497882462
  },
  {
    "Model Name": "jaspionjader/test-18",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2185558146482152,
    "Overall Score": 23.499236856418005,
    "MMLU Score": 32.55947104018913,
    "BBH Score": 32.86222851906328,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.284497742273707
  },
  {
    "Model Name": "jaspionjader/test-19",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2434502883277698,
    "Overall Score": 23.419129160518,
    "MMLU Score": 32.54100177304965,
    "BBH Score": 32.971901545171306,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.83398908694031
  },
  {
    "Model Name": "jaspionjader/test-20",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2302277666575685,
    "Overall Score": 23.71584434757474,
    "MMLU Score": 32.439420803782504,
    "BBH Score": 33.05064343643468,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.27760451384447
  },
  {
    "Model Name": "jayasuryajsk/Qwen2.5-3B-reasoner",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7555740737503304,
    "Overall Score": 22.088475922135004,
    "MMLU Score": 27.582003546099287,
    "BBH Score": 25.2688279392506,
    "Math Score": 20.84592145015106,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.23403103616
  },
  {
    "Model Name": "jeanmichela/o-distil-qwen",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.887746134959636,
    "Overall Score": 38.35229225785721,
    "MMLU Score": 40.639775413711575,
    "BBH Score": 40.67911488750861,
    "Math Score": 56.49546827794561,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.316445918019195
  },
  {
    "Model Name": "jebcarter/psyonic-cetacean-20B",
    "Parameters (B)": 19.994,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.289896326622158,
    "Overall Score": 16.012258737866414,
    "MMLU Score": 20.951536643026003,
    "BBH Score": 27.843060379681305,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.7325514461731486
  },
  {
    "Model Name": "jebish7/Llama-3-Nanda-10B-Chat",
    "Parameters (B)": 9.985,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.016650032181119,
    "Overall Score": 18.064509209714284,
    "MMLU Score": 23.96202718676123,
    "BBH Score": 29.600465622828253,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.768660441547148
  },
  {
    "Model Name": "jebish7/Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.44099168045061,
    "Overall Score": 24.02231249174472,
    "MMLU Score": 30.860298463356976,
    "BBH Score": 29.191619249410262,
    "Math Score": 15.483383685800604,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.67068090513385
  },
  {
    "Model Name": "jebish7/Nemotron-4-Mini-Hindi-4B-Base",
    "Parameters (B)": 4.191,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.0685416017226625,
    "Overall Score": 12.020294543391651,
    "MMLU Score": 16.703605200945624,
    "BBH Score": 14.862755734528111,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.810999659557854
  },
  {
    "Model Name": "jebish7/Nemotron-4-Mini-Hindi-4B-Instruct",
    "Parameters (B)": 4.191,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.968158775282016,
    "Overall Score": 14.629004135847651,
    "MMLU Score": 17.719414893617017,
    "BBH Score": 16.39051081744601,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.432837390749368
  },
  {
    "Model Name": "jebish7/Nemotron-Mini-4B-Instruct",
    "Parameters (B)": 4.191,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.8120929582167884,
    "Overall Score": 16.90052524850467,
    "MMLU Score": 19.806442080378247,
    "BBH Score": 19.43287640077525,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.009945439080249
  },
  {
    "Model Name": "jebish7/aya-expanse-8b",
    "Parameters (B)": 8.028,
    "Architecture": "CohereForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.7394495348237953,
    "Overall Score": 18.10730460297795,
    "MMLU Score": 23.361776004728128,
    "BBH Score": 28.243958088217383,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.409790132147872
  },
  {
    "Model Name": "jebish7/gemma-2-2b-it",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.4269121183326474,
    "Overall Score": 12.36333618408293,
    "MMLU Score": 19.05843676122932,
    "BBH Score": 20.91911520531148,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.094266121418879
  },
  {
    "Model Name": "jebish7/gemma-2-9b-it",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.890885756746063,
    "Overall Score": 21.76298915231794,
    "MMLU Score": 34.92353723404255,
    "BBH Score": 42.41412690099088,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.694349211813457
  },
  {
    "Model Name": "jebish7/qwen2.5-0.5B-IHA-Hin",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9351933586481094,
    "Overall Score": 3.251315269739358,
    "MMLU Score": 1.041666666666666,
    "BBH Score": 2.697703505644682,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.4766235663172083
  },
  {
    "Model Name": "jeffmeloy/Qwen-7B-nerd-uncensored-v1.0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4146738803403005,
    "Overall Score": 31.82039597916994,
    "MMLU Score": 37.3614804964539,
    "BBH Score": 34.18632007953577,
    "Math Score": 28.700906344410875,
    "Date Submitted": "2024-10-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 22.493096409976502
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-minperplexity-2",
    "Parameters (B)": 7.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9565629076320816,
    "Overall Score": 30.04145905845039,
    "MMLU Score": 37.1767878250591,
    "BBH Score": 36.89009035044375,
    "Math Score": 30.13595166163142,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.354200440612402
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v0.9",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.446062128659443,
    "Overall Score": 31.896915034467217,
    "MMLU Score": 37.37071513002365,
    "BBH Score": 34.79159883396676,
    "Math Score": 29.45619335347432,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.057776358500533
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4631763547494614,
    "Overall Score": 36.19369887340693,
    "MMLU Score": 36.151743498817964,
    "BBH Score": 34.73715707560444,
    "Math Score": 47.12990936555892,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.736388580858627
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.368201065409928,
    "Overall Score": 24.68428340568832,
    "MMLU Score": 31.663711583924343,
    "BBH Score": 26.661152209882328,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.0414151324262
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.251827084819927,
    "Overall Score": 23.39859502000825,
    "MMLU Score": 32.98426418439716,
    "BBH Score": 27.660911941379897,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.69155517063612
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.3",
    "Parameters (B)": 7.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.230700447758749,
    "Overall Score": 24.06198639675365,
    "MMLU Score": 33.51063829787233,
    "BBH Score": 28.900263386108733,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.55145660389851
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3226161315672365,
    "Overall Score": 31.56603265287841,
    "MMLU Score": 37.98943557919622,
    "BBH Score": 34.85601776135507,
    "Math Score": 28.09667673716012,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.866359935799498
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.5",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3682022783351009,
    "Overall Score": 31.834944840883523,
    "MMLU Score": 38.31264775413712,
    "BBH Score": 35.92532095316597,
    "Math Score": 27.567975830815712,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.26771804504077
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.7",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.329739617643981,
    "Overall Score": 28.677649337210752,
    "MMLU Score": 36.44725177304965,
    "BBH Score": 33.83351101288335,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.566364539864967
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.8",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3407312154562865,
    "Overall Score": 31.635927180803225,
    "MMLU Score": 37.149083924349874,
    "BBH Score": 34.6046086730829,
    "Math Score": 27.0392749244713,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.596024927365235
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.0",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8342811688561649,
    "Overall Score": 30.10856309487849,
    "MMLU Score": 39.623965721040186,
    "BBH Score": 38.22235774647793,
    "Math Score": 28.625377643504528,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.414366350200183
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.245356561264993,
    "Overall Score": 30.253116755964555,
    "MMLU Score": 37.2691341607565,
    "BBH Score": 35.43051618397058,
    "Math Score": 38.29305135951662,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 24.292734865615046
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.228986153444949,
    "Overall Score": 28.53753917623895,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 36.44070084062748,
    "Math Score": 28.47432024169184,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.220391129912965
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2636960715772714,
    "Overall Score": 29.2967667117791,
    "MMLU Score": 38.55274822695035,
    "BBH Score": 36.40248084197368,
    "Math Score": 31.04229607250756,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.183396206346192
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.4",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2292866933893654,
    "Overall Score": 29.1823372188292,
    "MMLU Score": 38.41422872340425,
    "BBH Score": 36.64655745900427,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.739244372985304
  },
  {
    "Model Name": "jeffmeloy/Qwen2.5-7B-olm-v1.5",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.025089690934133,
    "Overall Score": 29.23575275519298,
    "MMLU Score": 37.76780437352246,
    "BBH Score": 36.63313094998246,
    "Math Score": 28.172205438066467,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 28.520190002643897
  },
  {
    "Model Name": "jeffmeloy/jeffmeloy_Qwen2.5-7B-minperplexity-1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8395922038311503,
    "Overall Score": 27.475832080246903,
    "MMLU Score": 37.41688829787233,
    "BBH Score": 37.821507463733965,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.93582763779141
  },
  {
    "Model Name": "jeonsworld/CarbonVillain-en-10.7B-v4",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5394617546627765,
    "Overall Score": 20.32867638584285,
    "MMLU Score": 23.795803782505907,
    "BBH Score": 31.80563982727619,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.205054509649644
  },
  {
    "Model Name": "jiangxinyang-shanda/Homer-LLama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.392852021486215,
    "Overall Score": 19.91583079813962,
    "MMLU Score": 23.768099881796687,
    "BBH Score": 31.69897508701321,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.298597762660265
  },
  {
    "Model Name": "jieliu/Storm-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2238269795492844,
    "Overall Score": 19.763877835116062,
    "MMLU Score": 23.54646867612293,
    "BBH Score": 32.33028437916087,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.14924181716829
  },
  {
    "Model Name": "jiviai/medX_v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2845304472152206,
    "Overall Score": 17.31888331901421,
    "MMLU Score": 26.981752364066192,
    "BBH Score": 21.433009954500687,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.482656916821577
  },
  {
    "Model Name": "jlzhou/Qwen2.5-3B-Infinity-Instruct-0625",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.354438305921285,
    "Overall Score": 18.5491918072634,
    "MMLU Score": 24.432993498817968,
    "BBH Score": 26.914542436180227,
    "Math Score": 13.670694864048338,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.878393653642649
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.98703639559152,
    "Overall Score": 22.442126802141008,
    "MMLU Score": 30.43550531914893,
    "BBH Score": 29.55001380445773,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.294270629330985
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.61644064497357,
    "Overall Score": 21.44635595224064,
    "MMLU Score": 30.26928191489361,
    "BBH Score": 28.607718394442788,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.267642099281229
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0731261031285424,
    "Overall Score": 20.2797757714617,
    "MMLU Score": 28.14531619385342,
    "BBH Score": 28.135682301211705,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.78222006893725
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6365972948023049,
    "Overall Score": 21.833220529017808,
    "MMLU Score": 30.43550531914893,
    "BBH Score": 30.51494334374904,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.340618732756235
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.055803756066905,
    "Overall Score": 19.44753152983463,
    "MMLU Score": 26.049054373522463,
    "BBH Score": 27.665794638508448,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.459819047631763
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.630253600257623,
    "Overall Score": 22.37114529020572,
    "MMLU Score": 29.955304373522463,
    "BBH Score": 30.854731427683628,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.722494025880692
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.048876296373344,
    "Overall Score": 18.480197691407646,
    "MMLU Score": 25.5042109929078,
    "BBH Score": 27.16443115792157,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.01967469881852
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.868261638719137,
    "Overall Score": 21.77274590923878,
    "MMLU Score": 29.58591903073286,
    "BBH Score": 31.16350771474489,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.6540132591739
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.039531586586898,
    "Overall Score": 18.508789697368925,
    "MMLU Score": 25.60579196217494,
    "BBH Score": 27.22486881424896,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.075019881571382
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8704515446304009,
    "Overall Score": 21.931665888548704,
    "MMLU Score": 29.44739952718675,
    "BBH Score": 31.124765884679533,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.725332287547912
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.069728793671311,
    "Overall Score": 22.174229898217675,
    "MMLU Score": 30.69407505910165,
    "BBH Score": 29.53001282071684,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.713592025206717
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6826316614050705,
    "Overall Score": 21.30340213029072,
    "MMLU Score": 29.99224290780142,
    "BBH Score": 28.504906370089667,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.660763861118276
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.111585262349261,
    "Overall Score": 20.586572385911417,
    "MMLU Score": 29.01337174940898,
    "BBH Score": 29.136918888444114,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.749344605203232
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.70367132552859,
    "Overall Score": 21.72360178956288,
    "MMLU Score": 30.112293144208035,
    "BBH Score": 30.244175919150702,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.751052074450335
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9053695429986484,
    "Overall Score": 20.250340892451284,
    "MMLU Score": 28.12684692671393,
    "BBH Score": 29.32060751365874,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.628038517179997
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5867146866582529,
    "Overall Score": 21.442231277824096,
    "MMLU Score": 29.659796099290777,
    "BBH Score": 30.69307747198892,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.513602324424902
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.816962842530664,
    "Overall Score": 19.28808146621785,
    "MMLU Score": 27.665115248226947,
    "BBH Score": 28.7392660572686,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.61556186771185
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6125248160666634,
    "Overall Score": 21.626887508307224,
    "MMLU Score": 29.05954491725768,
    "BBH Score": 31.007758447741608,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.411816855668873
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8012618523667672,
    "Overall Score": 19.06061039400886,
    "MMLU Score": 27.268026004728128,
    "BBH Score": 28.219373273671145,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.581809840120792
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8598235896259063,
    "Overall Score": 21.36149715883409,
    "MMLU Score": 29.161125886524825,
    "BBH Score": 30.841602413783743,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.485765251063862
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_dare_linear",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8205118781666905,
    "Overall Score": 14.123522915539402,
    "MMLU Score": 15.715499408983453,
    "BBH Score": 19.610998997495773,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.7579954763943695
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8222681657441384,
    "Overall Score": 11.632495167787908,
    "MMLU Score": 14.05326536643026,
    "BBH Score": 16.85891694951123,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.383525425324917
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.846769484109694,
    "Overall Score": 15.96894703975495,
    "MMLU Score": 22.66917848699764,
    "BBH Score": 23.0949356647322,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.646962805676525
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0754243303213493,
    "Overall Score": 16.77203043517005,
    "MMLU Score": 23.86968085106384,
    "BBH Score": 25.253545989338345,
    "Math Score": 0.3021148036253776,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.081253645404235
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.659320863272562,
    "Overall Score": 17.30976967313407,
    "MMLU Score": 23.814273049645383,
    "BBH Score": 24.68762324471831,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.50909407442946
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_linear",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6522123560637827,
    "Overall Score": 21.370872595590694,
    "MMLU Score": 30.13076241134751,
    "BBH Score": 28.778577217548463,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.93470086769263
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_ties-density-0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5727219149830023,
    "Overall Score": 20.42851214060437,
    "MMLU Score": 28.893321513002363,
    "BBH Score": 28.76871888431649,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.989271622647387
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_ties-density-0.3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.914670665108153,
    "Overall Score": 18.85496971399459,
    "MMLU Score": 25.790484633569736,
    "BBH Score": 27.724506656987163,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.847630747990562
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_ties-density-0.5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6838661913258426,
    "Overall Score": 18.221595666098747,
    "MMLU Score": 24.165189125295505,
    "BBH Score": 26.01209708592899,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.821284826528542
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_ties-density-0.7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.796101901515267,
    "Overall Score": 18.056542734095075,
    "MMLU Score": 23.91585401891253,
    "BBH Score": 25.371407671115207,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.053183908363895
  },
  {
    "Model Name": "johnsutor/Llama-3-8B-Instruct_ties-density-0.9",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8021161854626704,
    "Overall Score": 18.13585052124981,
    "MMLU Score": 24.23906619385342,
    "BBH Score": 25.46373486461887,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.063641105689122
  },
  {
    "Model Name": "jpacifico/Chocolatine-14B-Instruct-4k-DPO",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 9.89640207015256,
    "Overall Score": 30.31642073798448,
    "MMLU Score": 41.8218085106383,
    "BBH Score": 48.02072159780435,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.063378036086314
  },
  {
    "Model Name": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.2",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.081206506576796,
    "Overall Score": 33.79581095053082,
    "MMLU Score": 41.07380319148936,
    "BBH Score": 49.845064475726,
    "Math Score": 20.921450151057403,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 10.968369331427184
  },
  {
    "Model Name": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.3",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.696518369708774,
    "Overall Score": 42.42049137915473,
    "MMLU Score": 48.60002955082743,
    "BBH Score": 54.84648579293099,
    "Math Score": 56.19335347432024,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.00443976120145
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-DPO-v2.0b1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6779976929912963,
    "Overall Score": 27.971479912083165,
    "MMLU Score": 45.8204048463357,
    "BBH Score": 52.01883589019085,
    "Math Score": 27.567975830815712,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.669558026757223
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-v2.0",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8617544792855063,
    "Overall Score": 33.39132529353342,
    "MMLU Score": 47.796616430260045,
    "BBH Score": 53.42017331810562,
    "Math Score": 48.036253776435046,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.93540752288033
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-v2.0.1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8069401829717733,
    "Overall Score": 33.080572523928765,
    "MMLU Score": 47.76891252955083,
    "BBH Score": 52.9014914620923,
    "Math Score": 47.9607250755287,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.307508370046317
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-v2.0.3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.812492225830732,
    "Overall Score": 41.32784968296863,
    "MMLU Score": 48.60002955082743,
    "BBH Score": 50.63134493995173,
    "Math Score": 42.06948640483384,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.840113824484822
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-v2.0b2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.728794217083159,
    "Overall Score": 41.24635883058548,
    "MMLU Score": 48.54462174940899,
    "BBH Score": 49.578491329758265,
    "Math Score": 39.50151057401813,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.06158088360541
  },
  {
    "Model Name": "jpacifico/Chocolatine-2-14B-Instruct-v2.0b3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.850071904512919,
    "Overall Score": 41.4335223068507,
    "MMLU Score": 48.19370567375886,
    "BBH Score": 49.56651063787595,
    "Math Score": 41.08761329305136,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.761752854091837
  },
  {
    "Model Name": "jpacifico/Chocolatine-3B-Instruct-DPO-Revised",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5094489904099078,
    "Overall Score": 28.22663122048826,
    "MMLU Score": 33.205895390070914,
    "BBH Score": 37.1552860906475,
    "Math Score": 18.051359516616312,
    "Date Submitted": "2024-07-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 18.699957004060803
  },
  {
    "Model Name": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.0",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.598445886916085,
    "Overall Score": 25.429590501932733,
    "MMLU Score": 32.63334810874704,
    "BBH Score": 36.55452005645581,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.908946752645205
  },
  {
    "Model Name": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9488891070112528,
    "Overall Score": 27.86191302191085,
    "MMLU Score": 31.96845449172577,
    "BBH Score": 35.99938785144921,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.296304967622756
  },
  {
    "Model Name": "jpacifico/Distilucie-7B-Math-Instruct-DPO-v0.1",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5573261754243181,
    "Overall Score": 11.128777731316648,
    "MMLU Score": 8.992686170212766,
    "BBH Score": 14.914767084175816,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.968159081786887
  },
  {
    "Model Name": "jpacifico/Lucie-7B-Instruct-DPO-v1.1",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4837132153094756,
    "Overall Score": 11.704829753358313,
    "MMLU Score": 9.306663711583925,
    "BBH Score": 14.205402704412563,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.19787052100626
  },
  {
    "Model Name": "jpacifico/Lucie-7B-Instruct-DPO-v1.1.3",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4789030712987271,
    "Overall Score": 10.946784224112012,
    "MMLU Score": 8.484781323877066,
    "BBH Score": 14.5656267629867,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.858037210798543
  },
  {
    "Model Name": "jpacifico/Lucie-7B-Instruct-Merged-Model_Stock-v1.0",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.4924219018987676,
    "Overall Score": 11.63540112320866,
    "MMLU Score": 9.676049054373523,
    "BBH Score": 14.756535323843266,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.62892689854537
  },
  {
    "Model Name": "jpacifico/Lucie-7B-Instruct-Merged-Model_Stock-v1.1",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5822830688657448,
    "Overall Score": 10.89983260022945,
    "MMLU Score": 9.574468085106382,
    "BBH Score": 14.68047975728274,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.719130235851992
  },
  {
    "Model Name": "jpacifico/Lucie-Boosted-7B-Instruct",
    "Parameters (B)": 6.707,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.990112213782646,
    "Overall Score": 8.306616536792435,
    "MMLU Score": 6.998005319148934,
    "BBH Score": 10.258060724767985,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.389570819511112
  },
  {
    "Model Name": "jsfs11/L3-8B-Stheno-slerp",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0704594209467124,
    "Overall Score": 24.999084327806248,
    "MMLU Score": 29.43816489361702,
    "BBH Score": 33.31031560721856,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.35360298449903
  },
  {
    "Model Name": "jsfs11/MixtureofMerges-MoE-4x7b-v4",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7676556130817755,
    "Overall Score": 20.02236121395877,
    "MMLU Score": 22.57683215130024,
    "BBH Score": 32.21799819533692,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.234412084841703
  },
  {
    "Model Name": "jsfs11/MixtureofMerges-MoE-4x7b-v5",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.8625448069978474,
    "Overall Score": 20.434941072567536,
    "MMLU Score": 23.30636820330969,
    "BBH Score": 32.82672418068055,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.138732299530046
  },
  {
    "Model Name": "kaist-ai/janus-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2132069966814876,
    "Overall Score": 17.616998787714394,
    "MMLU Score": 20.822251773049647,
    "BBH Score": 25.749870021061568,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.521016476085752
  },
  {
    "Model Name": "kaist-ai/janus-dpo-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2528567073492922,
    "Overall Score": 18.53164895276002,
    "MMLU Score": 21.95811170212766,
    "BBH Score": 27.090901576814417,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.79151513820603
  },
  {
    "Model Name": "kaist-ai/janus-rm-7b",
    "Parameters (B)": 7.111,
    "Architecture": "LLMForSequenceRegression",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0782212020370971,
    "Overall Score": 4.775598832496902,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 3.27778120364708,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.429145729535184
  },
  {
    "Model Name": "kaist-ai/mistral-orpo-capybara-7k",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3214870679674993,
    "Overall Score": 19.22089458033309,
    "MMLU Score": 21.90270390070922,
    "BBH Score": 23.434359116276923,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.544897976107785
  },
  {
    "Model Name": "kavonalds/BunderMaxx-0710",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3468797122616692,
    "Overall Score": 16.371169453634327,
    "MMLU Score": 3.4888445626477527,
    "BBH Score": 51.57754755283705,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 47.195523044267034
  },
  {
    "Model Name": "kavonalds/BunderMaxx-0710",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3648219238808784,
    "Overall Score": 13.954599839870426,
    "MMLU Score": 4.994089834515365,
    "BBH Score": 36.10977962702472,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.25044200037407
  },
  {
    "Model Name": "kavonalds/BunderMaxx-1010",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.3502886939320566,
    "Overall Score": 17.42694830116734,
    "MMLU Score": 2.491504137115838,
    "BBH Score": 56.82265210373464,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 49.75024487815054
  },
  {
    "Model Name": "kavonalds/Lancer-1-1b-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3665848496232295,
    "Overall Score": 12.306110155307538,
    "MMLU Score": 6.314642434988178,
    "BBH Score": 6.035793918460105,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 33.56960924041344
  },
  {
    "Model Name": "kayfour/T3Q-Qwen2.5-7B-it-KOR-Safe",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6672713485131164,
    "Overall Score": 32.418098677759176,
    "MMLU Score": 38.48810579196217,
    "BBH Score": 36.45157980184221,
    "Math Score": 37.61329305135951,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 48.58308205499391
  },
  {
    "Model Name": "keeeeenw/MicroLlama",
    "Parameters (B)": 0.305,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.371535779070013,
    "Overall Score": 5.266088341806957,
    "MMLU Score": 1.5311022458628842,
    "BBH Score": 2.831363636363637,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.173839071403682
  },
  {
    "Model Name": "kekmodel/StopCarbon-10.7B-v5",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4905873692729197,
    "Overall Score": 20.93299222055526,
    "MMLU Score": 23.96202718676123,
    "BBH Score": 31.9932224557197,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.043452032446764
  },
  {
    "Model Name": "kevin009/llamaRAGdrama",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.279278093587749,
    "Overall Score": 13.348717196012394,
    "MMLU Score": 19.15078309692672,
    "BBH Score": 16.637813694151937,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.434570296264337
  },
  {
    "Model Name": "khoantap/cheap-moe-merge",
    "Parameters (B)": 19.305,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.786928186769573,
    "Overall Score": 21.65501458108568,
    "MMLU Score": 25.98441193853428,
    "BBH Score": 29.79972446284684,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.523780958514739
  },
  {
    "Model Name": "khoantap/llama-3-8b-stock-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4837990968618608,
    "Overall Score": 23.933563133579472,
    "MMLU Score": 31.109633569739948,
    "BBH Score": 30.76062362954177,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.12992162092389
  },
  {
    "Model Name": "khoantap/llama-breadcrumbs-ties-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4975703501702071,
    "Overall Score": 17.906279895712146,
    "MMLU Score": 24.128250591016545,
    "BBH Score": 33.78078314143679,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.956887296598119
  },
  {
    "Model Name": "khoantap/llama-evolve-ties-best-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4619226795471676,
    "Overall Score": 27.644113718571266,
    "MMLU Score": 31.774527186761222,
    "BBH Score": 34.84865280113286,
    "Math Score": 15.634441087613292,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.909422574341665
  },
  {
    "Model Name": "khoantap/llama-linear-0.5-0.5-1-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4518757123498789,
    "Overall Score": 25.90696272224101,
    "MMLU Score": 31.47901891252955,
    "BBH Score": 38.20585226683991,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.843788212635822
  },
  {
    "Model Name": "khoantap/llama-linear-0.5-1-0.5-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3970814355436818,
    "Overall Score": 25.550040759082293,
    "MMLU Score": 29.89066193853428,
    "BBH Score": 42.29147047597542,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.288154225697916
  },
  {
    "Model Name": "khoantap/llama-linear-1-0.5-0.5-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.440187699468754,
    "Overall Score": 25.278191179525752,
    "MMLU Score": 29.281176122931434,
    "BBH Score": 36.494370655874725,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.552011580747557
  },
  {
    "Model Name": "khoantap/llama-slerp-merge",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4480991046886789,
    "Overall Score": 24.169846243728667,
    "MMLU Score": 29.752142434988176,
    "BBH Score": 39.91531358821765,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.69074040959707
  },
  {
    "Model Name": "khoantap/moe-out-merge",
    "Parameters (B)": 19.305,
    "Architecture": "Qwen2MoeForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.691127876028741,
    "Overall Score": 21.17751635635514,
    "MMLU Score": 26.08599290780142,
    "BBH Score": 30.04120594432831,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.514376268566548
  },
  {
    "Model Name": "khulaifi95/Llama-3.1-8B-Reason-Blend-888k",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.37775724599284,
    "Overall Score": 21.101958513598035,
    "MMLU Score": 23.33407210401891,
    "BBH Score": 26.547568201488428,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.316165873902941
  },
  {
    "Model Name": "kms7530/chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1",
    "Parameters (B)": 9.3,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.599955449714945,
    "Overall Score": 17.99671713302148,
    "MMLU Score": 19.98190011820331,
    "BBH Score": 19.079190454097787,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.9123677021995333
  },
  {
    "Model Name": "kms7530/chemeng_phi-3-mini-4k-instruct-bnb-4bit_16_4_100_1_nonmath",
    "Parameters (B)": 4.132,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7139691114871574,
    "Overall Score": 22.110300080411186,
    "MMLU Score": 27.56353427895981,
    "BBH Score": 29.25963050568337,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.14685030379566
  },
  {
    "Model Name": "kms7530/chemeng_qwen-math-7b_24_1_100_1",
    "Parameters (B)": 8.911,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.794124236950634,
    "Overall Score": 11.66485615226577,
    "MMLU Score": 12.871232269503546,
    "BBH Score": 10.326751194458687,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7169035692378267
  },
  {
    "Model Name": "kms7530/chemeng_qwen-math-7b_24_1_100_1_nonmath",
    "Parameters (B)": 15.231,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.5580615242566784,
    "Overall Score": 16.982090044361417,
    "MMLU Score": 16.13105791962175,
    "BBH Score": 14.135344732061384,
    "Math Score": 30.966767371601208,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.638655827207312
  },
  {
    "Model Name": "kno10/ende-chat-0.0.5",
    "Parameters (B)": 7.891,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9640345290148185,
    "Overall Score": 10.850085123772722,
    "MMLU Score": 8.780289598108746,
    "BBH Score": 11.125830654491324,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.6605798675965686
  },
  {
    "Model Name": "kno10/ende-chat-0.0.7",
    "Parameters (B)": 7.891,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9167316612184144,
    "Overall Score": 13.371913816595807,
    "MMLU Score": 10.738031914893616,
    "BBH Score": 13.57894913417845,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.976414115315257
  },
  {
    "Model Name": "kyutai/helium-1-preview-2b",
    "Parameters (B)": 2.173,
    "Architecture": "HeliumForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6881615613910846,
    "Overall Score": 9.329143600411902,
    "MMLU Score": 9.694518321513002,
    "BBH Score": 10.945139672307278,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.556618276605711
  },
  {
    "Model Name": "kz919/QwQ-0.5B-Distilled-SFT",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.019595475018066,
    "Overall Score": 9.089107211771186,
    "MMLU Score": 6.527039007092197,
    "BBH Score": 7.277628928283643,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.914424822854512
  },
  {
    "Model Name": "ladydaina/ECE-FDF",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8924481728804147,
    "Overall Score": 20.04236528565559,
    "MMLU Score": 22.299793144208035,
    "BBH Score": 32.250998220060005,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.45773580438626
  },
  {
    "Model Name": "laislemke/LLaMA-2-vicuna-7b-slerp",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1941514924080088,
    "Overall Score": 7.694402356108033,
    "MMLU Score": 3.802822104018913,
    "BBH Score": 2.598263938597983,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-07-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.443405551997642
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-0.5B-FT-V5-MUSR",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.165879958375255,
    "Overall Score": 7.057838460114436,
    "MMLU Score": 5.926787825059102,
    "BBH Score": 6.485922419195989,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.053657934003845
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-0.5B-SLERP-V4",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8909308333202324,
    "Overall Score": 4.380943329539663,
    "MMLU Score": 1.8727836879432624,
    "BBH Score": 2.096080371265706,
    "Math Score": 0.0,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.316818390362427
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-YL-0.5B-SLERP-BIS-V1",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0505467135859123,
    "Overall Score": 3.610722269051976,
    "MMLU Score": 1.3464095744680846,
    "BBH Score": 2.92944936253925,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.436993540941381
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-YL-1B-SLERP-V3",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.186213983282585,
    "Overall Score": 16.44790148688646,
    "MMLU Score": 21.4594414893617,
    "BBH Score": 18.22865501035824,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.865880624143823
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-YL-1B-SLERP-V4",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.223742513136464,
    "Overall Score": 16.43838512195718,
    "MMLU Score": 21.034648345153663,
    "BBH Score": 17.411751961605876,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.432879012943202
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-YL-6B-SLERP-V1",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.003160791822773,
    "Overall Score": 20.037041744632443,
    "MMLU Score": 24.599216903073284,
    "BBH Score": 24.515258836802445,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.9739083783613
  },
  {
    "Model Name": "lalainy/ECE-PRYMMAL-YL-6B-SLERP-V2",
    "Parameters (B)": 6.061,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.99626226450699,
    "Overall Score": 20.01164616460848,
    "MMLU Score": 24.599216903073284,
    "BBH Score": 24.515258836802445,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.086725029690285
  },
  {
    "Model Name": "langgptai/Qwen-las-v0.1",
    "Parameters (B)": 7.901,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.596192830549491,
    "Overall Score": 11.633178497007412,
    "MMLU Score": 14.727393617021276,
    "BBH Score": 14.698639898107368,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.2348594875625416
  },
  {
    "Model Name": "langgptai/qwen1.5-7b-chat-sa-v0.1",
    "Parameters (B)": 15.443,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.464321083426148,
    "Overall Score": 16.580170752646193,
    "MMLU Score": 22.14280437352246,
    "BBH Score": 20.302342129934097,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.322769944589412
  },
  {
    "Model Name": "lars1234/Mistral-Small-24B-Instruct-2501-writer",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2963527696731758,
    "Overall Score": 39.85579031723165,
    "MMLU Score": 49.42191193853428,
    "BBH Score": 52.78404012259051,
    "Math Score": 35.57401812688822,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 30.744555995571883
  },
  {
    "Model Name": "leafspark/Llama-3.1-8B-MultiReflection-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6968936655051676,
    "Overall Score": 26.87834660945809,
    "MMLU Score": 30.26928191489361,
    "BBH Score": 28.44804503711861,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.839735368130077
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.821376360861339,
    "Overall Score": 23.711508058895607,
    "MMLU Score": 35.847000591016545,
    "BBH Score": 42.03199052898647,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.073179019709905
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-Advanced-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.454554490472016,
    "Overall Score": 28.34483988750465,
    "MMLU Score": 36.040927895981085,
    "BBH Score": 41.16143815473681,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.391447919348469
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-Remix-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.314881808199638,
    "Overall Score": 32.35834799113052,
    "MMLU Score": 35.985520094562645,
    "BBH Score": 41.59231281593379,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.499243184283622
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.992483788088308,
    "Overall Score": 20.43264188820716,
    "MMLU Score": 35.791592789598106,
    "BBH Score": 39.79685359725269,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.4097116672760293
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v2a-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.9627924712961695,
    "Overall Score": 16.03899884599574,
    "MMLU Score": 27.942154255319146,
    "BBH Score": 31.19852836941699,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.6898469002912053
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v2f-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.797191109957615,
    "Overall Score": 20.70451439160213,
    "MMLU Score": 27.812869385342783,
    "BBH Score": 31.421336195418803,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.046039762111564
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.575991958976661,
    "Overall Score": 31.43055370780316,
    "MMLU Score": 35.51455378250591,
    "BBH Score": 42.21047229127766,
    "Math Score": 18.731117824773413,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.636764532488939
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v3b-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.607455531980445,
    "Overall Score": 32.188534615134834,
    "MMLU Score": 35.606900118203306,
    "BBH Score": 41.62398549212332,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.98618454192635
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v3i-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.951019763878497,
    "Overall Score": 23.82403905420512,
    "MMLU Score": 35.182106973995275,
    "BBH Score": 38.238824874777286,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.4274163883130573
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v3j-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.827644953576105,
    "Overall Score": 23.98724578545613,
    "MMLU Score": 34.821956264775416,
    "BBH Score": 38.16656919949616,
    "Math Score": 16.91842900302115,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.513253244501586
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v4-Advanced-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.659128481215576,
    "Overall Score": 33.40277377153587,
    "MMLU Score": 37.4076536643026,
    "BBH Score": 43.18189722480503,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.169318018639619
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v4a-Advanced-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.57923589361994,
    "Overall Score": 33.2858610237303,
    "MMLU Score": 36.77046394799054,
    "BBH Score": 42.73751687792403,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.268867950241678
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v4b-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.850033680484359,
    "Overall Score": 33.46834927886008,
    "MMLU Score": 37.29683806146573,
    "BBH Score": 43.44273930792989,
    "Math Score": 23.338368580060425,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.900642651932613
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v4c-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.530475180368803,
    "Overall Score": 33.406962694028415,
    "MMLU Score": 37.72163120567376,
    "BBH Score": 44.12536650674094,
    "Math Score": 22.658610271903324,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.0405230300302435
  },
  {
    "Model Name": "lemon07r/Gemma-2-Ataraxy-v4d-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.370554856308457,
    "Overall Score": 34.242385930784,
    "MMLU Score": 37.1767878250591,
    "BBH Score": 43.59523930792989,
    "Math Score": 23.338368580060425,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.37594938455225
  },
  {
    "Model Name": "lemon07r/Llama-3-RedMagic4-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5971920239970157,
    "Overall Score": 19.430990497953943,
    "MMLU Score": 29.733673167848696,
    "BBH Score": 19.475746974326068,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.1657197168612
  },
  {
    "Model Name": "lemon07r/llama-3-NeuralMahou-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6924554086165793,
    "Overall Score": 19.846074213837827,
    "MMLU Score": 29.89066193853428,
    "BBH Score": 18.69206874721008,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.726202127865866
  },
  {
    "Model Name": "lesubra/ECE-EIFFEL-3B",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.3088140916354853,
    "Overall Score": 22.50442333553349,
    "MMLU Score": 31.340499408983447,
    "BBH Score": 31.286439186186243,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.747178613065431
  },
  {
    "Model Name": "lesubra/ECE-EIFFEL-3Bv2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7206899111516971,
    "Overall Score": 23.141091471464545,
    "MMLU Score": 33.32594562647754,
    "BBH Score": 36.35313296509659,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.448728513771364
  },
  {
    "Model Name": "lesubra/ECE-EIFFEL-3Bv3",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4342936747088415,
    "Overall Score": 25.50122739306737,
    "MMLU Score": 33.05814125295508,
    "BBH Score": 36.46408334995511,
    "Math Score": 16.691842900302113,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.779641535576083
  },
  {
    "Model Name": "lesubra/ECE-PRYMMAL-3B-SLERP-V1",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4271879067095128,
    "Overall Score": 23.135359696186224,
    "MMLU Score": 32.227024231678485,
    "BBH Score": 35.05306761164019,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.210451046720614
  },
  {
    "Model Name": "lesubra/ECE-PRYMMAL-3B-SLERP-V2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4606505124151783,
    "Overall Score": 23.135359696186224,
    "MMLU Score": 32.227024231678485,
    "BBH Score": 35.05306761164019,
    "Math Score": 16.61631419939577,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.839079574163174
  },
  {
    "Model Name": "lesubra/ECE-PRYMMAL-3B-SLERP_2-V1",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2788553558488625,
    "Overall Score": 24.961424176446453,
    "MMLU Score": 33.2243646572104,
    "BBH Score": 35.710681082357645,
    "Math Score": 16.76737160120846,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.518567179849573
  },
  {
    "Model Name": "lesubra/ECE-PRYMMAL-3B-SLERP_2-V2",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.071033580260257,
    "Overall Score": 24.98681975647042,
    "MMLU Score": 33.2243646572104,
    "BBH Score": 35.710681082357645,
    "Math Score": 16.76737160120846,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.329632438227303
  },
  {
    "Model Name": "lesubra/merge-test",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9370512511842013,
    "Overall Score": 26.07552092100233,
    "MMLU Score": 31.93151595744681,
    "BBH Score": 33.353311441745,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.461451216152005
  },
  {
    "Model Name": "lightblue/suzume-llama-3-8B-multilingual",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6819792497844035,
    "Overall Score": 23.98630635028447,
    "MMLU Score": 26.48308215130024,
    "BBH Score": 28.895092037237777,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.260762344933232
  },
  {
    "Model Name": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-full",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6051331756851843,
    "Overall Score": 20.301707657676165,
    "MMLU Score": 25.66119976359338,
    "BBH Score": 25.07547488849692,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.647989565731804
  },
  {
    "Model Name": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-half",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.772673890349154,
    "Overall Score": 21.50979670721306,
    "MMLU Score": 29.0410756501182,
    "BBH Score": 26.34859792572119,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.134096871577656
  },
  {
    "Model Name": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top25",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6697367010796205,
    "Overall Score": 23.684768112420983,
    "MMLU Score": 29.82601950354609,
    "BBH Score": 27.66528501530012,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.184732297677145
  },
  {
    "Model Name": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top75",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8930085171068,
    "Overall Score": 23.647119777794057,
    "MMLU Score": 30.76795212765957,
    "BBH Score": 28.05625593898892,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.491819008788923
  },
  {
    "Model Name": "lkoenig/BBAI_145_",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8429295416019482,
    "Overall Score": 29.67056749240332,
    "MMLU Score": 38.77437943262411,
    "BBH Score": 36.73010277668871,
    "Math Score": 36.102719033232624,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.19934469969553
  },
  {
    "Model Name": "lkoenig/BBAI_200_Gemma",
    "Parameters (B)": 19.3,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.2482047638736105,
    "Overall Score": 5.086148057258666,
    "MMLU Score": 7.542848699763592,
    "BBH Score": 9.395846417818936,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 1.5658335686920293
  },
  {
    "Model Name": "lkoenig/BBAI_212_QwenLawLo",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6815753688502857,
    "Overall Score": 29.87984729137672,
    "MMLU Score": 38.765144799054376,
    "BBH Score": 36.93312368555738,
    "Math Score": 36.02719033232628,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 43.83938835961677
  },
  {
    "Model Name": "lkoenig/BBAI_212_Qwencore",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6966295253661859,
    "Overall Score": 29.286401247119155,
    "MMLU Score": 38.77437943262411,
    "BBH Score": 36.74407860821423,
    "Math Score": 34.894259818731115,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.040137807430206
  },
  {
    "Model Name": "lkoenig/BBAI_230_Xiaqwen",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7278725264579338,
    "Overall Score": 30.15538586081089,
    "MMLU Score": 38.672798463356976,
    "BBH Score": 36.82828817621174,
    "Math Score": 36.63141993957704,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.42948767081082
  },
  {
    "Model Name": "lkoenig/BBAI_375_QwenDyancabs",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6564723678266879,
    "Overall Score": 30.23229065895235,
    "MMLU Score": 38.62662529550827,
    "BBH Score": 36.71718233521738,
    "Math Score": 37.7643504531722,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 46.05264766747019
  },
  {
    "Model Name": "lkoenig/BBAI_456_QwenKoen",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6667178605086506,
    "Overall Score": 29.811925443075086,
    "MMLU Score": 38.54351359338061,
    "BBH Score": 36.54914615161445,
    "Math Score": 36.85800604229607,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.714454507534946
  },
  {
    "Model Name": "lkoenig/BBAI_7B_KoenQwenDyan",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.672759751244066,
    "Overall Score": 32.02495361134858,
    "MMLU Score": 38.44193262411347,
    "BBH Score": 36.2457227762662,
    "Math Score": 37.38670694864049,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 47.602362585050756
  },
  {
    "Model Name": "lkoenig/BBAI_7B_Qwen2.5koen",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6607702241816975,
    "Overall Score": 29.836311993118755,
    "MMLU Score": 38.71897163120567,
    "BBH Score": 36.307407586886015,
    "Math Score": 36.5558912386707,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.15383850727876
  },
  {
    "Model Name": "lkoenig/BBAI_7B_QwenDyanKoenLo",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6754508597915261,
    "Overall Score": 30.01758177649708,
    "MMLU Score": 38.49734042553191,
    "BBH Score": 36.678248178014,
    "Math Score": 36.40483383685801,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 44.44080770844208
  },
  {
    "Model Name": "lkoenig/BBAI_7B_QwenDyancabsLAW",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6552148107125473,
    "Overall Score": 31.81674398026488,
    "MMLU Score": 38.57121749408983,
    "BBH Score": 36.77999384422684,
    "Math Score": 36.78247734138973,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.55925638442775
  },
  {
    "Model Name": "llmat/Mistral-v0.3-7B-ORPO",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8980608067578275,
    "Overall Score": 12.399290010550857,
    "MMLU Score": 14.2010195035461,
    "BBH Score": 14.86315851911541,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.5326094751045956
  },
  {
    "Model Name": "llmat/Mistral-v0.3-7B-ORPO",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.6268180652325449,
    "Overall Score": 12.024321589275658,
    "MMLU Score": 14.45958924349882,
    "BBH Score": 15.59149132338697,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 19.183112702431004
  },
  {
    "Model Name": "llnYou/ECE-PRYMMAL-YL-1B-SLERP-V5",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2803565086009958,
    "Overall Score": 15.836336402400669,
    "MMLU Score": 21.45020685579196,
    "BBH Score": 18.879659027462832,
    "Math Score": 11.10271903323263,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.368692857042232
  },
  {
    "Model Name": "llnYou/ECE-PRYMMAL-YL-1B-SLERP-V6",
    "Parameters (B)": 1.357,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.110829086472649,
    "Overall Score": 9.39527358365648,
    "MMLU Score": 14.995197990543732,
    "BBH Score": 14.538923027777068,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.457893026091382
  },
  {
    "Model Name": "llnYou/ECE-PRYMMAL-YL-3B-SLERP-V1",
    "Parameters (B)": 2.81,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.158776856871636,
    "Overall Score": 11.626794158168616,
    "MMLU Score": 20.554447399527188,
    "BBH Score": 15.79746247814972,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.033678261022244
  },
  {
    "Model Name": "llnYou/ECE-PRYMMAL-YL-3B-SLERP-V2",
    "Parameters (B)": 2.81,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0876183581709418,
    "Overall Score": 11.813468340726132,
    "MMLU Score": 21.108525413711583,
    "BBH Score": 15.20224370386771,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.861777251160927
  },
  {
    "Model Name": "llnYou/ECE-PRYMMAL-YL-3B-SLERP-V3",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.086650979183976,
    "Overall Score": 23.42685471667849,
    "MMLU Score": 33.81538120567376,
    "BBH Score": 36.62575632451354,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.55876649029568
  },
  {
    "Model Name": "lmsys/vicuna-13b-v1.3",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.188465811376766,
    "Overall Score": 10.435533675653645,
    "MMLU Score": 13.813164893617024,
    "BBH Score": 7.48978931162921,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.768424355274091
  },
  {
    "Model Name": "lmsys/vicuna-7b-v1.3",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.126756406240769,
    "Overall Score": 8.525809191714858,
    "MMLU Score": 9.306663711583925,
    "BBH Score": 6.461378796018201,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.566683574633288
  },
  {
    "Model Name": "lmsys/vicuna-7b-v1.5",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2054362102644438,
    "Overall Score": 10.885152314855338,
    "MMLU Score": 12.741947399527188,
    "BBH Score": 15.15250931284372,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.030052542114523
  },
  {
    "Model Name": "lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8631477143759163,
    "Overall Score": 11.812819354645235,
    "MMLU Score": 10.821143617021276,
    "BBH Score": 14.43786307942362,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.340248421259546
  },
  {
    "Model Name": "lordjia/Llama-3-Cantonese-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5354059256889798,
    "Overall Score": 24.271708884717096,
    "MMLU Score": 27.942154255319146,
    "BBH Score": 26.79103884029782,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 15.808007822964274
  },
  {
    "Model Name": "lordjia/Qwen2-Cantonese-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.032013591793652,
    "Overall Score": 26.309196155583507,
    "MMLU Score": 31.589834515366427,
    "BBH Score": 32.45321665791298,
    "Math Score": 25.604229607250755,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.94735244972474
  },
  {
    "Model Name": "lt-asset/nova-1.3b",
    "Parameters (B)": 1.347,
    "Architecture": "NovaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4954933143986224,
    "Overall Score": 3.853650600815168,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 4.437619873492811,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.777401811147186
  },
  {
    "Model Name": "lunahr/thea-3b-50r-u1",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7253496126746135,
    "Overall Score": 19.037090298507373,
    "MMLU Score": 20.09271572104019,
    "BBH Score": 16.2229363475435,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.033758119895674
  },
  {
    "Model Name": "lunahr/thea-v2-3b-50r",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.265276493490633,
    "Overall Score": 12.953795195391686,
    "MMLU Score": 15.660091607565011,
    "BBH Score": 18.711907810841776,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.237916583477242
  },
  {
    "Model Name": "m42-health/Llama3-Med42-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 50.82246883597565,
    "Overall Score": 35.68301603364157,
    "MMLU Score": 44.02888593380615,
    "BBH Score": 52.9713478709021,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.7021110318116359
  },
  {
    "Model Name": "macadeliccc/Samantha-Qwen-2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.6796147912948087,
    "Overall Score": 25.06508576450433,
    "MMLU Score": 30.87876773049646,
    "BBH Score": 31.41189390746123,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.35398843368554
  },
  {
    "Model Name": "macadeliccc/magistrate-3.2-3b-base",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.460685925775111,
    "Overall Score": 6.046097363125316,
    "MMLU Score": 7.65366430260047,
    "BBH Score": 6.910280939116192,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.139217922509223
  },
  {
    "Model Name": "macadeliccc/magistrate-3.2-3b-it",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4059020586066877,
    "Overall Score": 7.088076253678785,
    "MMLU Score": 6.582446808510639,
    "BBH Score": 5.323155419813335,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.041657212383193
  },
  {
    "Model Name": "magnifi/Phi3_intent_v56_3_w_unknown_5_lr_0.002",
    "Parameters (B)": 3.821,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1572279473649057,
    "Overall Score": 7.1244683931064765,
    "MMLU Score": 5.243424940898343,
    "BBH Score": 5.851019142844943,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.31298991375565
  },
  {
    "Model Name": "maldv/Awqward2.5-32B-Instruct",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.445094544222052,
    "Overall Score": 46.74902268350894,
    "MMLU Score": 52.4785756501182,
    "BBH Score": 57.20733868173476,
    "Math Score": 62.31117824773413,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.279171124803199
  },
  {
    "Model Name": "maldv/Lytta2.5-32B-Instruct",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.23997856391598,
    "Overall Score": 24.790451743833525,
    "MMLU Score": 44.98005319148937,
    "BBH Score": 37.03153984906665,
    "Math Score": 34.44108761329305,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.420947621042006
  },
  {
    "Model Name": "maldv/Qwentile2.5-32B-Instruct",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.065083471182076,
    "Overall Score": 45.9002633632381,
    "MMLU Score": 54.21468676122932,
    "BBH Score": 57.20587763688364,
    "Math Score": 52.19033232628399,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.496775806041315
  },
  {
    "Model Name": "maldv/badger-kappa-llama-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9182506457299924,
    "Overall Score": 21.166688498001093,
    "MMLU Score": 29.94606973995272,
    "BBH Score": 30.153238604373765,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.034370584009936
  },
  {
    "Model Name": "maldv/badger-lambda-llama-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.222044435294825,
    "Overall Score": 20.943850248259498,
    "MMLU Score": 30.74024822695036,
    "BBH Score": 28.10305001435372,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.425486689459758
  },
  {
    "Model Name": "maldv/badger-mu-llama-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8092706264539988,
    "Overall Score": 20.322170525640896,
    "MMLU Score": 29.70596926713948,
    "BBH Score": 30.51396514214568,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.23224476676021
  },
  {
    "Model Name": "maldv/badger-writer-llama-3-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4716210285401963,
    "Overall Score": 21.09688762786649,
    "MMLU Score": 30.66637115839244,
    "BBH Score": 26.8783606145384,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.53564821801458
  },
  {
    "Model Name": "marcuscedricridia/Cheng-1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.072174042569459,
    "Overall Score": 36.05830324427348,
    "MMLU Score": 37.21372635933806,
    "BBH Score": 36.536366691615335,
    "Math Score": 48.94259818731118,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.40119435120509
  },
  {
    "Model Name": "marcuscedricridia/Cheng-2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.626526680992532,
    "Overall Score": 42.84836261136232,
    "MMLU Score": 44.59219858156028,
    "BBH Score": 49.97518634878575,
    "Math Score": 54.38066465256798,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.343473557541383
  },
  {
    "Model Name": "marcuscedricridia/Cheng-2-v1.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6672849363315172,
    "Overall Score": 42.67937804540463,
    "MMLU Score": 45.29403073286053,
    "BBH Score": 50.248143037694966,
    "Math Score": 53.92749244712991,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 25.598130898555908
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-MST",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6958530315799107,
    "Overall Score": 33.66195961349608,
    "MMLU Score": 35.145168439716315,
    "BBH Score": 35.35007344104428,
    "Math Score": 42.44712990936556,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 48.375099461832825
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-MST-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6743135699592855,
    "Overall Score": 35.229152099424084,
    "MMLU Score": 36.65964834515366,
    "BBH Score": 36.82982562300872,
    "Math Score": 46.52567975830816,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 52.24446558527836
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-MST-v1.3",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7067317403547374,
    "Overall Score": 35.73029750670216,
    "MMLU Score": 38.22030141843972,
    "BBH Score": 36.45190695170704,
    "Math Score": 47.583081570996974,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 50.55708618487641
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-Preview",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6838750927656837,
    "Overall Score": 35.12716296399811,
    "MMLU Score": 37.37994976359338,
    "BBH Score": 35.32875647048946,
    "Math Score": 37.53776435045317,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.364881300091064
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-RP-v1.4-1M",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7061472523162416,
    "Overall Score": 33.31791936262957,
    "MMLU Score": 34.83119089834515,
    "BBH Score": 32.681799063269544,
    "Math Score": 33.68580060422961,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 47.18267932551331
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6900126630786094,
    "Overall Score": 35.47835434931775,
    "MMLU Score": 35.85623522458629,
    "BBH Score": 34.40003587057091,
    "Math Score": 43.80664652567976,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.41696123521126
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-v1.2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6894710937811266,
    "Overall Score": 35.53808932923916,
    "MMLU Score": 35.52378841607564,
    "BBH Score": 34.7406275243418,
    "Math Score": 44.03323262839879,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.54398734012882
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-v1.3",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6526124113262405,
    "Overall Score": 33.93143365739242,
    "MMLU Score": 37.16755319148936,
    "BBH Score": 33.96881934058692,
    "Math Score": 33.23262839879154,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.993239890177506
  },
  {
    "Model Name": "marcuscedricridia/Hush-Qwen2.5-7B-v1.4",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6864942532990541,
    "Overall Score": 35.18387958085206,
    "MMLU Score": 35.50531914893617,
    "BBH Score": 35.05829745506504,
    "Math Score": 42.59818731117825,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 51.251528198190286
  },
  {
    "Model Name": "marcuscedricridia/Qwen2.5-7B-Preview",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7067649389855902,
    "Overall Score": 33.62064174853305,
    "MMLU Score": 36.19791666666667,
    "BBH Score": 33.85996689538109,
    "Math Score": 34.44108761329305,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 47.569764562441776
  },
  {
    "Model Name": "marcuscedricridia/Yell-Qwen2.5-7B-Preview",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6761295398176718,
    "Overall Score": 26.14768722498792,
    "MMLU Score": 31.091164302600465,
    "BBH Score": 34.76337530701511,
    "Math Score": 19.259818731117825,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.6725999755003
  },
  {
    "Model Name": "marcuscedricridia/Yell-Qwen2.5-7B-Preview-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.671546849924999,
    "Overall Score": 26.093952629179142,
    "MMLU Score": 31.46054964539008,
    "BBH Score": 34.15662850738155,
    "Math Score": 18.95770392749245,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.856488764847036
  },
  {
    "Model Name": "marcuscedricridia/absolute-o1-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6894055907798708,
    "Overall Score": 36.52860800635401,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 35.65576276082204,
    "Math Score": 50.83081570996979,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 52.985656767059346
  },
  {
    "Model Name": "marcuscedricridia/cursa-o1-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6845874324660594,
    "Overall Score": 36.70965718904586,
    "MMLU Score": 37.69392730496453,
    "BBH Score": 35.70429131124187,
    "Math Score": 49.546827794561935,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 53.62303695352436
  },
  {
    "Model Name": "marcuscedricridia/cursa-o1-7b-2-28-2025",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6999771631262225,
    "Overall Score": 35.843864079562,
    "MMLU Score": 37.38918439716312,
    "BBH Score": 34.668302854132016,
    "Math Score": 48.11178247734139,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 51.20719070244654
  },
  {
    "Model Name": "marcuscedricridia/cursa-o1-7b-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6935658180791084,
    "Overall Score": 36.50277690900421,
    "MMLU Score": 37.6846926713948,
    "BBH Score": 36.06689595024021,
    "Math Score": 49.848942598187314,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 52.63058812514991
  },
  {
    "Model Name": "marcuscedricridia/cursa-o1-7b-v1.2-normalize-false",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6751990549019224,
    "Overall Score": 36.79978502425582,
    "MMLU Score": 38.17412825059102,
    "BBH Score": 36.12772971752309,
    "Math Score": 49.92447129909365,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.50212756829355
  },
  {
    "Model Name": "marcuscedricridia/cursor-o1-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7800219303340636,
    "Overall Score": 20.57143109823525,
    "MMLU Score": 25.014775413711583,
    "BBH Score": 28.820714356242792,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.372888117934107
  },
  {
    "Model Name": "marcuscedricridia/cursorr-o1.2-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6764200040790131,
    "Overall Score": 4.069130519573485,
    "MMLU Score": 0.8939125295508273,
    "BBH Score": 3.4654936219477315,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.015686252676476
  },
  {
    "Model Name": "marcuscedricridia/etr1o-explicit-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8023332738780068,
    "Overall Score": 8.109189405741137,
    "MMLU Score": 2.16829196217494,
    "BBH Score": 4.190313048867292,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 10.10700873284999
  },
  {
    "Model Name": "marcuscedricridia/etr1o-explicit-v1.2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6925911936091056,
    "Overall Score": 4.805786982236451,
    "MMLU Score": 1.4018173758865236,
    "BBH Score": 1.9825717963953269,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.938850835214068
  },
  {
    "Model Name": "marcuscedricridia/etr1o-v1.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.427496992348548,
    "Overall Score": 4.967503215885146,
    "MMLU Score": 1.7434988179669018,
    "BBH Score": 3.321013560260136,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 3.479869479593442
  },
  {
    "Model Name": "marcuscedricridia/etr1o-v1.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7821409347839607,
    "Overall Score": 39.91280232445549,
    "MMLU Score": 47.95360520094562,
    "BBH Score": 47.700911102136416,
    "Math Score": 35.87613293051359,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.395985382207666
  },
  {
    "Model Name": "marcuscedricridia/fan-o1-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6796565802562364,
    "Overall Score": 20.50602935691369,
    "MMLU Score": 25.26411052009456,
    "BBH Score": 26.546331472502214,
    "Math Score": 16.1631419939577,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 30.171162838124424
  },
  {
    "Model Name": "marcuscedricridia/olmner-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6545304247150346,
    "Overall Score": 35.56417304972707,
    "MMLU Score": 36.77046394799054,
    "BBH Score": 35.74684409479422,
    "Math Score": 46.299093655589125,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.33540093298302
  },
  {
    "Model Name": "marcuscedricridia/olmner-della-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.651305802502441,
    "Overall Score": 36.354392479860905,
    "MMLU Score": 37.62005023640661,
    "BBH Score": 35.896041596647144,
    "Math Score": 49.62235649546828,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 55.81770090206536
  },
  {
    "Model Name": "marcuscedricridia/olmner-o1-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6713850918516362,
    "Overall Score": 36.29253264373472,
    "MMLU Score": 37.62005023640661,
    "BBH Score": 35.68672724705917,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.05620870079537
  },
  {
    "Model Name": "marcuscedricridia/olmner-sbr-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6974451975798761,
    "Overall Score": 36.29850278097941,
    "MMLU Score": 37.9155585106383,
    "BBH Score": 35.71538595353347,
    "Math Score": 49.47129909365559,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 52.044953362550416
  },
  {
    "Model Name": "marcuscedricridia/post-cursa-o1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6909705612974125,
    "Overall Score": 36.661699398945466,
    "MMLU Score": 37.34301122931442,
    "BBH Score": 35.82728921979409,
    "Math Score": 48.716012084592144,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 53.05826536243021
  },
  {
    "Model Name": "marcuscedricridia/pre-cursa-o1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7019430148436578,
    "Overall Score": 36.45904597530088,
    "MMLU Score": 38.04484338061466,
    "BBH Score": 35.72155461706918,
    "Math Score": 50.37764350453172,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 51.94017919449105
  },
  {
    "Model Name": "marcuscedricridia/pre-cursa-o1-v1.2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6879118341708577,
    "Overall Score": 36.88627889811711,
    "MMLU Score": 37.80474290780142,
    "BBH Score": 36.1178124071646,
    "Math Score": 50.6797583081571,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 53.620648847502764
  },
  {
    "Model Name": "marcuscedricridia/pre-cursa-o1-v1.3",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6831272927020302,
    "Overall Score": 36.71219961022997,
    "MMLU Score": 37.99867021276595,
    "BBH Score": 35.4685970258894,
    "Math Score": 50.75528700906344,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 53.741374415036404
  },
  {
    "Model Name": "marcuscedricridia/pre-cursa-o1-v1.4",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.691780936716261,
    "Overall Score": 36.26404735397632,
    "MMLU Score": 38.17412825059102,
    "BBH Score": 35.98044535759805,
    "Math Score": 48.338368580060425,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 52.421287475937326
  },
  {
    "Model Name": "marcuscedricridia/pre-cursa-o1-v1.6",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6700119516121076,
    "Overall Score": 36.795179506465466,
    "MMLU Score": 37.92479314420804,
    "BBH Score": 35.92091323812233,
    "Math Score": 50.0,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.917198742400096
  },
  {
    "Model Name": "marcuscedricridia/r1o-et",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6715149105937247,
    "Overall Score": 14.343384030894796,
    "MMLU Score": 17.5531914893617,
    "BBH Score": 18.9129347129545,
    "Math Score": 7.930513595166164,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.359740200277894
  },
  {
    "Model Name": "marcuscedricridia/sbr-o1-7b",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6722542404365971,
    "Overall Score": 36.69314046938948,
    "MMLU Score": 37.27836879432624,
    "BBH Score": 35.77966356053602,
    "Math Score": 49.848942598187314,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.58223728802222
  },
  {
    "Model Name": "marcuscedricridia/stray-r1o-et",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7094334830006445,
    "Overall Score": 5.1276666327892615,
    "MMLU Score": 1.041666666666666,
    "BBH Score": 2.644668427950033,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.227832849249101
  },
  {
    "Model Name": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-EnhancedMUSREnsembleV3",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7035439123483884,
    "Overall Score": 7.224121473565234,
    "MMLU Score": 7.99534574468085,
    "BBH Score": 7.918512040903256,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.240642945098232
  },
  {
    "Model Name": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-MUSR-ENSEMBLE-V2Mathis",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7290301608684984,
    "Overall Score": 7.224121473565234,
    "MMLU Score": 7.99534574468085,
    "BBH Score": 7.918512040903256,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-10-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.178135024513702
  },
  {
    "Model Name": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V4-MUSR-ENSEMBLE-Mathis",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7281217213354472,
    "Overall Score": 7.224121473565234,
    "MMLU Score": 7.99534574468085,
    "BBH Score": 7.918512040903256,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-10-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.180331387758162
  },
  {
    "Model Name": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V4-MUSR-Mathis",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8201847180981523,
    "Overall Score": 7.257344997193762,
    "MMLU Score": 8.00458037825059,
    "BBH Score": 8.079577103291848,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-10-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.9871475268601912
  },
  {
    "Model Name": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V5-MUSR-Mathis",
    "Parameters (B)": 0.63,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1979019569021543,
    "Overall Score": 5.9763915232152165,
    "MMLU Score": 1.291001773049644,
    "BBH Score": 3.083351877626656,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.719134720476193
  },
  {
    "Model Name": "mattshumer/Reflection-Llama-3.1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 39.03104120119348,
    "Overall Score": 24.392555308681647,
    "MMLU Score": 43.94577423167848,
    "BBH Score": 47.86623716674634,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.6249527186053079
  },
  {
    "Model Name": "mattshumer/ref_70_e3",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 64.10397419494268,
    "Overall Score": 35.395599658838286,
    "MMLU Score": 47.80585106382979,
    "BBH Score": 49.27446660003019,
    "Math Score": 27.94561933534744,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.5521592085882053
  },
  {
    "Model Name": "maywell/Qwen2-7B-Multilingual-RP",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.918825671514629,
    "Overall Score": 23.450878693391584,
    "MMLU Score": 31.765292553191493,
    "BBH Score": 30.54356147647468,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.221474332725903
  },
  {
    "Model Name": "meditsolutions/Llama-3.1-MedIT-SUN-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4261000691308154,
    "Overall Score": 30.19415971775715,
    "MMLU Score": 32.402482269503544,
    "BBH Score": 32.001650567550215,
    "Math Score": 20.921450151057403,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 21.172539270796047
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-1B-Instruct",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaMedITForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7034879137518993,
    "Overall Score": 15.524297116936124,
    "MMLU Score": 8.678708628841607,
    "BBH Score": 9.183738602498956,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.067610279387278
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-1B-chat",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0954387327649715,
    "Overall Score": 13.641365564259702,
    "MMLU Score": 9.306663711583925,
    "BBH Score": 8.690237956315015,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.452878610406488
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-26000",
    "Parameters (B)": 2.209,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6263405267461448,
    "Overall Score": 8.143484964590147,
    "MMLU Score": 3.830526004728132,
    "BBH Score": 2.8953053502640427,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.007244688714113
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-34800",
    "Parameters (B)": 2.209,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6310659932660034,
    "Overall Score": 8.193102548827737,
    "MMLU Score": 3.969045508274229,
    "BBH Score": 5.466179719646344,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.023158218400523
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-2.4B-v1.0.0",
    "Parameters (B)": 2.472,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 6.0196429945678105,
    "Overall Score": 13.31712952335647,
    "MMLU Score": 6.02836879432624,
    "BBH Score": 7.211667793228333,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.2122789566381242
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-2.5B-chat",
    "Parameters (B)": 2.472,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9139059464793857,
    "Overall Score": 13.98771014319157,
    "MMLU Score": 9.038859338061464,
    "BBH Score": 9.40909318881213,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.800330003818991
  },
  {
    "Model Name": "meditsolutions/Llama-3.2-SUN-HDIC-1B-Instruct",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7079900426911147,
    "Overall Score": 15.901863518867478,
    "MMLU Score": 7.635195035460991,
    "BBH Score": 9.529081854604923,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 22.460575092869238
  },
  {
    "Model Name": "meditsolutions/MSH-Lite-7B-v1-Bielik-v2.3-Instruct-Llama-Prune",
    "Parameters (B)": 7.646,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.1181999813821943,
    "Overall Score": 14.528174671948811,
    "MMLU Score": 13.222148345153665,
    "BBH Score": 16.138425927069104,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.858736096517528
  },
  {
    "Model Name": "meditsolutions/MSH-v1-Bielik-v2.3-Instruct-MedIT-merge",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6854816575360465,
    "Overall Score": 28.55070593519018,
    "MMLU Score": 27.77593085106383,
    "BBH Score": 38.0234352820579,
    "Math Score": 20.77039274924472,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.939197058321938
  },
  {
    "Model Name": "meditsolutions/MedIT-Mesh-3B-Instruct",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0609726975903322,
    "Overall Score": 28.318227712460025,
    "MMLU Score": 33.46446513002365,
    "BBH Score": 37.54705419374355,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-11-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.69081662212046
  },
  {
    "Model Name": "meditsolutions/SmolLM2-MedIT-Upscale-2B",
    "Parameters (B)": 2.114,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6722832325143988,
    "Overall Score": 15.922534280948163,
    "MMLU Score": 10.784205082742316,
    "BBH Score": 10.514326138245686,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.684265069941542
  },
  {
    "Model Name": "meetkai/functionary-small-v3.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4087393985659924,
    "Overall Score": 24.08333552224185,
    "MMLU Score": 26.09522754137116,
    "BBH Score": 28.616314665836143,
    "Math Score": 15.709969788519636,
    "Date Submitted": "2024-11-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 17.095664071550182
  },
  {
    "Model Name": "meraGPT/mera-mix-4x7B",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3288013261759777,
    "Overall Score": 17.854958732939675,
    "MMLU Score": 19.418587470449168,
    "BBH Score": 17.48643895465503,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.3637802269956705
  },
  {
    "Model Name": "mergekit-community/JAJUKA-WEWILLNEVERFORGETYOU-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5939820838944418,
    "Overall Score": 19.54557410472629,
    "MMLU Score": 22.586066784869978,
    "BBH Score": 20.143745533955016,
    "Math Score": 12.462235649546828,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 32.905999414285
  },
  {
    "Model Name": "mergekit-community/SuperQwen-2.5-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1848733045334847,
    "Overall Score": 3.2597119953830176,
    "MMLU Score": 0.8292700945626471,
    "BBH Score": 1.735104550745163,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.751105947708435
  },
  {
    "Model Name": "mergekit-community/VirtuosoSmall-InstructModelStock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.973855401053847,
    "Overall Score": 38.226936795467445,
    "MMLU Score": 49.11716903073285,
    "BBH Score": 49.941772258845,
    "Math Score": 40.93655589123867,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.619609406353801
  },
  {
    "Model Name": "mergekit-community/diabolic6045_ELN-AOC-CAIN",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7230044845561019,
    "Overall Score": 4.069643163144771,
    "MMLU Score": 2.1221187943262403,
    "BBH Score": 4.63001485442662,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.628793804292074
  },
  {
    "Model Name": "mergekit-community/mergekit-dare_ties-ajgjgea",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6912931762856392,
    "Overall Score": 13.518727290811396,
    "MMLU Score": 8.263150118203308,
    "BBH Score": 9.245558662707438,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.555707700527797
  },
  {
    "Model Name": "mergekit-community/mergekit-della-zgowfmf",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.871068971831803,
    "Overall Score": 37.278572482000335,
    "MMLU Score": 49.05252659574468,
    "BBH Score": 50.99537348773462,
    "Math Score": 36.17824773413897,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.630046055304456
  },
  {
    "Model Name": "mergekit-community/mergekit-model_stock-azgztvm",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.067797803780636,
    "Overall Score": 38.37425822937247,
    "MMLU Score": 48.95094562647754,
    "BBH Score": 50.29437669451047,
    "Math Score": 43.73111782477341,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.433669046604823
  },
  {
    "Model Name": "mergekit-community/mergekit-slerp-fmrazcr",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4609692317722878,
    "Overall Score": 22.697490367242235,
    "MMLU Score": 30.85106382978724,
    "BBH Score": 33.65092926552356,
    "Math Score": 11.933534743202417,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.5359126486929
  },
  {
    "Model Name": "mergekit-community/mergekit-ties-rraxdhv",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.899638950179652,
    "Overall Score": 16.32304915695013,
    "MMLU Score": 32.328605200945624,
    "BBH Score": 31.666384922678485,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.185784726608638
  },
  {
    "Model Name": "mergekit-community/mergekit-ties-ykqemwr",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0678520276800887,
    "Overall Score": 22.44135054998993,
    "MMLU Score": 30.38009751773049,
    "BBH Score": 34.709885806490576,
    "Math Score": 12.235649546827794,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.852493432601536
  },
  {
    "Model Name": "mergekit-community/sexeh_time_testing",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.085064801011152,
    "Overall Score": 25.63134503622095,
    "MMLU Score": 29.63209219858156,
    "BBH Score": 32.4874943439471,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 23.621948672867802
  },
  {
    "Model Name": "meta-llama/Llama-2-13b-chat-hf",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7491390164303326,
    "Overall Score": 11.12963532656997,
    "MMLU Score": 10.257830969267138,
    "BBH Score": 7.155379968626988,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.362922113122538
  },
  {
    "Model Name": "meta-llama/Llama-2-13b-hf",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.224760312615953,
    "Overall Score": 11.065185981273997,
    "MMLU Score": 15.309175531914892,
    "BBH Score": 17.222559825058127,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.973653080076367
  },
  {
    "Model Name": "meta-llama/Llama-2-70b-chat-hf",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 45.79691011052116,
    "Overall Score": 13.073695775827504,
    "MMLU Score": 15.918661347517732,
    "BBH Score": 4.613767082590614,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.2854711320977093
  },
  {
    "Model Name": "meta-llama/Llama-2-70b-hf",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 59.24249323430371,
    "Overall Score": 18.372598605703004,
    "MMLU Score": 30.1954048463357,
    "BBH Score": 35.900061863721675,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.31012534420250487
  },
  {
    "Model Name": "meta-llama/Llama-2-7b-chat-hf",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.7913927457321086,
    "Overall Score": 9.609483264152257,
    "MMLU Score": 7.644429669030731,
    "BBH Score": 4.459171645959485,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.364252639208406
  },
  {
    "Model Name": "meta-llama/Llama-2-7b-hf",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1261891255441274,
    "Overall Score": 8.806357596540016,
    "MMLU Score": 9.56523345153664,
    "BBH Score": 10.35141665784897,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.819608089613858
  },
  {
    "Model Name": "meta-llama/Llama-3.1-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 13.601852032718597,
    "Overall Score": 26.200215843375947,
    "MMLU Score": 40.602836879432616,
    "BBH Score": 46.39941295581887,
    "Math Score": 18.42900302114804,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.92622414803165
  },
  {
    "Model Name": "meta-llama/Llama-3.1-70B-Instruct",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 40.22182401425256,
    "Overall Score": 43.409948245645786,
    "MMLU Score": 47.87972813238771,
    "BBH Score": 55.92799173898473,
    "Math Score": 38.06646525679759,
    "Date Submitted": "2024-08-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.0792635418588554
  },
  {
    "Model Name": "meta-llama/Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4264871618876929,
    "Overall Score": 14.42086519266696,
    "MMLU Score": 25.42109929078014,
    "BBH Score": 25.30447063475493,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.109355049213063
  },
  {
    "Model Name": "meta-llama/Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.1060373342307948,
    "Overall Score": 23.763729445470883,
    "MMLU Score": 31.091164302600465,
    "BBH Score": 29.379192497334035,
    "Math Score": 15.55891238670695,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.283622117815069
  },
  {
    "Model Name": "meta-llama/Llama-3.2-1B",
    "Parameters (B)": 1.24,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.83825703568204,
    "Overall Score": 4.195140014045501,
    "MMLU Score": 2.2606382978723394,
    "BBH Score": 4.366029656556756,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.004598632008098
  },
  {
    "Model Name": "meta-llama/Llama-3.2-1B-Instruct",
    "Parameters (B)": 1.24,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8098090498152448,
    "Overall Score": 14.443126333711136,
    "MMLU Score": 7.579787234042552,
    "BBH Score": 8.742521312303046,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.83522465821577
  },
  {
    "Model Name": "meta-llama/Llama-3.2-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.0137352826123074,
    "Overall Score": 8.697822716562822,
    "MMLU Score": 16.528147163120565,
    "BBH Score": 14.232664884364109,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.3192483101749195
  },
  {
    "Model Name": "meta-llama/Llama-3.2-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9279617086879264,
    "Overall Score": 24.204650807793456,
    "MMLU Score": 24.386820330969268,
    "BBH Score": 24.05918644688548,
    "Math Score": 17.673716012084594,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.554528805588117
  },
  {
    "Model Name": "meta-llama/Llama-3.3-70B-Instruct",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 76.55907410745293,
    "Overall Score": 44.84747145129876,
    "MMLU Score": 48.12906323877069,
    "BBH Score": 56.561410788022194,
    "Math Score": 48.338368580060425,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.585789104350374
  },
  {
    "Model Name": "meta-llama/Meta-Llama-3-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 46.8143715587228,
    "Overall Score": 26.705350171613343,
    "MMLU Score": 41.21232269503546,
    "BBH Score": 48.709812647505885,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.5704519634128765
  },
  {
    "Model Name": "meta-llama/Meta-Llama-3-70B-Instruct",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 36.47830023547829,
    "Overall Score": 36.37222412927012,
    "MMLU Score": 46.74386820330969,
    "BBH Score": 50.18513318440344,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.9970920765078578
  },
  {
    "Model Name": "meta-llama/Meta-Llama-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.7451369952216194,
    "Overall Score": 13.626857071686077,
    "MMLU Score": 24.553043735224584,
    "BBH Score": 24.50076379676797,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.808474124952905
  },
  {
    "Model Name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7974996778909468,
    "Overall Score": 23.90873569393684,
    "MMLU Score": 29.604388297872337,
    "BBH Score": 28.24494957634361,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 29.979617994536937
  },
  {
    "Model Name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.898946514376925,
    "Overall Score": 20.60915944602588,
    "MMLU Score": 28.791740543735223,
    "BBH Score": 26.795283502573653,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-07-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 10.8529436137321
  },
  {
    "Model Name": "mhl1/Qwen2.5-0.5B-cinstruct-stage1",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7648014609925822,
    "Overall Score": 4.551664639073516,
    "MMLU Score": 1.549571513002364,
    "BBH Score": 5.724527290624836,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.5791369395815833
  },
  {
    "Model Name": "microsoft/DialoGPT-medium",
    "Parameters (B)": 0.345,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.2589289702005322,
    "Overall Score": 5.251433606790305,
    "MMLU Score": 1.3187056737588652,
    "BBH Score": 2.5568557723352243,
    "Math Score": 0.0,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 20.28136752223298
  },
  {
    "Model Name": "microsoft/Orca-2-13b",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0171633991909843,
    "Overall Score": 18.501871091807203,
    "MMLU Score": 19.437056737588648,
    "BBH Score": 27.30801949994257,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.172222289591252
  },
  {
    "Model Name": "microsoft/Orca-2-7b",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8106704974598915,
    "Overall Score": 14.404830081400474,
    "MMLU Score": 14.653516548463358,
    "BBH Score": 22.429468402818458,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.955522609778182
  },
  {
    "Model Name": "microsoft/Phi-3-medium-128k-instruct",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.895117489052336,
    "Overall Score": 32.026356176108685,
    "MMLU Score": 41.24002659574468,
    "BBH Score": 48.46045127399018,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.222179758665137
  },
  {
    "Model Name": "microsoft/Phi-3-medium-4k-instruct",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.910525046658732,
    "Overall Score": 33.09765943937642,
    "MMLU Score": 40.84293735224587,
    "BBH Score": 49.38061007422016,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.371714350086892
  },
  {
    "Model Name": "microsoft/Phi-3-mini-128k-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 48.44450318537764,
    "Overall Score": 26.34380993186564,
    "MMLU Score": 30.38009751773049,
    "BBH Score": 37.09976663224031,
    "Math Score": 14.04833836858006,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.5437935823401567
  },
  {
    "Model Name": "microsoft/Phi-3-mini-4k-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8040748299123722,
    "Overall Score": 25.967732638041607,
    "MMLU Score": 31.848404255319146,
    "BBH Score": 39.2693352377728,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 32.29516914597558
  },
  {
    "Model Name": "microsoft/Phi-3-mini-4k-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5733985309086815,
    "Overall Score": 27.56217404359228,
    "MMLU Score": 33.57528073286053,
    "BBH Score": 36.55985530518785,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 17.517605045477165
  },
  {
    "Model Name": "microsoft/Phi-3-small-128k-instruct",
    "Parameters (B)": 7.392,
    "Architecture": "Phi3SmallForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.8980242595219776,
    "Overall Score": 31.96780316372565,
    "MMLU Score": 38.783614066193856,
    "BBH Score": 45.63406964144793,
    "Math Score": 20.26086956521739,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.201027247492279
  },
  {
    "Model Name": "microsoft/Phi-3-small-8k-instruct",
    "Parameters (B)": 7.392,
    "Architecture": "Phi3SmallForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.050907207043598,
    "Overall Score": 32.34201367038736,
    "MMLU Score": 38.95907210401891,
    "BBH Score": 46.20557036638908,
    "Math Score": 18.869565217391305,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.769613349308319
  },
  {
    "Model Name": "microsoft/Phi-3.5-MoE-instruct",
    "Parameters (B)": 42.0,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 9.264557227888623,
    "Overall Score": 36.8789647220093,
    "MMLU Score": 40.639775413711575,
    "BBH Score": 48.77464635932187,
    "Math Score": 31.19335347432024,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.9806505389156035
  },
  {
    "Model Name": "microsoft/Phi-3.5-mini-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.392008604674748,
    "Overall Score": 28.184391192864627,
    "MMLU Score": 32.91038711583924,
    "BBH Score": 36.74585390851661,
    "Math Score": 19.637462235649547,
    "Date Submitted": "2024-08-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.8128190455623465
  },
  {
    "Model Name": "microsoft/Phi-4-mini-instruct",
    "Parameters (B)": 3.836,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8282398315230278,
    "Overall Score": 29.412433568419846,
    "MMLU Score": 32.5779403073286,
    "BBH Score": 38.73553611173529,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.51197666300849
  },
  {
    "Model Name": "microsoft/phi-1",
    "Parameters (B)": 1.418,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5724584950561591,
    "Overall Score": 5.574318195377169,
    "MMLU Score": 1.798906619385342,
    "BBH Score": 4.273999212214679,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.737506288259937
  },
  {
    "Model Name": "microsoft/phi-1_5",
    "Parameters (B)": 1.418,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6817241381152663,
    "Overall Score": 7.170966845799231,
    "MMLU Score": 7.681368203309693,
    "BBH Score": 7.468938770070243,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.51886891613446
  },
  {
    "Model Name": "microsoft/phi-2",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8470419651804781,
    "Overall Score": 15.5342915582149,
    "MMLU Score": 18.088800236406616,
    "BBH Score": 28.038519293439304,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.339459196575966
  },
  {
    "Model Name": "microsoft/phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8783618221059865,
    "Overall Score": 29.48341679122318,
    "MMLU Score": 47.722739361702125,
    "BBH Score": 52.57567157258284,
    "Math Score": 27.870090634441087,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 33.566368720959275
  },
  {
    "Model Name": "microsoft/phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.7731595658140327,
    "Overall Score": 30.35812781134617,
    "MMLU Score": 47.630393026004725,
    "BBH Score": 52.42784845820486,
    "Math Score": 31.64652567975831,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.94712622583434
  },
  {
    "Model Name": "migtissera/Llama-3-70B-Synthia-v3.5",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 17.539395979120005,
    "Overall Score": 35.56935395079021,
    "MMLU Score": 40.64901004728132,
    "BBH Score": 49.118159695748176,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.02796914974348
  },
  {
    "Model Name": "migtissera/Llama-3-8B-Synthia-v3.5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6573967325482626,
    "Overall Score": 19.94844014518933,
    "MMLU Score": 22.55836288416076,
    "BBH Score": 27.54233943005765,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.036007887211424
  },
  {
    "Model Name": "migtissera/Tess-3-7B-SFT",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2943395475718065,
    "Overall Score": 17.20945620208202,
    "MMLU Score": 22.59530141843972,
    "BBH Score": 24.123847398237004,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-07-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.295936320857326
  },
  {
    "Model Name": "migtissera/Tess-3-Mistral-Nemo-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.779983713025445,
    "Overall Score": 16.720173026027776,
    "MMLU Score": 17.386968085106382,
    "BBH Score": 28.042728344416503,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.423345256333178
  },
  {
    "Model Name": "migtissera/Tess-v2.5-Phi-3-medium-128k-14B",
    "Parameters (B)": 13.96,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.476340449162089,
    "Overall Score": 24.14120139478955,
    "MMLU Score": 30.352393617021285,
    "BBH Score": 46.21582810863877,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.3930664275789075
  },
  {
    "Model Name": "migtissera/Tess-v2.5.2-Qwen2-72B",
    "Parameters (B)": 72.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 29.226174533933744,
    "Overall Score": 33.60333761198978,
    "MMLU Score": 50.67782210401892,
    "BBH Score": 52.30813577387958,
    "Math Score": 29.38066465256798,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.1497685943459288
  },
  {
    "Model Name": "migtissera/Trinity-2-Codestral-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.0043146213260017,
    "Overall Score": 21.99524449180148,
    "MMLU Score": 25.642730496453904,
    "BBH Score": 36.41273800501431,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.321218735104891
  },
  {
    "Model Name": "migtissera/Trinity-2-Codestral-22B-v0.2",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.553521592870461,
    "Overall Score": 21.869825084599302,
    "MMLU Score": 26.002881205673763,
    "BBH Score": 37.61424608895926,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 14.077580372854783
  },
  {
    "Model Name": "migtissera/Trinity-2-Codestral-22B-v0.2",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.122415137327222,
    "Overall Score": 22.250269105139868,
    "MMLU Score": 26.150635342789595,
    "BBH Score": 37.78604101957199,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.125980411491994
  },
  {
    "Model Name": "mindw96/DeepSeek-llama3.3-Bllossom-8B-DACON-LLM3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.553126557664898,
    "Overall Score": 4.009061305596173,
    "MMLU Score": 1.1801861702127647,
    "BBH Score": 3.315965497566667,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 2.581284368495852
  },
  {
    "Model Name": "minghaowu/Qwen1.5-1.8B-OpenHermes-2.5",
    "Parameters (B)": 1.837,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.1898006910849936,
    "Overall Score": 8.684751175879422,
    "MMLU Score": 8.798758865248226,
    "BBH Score": 7.561477534247794,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.966000746659887
  },
  {
    "Model Name": "ministral/Ministral-3b-instruct",
    "Parameters (B)": 3.316,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5289738610329241,
    "Overall Score": 3.520082773406306,
    "MMLU Score": 1.032432033096926,
    "BBH Score": 4.675863578564667,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.6545495585219685
  },
  {
    "Model Name": "mistral-community/Mistral-7B-v0.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1064265558408706,
    "Overall Score": 14.215362442692104,
    "MMLU Score": 21.699541962174944,
    "BBH Score": 23.9508653830296,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.847994625263313
  },
  {
    "Model Name": "mistral-community/Mixtral-8x22B-v0.1",
    "Parameters (B)": 0.0,
    "Architecture": "Unknown",
    "Model Type": "仇 other",
    "Training CO2 (kg)": 15.173201632269498,
    "Overall Score": 16.827390145446955,
    "MMLU Score": 28.888888888888893,
    "BBH Score": 12.647903050108935,
    "Math Score": 15.428571428571429,
    "Date Submitted": null,
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": null,
    "Carbon_Efficiency": 1.1090204001283042
  },
  {
    "Model Name": "mistral-community/mixtral-8x22B-v0.3",
    "Parameters (B)": 140.63,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 104.98897033710952,
    "Overall Score": 25.80199472534573,
    "MMLU Score": 40.4366134751773,
    "BBH Score": 45.73104089763324,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.2457590987176843
  },
  {
    "Model Name": "mistralai/Codestral-22B-v0.1",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.6133391218762,
    "Overall Score": 23.27991740686463,
    "MMLU Score": 23.95279255319149,
    "BBH Score": 30.737634411945635,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.908111929289618
  },
  {
    "Model Name": "mistralai/Ministral-8B-Instruct-2410",
    "Parameters (B)": 8.02,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.594172784313864,
    "Overall Score": 24.185603139774845,
    "MMLU Score": 25.458037825059098,
    "BBH Score": 25.82477440941784,
    "Math Score": 19.561933534743204,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 15.171255824809723
  },
  {
    "Model Name": "mistralai/Mistral-7B-Instruct-v0.1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8629137373078644,
    "Overall Score": 12.771229395030618,
    "MMLU Score": 15.715499408983453,
    "BBH Score": 7.647020535827543,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.85551302739685
  },
  {
    "Model Name": "mistralai/Mistral-7B-Instruct-v0.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0688132581019694,
    "Overall Score": 18.50789159273764,
    "MMLU Score": 19.0769060283688,
    "BBH Score": 22.910601936713604,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.316300534673857
  },
  {
    "Model Name": "mistralai/Mistral-7B-Instruct-v0.3",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0755669287782,
    "Overall Score": 19.225098776905867,
    "MMLU Score": 23.05703309692672,
    "BBH Score": 25.56911494885904,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 17.874386300390245
  },
  {
    "Model Name": "mistralai/Mistral-7B-v0.1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7780735286284418,
    "Overall Score": 14.575358924083137,
    "MMLU Score": 22.36443557919621,
    "BBH Score": 22.0182553990746,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.732624087309617
  },
  {
    "Model Name": "mistralai/Mistral-7B-v0.3",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7629089045793841,
    "Overall Score": 14.229760590840252,
    "MMLU Score": 21.699541962174944,
    "BBH Score": 24.03725427191849,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 18.651978637850046
  },
  {
    "Model Name": "mistralai/Mistral-Large-Instruct-2411",
    "Parameters (B)": 122.61,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 52.54461045774598,
    "Overall Score": 46.524214355965,
    "MMLU Score": 50.687056737588655,
    "BBH Score": 52.7448919952634,
    "Math Score": 49.546827794561935,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.8854231471251973
  },
  {
    "Model Name": "mistralai/Mistral-Nemo-Base-2407",
    "Parameters (B)": 11.58,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 3.4059909098206287,
    "Overall Score": 15.239356042755924,
    "MMLU Score": 27.46195330969267,
    "BBH Score": 29.37473644096688,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-07-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 4.474279716606314
  },
  {
    "Model Name": "mistralai/Mistral-Nemo-Instruct-2407",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.468047939362798,
    "Overall Score": 24.66559994130468,
    "MMLU Score": 27.969858156028373,
    "BBH Score": 29.679970381152803,
    "Math Score": 12.68882175226586,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.520442098215786
  },
  {
    "Model Name": "mistralai/Mistral-Small-24B-Base-2501",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 4.275624553104299,
    "Overall Score": 27.195130187978368,
    "MMLU Score": 48.96018026004729,
    "BBH Score": 48.53757597081616,
    "Math Score": 19.71299093655589,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.360504728656182
  },
  {
    "Model Name": "mistralai/Mistral-Small-Instruct-2409",
    "Parameters (B)": 22.05,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3793375088517446,
    "Overall Score": 26.26274897641828,
    "MMLU Score": 32.89191784869976,
    "BBH Score": 30.7920960925092,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.04011803338923
  },
  {
    "Model Name": "mistralai/Mistral-Small-Instruct-2409",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.220014976082721,
    "Overall Score": 29.918947504475216,
    "MMLU Score": 34.43410165484633,
    "BBH Score": 40.5597130348992,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.291555389246305
  },
  {
    "Model Name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "Parameters (B)": 140.621,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 47.14757859237797,
    "Overall Score": 33.88568028808198,
    "MMLU Score": 38.70050236406619,
    "BBH Score": 44.11434558724835,
    "Math Score": 18.731117824773413,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.7187151768926697
  },
  {
    "Model Name": "mistralai/Mixtral-8x22B-v0.1",
    "Parameters (B)": 140.621,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 157.56579172301616,
    "Overall Score": 25.74093627522265,
    "MMLU Score": 40.4366134751773,
    "BBH Score": 45.58840384342722,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.1633662738195894
  },
  {
    "Model Name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 17.48498670577522,
    "Overall Score": 23.8171027058463,
    "MMLU Score": 29.90913120567376,
    "BBH Score": 29.74239838096733,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.3621458858747433
  },
  {
    "Model Name": "mistralai/Mixtral-8x7B-v0.1",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 23.377818804576776,
    "Overall Score": 19.56528101279984,
    "MMLU Score": 31.663711583924343,
    "BBH Score": 30.294194918961484,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-08-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.8369164453002544
  },
  {
    "Model Name": "mistralai/Mixtral-8x7B-v0.1",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.135099854813959,
    "Overall Score": 19.665108918316083,
    "MMLU Score": 31.903812056737586,
    "BBH Score": 30.4002992674255,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.829547520849239
  },
  {
    "Model Name": "mixtao/MixTAO-7Bx2-MoE-v8.1",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.848070143547014,
    "Overall Score": 21.07792698379691,
    "MMLU Score": 23.592641843971627,
    "BBH Score": 32.31034233969924,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.405371737320477
  },
  {
    "Model Name": "mkurman/llama-3.2-MEDIT-3B-o1",
    "Parameters (B)": 3.607,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1526858646753746,
    "Overall Score": 17.028893537984814,
    "MMLU Score": 19.34471040189125,
    "BBH Score": 20.819346310345164,
    "Math Score": 13.066465256797583,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.773230122658422
  },
  {
    "Model Name": "mkurman/phi-4-MedIT-11B-exp-1",
    "Parameters (B)": 11.514,
    "Architecture": "Phi3ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5993077108986922,
    "Overall Score": 24.60723512531726,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 34.73718585543679,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.386179255954328
  },
  {
    "Model Name": "mkurman/phi4-MedIT-10B-o1",
    "Parameters (B)": 10.255,
    "Architecture": "LlamaMedITForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.718869422646144,
    "Overall Score": 18.92073804361014,
    "MMLU Score": 27.859042553191493,
    "BBH Score": 31.19028076222879,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.007664569704355
  },
  {
    "Model Name": "mkxu/llama-3-8b-instruct-fpo",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8134638721206331,
    "Overall Score": 23.813703419888128,
    "MMLU Score": 28.93949468085106,
    "BBH Score": 28.86756493261528,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2025-02-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.2744450442621
  },
  {
    "Model Name": "mkxu/llama-3-8b-po1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0243762813337047,
    "Overall Score": 19.76700219170176,
    "MMLU Score": 28.46852836879432,
    "BBH Score": 29.181758873323105,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.296622297780814
  },
  {
    "Model Name": "mlabonne/AlphaMonarch-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1451434197618258,
    "Overall Score": 17.63062119200965,
    "MMLU Score": 16.36192375886525,
    "BBH Score": 23.947378025426246,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.395993975738495
  },
  {
    "Model Name": "mlabonne/Beyonder-4x7B-v3",
    "Parameters (B)": 24.154,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.772605414165064,
    "Overall Score": 19.40685869832663,
    "MMLU Score": 16.805186170212764,
    "BBH Score": 24.55720918011033,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.999502561445717
  },
  {
    "Model Name": "mlabonne/BigQwen2.5-52B-Instruct",
    "Parameters (B)": 52.268,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 41.174805201061055,
    "Overall Score": 43.55000484859215,
    "MMLU Score": 50.21609042553191,
    "BBH Score": 59.80960695923371,
    "Math Score": 54.7583081570997,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.0576857531185087
  },
  {
    "Model Name": "mlabonne/BigQwen2.5-Echo-47B-Instruct",
    "Parameters (B)": 47.392,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 17.04615353886009,
    "Overall Score": 37.03189501778666,
    "MMLU Score": 41.48936170212765,
    "BBH Score": 44.52224375363397,
    "Math Score": 43.80664652567976,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.1724487541054414
  },
  {
    "Model Name": "mlabonne/ChimeraLlama-3-8B-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6748195150215983,
    "Overall Score": 20.120505180125026,
    "MMLU Score": 28.54240543735224,
    "BBH Score": 28.47879573339652,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-08-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.013536383868535
  },
  {
    "Model Name": "mlabonne/ChimeraLlama-3-8B-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.64747918851681,
    "Overall Score": 20.69713005370356,
    "MMLU Score": 29.650561465721044,
    "BBH Score": 27.64609355033005,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2024-08-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.562908349899546
  },
  {
    "Model Name": "mlabonne/Daredevil-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.0238293771520777,
    "Overall Score": 22.40964638898709,
    "MMLU Score": 31.451315011820324,
    "BBH Score": 31.62685476252992,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.411015501837966
  },
  {
    "Model Name": "mlabonne/Daredevil-8B-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.396723763195856,
    "Overall Score": 19.687995572747763,
    "MMLU Score": 30.010712174940902,
    "BBH Score": 19.865777111108127,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-07-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.214545153295122
  },
  {
    "Model Name": "mlabonne/Hermes-3-Llama-3.1-70B-lorablated",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 51.32537082329407,
    "Overall Score": 31.74585457101121,
    "MMLU Score": 40.87987588652482,
    "BBH Score": 52.75007315730804,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.618521679664189
  },
  {
    "Model Name": "mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.2739685009650388,
    "Overall Score": 23.20255227143772,
    "MMLU Score": 27.812869385342783,
    "BBH Score": 27.12916478111247,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-10-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.086980911575206
  },
  {
    "Model Name": "mlabonne/NeuralBeagle14-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3434142300269432,
    "Overall Score": 18.91007634574491,
    "MMLU Score": 17.793291962174944,
    "BBH Score": 23.959695145493203,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.076132233142754
  },
  {
    "Model Name": "mlabonne/NeuralDaredevil-8B-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4388458273356126,
    "Overall Score": 27.186740676442746,
    "MMLU Score": 31.57136524822695,
    "BBH Score": 30.30798586214647,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.905774798141152
  },
  {
    "Model Name": "mlabonne/NeuralDaredevil-8B-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9850067516335184,
    "Overall Score": 21.499914415098534,
    "MMLU Score": 31.128102836879428,
    "BBH Score": 29.763198395755456,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 21.827174666004517
  },
  {
    "Model Name": "mlabonne/OrpoLlama-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.780599641553538,
    "Overall Score": 15.157036730116474,
    "MMLU Score": 18.94762115839244,
    "BBH Score": 21.95410762879941,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.512321566510177
  },
  {
    "Model Name": "mlabonne/phixtral-2x2_8",
    "Parameters (B)": 4.458,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9219021341362847,
    "Overall Score": 15.553113591688318,
    "MMLU Score": 17.229979314420802,
    "BBH Score": 28.502644855771297,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.092562735343435
  },
  {
    "Model Name": "mlx-community/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1-float32",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0003469456246885,
    "Overall Score": 9.708088086359409,
    "MMLU Score": 7.090351654846336,
    "BBH Score": 7.2211690840719855,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.704721075843322
  },
  {
    "Model Name": "mlx-community/Mistral-Small-24B-Instruct-2501-bf16",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.578044788554092,
    "Overall Score": 38.66942426997438,
    "MMLU Score": 48.83089539007093,
    "BBH Score": 52.39286892867324,
    "Math Score": 32.25075528700906,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.999516083528672
  },
  {
    "Model Name": "mmnga/Llama-3-70B-japanese-suzume-vector-v0.1",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 32.19425003207018,
    "Overall Score": 30.38004447303165,
    "MMLU Score": 46.93779550827424,
    "BBH Score": 50.02266053282724,
    "Math Score": 23.26283987915408,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.9436481496779295
  },
  {
    "Model Name": "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Llama3-8B-v1.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.732228154167841,
    "Overall Score": 15.806892418961333,
    "MMLU Score": 13.314494680851062,
    "BBH Score": 7.891833484522146,
    "Math Score": 32.85498489425982,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.587386839728214
  },
  {
    "Model Name": "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Qwen-7B-v1.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6752667672164052,
    "Overall Score": 17.737904923149653,
    "MMLU Score": 14.736628250591016,
    "BBH Score": 11.565400479411355,
    "Math Score": 34.96978851963746,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.267996270968748
  },
  {
    "Model Name": "moeru-ai/L3.1-Moe-2x8B-v0.2",
    "Parameters (B)": 13.668,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.853135891354159,
    "Overall Score": 28.87809430190244,
    "MMLU Score": 31.756057919621743,
    "BBH Score": 32.94589106477927,
    "Math Score": 16.993957703927492,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.494699153149625
  },
  {
    "Model Name": "moeru-ai/L3.1-Moe-4x8B-v0.1",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.704718244862379,
    "Overall Score": 19.441557290549515,
    "MMLU Score": 27.268026004728128,
    "BBH Score": 27.85676478887692,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.2334504970363787
  },
  {
    "Model Name": "moeru-ai/L3.1-Moe-4x8B-v0.2",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.732653962817818,
    "Overall Score": 18.31051307041189,
    "MMLU Score": 19.58481087470449,
    "BBH Score": 21.33700714055054,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-10-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.7196575334978883
  },
  {
    "Model Name": "monsterapi/Llama-3_1-8B-Instruct-orca-ORPO",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.065360523092142,
    "Overall Score": 4.832138103419669,
    "MMLU Score": 1.8635490543735225,
    "BBH Score": 1.3404688979507675,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.5763686088530013
  },
  {
    "Model Name": "monsterapi/gemma-2-2b-LoRA-MonsterInstruct",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.677375097994,
    "Overall Score": 12.519872991689503,
    "MMLU Score": 10.968897754137116,
    "BBH Score": 11.965057260762338,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.676174437070812
  },
  {
    "Model Name": "mosaicml/mpt-7b",
    "Parameters (B)": 7.0,
    "Architecture": "MPTForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.2870068503861511,
    "Overall Score": 6.032029339143736,
    "MMLU Score": 2.288342198581559,
    "BBH Score": 6.550600790794161,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.686866536362178
  },
  {
    "Model Name": "mosama/Qwen2.5-1.5B-Instruct-CoT-Reflection",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.180675835076376,
    "Overall Score": 11.862792186560862,
    "MMLU Score": 18.34736997635934,
    "BBH Score": 17.973737754110076,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.047459119711277
  },
  {
    "Model Name": "mrdayl/OpenCogito",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.847273411295232,
    "Overall Score": 22.15854722544321,
    "MMLU Score": 27.24032210401891,
    "BBH Score": 26.332720219789724,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 3.236112521648481
  },
  {
    "Model Name": "mrdayl/OpenCognito",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7731262810208155,
    "Overall Score": 22.28566396506271,
    "MMLU Score": 27.14797576832151,
    "BBH Score": 25.985835789865742,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 28.825386631065378
  },
  {
    "Model Name": "mrdayl/OpenCognito-r1",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.837371991061996,
    "Overall Score": 22.15261487014885,
    "MMLU Score": 27.498891843971627,
    "BBH Score": 25.595543700365017,
    "Math Score": 19.033232628398792,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.7728609375756905
  },
  {
    "Model Name": "mrdayl/OpenCognito-r2",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5756295880841664,
    "Overall Score": 21.967469611464537,
    "MMLU Score": 27.351137706855795,
    "BBH Score": 25.775897615557778,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.942026588987288
  },
  {
    "Model Name": "mrdayl/OpenThink",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7678727607437676,
    "Overall Score": 12.3979226641244,
    "MMLU Score": 9.445183215130024,
    "BBH Score": 9.176574989757906,
    "Math Score": 28.851963746223564,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.012904400941405
  },
  {
    "Model Name": "mrm8488/phi-4-14B-grpo-gsm8k-3e",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9518350998409444,
    "Overall Score": 39.20729001022834,
    "MMLU Score": 47.42723108747045,
    "BBH Score": 54.020966104974086,
    "Math Score": 45.2416918429003,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.19126308409938
  },
  {
    "Model Name": "mrm8488/phi-4-14B-grpo-limo",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9483571391292158,
    "Overall Score": 39.0640880591307,
    "MMLU Score": 47.34411938534279,
    "BBH Score": 53.67590173579206,
    "Math Score": 45.69486404833837,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.19132597557019
  },
  {
    "Model Name": "mukaj/Llama-3.1-Hawkish-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.364196599849899,
    "Overall Score": 26.581501102977555,
    "MMLU Score": 25.901300236406616,
    "BBH Score": 28.13584109991744,
    "Math Score": 24.3202416918429,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.485095554337466
  },
  {
    "Model Name": "natong19/Mistral-Nemo-Instruct-2407-abliterated",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4757141885799543,
    "Overall Score": 25.01762542054813,
    "MMLU Score": 27.979092789598106,
    "BBH Score": 29.915044266359,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.105215511528007
  },
  {
    "Model Name": "natong19/Qwen2-7B-Instruct-abliterated",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1516712075859235,
    "Overall Score": 28.51534160052497,
    "MMLU Score": 31.580599881796683,
    "BBH Score": 37.74683385346309,
    "Math Score": 27.64350453172205,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.252648220597736
  },
  {
    "Model Name": "nazimali/Mistral-Nemo-Kurdish",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 3.699454457141784,
    "Overall Score": 19.48223781673813,
    "MMLU Score": 24.830082742316783,
    "BBH Score": 29.855897080399064,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.26624615668068
  },
  {
    "Model Name": "nazimali/Mistral-Nemo-Kurdish-Instruct",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7021165130013975,
    "Overall Score": 18.555957634452803,
    "MMLU Score": 22.91851359338061,
    "BBH Score": 25.56142263482943,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.90169650121805
  },
  {
    "Model Name": "nazimali/Mistral-Nemo-Kurdish-Instruct",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.503441350239854,
    "Overall Score": 19.94862211656385,
    "MMLU Score": 23.186317966903072,
    "BBH Score": 26.02174135407743,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.694007726202729
  },
  {
    "Model Name": "nbeerbower/BigKartoffel-mistral-nemo-20B",
    "Parameters (B)": 20.427,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.457533630709938,
    "Overall Score": 23.763763321614324,
    "MMLU Score": 28.10837765957446,
    "BBH Score": 35.79864416611619,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.669761188476349
  },
  {
    "Model Name": "nbeerbower/DoppelKartoffel-Mistral-Nemo-23B",
    "Parameters (B)": 23.153,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.060303790612012,
    "Overall Score": 19.833865427806835,
    "MMLU Score": 23.11244089834516,
    "BBH Score": 31.92069738572152,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2025-02-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.4810119468042675
  },
  {
    "Model Name": "nbeerbower/DoublePotato-Mistral-Nemo-13B",
    "Parameters (B)": 13.338,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0616733141864731,
    "Overall Score": 26.79626366510183,
    "MMLU Score": 28.847148345153663,
    "BBH Score": 35.211852906317226,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.23965075418229
  },
  {
    "Model Name": "nbeerbower/Dumpling-Qwen2.5-1.5B",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2052012329738229,
    "Overall Score": 15.625094396198312,
    "MMLU Score": 19.686391843971627,
    "BBH Score": 18.17835840988572,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.96471823020255
  },
  {
    "Model Name": "nbeerbower/Dumpling-Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3805834781919857,
    "Overall Score": 34.79872132286164,
    "MMLU Score": 46.33754432624114,
    "BBH Score": 49.666835922992384,
    "Math Score": 30.966767371601208,
    "Date Submitted": "2025-02-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.20580745210286
  },
  {
    "Model Name": "nbeerbower/Dumpling-Qwen2.5-7B-1k-r16",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6338280131013287,
    "Overall Score": 25.2956618399845,
    "MMLU Score": 32.87344858156028,
    "BBH Score": 32.10172952662796,
    "Math Score": 23.6404833836858,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.90934656897302
  },
  {
    "Model Name": "nbeerbower/Dumpling-Qwen2.5-7B-1k-r64-2e-5",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6772306626905065,
    "Overall Score": 25.052668360308672,
    "MMLU Score": 34.68343676122932,
    "BBH Score": 33.86711491322243,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 36.99281462061872
  },
  {
    "Model Name": "nbeerbower/EVA-abliterated-TIES-Qwen2.5-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.230458643725809,
    "Overall Score": 15.375831467238893,
    "MMLU Score": 19.02149822695035,
    "BBH Score": 15.2183657081488,
    "Math Score": 13.746223564954684,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.496016461537563
  },
  {
    "Model Name": "nbeerbower/EVA-abliterated-TIES-Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.395555570529591,
    "Overall Score": 42.16442636538604,
    "MMLU Score": 46.7900413711584,
    "BBH Score": 48.52247811572799,
    "Math Score": 50.45317220543807,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 30.213362517255632
  },
  {
    "Model Name": "nbeerbower/Flammades-Mistral-Nemo-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.254839563055808,
    "Overall Score": 22.56672421581219,
    "MMLU Score": 29.56744976359338,
    "BBH Score": 32.39377187272594,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-10-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.933283124599054
  },
  {
    "Model Name": "nbeerbower/Gemma2-Gutenberg-Doppel-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.8946312576793183,
    "Overall Score": 32.54244427540016,
    "MMLU Score": 34.748079196217496,
    "BBH Score": 41.08306318800703,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.355718968576019
  },
  {
    "Model Name": "nbeerbower/Gutensuppe-mistral-nemo-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.112498654874653,
    "Overall Score": 22.29422199063106,
    "MMLU Score": 29.779846335697403,
    "BBH Score": 35.56934797458052,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.162805341526772
  },
  {
    "Model Name": "nbeerbower/Hermes2-Gutenberg2-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.162242015174426,
    "Overall Score": 19.363860758860653,
    "MMLU Score": 22.14280437352246,
    "BBH Score": 28.907334664767347,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.66078192497161
  },
  {
    "Model Name": "nbeerbower/Kartoffel-Deepfry-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8020515214304915,
    "Overall Score": 24.14748758265313,
    "MMLU Score": 28.690159574468087,
    "BBH Score": 33.75497378644494,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 30.107152642245605
  },
  {
    "Model Name": "nbeerbower/Llama-3.1-Nemotron-lorablated-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 70.17863885649874,
    "Overall Score": 40.87645031021374,
    "MMLU Score": 48.25834810874704,
    "BBH Score": 54.18258128894629,
    "Math Score": 33.383685800604226,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.5824628544562954
  },
  {
    "Model Name": "nbeerbower/Llama3.1-Gutenberg-Doppel-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 19.987186070631697,
    "Overall Score": 36.9233900222014,
    "MMLU Score": 41.51706560283688,
    "BBH Score": 52.556778995199046,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.847353093713128
  },
  {
    "Model Name": "nbeerbower/Lyra-Gutenberg-mistral-nemo-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.837203880171369,
    "Overall Score": 22.867363852612016,
    "MMLU Score": 29.19806442080379,
    "BBH Score": 36.99243243937594,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.959382030957074
  },
  {
    "Model Name": "nbeerbower/Lyra4-Gutenberg-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.381067171584864,
    "Overall Score": 19.84411922998086,
    "MMLU Score": 28.570109338061467,
    "BBH Score": 34.23559275480162,
    "Math Score": 12.990936555891238,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.869188106274444
  },
  {
    "Model Name": "nbeerbower/Lyra4-Gutenberg2-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.6186791428073777,
    "Overall Score": 19.944881796280978,
    "MMLU Score": 28.50546690307328,
    "BBH Score": 33.73063962440059,
    "Math Score": 11.706948640483382,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.51164693225819
  },
  {
    "Model Name": "nbeerbower/Mahou-1.5-mistral-nemo-12B-lorablated",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.810848990859813,
    "Overall Score": 27.050923083044733,
    "MMLU Score": 28.59781323877068,
    "BBH Score": 36.077381004161374,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-10-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.623755374624414
  },
  {
    "Model Name": "nbeerbower/Mistral-Gutenberg-Doppel-7B-FFT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8736325668731033,
    "Overall Score": 18.33827572865676,
    "MMLU Score": 19.20619089834516,
    "BBH Score": 17.34657495584369,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.990833473954535
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.553542590294508,
    "Overall Score": 21.53798697951247,
    "MMLU Score": 28.65322104018913,
    "BBH Score": 32.42152675939865,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.060990246279125
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.809713066840293,
    "Overall Score": 25.90126357738714,
    "MMLU Score": 28.29307033096927,
    "BBH Score": 34.35741284991507,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2024-10-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.218472833781142
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Moderne-12B-FFT-experimental",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.434314828450036,
    "Overall Score": 18.11946550214844,
    "MMLU Score": 27.277260638297868,
    "BBH Score": 32.0715397550976,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.44335337828319
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Prism-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9185760053957552,
    "Overall Score": 27.924007108863105,
    "MMLU Score": 28.680924940898343,
    "BBH Score": 35.91800839002647,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.55454828494171
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Prism-12B-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.87110437363746,
    "Overall Score": 28.07046513725069,
    "MMLU Score": 28.52393617021276,
    "BBH Score": 36.19978764533613,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.002084080794067
  },
  {
    "Model Name": "nbeerbower/Mistral-Nemo-Prism-12B-v7",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9510222086933136,
    "Overall Score": 28.03478834595649,
    "MMLU Score": 28.782505910165483,
    "BBH Score": 36.44001728504705,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.369282021004073
  },
  {
    "Model Name": "nbeerbower/Mistral-Small-Drummer-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.22544340715805,
    "Overall Score": 29.81940879761473,
    "MMLU Score": 34.38792848699764,
    "BBH Score": 40.12177010845507,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.245057200953566
  },
  {
    "Model Name": "nbeerbower/Mistral-Small-Gutenberg-Doppel-22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.177206465624349,
    "Overall Score": 27.972039733086746,
    "MMLU Score": 34.711140661938536,
    "BBH Score": 40.93134519747112,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.803972935259024
  },
  {
    "Model Name": "nbeerbower/Nemo-Loony-12B-experimental",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.475163168845021,
    "Overall Score": 10.46956739279853,
    "MMLU Score": 6.545508274231676,
    "BBH Score": 12.974588389942944,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.229849379054843
  },
  {
    "Model Name": "nbeerbower/Nemoties-ChatML-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6053630785359911,
    "Overall Score": 26.439234908921165,
    "MMLU Score": 28.33924349881796,
    "BBH Score": 35.76579510118981,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 16.469317914694034
  },
  {
    "Model Name": "nbeerbower/Qwen2.5-Gutenberg-Doppel-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.3812237309009148,
    "Overall Score": 41.327794892427,
    "MMLU Score": 43.567154255319146,
    "BBH Score": 48.23890863039215,
    "Math Score": 54.15407854984894,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.22273300483886
  },
  {
    "Model Name": "nbeerbower/SmolNemo-12B-FFT-experimental",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.450829511655165,
    "Overall Score": 8.496288137169051,
    "MMLU Score": 2.40839243498818,
    "BBH Score": 6.542438534179723,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.466698967334979
  },
  {
    "Model Name": "nbeerbower/Stella-mistral-nemo-12B-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4817441830156293,
    "Overall Score": 22.49330971799377,
    "MMLU Score": 29.82601950354609,
    "BBH Score": 35.364516100686416,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.460356802696437
  },
  {
    "Model Name": "nbeerbower/gemma2-gutenberg-27B",
    "Parameters (B)": 27.227,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 15.390916539476832,
    "Overall Score": 10.4236638747709,
    "MMLU Score": 10.913489952718674,
    "BBH Score": 13.091524912026523,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.6772607627385147
  },
  {
    "Model Name": "nbeerbower/gemma2-gutenberg-9B",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.619217537698095,
    "Overall Score": 23.71924645280773,
    "MMLU Score": 35.4683806146572,
    "BBH Score": 42.35561106809721,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.2210941814728695
  },
  {
    "Model Name": "nbeerbower/llama-3-gutenberg-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7671387810092376,
    "Overall Score": 21.30881705657422,
    "MMLU Score": 31.451315011820324,
    "BBH Score": 27.958132724191334,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-07-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.058372146869221
  },
  {
    "Model Name": "nbeerbower/llama3.1-cc-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8744749214923344,
    "Overall Score": 20.25604166075388,
    "MMLU Score": 26.076758274231683,
    "BBH Score": 26.48381169342659,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.806248421092421
  },
  {
    "Model Name": "nbeerbower/llama3.1-kartoffeldes-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 23.33503403405791,
    "Overall Score": 41.11056038125863,
    "MMLU Score": 44.31515957446809,
    "BBH Score": 55.593932574971824,
    "Math Score": 32.17522658610272,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.7617527500177208
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-bophades-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.104693009226808,
    "Overall Score": 25.72860228091272,
    "MMLU Score": 27.785165484633573,
    "BBH Score": 29.543905352144947,
    "Math Score": 12.31117824773414,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.2680941602887765
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-bophades3-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8778242145913857,
    "Overall Score": 27.16558651541493,
    "MMLU Score": 26.34456264775413,
    "BBH Score": 35.24465712316055,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.466522640579623
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-cc-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.989244841610021,
    "Overall Score": 17.20341027317436,
    "MMLU Score": 28.865617612293136,
    "BBH Score": 34.44654701952267,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.755102437145471
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutades-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.649240112002621,
    "Overall Score": 21.075924659452493,
    "MMLU Score": 28.45005910165484,
    "BBH Score": 34.57440821872691,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.775428311809962
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutenberg-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.1496291404937486,
    "Overall Score": 21.02415496481448,
    "MMLU Score": 28.46852836879432,
    "BBH Score": 32.43387434197657,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.675120792639938
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutenberg-12B-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.211238079190083,
    "Overall Score": 25.51431983722001,
    "MMLU Score": 27.76669621749409,
    "BBH Score": 34.73061633928093,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.058626787998412
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutenberg-12B-v3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.6707380977300472,
    "Overall Score": 19.29051213358064,
    "MMLU Score": 29.38275709219858,
    "BBH Score": 34.95791456295642,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.25521342574392
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutenberg-12B-v4",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.520922673562402,
    "Overall Score": 19.83898144810974,
    "MMLU Score": 28.616282505910167,
    "BBH Score": 31.97125827358258,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.634597316514492
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-gutenberg2-12B-test",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.350053941716089,
    "Overall Score": 20.97057995062581,
    "MMLU Score": 28.385416666666668,
    "BBH Score": 32.04475928596384,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.259773817219039
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-kartoffel-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5291241048613553,
    "Overall Score": 28.21995794267338,
    "MMLU Score": 28.717863475177303,
    "BBH Score": 36.05253256686901,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.454982073042437
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-narwhal-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8852501869190184,
    "Overall Score": 21.240878416352583,
    "MMLU Score": 27.59123817966903,
    "BBH Score": 29.562789508057296,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-01-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.266875114896882
  },
  {
    "Model Name": "nbeerbower/mistral-nemo-wissenschaft-12B",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.858746838889556,
    "Overall Score": 25.50992586494861,
    "MMLU Score": 28.13608156028369,
    "BBH Score": 29.567999415715217,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.923464476783685
  },
  {
    "Model Name": "nbrahme/IndusQ",
    "Parameters (B)": 1.176,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3012337303541204,
    "Overall Score": 5.636134043635501,
    "MMLU Score": 1.337174940898345,
    "BBH Score": 3.747096495974056,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.71016913348266
  },
  {
    "Model Name": "necva/IE-cont-Llama3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.732556864105992,
    "Overall Score": 5.093186530380667,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.952615940055877
  },
  {
    "Model Name": "necva/replica-IEPile",
    "Parameters (B)": 4.65,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.203072647367737,
    "Overall Score": 21.56058539635963,
    "MMLU Score": 28.45005910165484,
    "BBH Score": 25.31651874657448,
    "Math Score": 12.386706948640484,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.92126638697432
  },
  {
    "Model Name": "neopolita/jessi-v0.1-bf16-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2283502198182912,
    "Overall Score": 34.92479232482063,
    "MMLU Score": 32.4855939716312,
    "BBH Score": 36.13467912106424,
    "Math Score": 38.06646525679759,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 28.43227587811807
  },
  {
    "Model Name": "neopolita/jessi-v0.1-falcon3-10b-instruct",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5816365822647414,
    "Overall Score": 32.33560766198001,
    "MMLU Score": 35.422207446808514,
    "BBH Score": 41.44033637148312,
    "Math Score": 20.01510574018127,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.444397925899477
  },
  {
    "Model Name": "neopolita/jessi-v0.1-qwen2.5-7b-instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.5377250785430245,
    "Overall Score": 32.77563297433888,
    "MMLU Score": 35.865469858156025,
    "BBH Score": 33.34225906937014,
    "Math Score": 40.86102719033233,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.918609629310481
  },
  {
    "Model Name": "neopolita/jessi-v0.1-virtuoso-small",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.1233827346905625,
    "Overall Score": 38.86960435987991,
    "MMLU Score": 45.885047281323885,
    "BBH Score": 48.8603145722634,
    "Math Score": 33.987915407854985,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.444713844437246
  },
  {
    "Model Name": "neopolita/jessi-v0.2-falcon3-10b-instruct",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7127002701328409,
    "Overall Score": 34.10450143941555,
    "MMLU Score": 37.2691341607565,
    "BBH Score": 45.02184351970056,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.912708624008292
  },
  {
    "Model Name": "neopolita/jessi-v0.2-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6919950892511235,
    "Overall Score": 29.040362033793667,
    "MMLU Score": 32.273197399527184,
    "BBH Score": 34.382892384888216,
    "Math Score": 25.37764350453172,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.163384349210446
  },
  {
    "Model Name": "neopolita/jessi-v0.3-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8228880258629985,
    "Overall Score": 31.56157882788928,
    "MMLU Score": 33.00273345153664,
    "BBH Score": 34.56526833956577,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.31405241577978
  },
  {
    "Model Name": "neopolita/jessi-v0.4-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.321471697143095,
    "Overall Score": 35.58265268401903,
    "MMLU Score": 33.38135342789598,
    "BBH Score": 36.167444072028246,
    "Math Score": 37.68882175226586,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.926534076322316
  },
  {
    "Model Name": "neopolita/jessi-v0.5-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2662553132853336,
    "Overall Score": 35.17362960818127,
    "MMLU Score": 32.95656028368795,
    "BBH Score": 37.16806936900627,
    "Math Score": 37.38670694864049,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.7776758282043
  },
  {
    "Model Name": "neopolita/jessi-v0.6-falcon3-7b-instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.278937826257381,
    "Overall Score": 34.54828176574102,
    "MMLU Score": 32.8549793144208,
    "BBH Score": 35.85132240048754,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 27.013261361454422
  },
  {
    "Model Name": "neopolita/loki-v0.1-virtuoso",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.458282865864776,
    "Overall Score": 39.19696212178447,
    "MMLU Score": 45.87581264775414,
    "BBH Score": 49.45293175936923,
    "Math Score": 33.91238670694864,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.334226736823885
  },
  {
    "Model Name": "netcat420/DeepSeek-R1-Distill-Qwen-MFANN-Slerp-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8742780635509655,
    "Overall Score": 3.574293533040167,
    "MMLU Score": 0.9954934988179668,
    "BBH Score": 2.015537689546553,
    "Math Score": 0.1510574018126888,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.088280013023346
  },
  {
    "Model Name": "netcat420/DeepSeek-R1-MFANN-TIES-unretrained-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3564000813676969,
    "Overall Score": 5.947003320776368,
    "MMLU Score": 1.6142139479905429,
    "BBH Score": 4.561587443058031,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.384402067257202
  },
  {
    "Model Name": "netcat420/Llama3.1-MFANN-8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.401012415623717,
    "Overall Score": 13.117063178518029,
    "MMLU Score": 19.1692523640662,
    "BBH Score": 19.286683760193657,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.36256026873141
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-TIES-V2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.408225870268352,
    "Overall Score": 19.213728182261345,
    "MMLU Score": 28.02526595744681,
    "BBH Score": 26.938370096724565,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.643925017937619
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-TIES-V3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4418208917092483,
    "Overall Score": 19.222030340557662,
    "MMLU Score": 27.665115248226947,
    "BBH Score": 26.978850946197483,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.331774044257571
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-V4",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4449346149215017,
    "Overall Score": 19.39947102160331,
    "MMLU Score": 27.960623522458626,
    "BBH Score": 26.706074443441803,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.425846970007855
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-V5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.411251889010262,
    "Overall Score": 19.493723327477287,
    "MMLU Score": 27.16644503546099,
    "BBH Score": 27.36714348720693,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.813071556735776
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-Slerp-TIES",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5466287967945442,
    "Overall Score": 19.24800486274757,
    "MMLU Score": 28.12684692671393,
    "BBH Score": 27.59982935067644,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.445135447264335
  },
  {
    "Model Name": "netcat420/MFANN-Llama3.1-Abliterated-Slerp-V3.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4828376977168216,
    "Overall Score": 19.05371896057877,
    "MMLU Score": 28.08067375886525,
    "BBH Score": 27.774394299037056,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.84949727803418
  },
  {
    "Model Name": "netcat420/MFANN-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3116005548268403,
    "Overall Score": 17.932006161848246,
    "MMLU Score": 25.956708037825056,
    "BBH Score": 26.20853268810661,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.671850088699955
  },
  {
    "Model Name": "netcat420/MFANN-abliterated-phi2-merge-unretrained",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8952711221903973,
    "Overall Score": 9.638779331398394,
    "MMLU Score": 5.308067375886525,
    "BBH Score": 17.590366415972785,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.766324404405971
  },
  {
    "Model Name": "netcat420/MFANN-llama3.1-Abliterated-SLERP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.547158362175965,
    "Overall Score": 13.881633563903852,
    "MMLU Score": 21.42250295508274,
    "BBH Score": 22.28062513418979,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.972341748119662
  },
  {
    "Model Name": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.583139304892755,
    "Overall Score": 18.04226152595201,
    "MMLU Score": 28.117612293144205,
    "BBH Score": 27.1872703942033,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.39650911969129
  },
  {
    "Model Name": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.661015065343464,
    "Overall Score": 18.96623306213071,
    "MMLU Score": 28.25613179669031,
    "BBH Score": 27.02631553274448,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.127442948047605
  },
  {
    "Model Name": "netcat420/MFANN-llama3.1-abliterated-v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.649047154175584,
    "Overall Score": 19.77111132997354,
    "MMLU Score": 27.67434988179669,
    "BBH Score": 27.35361826731554,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.9894153905246
  },
  {
    "Model Name": "netcat420/MFANN-phigments-slerp-V2",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8162400046189335,
    "Overall Score": 16.26870816278764,
    "MMLU Score": 19.0769060283688,
    "BBH Score": 26.92749154408088,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 19.931280102330664
  },
  {
    "Model Name": "netcat420/MFANN-phigments-slerp-V3.2",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.5783076437872776,
    "Overall Score": 16.453301876572546,
    "MMLU Score": 18.94762115839244,
    "BBH Score": 26.91803539968917,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 28.450777113754807
  },
  {
    "Model Name": "netcat420/MFANN-phigments-slerp-V3.3",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.59147703430892,
    "Overall Score": 17.167734327311486,
    "MMLU Score": 20.02807328605201,
    "BBH Score": 28.170621881092465,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 29.025191734401346
  },
  {
    "Model Name": "netcat420/MFANN3b",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.751985004082596,
    "Overall Score": 12.652447668077093,
    "MMLU Score": 14.505762411347517,
    "BBH Score": 22.23921095390767,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.82539891006574
  },
  {
    "Model Name": "netcat420/MFANN3bv0.15",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9342759214225445,
    "Overall Score": 11.92455505796081,
    "MMLU Score": 16.315750591016545,
    "BBH Score": 23.46934667082661,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-07-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.76341901202407
  },
  {
    "Model Name": "netcat420/MFANN3bv0.18",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9650273588651338,
    "Overall Score": 12.649876255790772,
    "MMLU Score": 16.666666666666664,
    "BBH Score": 23.07340376774899,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 13.108308422122818
  },
  {
    "Model Name": "netcat420/MFANN3bv0.19",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9729765164528664,
    "Overall Score": 12.591488714276778,
    "MMLU Score": 16.888297872340427,
    "BBH Score": 22.9070546869096,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.941205158970291
  },
  {
    "Model Name": "netcat420/MFANN3bv0.20",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0188364205113325,
    "Overall Score": 12.5720051522728,
    "MMLU Score": 16.666666666666664,
    "BBH Score": 22.790710795250103,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 12.3395717891231
  },
  {
    "Model Name": "netcat420/MFANN3bv0.21",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9486781620716105,
    "Overall Score": 12.00855289802916,
    "MMLU Score": 15.475398936170212,
    "BBH Score": 22.58342571657233,
    "Math Score": 3.1722054380664653,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.162409540866948
  },
  {
    "Model Name": "netcat420/MFANN3bv0.22",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7913362528706576,
    "Overall Score": 12.2565063872572,
    "MMLU Score": 16.860593971631204,
    "BBH Score": 22.49153679693963,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.48836710411712
  },
  {
    "Model Name": "netcat420/MFANN3bv0.23",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7763674723624213,
    "Overall Score": 11.448026000697595,
    "MMLU Score": 15.752437943262413,
    "BBH Score": 22.696340563264982,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 14.74562807978316
  },
  {
    "Model Name": "netcat420/MFANN3bv0.24",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7690731161151534,
    "Overall Score": 11.81028360635554,
    "MMLU Score": 15.022901891252952,
    "BBH Score": 21.54538472469568,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.356515991630612
  },
  {
    "Model Name": "netcat420/MFANN3bv1.1",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7763197255061175,
    "Overall Score": 6.659216615990036,
    "MMLU Score": 1.7619680851063828,
    "BBH Score": 8.39170874742591,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.577930454682953
  },
  {
    "Model Name": "netcat420/MFANN3bv1.2",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7992262592949151,
    "Overall Score": 8.060474667336623,
    "MMLU Score": 5.003324468085105,
    "BBH Score": 11.121791518461544,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.085347639162467
  },
  {
    "Model Name": "netcat420/MFANN3bv1.3",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8240365026004964,
    "Overall Score": 11.533255279970446,
    "MMLU Score": 14.17331560283688,
    "BBH Score": 22.63700866653784,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.996049014301878
  },
  {
    "Model Name": "netcat420/MFANN3bv1.4",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6589172532409903,
    "Overall Score": 16.497599656783464,
    "MMLU Score": 18.94762115839244,
    "BBH Score": 26.91803539968917,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.037437668595523
  },
  {
    "Model Name": "netcat420/MFANNv0.19",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.914157527087684,
    "Overall Score": 14.38906583250676,
    "MMLU Score": 16.36192375886525,
    "BBH Score": 24.92410586579366,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-07-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.5171795575253215
  },
  {
    "Model Name": "netcat420/MFANNv0.20",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7357681975677204,
    "Overall Score": 16.46165681188948,
    "MMLU Score": 24.469932033096924,
    "BBH Score": 22.40169690458168,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-08-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 9.483787544302691
  },
  {
    "Model Name": "netcat420/MFANNv0.21",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7588214654326866,
    "Overall Score": 15.886167017885262,
    "MMLU Score": 22.567597517730498,
    "BBH Score": 22.058431786302453,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.03227947242338
  },
  {
    "Model Name": "netcat420/MFANNv0.22.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.681057346999856,
    "Overall Score": 15.66737725944644,
    "MMLU Score": 26.03058510638298,
    "BBH Score": 23.602792666118614,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.319954067841673
  },
  {
    "Model Name": "netcat420/MFANNv0.23",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.620759423363359,
    "Overall Score": 16.652655864272365,
    "MMLU Score": 26.529255319148938,
    "BBH Score": 27.04234546686432,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.274600674364857
  },
  {
    "Model Name": "netcat420/MFANNv0.24",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4878053287353832,
    "Overall Score": 16.398373723349362,
    "MMLU Score": 26.08599290780142,
    "BBH Score": 25.3517249924116,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-11-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.021854409735033
  },
  {
    "Model Name": "netcat420/MFANNv0.25",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4245766930388508,
    "Overall Score": 16.59696503760558,
    "MMLU Score": 26.03058510638298,
    "BBH Score": 25.409784264889016,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 11.650453863737999
  },
  {
    "Model Name": "netcat420/Qwen2.5-7B-nerd-uncensored-v0.9-MFANN",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.389124408781623,
    "Overall Score": 28.031122057978823,
    "MMLU Score": 32.263962765957444,
    "BBH Score": 32.26698603219006,
    "Math Score": 33.76132930513595,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.17898604385221
  },
  {
    "Model Name": "netcat420/Qwen2.5-7b-MFANN-slerp",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2955584130195623,
    "Overall Score": 27.70922289818492,
    "MMLU Score": 26.85246749408984,
    "BBH Score": 30.361031469633605,
    "Math Score": 28.700906344410875,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.3878607245527
  },
  {
    "Model Name": "netcat420/Qwen2.5-7b-nerd-uncensored-MFANN-slerp",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.597223719083247,
    "Overall Score": 4.248121471104624,
    "MMLU Score": 1.1155437352245865,
    "BBH Score": 1.7557228747317382,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.6596909502088435
  },
  {
    "Model Name": "netcat420/Qwen2.5-Coder-Scholar-7B-Abliterated-MFANN",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3103782032517788,
    "Overall Score": 25.39674192004996,
    "MMLU Score": 23.96202718676123,
    "BBH Score": 29.98074987281026,
    "Math Score": 25.6797583081571,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.38123043944602
  },
  {
    "Model Name": "netcat420/Qwen2.5-Coder-Scholar-7B-Abliterated-MFANN-Slerp-Unretrained",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2968626346961016,
    "Overall Score": 28.058882677645745,
    "MMLU Score": 27.01869089834516,
    "BBH Score": 29.939052758341504,
    "Math Score": 29.909365558912388,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.635971248582454
  },
  {
    "Model Name": "netcat420/Qwen2.5-DeepSeek-R1-MFANN-Slerp-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4050991694505164,
    "Overall Score": 8.630087573410409,
    "MMLU Score": 7.524379432624113,
    "BBH Score": 13.455601394009934,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.141977563608784
  },
  {
    "Model Name": "netcat420/Qwen2.5-MFANN-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.369620060318377,
    "Overall Score": 26.18533023472354,
    "MMLU Score": 24.811613475177303,
    "BBH Score": 30.29029020592803,
    "Math Score": 27.870090634441087,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.118681883672608
  },
  {
    "Model Name": "netcat420/qwen2.5-MFANN-7b-SLERP-V1.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.675172916438298,
    "Overall Score": 28.515188837080995,
    "MMLU Score": 27.09256796690307,
    "BBH Score": 30.83088103280173,
    "Math Score": 28.700906344410875,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.23390503799468
  },
  {
    "Model Name": "netcat420/qwen2.5-MFANN-7b-SLERPv1.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.945654531904768,
    "Overall Score": 27.98224762603196,
    "MMLU Score": 27.203383569739948,
    "BBH Score": 29.97691243171087,
    "Math Score": 29.68277945619335,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.38191989748444
  },
  {
    "Model Name": "netcat420/qwen2.5-MFANN-7b-v1.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6459238625100258,
    "Overall Score": 26.134594460492067,
    "MMLU Score": 24.977836879432623,
    "BBH Score": 29.471725204280187,
    "Math Score": 28.24773413897281,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 40.46079728179483
  },
  {
    "Model Name": "netease-youdao/Confucius-o1-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.783276905087744,
    "Overall Score": 38.52750121655241,
    "MMLU Score": 47.39029255319149,
    "BBH Score": 47.34523316427439,
    "Math Score": 43.126888217522655,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.183632386183705
  },
  {
    "Model Name": "newsbang/Homer-7B-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3814683906575005,
    "Overall Score": 33.058437903590075,
    "MMLU Score": 38.60815602836879,
    "BBH Score": 37.30922654202453,
    "Math Score": 38.59516616314199,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 23.929927117518872
  },
  {
    "Model Name": "newsbang/Homer-7B-v0.2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3491966845781551,
    "Overall Score": 33.0139580788785,
    "MMLU Score": 37.88785460992907,
    "BBH Score": 36.4034863975643,
    "Math Score": 24.773413897280967,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 24.46934420773556
  },
  {
    "Model Name": "newsbang/Homer-v0.3-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1712069632647957,
    "Overall Score": 31.31478883195753,
    "MMLU Score": 38.39575945626477,
    "BBH Score": 36.41367722607503,
    "Math Score": 30.891238670694865,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.737194888823108
  },
  {
    "Model Name": "newsbang/Homer-v0.4-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2794408280333436,
    "Overall Score": 33.944012752963395,
    "MMLU Score": 37.3614804964539,
    "BBH Score": 36.6037028382434,
    "Math Score": 27.794561933534744,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 26.530349828791596
  },
  {
    "Model Name": "newsbang/Homer-v0.5-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.345168376991957,
    "Overall Score": 34.76384451852059,
    "MMLU Score": 37.43535756501182,
    "BBH Score": 36.67808911980736,
    "Math Score": 37.235649546827794,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.843489271030087
  },
  {
    "Model Name": "newsbang/Homer-v1.0-Qwen2.5-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 29.548857722554818,
    "Overall Score": 47.464376408361055,
    "MMLU Score": 57.16976950354611,
    "BBH Score": 62.27406507872839,
    "Math Score": 49.01812688821752,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.6063015651576682
  },
  {
    "Model Name": "newsbang/Homer-v1.0-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2785042364113015,
    "Overall Score": 32.62357604568507,
    "MMLU Score": 39.27304964539008,
    "BBH Score": 37.81084749225178,
    "Math Score": 33.23262839879154,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 25.516987051413956
  },
  {
    "Model Name": "nguyentd/FinancialAdvice-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3088900896654123,
    "Overall Score": 21.287932324484498,
    "MMLU Score": 30.583259456264773,
    "BBH Score": 25.63043562216033,
    "Math Score": 11.48036253776435,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.26410994518743
  },
  {
    "Model Name": "ngxson/MiniThinky-1B-Llama-3.2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1223291009575076,
    "Overall Score": 6.937116033349191,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 4.347795393431276,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.180999875554181
  },
  {
    "Model Name": "ngxson/MiniThinky-v2-1B-Llama-3.2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1046860596842587,
    "Overall Score": 6.55067744157533,
    "MMLU Score": 1.291001773049644,
    "BBH Score": 4.893769484250589,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.929899616410154
  },
  {
    "Model Name": "nhyha/N3N_Delirium-v1_1030_0227",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.294386987361042,
    "Overall Score": 33.094478522688185,
    "MMLU Score": 34.99741430260047,
    "BBH Score": 40.77504007448568,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.706449982288434
  },
  {
    "Model Name": "nhyha/N3N_Llama-3.1-8B-Instruct_1028_0216",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4914317034052258,
    "Overall Score": 23.47935177286844,
    "MMLU Score": 29.308880023640665,
    "BBH Score": 28.980464124810663,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 15.742827324416236
  },
  {
    "Model Name": "nhyha/N3N_gemma-2-9b-it_20241029_1532",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.788088397014556,
    "Overall Score": 32.14813042759547,
    "MMLU Score": 34.692671394799056,
    "BBH Score": 40.9866677332497,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.7141889961013055
  },
  {
    "Model Name": "nhyha/N3N_gemma-2-9b-it_20241110_2026",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.081099820650457,
    "Overall Score": 29.119584296103525,
    "MMLU Score": 33.55681146572104,
    "BBH Score": 40.94410554905775,
    "Math Score": 16.08761329305136,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.730960879327063
  },
  {
    "Model Name": "nhyha/merge_Qwen2.5-7B-Instruct_20241023_0314",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3954515108393644,
    "Overall Score": 31.4495497347518,
    "MMLU Score": 39.35616134751773,
    "BBH Score": 36.36518528982388,
    "Math Score": 35.422960725075534,
    "Date Submitted": "2024-11-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.53718562806592
  },
  {
    "Model Name": "nidum/Nidum-Limitless-Gemma-2B",
    "Parameters (B)": 2.506,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7936273921827564,
    "Overall Score": 6.166007951282463,
    "MMLU Score": 1.9281914893617007,
    "BBH Score": 3.4510601516101125,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.76939910595041
  },
  {
    "Model Name": "nisten/franqwenstein-35b",
    "Parameters (B)": 34.714,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.035539404554576,
    "Overall Score": 36.57133162829882,
    "MMLU Score": 52.56168735224587,
    "BBH Score": 52.227468077653526,
    "Math Score": 34.06344410876133,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.6441819571453347
  },
  {
    "Model Name": "nisten/franqwenstein-35b",
    "Parameters (B)": 34.714,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.328604130163559,
    "Overall Score": 34.451116831224226,
    "MMLU Score": 51.23190011820331,
    "BBH Score": 51.68027687329707,
    "Math Score": 30.438066465256803,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.443714936603857
  },
  {
    "Model Name": "nisten/tqwendo-36b",
    "Parameters (B)": 35.69,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 18.30078252164624,
    "Overall Score": 37.04172043230399,
    "MMLU Score": 37.56464243498817,
    "BBH Score": 49.41493648187427,
    "Math Score": 41.54078549848943,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 2.0240511786034774
  },
  {
    "Model Name": "nlpguy/Lion-Lamarck-v.1.0.8",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.057618841091383,
    "Overall Score": 35.883024988283445,
    "MMLU Score": 40.48278664302601,
    "BBH Score": 40.84844139218024,
    "Math Score": 55.4380664652568,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.843370063471005
  },
  {
    "Model Name": "nlpguy/Lion-Lamarck-v.1.0.9",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.906622065412632,
    "Overall Score": 36.365577681666096,
    "MMLU Score": 41.15691489361702,
    "BBH Score": 40.46884807072923,
    "Math Score": 56.41993957703928,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.308701244389514
  },
  {
    "Model Name": "nlpguy/Lion-Lamarck-v.1.1.0",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.887952209747372,
    "Overall Score": 37.03161283098529,
    "MMLU Score": 40.3442671394799,
    "BBH Score": 41.16630363693309,
    "Math Score": 57.55287009063444,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.524708852681986
  },
  {
    "Model Name": "nlpguy/Miisce-one",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0187925477418864,
    "Overall Score": 39.83702135003988,
    "MMLU Score": 49.02482269503546,
    "BBH Score": 49.71168185726318,
    "Math Score": 41.69184290030212,
    "Date Submitted": "2025-02-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.733093127671513
  },
  {
    "Model Name": "nlpguy/Mistral-NeMo-Minitron-Upscale-v1",
    "Parameters (B)": 12.451,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.868611599373479,
    "Overall Score": 10.990222795976974,
    "MMLU Score": 17.082225177304963,
    "BBH Score": 22.06890968577206,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.8727125845490042
  },
  {
    "Model Name": "nlpguy/Mistral-NeMo-Minitron-Upscale-v2",
    "Parameters (B)": 12.451,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 5.849237341350645,
    "Overall Score": 8.345444097364796,
    "MMLU Score": 10.2947695035461,
    "BBH Score": 14.382673288078204,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.4267576455425133
  },
  {
    "Model Name": "nlpguy/Mistral-NeMo-Minitron-Upscale-v3",
    "Parameters (B)": 12.451,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 9.086727159842797,
    "Overall Score": 5.202259190321894,
    "MMLU Score": 1.9004875886524817,
    "BBH Score": 3.3982664477164874,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 0.5725118735062685
  },
  {
    "Model Name": "nlpguy/StableProse",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.588726111482876,
    "Overall Score": 16.623904800931484,
    "MMLU Score": 27.425014775413715,
    "BBH Score": 30.18020271418596,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-08-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.6322578777298835
  },
  {
    "Model Name": "nlpguy/StarFusion-alpha1",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7569972792351518,
    "Overall Score": 20.8283235530266,
    "MMLU Score": 24.34064716312057,
    "BBH Score": 21.933181635654744,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.854499605197734
  },
  {
    "Model Name": "noname0202/Llama-3.2-4x3B-Instruct",
    "Parameters (B)": 9.949,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.384502028042734,
    "Overall Score": 24.0101269924204,
    "MMLU Score": 25.39339539007092,
    "BBH Score": 24.68990853488361,
    "Math Score": 15.861027190332328,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.069241590089392
  },
  {
    "Model Name": "noname0202/gemma-2-2b-it-ties",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.405395119018224,
    "Overall Score": 10.06382335103593,
    "MMLU Score": 17.340794917257686,
    "BBH Score": 18.13956937900525,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.1838545657079145
  },
  {
    "Model Name": "noname0202/gemma-2-9b-sft-jp-en-zh-v1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.83147165254028,
    "Overall Score": 16.85196649387241,
    "MMLU Score": 23.61111111111111,
    "BBH Score": 22.0002402150018,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.201325322452284
  },
  {
    "Model Name": "noname0202/gemma-2-9b-sft-jp-en-zh-v2",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.625544838025149,
    "Overall Score": 19.13081989964549,
    "MMLU Score": 29.724438534278963,
    "BBH Score": 22.658058596327027,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.768866322313968
  },
  {
    "Model Name": "noname0202/llama-math-1b-r16-0to512tokens-test",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7330675322960788,
    "Overall Score": 13.804072106791525,
    "MMLU Score": 8.087692080378249,
    "BBH Score": 8.389239359006991,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.83055993975763
  },
  {
    "Model Name": "noname0202/llama-math-1b-r32-0to512tokens-test",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8009289669930701,
    "Overall Score": 14.371257364913582,
    "MMLU Score": 8.447842789598107,
    "BBH Score": 8.191900397270365,
    "Math Score": 9.06344410876133,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.94323586380904
  },
  {
    "Model Name": "noname0202/llama-math-1b-r32-test",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7467959408138168,
    "Overall Score": 14.418127068599686,
    "MMLU Score": 8.678708628841607,
    "BBH Score": 8.498754758774203,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.30664895270803
  },
  {
    "Model Name": "noname0202/llama-math-1b-r8-512tokens-test",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7317208362766235,
    "Overall Score": 14.630751727519524,
    "MMLU Score": 8.36473108747045,
    "BBH Score": 8.396798396874248,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 19.994991261924977
  },
  {
    "Model Name": "notbdq/Qwen2.5-14B-Instruct-1M-GRPO-Reasoning",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.391751948378743,
    "Overall Score": 41.559026792386994,
    "MMLU Score": 42.77297576832151,
    "BBH Score": 45.65828060023316,
    "Math Score": 53.02114803625378,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.252967618180984
  },
  {
    "Model Name": "nothingiisreal/L3.1-8B-Celeste-V1.5",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4143282385062868,
    "Overall Score": 26.172145831649967,
    "MMLU Score": 30.04765070921986,
    "BBH Score": 28.887966925667627,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.50500125719835
  },
  {
    "Model Name": "nothingiisreal/MN-12B-Starcannon-v2",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.445325569110211,
    "Overall Score": 18.181449904707133,
    "MMLU Score": 23.648049645390067,
    "BBH Score": 28.424782963573875,
    "Math Score": 5.966767371601208,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.277135510129067
  },
  {
    "Model Name": "nothingiisreal/MN-12B-Starcannon-v3",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4913418617587566,
    "Overall Score": 19.14447126423964,
    "MMLU Score": 25.162529550827426,
    "BBH Score": 30.87300162638861,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.48341354764831
  },
  {
    "Model Name": "nvidia/AceInstruct-1.5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7064082962319682,
    "Overall Score": 18.11586485792988,
    "MMLU Score": 17.48854905437352,
    "BBH Score": 15.468561041610592,
    "Math Score": 31.268882175226587,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.616371766319178
  },
  {
    "Model Name": "nvidia/AceInstruct-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 80.78669497709723,
    "Overall Score": 40.40502231212503,
    "MMLU Score": 43.04078014184397,
    "BBH Score": 44.20381994540313,
    "Math Score": 62.61329305135952,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.5001445141873885
  },
  {
    "Model Name": "nvidia/AceInstruct-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8501446641433856,
    "Overall Score": 33.05654347527337,
    "MMLU Score": 35.30215721040189,
    "BBH Score": 36.57481399081368,
    "Math Score": 52.94561933534743,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.86700473531809
  },
  {
    "Model Name": "nvidia/AceMath-1.5B-Instruct",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.663243327095496,
    "Overall Score": 20.18985986442293,
    "MMLU Score": 11.818484042553193,
    "BBH Score": 16.762509591549986,
    "Math Score": 52.87009063444109,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.138849160261035
  },
  {
    "Model Name": "nvidia/AceMath-72B-Instruct",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 88.01123585671756,
    "Overall Score": 36.65560439276686,
    "MMLU Score": 37.89708924349882,
    "BBH Score": 48.68777244219516,
    "Math Score": 71.45015105740181,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.41648778176961687
  },
  {
    "Model Name": "nvidia/AceMath-72B-RM",
    "Parameters (B)": 71.461,
    "Architecture": "Qwen2ForSequenceClassification",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 150.00072389582226,
    "Overall Score": 3.4288267214523853,
    "MMLU Score": 1.9835992907801416,
    "BBH Score": 1.4035016501209492,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.022858734494066554
  },
  {
    "Model Name": "nvidia/AceMath-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9773082959878767,
    "Overall Score": 30.32749004744572,
    "MMLU Score": 26.48308215130024,
    "BBH Score": 29.99382585790849,
    "Math Score": 63.36858006042296,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.337765035924203
  },
  {
    "Model Name": "nvidia/AceMath-7B-RM",
    "Parameters (B)": 7.071,
    "Architecture": "Qwen2ForSequenceClassification",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.354279302653559,
    "Overall Score": 3.2243900063069617,
    "MMLU Score": 1.540336879432624,
    "BBH Score": 0.2515270350564467,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.3808899685531117
  },
  {
    "Model Name": "nvidia/Hymba-1.5B-Base",
    "Parameters (B)": 1.523,
    "Architecture": "HymbaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 18.215828757603376,
    "Overall Score": 8.035282134433706,
    "MMLU Score": 10.248596335697398,
    "BBH Score": 7.689941118138137,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.44111537505971227
  },
  {
    "Model Name": "nvidia/Hymba-1.5B-Instruct",
    "Parameters (B)": 1.523,
    "Architecture": "HymbaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 13.425331528485655,
    "Overall Score": 14.192383567083992,
    "MMLU Score": 11.55991430260047,
    "BBH Score": 4.591463615472479,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.0571346813276692
  },
  {
    "Model Name": "nvidia/Llama-3.1-Minitron-4B-Depth-Base",
    "Parameters (B)": 4.02,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.935381271610458,
    "Overall Score": 11.658051143450892,
    "MMLU Score": 19.98190011820331,
    "BBH Score": 19.44410955550794,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.463421598530699
  },
  {
    "Model Name": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 27.25749526720252,
    "Overall Score": 36.90717314950126,
    "MMLU Score": 43.53945035460993,
    "BBH Score": 47.10953049372728,
    "Math Score": 42.6737160120846,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3540192445308679
  },
  {
    "Model Name": "nvidia/Minitron-4B-Base",
    "Parameters (B)": 4.0,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.3785336263128607,
    "Overall Score": 11.977737055629914,
    "MMLU Score": 17.99645390070922,
    "BBH Score": 17.215600655061085,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.035765281232321
  },
  {
    "Model Name": "nvidia/Minitron-8B-Base",
    "Parameters (B)": 7.22,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.8250414403326536,
    "Overall Score": 14.21649076588472,
    "MMLU Score": 24.229831560283685,
    "BBH Score": 22.04079297000523,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.0323122921024135
  },
  {
    "Model Name": "nvidia/Mistral-NeMo-Minitron-8B-Base",
    "Parameters (B)": 7.88,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.115428506801799,
    "Overall Score": 17.697925857529604,
    "MMLU Score": 31.06346040189125,
    "BBH Score": 31.82201515749016,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-08-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.4597152191643996
  },
  {
    "Model Name": "nvidia/Mistral-NeMo-Minitron-8B-Instruct",
    "Parameters (B)": 8.414,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.987795925850581,
    "Overall Score": 23.57259648330948,
    "MMLU Score": 33.23359929078014,
    "BBH Score": 34.126491245346166,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.911184253562709
  },
  {
    "Model Name": "nvidia/Nemotron-Mini-4B-Instruct",
    "Parameters (B)": 4.0,
    "Architecture": "NemotronForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.2346275759953937,
    "Overall Score": 18.36351131288577,
    "MMLU Score": 18.070330969267136,
    "BBH Score": 14.203825178862052,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-09-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.21770549605158
  },
  {
    "Model Name": "nvidia/OpenMath2-Llama3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5522116124404097,
    "Overall Score": 12.751664730325508,
    "MMLU Score": 6.148419030732861,
    "BBH Score": 16.294369976218587,
    "Math Score": 26.73716012084592,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.996319532506336
  },
  {
    "Model Name": "nxmwxm/Beast-Soul-new",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3140460927306377,
    "Overall Score": 21.81767341260428,
    "MMLU Score": 23.352541371158388,
    "BBH Score": 33.07275916855207,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.60343083343928
  },
  {
    "Model Name": "occiglot/occiglot-7b-es-en-instruct",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3774762414851427,
    "Overall Score": 12.457903975085708,
    "MMLU Score": 14.561170212765957,
    "BBH Score": 17.23541035561212,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-09-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.044006422683609
  },
  {
    "Model Name": "odyssey-labs/Astral-1-10B",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5137985130131593,
    "Overall Score": 18.690197061048178,
    "MMLU Score": 22.0596926713948,
    "BBH Score": 28.313232406760367,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.346555304672641
  },
  {
    "Model Name": "olabs-ai/reflection_model",
    "Parameters (B)": 9.3,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.815086899243573,
    "Overall Score": 14.079165535571102,
    "MMLU Score": 25.67966903073286,
    "BBH Score": 25.206881738811884,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.9239691474276137
  },
  {
    "Model Name": "ontocord/Llama_3.2_1b-autoredteam_helpfulness-train",
    "Parameters (B)": 1.498,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7629543025609749,
    "Overall Score": 6.603005260709961,
    "MMLU Score": 1.466459810874704,
    "BBH Score": 4.336962243234709,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.654522608426149
  },
  {
    "Model Name": "ontocord/RedPajama-3B-v1-AutoRedteam",
    "Parameters (B)": 2.776,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3539917321904564,
    "Overall Score": 3.5632816248649792,
    "MMLU Score": 1.198655437352245,
    "BBH Score": 2.949522338615812,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.06600239733239
  },
  {
    "Model Name": "ontocord/RedPajama-3B-v1-AutoRedteam-Harmless-only",
    "Parameters (B)": 2.776,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.445491323704418,
    "Overall Score": 3.9505437890141017,
    "MMLU Score": 1.1063091016548463,
    "BBH Score": 3.779555839764309,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.867835530811087
  },
  {
    "Model Name": "ontocord/RedPajama3b_v1-autoredteam_helpfulness-train",
    "Parameters (B)": 2.776,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.66425869125511,
    "Overall Score": 6.038454723335806,
    "MMLU Score": 1.1894208037825047,
    "BBH Score": 3.372124671371246,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-01-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.090516696027278
  },
  {
    "Model Name": "ontocord/merged_0.2_expert_0.8",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2660091528370207,
    "Overall Score": 4.808386541486368,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 3.2883157460305967,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.0760191527409
  },
  {
    "Model Name": "ontocord/merged_0.2_expert_0.8-stack_2x",
    "Parameters (B)": 6.512,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4856000267205438,
    "Overall Score": 4.697285033470183,
    "MMLU Score": 1.1432476359338055,
    "BBH Score": 2.818672035294685,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.673156455927064
  },
  {
    "Model Name": "ontocord/merged_0.5_expert_0.5",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2698188989368498,
    "Overall Score": 4.592377750754853,
    "MMLU Score": 1.198655437352245,
    "BBH Score": 3.102804970729669,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.02022270808274
  },
  {
    "Model Name": "ontocord/ontocord_wide_3b-stage1_shuf_sample1_jsonl-pretrained-autoredteam_helpful-0.25_helpful",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2752249678935142,
    "Overall Score": 4.00101442542838,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 2.34885308225961,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 14.537250948018608
  },
  {
    "Model Name": "ontocord/ontocord_wide_7b-stacked-stage1",
    "Parameters (B)": 7.888,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5826571279896559,
    "Overall Score": 3.907682384845091,
    "MMLU Score": 1.1709515366430252,
    "BBH Score": 1.5650455535749657,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.706658508285623
  },
  {
    "Model Name": "ontocord/ontocord_wide_7b-stacked-stage1-instruct",
    "Parameters (B)": 7.888,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5963748017116766,
    "Overall Score": 3.6656823104305456,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 1.4889344424638544,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.146608307241587
  },
  {
    "Model Name": "ontocord/starcoder2-29b-ls",
    "Parameters (B)": 29.009,
    "Architecture": "Starcoder2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.598554292061173,
    "Overall Score": 8.448973787058975,
    "MMLU Score": 9.657579787234043,
    "BBH Score": 10.973636465379014,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 3.2514132234494317
  },
  {
    "Model Name": "ontocord/starcoder2_3b-AutoRedteam",
    "Parameters (B)": 3.181,
    "Architecture": "Starcoder2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4794093255439144,
    "Overall Score": 5.416510549136297,
    "MMLU Score": 3.7381796690307305,
    "BBH Score": 8.637687220647841,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.298300346975914
  },
  {
    "Model Name": "ontocord/wide_3b-merge_test",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2729645023063523,
    "Overall Score": 3.9416429369423778,
    "MMLU Score": 0.7369237588652473,
    "BBH Score": 2.934818240684116,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 14.440130140140388
  },
  {
    "Model Name": "ontocord/wide_3b-stage1_shuf_sample1_jsonl-pretrained",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2735087898775489,
    "Overall Score": 4.323686258344847,
    "MMLU Score": 1.5588061465721037,
    "BBH Score": 2.582584568793929,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.808216841150081
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stag1.2-lyrical_law_news_software_howto_formattedtext_math_wiki-merge",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2681320019385192,
    "Overall Score": 4.866410642270219,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 3.1835355510761367,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.14930932185429
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stag1.2-lyrical_news_software_howto_formattedtext-merge",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2669489730194698,
    "Overall Score": 4.700634702140898,
    "MMLU Score": 1.383348108747044,
    "BBH Score": 2.551802473439225,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.60873866256852
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-no_redteam_skg_poem.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2773049348778444,
    "Overall Score": 4.6361259036379225,
    "MMLU Score": 1.198655437352245,
    "BBH Score": 3.3516775197492783,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 16.718512080140883
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2774853861444414,
    "Overall Score": 4.124470876297795,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 3.3670533974072723,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 14.863740875171189
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2787363319062327,
    "Overall Score": 3.633703566106593,
    "MMLU Score": 2.0297724586288406,
    "BBH Score": 2.2297571883124263,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.036347078460429
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math_stories.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3110549352303448,
    "Overall Score": 3.8641325845274888,
    "MMLU Score": 1.4387559101654843,
    "BBH Score": 4.415068812630222,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.422669267941343
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math_stories.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5560188956870915,
    "Overall Score": 3.712730535219289,
    "MMLU Score": 1.374113475177304,
    "BBH Score": 4.554520467313206,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.67734597514234
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math_stories_no_orig_instr.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2798149673720302,
    "Overall Score": 4.284721666227881,
    "MMLU Score": 1.6049793144208029,
    "BBH Score": 2.93878288661528,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.312696481068132
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_stories.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.272358543214764,
    "Overall Score": 3.670762265147779,
    "MMLU Score": 1.798906619385342,
    "BBH Score": 2.9977998836734763,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.477683577758228
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_math.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.272251793359482,
    "Overall Score": 3.5261580781434336,
    "MMLU Score": 1.4202866430260035,
    "BBH Score": 3.275690229364662,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 12.951826816756666
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_math.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2703948074478163,
    "Overall Score": 4.767499605566051,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 3.133656346349717,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.63162410759731
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.1-ss1-with_r1_generics_intr_math_stories.no_issue",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2923910617635221,
    "Overall Score": 5.093186530380667,
    "MMLU Score": 1.854314420803781,
    "BBH Score": 2.3470409575204094,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.419091061339955
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_fictional_lyrical",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2758668885395803,
    "Overall Score": 4.837021332568196,
    "MMLU Score": 1.5680407801418434,
    "BBH Score": 2.477490056885344,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 17.53389599663462
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_formatted_text",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2704957114431379,
    "Overall Score": 4.304343127317076,
    "MMLU Score": 1.6234485815602824,
    "BBH Score": 3.7308056255712647,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.912796193154845
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_how-to",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5351948830890698,
    "Overall Score": 4.2152701749908585,
    "MMLU Score": 1.6973256501182026,
    "BBH Score": 3.814087152005469,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.876140651160396
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_math",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5454428641010042,
    "Overall Score": 5.136738708504239,
    "MMLU Score": 1.0231973995271864,
    "BBH Score": 3.1664911884922264,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.417555983559492
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_news",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2639636588021562,
    "Overall Score": 4.449975118096195,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 1.9437982768865123,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 16.858287001664507
  },
  {
    "Model Name": "ontocord/wide_3b_sft_stage1.2-ss1-expert_software",
    "Parameters (B)": 3.759,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2774434066210583,
    "Overall Score": 4.290233092582329,
    "MMLU Score": 1.5588061465721037,
    "BBH Score": 2.499488323419256,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.463453050957076
  },
  {
    "Model Name": "ontocord/wide_6.6b_sft_stag1.2-lyrical_law_news_software_howto_formattedtext_math_wiki-merge-stacked",
    "Parameters (B)": 7.888,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5821794147377032,
    "Overall Score": 3.97781016722033,
    "MMLU Score": 1.2725325059101646,
    "BBH Score": 3.014694718783778,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.83261906299539
  },
  {
    "Model Name": "oobabooga/CodeBooga-34B-v0.1",
    "Parameters (B)": 33.744,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.174007137499851,
    "Overall Score": 15.66170616238157,
    "MMLU Score": 15.106013593380617,
    "BBH Score": 8.562465862636055,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 3.752199180896137
  },
  {
    "Model Name": "oopere/Llama-FinSent-S",
    "Parameters (B)": 0.914,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3674071263428753,
    "Overall Score": 5.811805794594786,
    "MMLU Score": 1.4479905437352243,
    "BBH Score": 4.1560152972776905,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.81843513065404
  },
  {
    "Model Name": "oopere/Llama-FinSent-S",
    "Parameters (B)": 0.914,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3679716763261966,
    "Overall Score": 5.86640376735036,
    "MMLU Score": 1.4849290780141835,
    "BBH Score": 4.30733068735382,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.94254162689945
  },
  {
    "Model Name": "oopere/pruned10-llama-3.2-3B",
    "Parameters (B)": 3.001,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.3210679670165064,
    "Overall Score": 6.919943456537481,
    "MMLU Score": 7.108820921985815,
    "BBH Score": 7.759477124183007,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.23814340314787
  },
  {
    "Model Name": "oopere/pruned20-llama-1b",
    "Parameters (B)": 1.075,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8029560920393041,
    "Overall Score": 4.989519628599489,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 3.185394259848986,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.21393831875337
  },
  {
    "Model Name": "oopere/pruned20-llama-3.2-3b",
    "Parameters (B)": 2.79,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.212079009731279,
    "Overall Score": 5.656559779770029,
    "MMLU Score": 3.1102245862884166,
    "BBH Score": 6.3327454652272905,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.6668243029999354
  },
  {
    "Model Name": "oopere/pruned40-llama-1b",
    "Parameters (B)": 0.914,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7532425709708284,
    "Overall Score": 6.608357202270273,
    "MMLU Score": 0.912381796690307,
    "BBH Score": 2.6553089313766187,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.773212583766993
  },
  {
    "Model Name": "oopere/pruned40-llama-3.2-1B",
    "Parameters (B)": 0.914,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3781415746182163,
    "Overall Score": 6.877693765654211,
    "MMLU Score": 1.2725325059101646,
    "BBH Score": 2.7012729836642007,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.188144936451774
  },
  {
    "Model Name": "oopere/pruned40-llama-3.2-3b",
    "Parameters (B)": 2.367,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.1953346374394476,
    "Overall Score": 5.371284651830273,
    "MMLU Score": 1.965130023640662,
    "BBH Score": 4.740101545945625,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.4935405396903905
  },
  {
    "Model Name": "oopere/pruned60-llama-1b",
    "Parameters (B)": 0.753,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7649757630301478,
    "Overall Score": 5.46756672622325,
    "MMLU Score": 1.9189568557919607,
    "BBH Score": 2.9425264807533544,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.147372492646898
  },
  {
    "Model Name": "oopere/pruned60-llama-3.2-3b",
    "Parameters (B)": 1.944,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.241768441814752,
    "Overall Score": 5.128680683633621,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 3.9884019153468855,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.130142553903557
  },
  {
    "Model Name": "open-atlas/Atlas-Flash-1.5B-Preview",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.210487794649369,
    "Overall Score": 11.111374803615629,
    "MMLU Score": 4.153738179669029,
    "BBH Score": 5.6543805979986255,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.17925389477732
  },
  {
    "Model Name": "open-atlas/Atlas-Flash-7B-Preview",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3441327579015,
    "Overall Score": 17.496191215913385,
    "MMLU Score": 19.824911347517727,
    "BBH Score": 9.39485410104266,
    "Math Score": 25.755287009063444,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.01671364905127
  },
  {
    "Model Name": "open-neo/Kyro-n1-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7749305983569827,
    "Overall Score": 23.492573830963973,
    "MMLU Score": 26.917109929078016,
    "BBH Score": 25.78921982449477,
    "Math Score": 28.54984894259819,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 30.315713279064234
  },
  {
    "Model Name": "open-neo/Kyro-n1-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7370336620638953,
    "Overall Score": 28.918698187681176,
    "MMLU Score": 37.038268321512994,
    "BBH Score": 34.40152837379154,
    "Math Score": 38.97280966767372,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 39.23660434545273
  },
  {
    "Model Name": "open-thoughts/OpenThinker-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6851186403453313,
    "Overall Score": 26.578519435108664,
    "MMLU Score": 35.163637706855795,
    "BBH Score": 34.50881791580879,
    "Math Score": 42.59818731117825,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 38.79403926553781
  },
  {
    "Model Name": "openai-community/gpt2",
    "Parameters (B)": 0.137,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.0859412568146148,
    "Overall Score": 6.510807087761722,
    "MMLU Score": 1.7712027186761226,
    "BBH Score": 2.674981367986987,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 75.75880699308696
  },
  {
    "Model Name": "openai-community/gpt2",
    "Parameters (B)": 0.137,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.234773790497622,
    "Overall Score": 6.33423541829189,
    "MMLU Score": 1.8358451536643017,
    "BBH Score": 2.8159113095085133,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2024-08-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 26.98016420344863
  },
  {
    "Model Name": "openai-community/gpt2-large",
    "Parameters (B)": 0.812,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.3609244768632378,
    "Overall Score": 5.567707192929642,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 3.2537905449787403,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.426238866696114
  },
  {
    "Model Name": "openai-community/gpt2-medium",
    "Parameters (B)": 0.38,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.2421238300011916,
    "Overall Score": 5.902340287154445,
    "MMLU Score": 2.020537825059101,
    "BBH Score": 2.719972238356244,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 24.37736214203037
  },
  {
    "Model Name": "openai-community/gpt2-xl",
    "Parameters (B)": 1.608,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.4306273996769696,
    "Overall Score": 5.093480678758688,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 2.580960647452716,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.828045968694761
  },
  {
    "Model Name": "openbmb/MiniCPM-S-1B-sft-llama-format",
    "Parameters (B)": 1.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0800736949422725,
    "Overall Score": 8.996065699730169,
    "MMLU Score": 9.537529550827422,
    "BBH Score": 3.898455214242885,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.32912211625614
  },
  {
    "Model Name": "openchat/openchat-3.5-0106",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.962835689481651,
    "Overall Score": 22.70925524673515,
    "MMLU Score": 25.458037825059098,
    "BBH Score": 24.03871121391158,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.664702881552011
  },
  {
    "Model Name": "openchat/openchat-3.5-1210",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0329021207593168,
    "Overall Score": 22.727849608659103,
    "MMLU Score": 23.805038416075647,
    "BBH Score": 23.236296582166464,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 22.00387544170322
  },
  {
    "Model Name": "openchat/openchat-3.6-8b-20240522",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.349911793665565,
    "Overall Score": 23.10731592675394,
    "MMLU Score": 24.765440307328607,
    "BBH Score": 33.23293691836929,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.31213436566767
  },
  {
    "Model Name": "openchat/openchat_3.5",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.002421182361135,
    "Overall Score": 21.635827111564595,
    "MMLU Score": 23.92508865248227,
    "BBH Score": 21.58216684769999,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 21.58356935415398
  },
  {
    "Model Name": "openchat/openchat_v3.2",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 10.604910103456026,
    "Overall Score": 13.833145550526876,
    "MMLU Score": 15.79861111111111,
    "BBH Score": 20.32300299720885,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.3044095061229046
  },
  {
    "Model Name": "openchat/openchat_v3.2_super",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 10.055387243693328,
    "Overall Score": 12.92357500340055,
    "MMLU Score": 15.83554964539007,
    "BBH Score": 19.15353958747753,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.2852389162342932
  },
  {
    "Model Name": "orai-nlp/Llama-eus-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.7385151629295177,
    "Overall Score": 13.943754358263163,
    "MMLU Score": 22.86310579196217,
    "BBH Score": 20.96137115221118,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.020496257718557
  },
  {
    "Model Name": "oxyapi/oxy-1-small",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.773817220491188,
    "Overall Score": 36.10082946641055,
    "MMLU Score": 44.45367907801419,
    "BBH Score": 41.1754471888895,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.014855196557548
  },
  {
    "Model Name": "ozone-ai/0x-lite",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.4526879760369664,
    "Overall Score": 40.48460307410717,
    "MMLU Score": 46.485298463356976,
    "BBH Score": 47.5284725075208,
    "Math Score": 50.45317220543807,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.725531920372326
  },
  {
    "Model Name": "ozone-research/Chirp-01",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7157807215491061,
    "Overall Score": 28.252602808689176,
    "MMLU Score": 27.868277186761222,
    "BBH Score": 25.03833036298149,
    "Math Score": 34.66767371601209,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 39.47103066361491
  },
  {
    "Model Name": "paloalma/ECE-TW3-JRGL-V1",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 12.383388365937348,
    "Overall Score": 30.236001116528566,
    "MMLU Score": 35.791592789598106,
    "BBH Score": 46.69713905397109,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 2.441658149048924
  },
  {
    "Model Name": "paloalma/ECE-TW3-JRGL-V2",
    "Parameters (B)": 72.288,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 25.09249892397867,
    "Overall Score": 25.79271499886927,
    "MMLU Score": 39.86406619385342,
    "BBH Score": 43.17326773447519,
    "Math Score": 18.50453172205438,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.0279053942380152
  },
  {
    "Model Name": "paloalma/ECE-TW3-JRGL-V5",
    "Parameters (B)": 72.289,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 34.56184207719644,
    "Overall Score": 29.49204681730805,
    "MMLU Score": 40.528959810874696,
    "BBH Score": 43.46251365157702,
    "Math Score": 18.35347432024169,
    "Date Submitted": "2024-08-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 0.853312353879616
  },
  {
    "Model Name": "paloalma/Le_Triomphant-ECE-TW3",
    "Parameters (B)": 72.289,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 20.8367824579458,
    "Overall Score": 31.99629419421313,
    "MMLU Score": 41.81257387706855,
    "BBH Score": 44.96329362428286,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 1.5355678958011012
  },
  {
    "Model Name": "paloalma/TW3-JRGL-v2",
    "Parameters (B)": 72.289,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 31.846913566660287,
    "Overall Score": 32.46253888329018,
    "MMLU Score": 42.86532210401891,
    "BBH Score": 45.61110998256794,
    "Math Score": 17.900302114803626,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.0193307685952455
  },
  {
    "Model Name": "pankajmathur/Al_Dente_v1_8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8170640097905248,
    "Overall Score": 17.300059065636294,
    "MMLU Score": 20.665263002364064,
    "BBH Score": 27.247898492647995,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.520885875468242
  },
  {
    "Model Name": "pankajmathur/model_007_13b_v2",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.363560105318781,
    "Overall Score": 16.00740369607647,
    "MMLU Score": 16.232638888888886,
    "BBH Score": 25.454420185872465,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.668427455958475
  },
  {
    "Model Name": "pankajmathur/orca_mini_3b",
    "Parameters (B)": 3.426,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.049551149033351,
    "Overall Score": 3.1252754271378507,
    "MMLU Score": 1.6142139479905429,
    "BBH Score": 4.6859845437903855,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.97772569732906
  },
  {
    "Model Name": "pankajmathur/orca_mini_7b",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5214411396948289,
    "Overall Score": 3.405696058391802,
    "MMLU Score": 2.731604609929078,
    "BBH Score": 7.81893018360044,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.531314465109083
  },
  {
    "Model Name": "pankajmathur/orca_mini_phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7007696703119202,
    "Overall Score": 40.67628242552744,
    "MMLU Score": 47.27947695035461,
    "BBH Score": 54.63137024552032,
    "Math Score": 29.531722054380666,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.916396873462258
  },
  {
    "Model Name": "pankajmathur/orca_mini_v2_7b",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.185022969094885,
    "Overall Score": 5.502368522121576,
    "MMLU Score": 6.019134160756501,
    "BBH Score": 10.199953477088153,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.643258962587248
  },
  {
    "Model Name": "pankajmathur/orca_mini_v3_13b",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1943587430415645,
    "Overall Score": 15.041296989515962,
    "MMLU Score": 14.496527777777777,
    "BBH Score": 25.549482064607844,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.854529614728113
  },
  {
    "Model Name": "pankajmathur/orca_mini_v3_70b",
    "Parameters (B)": 70.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 12.813073977150223,
    "Overall Score": 25.29815949268638,
    "MMLU Score": 30.63866725768321,
    "BBH Score": 42.975787003923045,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.9744020472995807
  },
  {
    "Model Name": "pankajmathur/orca_mini_v3_7b",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.279900284323806,
    "Overall Score": 13.644021205601405,
    "MMLU Score": 12.04011524822695,
    "BBH Score": 17.843955571096647,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.66022202878858
  },
  {
    "Model Name": "pankajmathur/orca_mini_v5_8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7579415515670855,
    "Overall Score": 20.498300732442388,
    "MMLU Score": 23.066267730496453,
    "BBH Score": 29.34579501072649,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 11.660399467871697
  },
  {
    "Model Name": "pankajmathur/orca_mini_v5_8b_dpo",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6333793278135202,
    "Overall Score": 20.33420699350285,
    "MMLU Score": 23.50953014184397,
    "BBH Score": 29.60537298923376,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.449163918783455
  },
  {
    "Model Name": "pankajmathur/orca_mini_v5_8b_orpo",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.943699538564584,
    "Overall Score": 12.99373010020274,
    "MMLU Score": 21.63489952718676,
    "BBH Score": 27.87762825685837,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.685050771683862
  },
  {
    "Model Name": "pankajmathur/orca_mini_v6_8b",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.432735692418171,
    "Overall Score": 1.476338760647978,
    "MMLU Score": 1.383348108747044,
    "BBH Score": 3.219809856556432,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.6068636084261493
  },
  {
    "Model Name": "pankajmathur/orca_mini_v6_8b_dpo",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.539647289874839,
    "Overall Score": 20.39249236211252,
    "MMLU Score": 28.847148345153663,
    "BBH Score": 32.47882597428379,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.24491167309512
  },
  {
    "Model Name": "pankajmathur/orca_mini_v7_72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 28.10341439624203,
    "Overall Score": 36.215290911205,
    "MMLU Score": 51.35195035460993,
    "BBH Score": 55.05552307693972,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 1.288643806784121
  },
  {
    "Model Name": "pankajmathur/orca_mini_v7_7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.850218823029076,
    "Overall Score": 23.986504270832167,
    "MMLU Score": 35.19134160756501,
    "BBH Score": 33.95043410425148,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.96414454997425
  },
  {
    "Model Name": "pankajmathur/orca_mini_v8_1_70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 54.448936643551214,
    "Overall Score": 43.191232219399744,
    "MMLU Score": 44.25975177304965,
    "BBH Score": 53.51972670972081,
    "Math Score": 35.27190332326284,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.7932428965904369
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_0_3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2023625178594268,
    "Overall Score": 20.660838216117185,
    "MMLU Score": 17.81176122931442,
    "BBH Score": 21.368152564693613,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.183534840141057
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_1_1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7135759715391796,
    "Overall Score": 9.063245765360724,
    "MMLU Score": 4.153738179669029,
    "BBH Score": 6.406448543994878,
    "Math Score": 4.607250755287009,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.701164454586875
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_2_14B",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8814172421796664,
    "Overall Score": 40.67628242552744,
    "MMLU Score": 47.27947695035461,
    "BBH Score": 54.63137024552032,
    "Math Score": 29.531722054380666,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.620022137355882
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_2_70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 48.05524024512421,
    "Overall Score": 40.72477703174064,
    "MMLU Score": 42.45899822695035,
    "BBH Score": 53.03309980255676,
    "Math Score": 29.38066465256798,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.8474575680822378
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_4_70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 60.69019593236153,
    "Overall Score": 39.32550746750958,
    "MMLU Score": 39.29151891252955,
    "BBH Score": 48.69261714198851,
    "Math Score": 32.62839879154079,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 0.6479713380944984
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_5_1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.091074704963622,
    "Overall Score": 10.693501511833992,
    "MMLU Score": 4.10756501182033,
    "BBH Score": 6.6988165369101145,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.800888484707862
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_5_1B-Instruct_preview",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7155956947297311,
    "Overall Score": 9.541822835013244,
    "MMLU Score": 3.6365986997635926,
    "BBH Score": 5.582691663791198,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.334097599087759
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_5_3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1120528502404838,
    "Overall Score": 24.152680776912927,
    "MMLU Score": 20.914598108747047,
    "BBH Score": 21.51790435310073,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.719004426534095
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_6_1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7610068389439243,
    "Overall Score": 15.323670701472976,
    "MMLU Score": 8.983451536643026,
    "BBH Score": 9.659037433840986,
    "Math Score": 7.7039274924471295,
    "Date Submitted": "2025-01-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.136048609941756
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_6_3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6625691395723998,
    "Overall Score": 24.08682629932844,
    "MMLU Score": 20.563682033096924,
    "BBH Score": 22.86989036357046,
    "Math Score": 13.293051359516618,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.487714060134298
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_7_1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8512147170563129,
    "Overall Score": 12.485692413724529,
    "MMLU Score": 3.830526004728132,
    "BBH Score": 5.052028049769791,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.668088043523014
  },
  {
    "Model Name": "pankajmathur/orca_mini_v9_7_3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0710980392937726,
    "Overall Score": 13.034702793317214,
    "MMLU Score": 4.162972813238769,
    "BBH Score": 6.301038778871171,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.169476850047856
  },
  {
    "Model Name": "paulml/ECE-ILAB-Q1",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 22.83028414132809,
    "Overall Score": 42.50307248816295,
    "MMLU Score": 50.05910165484633,
    "BBH Score": 53.70222770817057,
    "Math Score": 35.57401812688822,
    "Date Submitted": "2024-09-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.8616970434994529
  },
  {
    "Model Name": "pints-ai/1.5-Pints-16K-v0.1",
    "Parameters (B)": 1.566,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5598769163544511,
    "Overall Score": 4.250927888464816,
    "MMLU Score": 1.3187056737588652,
    "BBH Score": 3.658292060342125,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.592611454932009
  },
  {
    "Model Name": "pints-ai/1.5-Pints-2K-v0.1",
    "Parameters (B)": 1.566,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.5828330308866719,
    "Overall Score": 4.044439684591542,
    "MMLU Score": 1.1524822695035457,
    "BBH Score": 2.3744704635071923,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-09-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.9392767229384384
  },
  {
    "Model Name": "piotr25691/thea-3b-25r",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.38101522973834,
    "Overall Score": 23.996071012635184,
    "MMLU Score": 24.248300827423165,
    "BBH Score": 22.54671082396668,
    "Math Score": 17.82477341389728,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.375674428428788
  },
  {
    "Model Name": "piotr25691/thea-c-3b-25r",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.324912414241504,
    "Overall Score": 23.25479609330286,
    "MMLU Score": 24.202127659574465,
    "BBH Score": 22.767850009265825,
    "Math Score": 15.256797583081571,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.55194973142126
  },
  {
    "Model Name": "piotr25691/thea-rp-3b-25r",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.316906699515089,
    "Overall Score": 21.845382189211342,
    "MMLU Score": 22.89080969267139,
    "BBH Score": 20.0073809275686,
    "Math Score": 13.217522658610273,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.58840538760661
  },
  {
    "Model Name": "postbot/gpt2-medium-emailgen",
    "Parameters (B)": 0.38,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 0.1563727075714753,
    "Overall Score": 4.743048119298616,
    "MMLU Score": 1.632683215130022,
    "BBH Score": 3.673700346196318,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 30.331687626056162
  },
  {
    "Model Name": "prince-canuma/Ministral-8B-Instruct-2410-HF",
    "Parameters (B)": 8.02,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.033869215728028,
    "Overall Score": 23.74474818460179,
    "MMLU Score": 25.53191489361702,
    "BBH Score": 23.77846492727436,
    "Math Score": 19.18429003021148,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.674668164984396
  },
  {
    "Model Name": "princeton-nlp/Llama-3-8B-ProLong-512k-Base",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.7573275822291825,
    "Overall Score": 21.67904493201005,
    "MMLU Score": 25.882830969267133,
    "BBH Score": 29.847246369144035,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.336370948272506
  },
  {
    "Model Name": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.344706085397087,
    "Overall Score": 21.942343537569432,
    "MMLU Score": 24.793144208037827,
    "BBH Score": 29.151153442911763,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.358249067645248
  },
  {
    "Model Name": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.448747104795808,
    "Overall Score": 19.242001937233777,
    "MMLU Score": 24.959367612293143,
    "BBH Score": 28.66921858384416,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.281822530334455
  },
  {
    "Model Name": "princeton-nlp/Llama-3-8B-ProLong-64k-Base",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.714774969456653,
    "Overall Score": 21.65219829915355,
    "MMLU Score": 26.08599290780142,
    "BBH Score": 28.687899000980178,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.97568805619536
  },
  {
    "Model Name": "princeton-nlp/Llama-3-8B-ProLong-64k-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.417880176151947,
    "Overall Score": 23.020991799409,
    "MMLU Score": 25.2733451536643,
    "BBH Score": 30.08957216568684,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.521146674872398
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.620909789947218,
    "Overall Score": 15.96420649511064,
    "MMLU Score": 23.26019503546099,
    "BBH Score": 24.345967199755464,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.091093465461144
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-CPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9356921108847127,
    "Overall Score": 15.953789309641664,
    "MMLU Score": 21.95811170212766,
    "BBH Score": 25.474648628373444,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.24190439168032
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-DPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8526797331815927,
    "Overall Score": 18.376219112296344,
    "MMLU Score": 23.093971631205672,
    "BBH Score": 26.001873821480995,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.918724096333154
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-IPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8643816941174216,
    "Overall Score": 18.722473272112868,
    "MMLU Score": 23.50029550827423,
    "BBH Score": 25.705433288023944,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.042188963336656
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-KTO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7237038714780366,
    "Overall Score": 18.6446163938307,
    "MMLU Score": 22.826167257683213,
    "BBH Score": 25.55523001299593,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.816600636769103
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-ORPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8131264465728392,
    "Overall Score": 19.268325889820545,
    "MMLU Score": 23.140144799054376,
    "BBH Score": 26.48589369385502,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.627127482609621
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-RDPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8048707562728683,
    "Overall Score": 19.142302231808696,
    "MMLU Score": 22.38290484633569,
    "BBH Score": 25.526521127200017,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.605913008052903
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-RRHF",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9029374463777384,
    "Overall Score": 16.28272427355282,
    "MMLU Score": 20.988475177304963,
    "BBH Score": 23.659142323042403,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.556626127961882
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-SLiC-HF",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9209421284151864,
    "Overall Score": 19.7431134910636,
    "MMLU Score": 22.92774822695035,
    "BBH Score": 26.37396261839453,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.277828362977306
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Base-8B-SFT-SimPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7231300520645123,
    "Overall Score": 19.85850945722653,
    "MMLU Score": 23.389479905437348,
    "BBH Score": 26.39594961870209,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.524672460696568
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-CPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.478832591107401,
    "Overall Score": 23.999076429407367,
    "MMLU Score": 29.46586879432624,
    "BBH Score": 28.604298572618475,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.228392972754293
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5457710913976703,
    "Overall Score": 24.883954972962343,
    "MMLU Score": 30.06611997635934,
    "BBH Score": 29.08640671420084,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.098085357814867
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-DPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1297075680762036,
    "Overall Score": 23.49823972598104,
    "MMLU Score": 29.613622931442084,
    "BBH Score": 28.50739167799402,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 20.800285303918564
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2057596581828285,
    "Overall Score": 25.208963221170475,
    "MMLU Score": 30.76795212765957,
    "BBH Score": 28.939587046939987,
    "Math Score": 8.987915407854985,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 20.907121124919954
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-KTO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2050342644520593,
    "Overall Score": 23.419046565350595,
    "MMLU Score": 28.874852245862886,
    "BBH Score": 28.64965788695442,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.43434079527976
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2610727933649517,
    "Overall Score": 24.659390077356026,
    "MMLU Score": 29.6413268321513,
    "BBH Score": 29.64840552320977,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.55429552290694
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-ORPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2478082307124323,
    "Overall Score": 23.622591862806686,
    "MMLU Score": 29.40122635933806,
    "BBH Score": 28.839356158957287,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.9312678674346
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1884649884315808,
    "Overall Score": 25.9661449482921,
    "MMLU Score": 30.34315898345153,
    "BBH Score": 29.60483732707141,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 21.848472778789777
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-RDPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1324999349471547,
    "Overall Score": 23.603754396673683,
    "MMLU Score": 28.96719858156028,
    "BBH Score": 29.032479102136296,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 20.842168434892752
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1158963882127917,
    "Overall Score": 25.03222506807271,
    "MMLU Score": 30.82335992907802,
    "BBH Score": 28.85427665062166,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 22.432391871223874
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-RRHF",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2784314455881307,
    "Overall Score": 24.084494106293988,
    "MMLU Score": 29.37352245862884,
    "BBH Score": 27.21648494751436,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.83909707431683
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0117469934821683,
    "Overall Score": 23.75375059997253,
    "MMLU Score": 27.582003546099287,
    "BBH Score": 28.498723991187727,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 23.477955213109492
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4503845366506314,
    "Overall Score": 25.30814408533829,
    "MMLU Score": 28.717863475177303,
    "BBH Score": 29.211612180239623,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 17.449264967883835
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0424785340309333,
    "Overall Score": 23.72835501994857,
    "MMLU Score": 27.582003546099287,
    "BBH Score": 28.498723991187727,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 22.76148068795101
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-SimPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.0666912046425685,
    "Overall Score": 23.664165370275043,
    "MMLU Score": 27.655880614657207,
    "BBH Score": 26.709132779658223,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 22.18464469124833
  },
  {
    "Model Name": "princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1599632156488957,
    "Overall Score": 24.75153967862504,
    "MMLU Score": 29.1334219858156,
    "BBH Score": 29.214021710829385,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 21.338210854194
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-CPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.619537565872139,
    "Overall Score": 17.3989699937128,
    "MMLU Score": 18.34736997635934,
    "BBH Score": 21.857696499882195,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.743171606731618
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3352393409486394,
    "Overall Score": 16.311853642274055,
    "MMLU Score": 18.28272754137116,
    "BBH Score": 20.79098038827006,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.216426779849874
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-IPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3346689175278992,
    "Overall Score": 17.273368181499578,
    "MMLU Score": 19.908023049645383,
    "BBH Score": 23.70349052130433,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.942062225809273
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-KTO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.332033050953054,
    "Overall Score": 19.012992284438702,
    "MMLU Score": 20.794547872340427,
    "BBH Score": 23.10764227790982,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.273664058737229
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-RDPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3250104348805782,
    "Overall Score": 16.4909336267166,
    "MMLU Score": 19.741799645390067,
    "BBH Score": 22.98200980704625,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.445889626675212
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-RRHF",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.338002273442345,
    "Overall Score": 16.18202454301279,
    "MMLU Score": 15.530806737588652,
    "BBH Score": 19.59883081662414,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.094168197024429
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.336883911603808,
    "Overall Score": 19.005885681302413,
    "MMLU Score": 19.78797281323877,
    "BBH Score": 22.304722895019296,
    "Math Score": 3.5498489425981874,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.216556513498457
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Base-SFT-SimPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.271412786584075,
    "Overall Score": 17.032014558172765,
    "MMLU Score": 18.91068262411348,
    "BBH Score": 22.33288648076616,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.396132820036325
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-CPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.291844519171918,
    "Overall Score": 15.540359200506424,
    "MMLU Score": 18.901447990543733,
    "BBH Score": 17.248538100586853,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.029589451266094
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2105331772003622,
    "Overall Score": 16.56219551319486,
    "MMLU Score": 19.42782210401891,
    "BBH Score": 16.875389341982814,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.681736135063037
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-IPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2514953431562663,
    "Overall Score": 17.71968449150264,
    "MMLU Score": 18.975325059101653,
    "BBH Score": 20.094109548877523,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.15880976977003
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-KTO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2067562596637862,
    "Overall Score": 16.702591779643708,
    "MMLU Score": 20.13888888888889,
    "BBH Score": 17.81264785919903,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.840899225413763
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-ORPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2485932476809387,
    "Overall Score": 16.088293109620597,
    "MMLU Score": 18.467420212765955,
    "BBH Score": 18.03837283661216,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.885135443029197
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-RDPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2212311182397022,
    "Overall Score": 16.433078686509017,
    "MMLU Score": 19.741799645390067,
    "BBH Score": 17.04838760964466,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.45615784029141
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-RRHF",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1755025923318254,
    "Overall Score": 16.892023987011328,
    "MMLU Score": 18.34736997635934,
    "BBH Score": 19.20655206374787,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.370044011134755
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-SLiC-HF",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2449057092755338,
    "Overall Score": 16.389143637193502,
    "MMLU Score": 19.05843676122932,
    "BBH Score": 16.653429432655862,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.164967848634156
  },
  {
    "Model Name": "princeton-nlp/Mistral-7B-Instruct-SimPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.141124919299414,
    "Overall Score": 17.607315799541798,
    "MMLU Score": 19.96343085106384,
    "BBH Score": 22.38227741589404,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2024-09-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.429788186863618
  },
  {
    "Model Name": "princeton-nlp/Sheared-LLaMA-1.3B",
    "Parameters (B)": 1.3,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7092001641474984,
    "Overall Score": 5.580925572139816,
    "MMLU Score": 1.9004875886524817,
    "BBH Score": 4.744629874421679,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 7.869323576438292
  },
  {
    "Model Name": "princeton-nlp/Sheared-LLaMA-2.7B",
    "Parameters (B)": 2.7,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.940099527821622,
    "Overall Score": 6.437920061018112,
    "MMLU Score": 2.0759456264775418,
    "BBH Score": 5.655521329938437,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-07-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.848126044628402
  },
  {
    "Model Name": "princeton-nlp/gemma-2-9b-it-DPO",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.78125394205658,
    "Overall Score": 20.818727391139728,
    "MMLU Score": 30.26004728132387,
    "BBH Score": 41.59365445538448,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.601074714897203
  },
  {
    "Model Name": "princeton-nlp/gemma-2-9b-it-SimPO",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.538007448508068,
    "Overall Score": 22.3449346084354,
    "MMLU Score": 33.05814125295508,
    "BBH Score": 40.093429916371655,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.034832891829189
  },
  {
    "Model Name": "prithivMLmods/Bellatrix-1.5B-xElite",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1993278028558003,
    "Overall Score": 12.228869542511774,
    "MMLU Score": 7.302748226950355,
    "BBH Score": 9.486709175278516,
    "Math Score": 28.700906344410875,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.196436298227047
  },
  {
    "Model Name": "prithivMLmods/Bellatrix-Tiny-1.5B-R1",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1689612409686612,
    "Overall Score": 14.322564666933152,
    "MMLU Score": 19.455526004728128,
    "BBH Score": 15.857580425391273,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.252386276780863
  },
  {
    "Model Name": "prithivMLmods/Bellatrix-Tiny-1B-v2",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7737320997953054,
    "Overall Score": 6.033864136016213,
    "MMLU Score": 5.474290780141842,
    "BBH Score": 6.032561968055522,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.798389310217969
  },
  {
    "Model Name": "prithivMLmods/Blaze-14B-xElite",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8817105453993044,
    "Overall Score": 29.122992008208428,
    "MMLU Score": 45.6818853427896,
    "BBH Score": 51.57326409688974,
    "Math Score": 36.933534743202415,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.476871338906403
  },
  {
    "Model Name": "prithivMLmods/COCO-7B-Instruct-1M",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3381043677295874,
    "Overall Score": 28.952308445124856,
    "MMLU Score": 35.403738179669034,
    "BBH Score": 34.67788338275968,
    "Math Score": 34.96978851963746,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.63680886435588
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.024797067435322,
    "Overall Score": 40.07735278337776,
    "MMLU Score": 47.796616430260045,
    "BBH Score": 46.93415830006768,
    "Math Score": 47.88519637462236,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.957608324564752
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.022332794511404,
    "Overall Score": 38.249365220151496,
    "MMLU Score": 47.85202423167848,
    "BBH Score": 46.53280917875986,
    "Math Score": 37.08459214501511,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.91348709963068
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite-1M",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.893608616767551,
    "Overall Score": 37.61517905195512,
    "MMLU Score": 46.13438238770685,
    "BBH Score": 46.93552255298414,
    "Math Score": 44.5619335347432,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.660749899198393
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite-Stock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.9744594479509305,
    "Overall Score": 39.73983420814852,
    "MMLU Score": 47.60268912529552,
    "BBH Score": 46.89789858349237,
    "Math Score": 46.67673716012085,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.998802284581558
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.025445929856857,
    "Overall Score": 40.24980893567484,
    "MMLU Score": 47.78738179669031,
    "BBH Score": 46.80614993275231,
    "Math Score": 46.90332326283988,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.998844758326218
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite2-R1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.6780303849911,
    "Overall Score": 38.56373181629569,
    "MMLU Score": 47.19636524822696,
    "BBH Score": 47.33709556238046,
    "Math Score": 33.383685800604226,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.484886686543511
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.024630380631692,
    "Overall Score": 38.80335311719453,
    "MMLU Score": 48.16600177304965,
    "BBH Score": 47.07459951045248,
    "Math Score": 47.05438066465257,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.64147001024827
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Elite4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.9166011940560086,
    "Overall Score": 36.74386944728247,
    "MMLU Score": 46.0974438534279,
    "BBH Score": 45.20847500962782,
    "Math Score": 36.25377643504532,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.381570302089077
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-14B-Merge",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.138515371119,
    "Overall Score": 38.01116092312885,
    "MMLU Score": 48.39686761229315,
    "BBH Score": 46.76666800624009,
    "Math Score": 46.37462235649547,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.184733537150334
  },
  {
    "Model Name": "prithivMLmods/Calcium-Opus-20B-v1",
    "Parameters (B)": 19.173,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.472539882729625,
    "Overall Score": 31.041733901500965,
    "MMLU Score": 41.48936170212765,
    "BBH Score": 41.80557589234856,
    "Math Score": 36.17824773413897,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.67227184574081
  },
  {
    "Model Name": "prithivMLmods/Codepy-Deepthink-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.211006964059197,
    "Overall Score": 17.43076520482992,
    "MMLU Score": 23.223256501182032,
    "BBH Score": 18.640887671757213,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.393612689396445
  },
  {
    "Model Name": "prithivMLmods/Coma-II-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.700583447666952,
    "Overall Score": 39.45146855133309,
    "MMLU Score": 44.88770685579197,
    "BBH Score": 46.89147136445168,
    "Math Score": 55.135951661631424,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 10.660877969447071
  },
  {
    "Model Name": "prithivMLmods/Condor-Opus-14B-Exp",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7127687329836954,
    "Overall Score": 37.617199777677776,
    "MMLU Score": 44.60143321513003,
    "BBH Score": 44.07709222484056,
    "Math Score": 52.26586102719033,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.962801546562254
  },
  {
    "Model Name": "prithivMLmods/Cygnus-II-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.001975881015083,
    "Overall Score": 40.52948756458168,
    "MMLU Score": 48.78472222222222,
    "BBH Score": 52.14038233919259,
    "Math Score": 43.957703927492446,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.24474318043811
  },
  {
    "Model Name": "prithivMLmods/Deepthink-Llama-3-8B-Preview",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7295998014032185,
    "Overall Score": 20.957476415581784,
    "MMLU Score": 19.317006501182032,
    "BBH Score": 24.80087982370277,
    "Math Score": 35.49848942598187,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 28.724619134044264
  },
  {
    "Model Name": "prithivMLmods/Deepthink-Reasoning-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.900782398935849,
    "Overall Score": 37.765949130344175,
    "MMLU Score": 47.73197399527187,
    "BBH Score": 47.30625659928727,
    "Math Score": 42.296072507552864,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.681634417917516
  },
  {
    "Model Name": "prithivMLmods/Deepthink-Reasoning-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.253995016550189,
    "Overall Score": 29.122241455484662,
    "MMLU Score": 37.21372635933806,
    "BBH Score": 35.623731448580884,
    "Math Score": 33.45921450151057,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.2235703261418
  },
  {
    "Model Name": "prithivMLmods/Dinobot-Opus-14B-Exp",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7046318064582169,
    "Overall Score": 41.765081012881176,
    "MMLU Score": 44.213578605200944,
    "BBH Score": 48.19594986631396,
    "Math Score": 53.17220543806647,
    "Date Submitted": "2025-02-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 24.50093964846179
  },
  {
    "Model Name": "prithivMLmods/Elita-0.1-Distilled-R1-abliterated",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7736586005657055,
    "Overall Score": 17.39921663367112,
    "MMLU Score": 19.52940307328605,
    "BBH Score": 13.606416556106325,
    "Math Score": 30.664652567975832,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.489527836889128
  },
  {
    "Model Name": "prithivMLmods/Elita-1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.843754231777964,
    "Overall Score": 36.545369563806254,
    "MMLU Score": 48.68314125295508,
    "BBH Score": 49.928735220527614,
    "Math Score": 34.29003021148036,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.507727955567507
  },
  {
    "Model Name": "prithivMLmods/Epimetheus-14B-Axo",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9946034537563264,
    "Overall Score": 39.08056006814201,
    "MMLU Score": 47.82432033096927,
    "BBH Score": 51.45544715649952,
    "Math Score": 41.012084592145015,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.593147697876365
  },
  {
    "Model Name": "prithivMLmods/Equuleus-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.902014927917551,
    "Overall Score": 42.199750941616415,
    "MMLU Score": 48.60002955082743,
    "BBH Score": 48.61670086911542,
    "Math Score": 45.84592145015105,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.186866318562195
  },
  {
    "Model Name": "prithivMLmods/Eridanus-Opus-14B-r999",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9579416118707536,
    "Overall Score": 40.111313344425874,
    "MMLU Score": 48.46151004728132,
    "BBH Score": 51.03833480947816,
    "Math Score": 38.59516616314199,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.486470638979238
  },
  {
    "Model Name": "prithivMLmods/Evac-Opus-14B-Exp",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.944293501458255,
    "Overall Score": 39.323054993397584,
    "MMLU Score": 47.96283983451538,
    "BBH Score": 49.58175106916661,
    "Math Score": 42.14501510574018,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.22485543664297
  },
  {
    "Model Name": "prithivMLmods/FastThink-0.5B-Tiny",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0750746175098636,
    "Overall Score": 7.516955448134702,
    "MMLU Score": 7.210401891252953,
    "BBH Score": 5.01960978303041,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.9920313675955015
  },
  {
    "Model Name": "prithivMLmods/GWQ-9B-Preview",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.922323401670357,
    "Overall Score": 30.15453648521797,
    "MMLU Score": 33.150487588652474,
    "BBH Score": 40.6697225433022,
    "Math Score": 22.658610271903324,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.126077875132145
  },
  {
    "Model Name": "prithivMLmods/GWQ-9B-Preview2",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.905647704544523,
    "Overall Score": 30.0471879091734,
    "MMLU Score": 33.298241725768314,
    "BBH Score": 40.18486053315952,
    "Math Score": 23.716012084592144,
    "Date Submitted": "2025-01-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.125019511967422
  },
  {
    "Model Name": "prithivMLmods/GWQ2b",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.408578642384382,
    "Overall Score": 16.42971150895339,
    "MMLU Score": 16.36192375886525,
    "BBH Score": 17.6803497776584,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.821330730014583
  },
  {
    "Model Name": "prithivMLmods/Gaea-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0040682772167764,
    "Overall Score": 40.11380825495326,
    "MMLU Score": 48.8955378250591,
    "BBH Score": 50.51229448373768,
    "Math Score": 42.74924471299094,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.016188425806924
  },
  {
    "Model Name": "prithivMLmods/Galactic-Qwen-14B-Exp1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1030774034920614,
    "Overall Score": 39.46950467300847,
    "MMLU Score": 48.84013002364066,
    "BBH Score": 50.98957194551118,
    "Math Score": 40.181268882175225,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 18.767499763665956
  },
  {
    "Model Name": "prithivMLmods/Galactic-Qwen-14B-Exp2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.180329277429034,
    "Overall Score": 43.56371836153858,
    "MMLU Score": 52.11842494089834,
    "BBH Score": 59.91731650130399,
    "Math Score": 34.74320241691843,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.697864139638812
  },
  {
    "Model Name": "prithivMLmods/Gauss-Opus-14B-R999",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8817541920229752,
    "Overall Score": 38.80249475115856,
    "MMLU Score": 44.52755614657211,
    "BBH Score": 44.93611504035883,
    "Math Score": 57.55287009063444,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.62038438157751
  },
  {
    "Model Name": "prithivMLmods/Jolt-v0.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.9516953293416273,
    "Overall Score": 37.194359554127736,
    "MMLU Score": 48.73854905437352,
    "BBH Score": 50.0297418150364,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.412253844054447
  },
  {
    "Model Name": "prithivMLmods/Lacerta-Opus-14B-Elite8",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.021558179765879,
    "Overall Score": 38.069826308128185,
    "MMLU Score": 48.01824763593381,
    "BBH Score": 48.182387387883786,
    "Math Score": 36.48036253776435,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 18.83192217230035
  },
  {
    "Model Name": "prithivMLmods/Llama-3.1-5B-Instruct",
    "Parameters (B)": 5.413,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9991042465955756,
    "Overall Score": 4.207173577211278,
    "MMLU Score": 2.039007092198581,
    "BBH Score": 3.109216174639221,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.210945546019971
  },
  {
    "Model Name": "prithivMLmods/Llama-3.1-8B-Open-SFT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4555876766450873,
    "Overall Score": 21.04370403547396,
    "MMLU Score": 28.02526595744681,
    "BBH Score": 28.17992791986844,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.457187549139302
  },
  {
    "Model Name": "prithivMLmods/Llama-3.2-3B-Math-Oct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.191365208223217,
    "Overall Score": 17.441953756100272,
    "MMLU Score": 21.237810283687946,
    "BBH Score": 19.946749736299825,
    "Math Score": 11.555891238670696,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.640308140366903
  },
  {
    "Model Name": "prithivMLmods/Llama-3.2-6B-AlgoCode",
    "Parameters (B)": 6.339,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5547206744933495,
    "Overall Score": 9.301000017101474,
    "MMLU Score": 8.863401300236404,
    "BBH Score": 11.60252636544502,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.982425119632807
  },
  {
    "Model Name": "prithivMLmods/Llama-8B-Distill-CoT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4350045268373062,
    "Overall Score": 20.756374392650613,
    "MMLU Score": 19.243129432624112,
    "BBH Score": 19.59512258030452,
    "Math Score": 40.03021148036254,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.46432677003246
  },
  {
    "Model Name": "prithivMLmods/Llama-Deepsync-1B",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7542739289022414,
    "Overall Score": 10.269419049452202,
    "MMLU Score": 8.19850768321513,
    "BBH Score": 7.763872793811656,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.614972831419687
  },
  {
    "Model Name": "prithivMLmods/Llama-Deepsync-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2161541593013407,
    "Overall Score": 17.176506909330996,
    "MMLU Score": 22.567597517730498,
    "BBH Score": 18.963664295918168,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.123626333028865
  },
  {
    "Model Name": "prithivMLmods/Llama-Express.1-Math",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7120903218166346,
    "Overall Score": 12.170622691501343,
    "MMLU Score": 6.776374113475176,
    "BBH Score": 7.199019778023913,
    "Math Score": 5.589123867069486,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.091403040631853
  },
  {
    "Model Name": "prithivMLmods/LwQ-10B-Instruct",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4503505632541436,
    "Overall Score": 20.967461043098936,
    "MMLU Score": 25.75354609929078,
    "BBH Score": 31.59027306507356,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.456822767079402
  },
  {
    "Model Name": "prithivMLmods/LwQ-Reasoner-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7891952569981957,
    "Overall Score": 26.99437823708219,
    "MMLU Score": 34.96971040189125,
    "BBH Score": 40.33724839462296,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.08744120100773
  },
  {
    "Model Name": "prithivMLmods/Magellanic-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9412251013841813,
    "Overall Score": 40.055124365076594,
    "MMLU Score": 47.473404255319146,
    "BBH Score": 48.00332430163465,
    "Math Score": 37.99093655589124,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.633941080050676
  },
  {
    "Model Name": "prithivMLmods/Magellanic-Qwen-25B-R999",
    "Parameters (B)": 24.962,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.404560147513011,
    "Overall Score": 4.9765268528155335,
    "MMLU Score": 3.331855791962176,
    "BBH Score": 2.00355862547039,
    "Math Score": 0.5287009063444109,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 2.069620449279531
  },
  {
    "Model Name": "prithivMLmods/Megatron-Corpus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8062468013764728,
    "Overall Score": 35.55395685759063,
    "MMLU Score": 47.33488475177305,
    "BBH Score": 47.91897959935681,
    "Math Score": 34.29003021148036,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.68388640494549
  },
  {
    "Model Name": "prithivMLmods/Megatron-Corpus-14B-Exp.v2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.53827930059856,
    "Overall Score": 31.898674141338944,
    "MMLU Score": 42.329713356974,
    "BBH Score": 46.78841154317365,
    "Math Score": 25.90634441087613,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.01530699850143
  },
  {
    "Model Name": "prithivMLmods/Megatron-Opus-14B-2.0",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8824604199255072,
    "Overall Score": 36.80518021675177,
    "MMLU Score": 46.33754432624114,
    "BBH Score": 54.69962231498104,
    "Math Score": 27.794561933534744,
    "Date Submitted": "2025-02-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 41.7074572249469
  },
  {
    "Model Name": "prithivMLmods/Megatron-Opus-14B-2.1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8557331146586711,
    "Overall Score": 28.50969719045679,
    "MMLU Score": 46.3744828605201,
    "BBH Score": 52.531003009357,
    "Math Score": 29.984894259818727,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 33.31610837781887
  },
  {
    "Model Name": "prithivMLmods/Megatron-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.8280680323285137,
    "Overall Score": 36.964774794825566,
    "MMLU Score": 48.8955378250591,
    "BBH Score": 50.00287913113638,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.656248134216376
  },
  {
    "Model Name": "prithivMLmods/Megatron-Opus-14B-Stock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.65052126683003,
    "Overall Score": 36.31374014966015,
    "MMLU Score": 47.704270094562645,
    "BBH Score": 48.128851193275885,
    "Math Score": 33.45921450151057,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.947549266352743
  },
  {
    "Model Name": "prithivMLmods/Megatron-Opus-7B-Exp",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.196807166029562,
    "Overall Score": 27.61772604132373,
    "MMLU Score": 32.227024231678485,
    "BBH Score": 34.37153536149186,
    "Math Score": 19.71299093655589,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.0761703516083
  },
  {
    "Model Name": "prithivMLmods/Messier-Opus-14B-Elite7",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7894127463904677,
    "Overall Score": 41.66277236825811,
    "MMLU Score": 48.93247635933806,
    "BBH Score": 49.704671266379385,
    "Math Score": 40.70996978851964,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.282930364891275
  },
  {
    "Model Name": "prithivMLmods/Omni-Reasoner-Merged",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2628315519731843,
    "Overall Score": 29.234864632923,
    "MMLU Score": 37.37994976359338,
    "BBH Score": 35.36177667333275,
    "Math Score": 33.30815709969788,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.150248809703314
  },
  {
    "Model Name": "prithivMLmods/Omni-Reasoner3-Merged",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1765997861113684,
    "Overall Score": 18.433737471025804,
    "MMLU Score": 21.66260342789598,
    "BBH Score": 20.586521670513378,
    "Math Score": 10.876132930513595,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.666956333511521
  },
  {
    "Model Name": "prithivMLmods/Pegasus-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8781152230431404,
    "Overall Score": 41.62328046376648,
    "MMLU Score": 49.02482269503546,
    "BBH Score": 50.30694887028773,
    "Math Score": 40.86102719033233,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.16226137410441
  },
  {
    "Model Name": "prithivMLmods/Phi-4-Empathetic",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7952762660673902,
    "Overall Score": 28.208396720096133,
    "MMLU Score": 45.1739804964539,
    "BBH Score": 52.83893775599707,
    "Math Score": 26.20845921450152,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.712565945010526
  },
  {
    "Model Name": "prithivMLmods/Phi-4-Math-IO",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9338931212866448,
    "Overall Score": 31.821782745368303,
    "MMLU Score": 46.725398936170215,
    "BBH Score": 52.093770592369005,
    "Math Score": 45.77039274924472,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.454778392405082
  },
  {
    "Model Name": "prithivMLmods/Phi-4-QwQ",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9715288725951656,
    "Overall Score": 31.262674551400632,
    "MMLU Score": 47.50110815602837,
    "BBH Score": 52.28684974505503,
    "Math Score": 45.77039274924472,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.857071629008864
  },
  {
    "Model Name": "prithivMLmods/Phi-4-Super",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.925290932101336,
    "Overall Score": 30.387370956217424,
    "MMLU Score": 47.399527186761226,
    "BBH Score": 52.6972954461393,
    "Math Score": 34.894259818731115,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.78326186944198
  },
  {
    "Model Name": "prithivMLmods/Phi-4-Super-1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.871196147548961,
    "Overall Score": 30.230266805569844,
    "MMLU Score": 47.05784574468086,
    "BBH Score": 52.905830976180994,
    "Math Score": 35.196374622356494,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.155584140747518
  },
  {
    "Model Name": "prithivMLmods/Phi-4-Super-o1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9283047003225893,
    "Overall Score": 30.230266805569844,
    "MMLU Score": 47.05784574468086,
    "BBH Score": 52.905830976180994,
    "Math Score": 35.196374622356494,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.677121359768803
  },
  {
    "Model Name": "prithivMLmods/Phi-4-o1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7381666316866269,
    "Overall Score": 30.20428963456544,
    "MMLU Score": 46.3744828605201,
    "BBH Score": 52.17086167586282,
    "Math Score": 39.95468277945619,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.37709669714276
  },
  {
    "Model Name": "prithivMLmods/Phi4-Super",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.837064032587418,
    "Overall Score": 30.387370956217424,
    "MMLU Score": 47.399527186761226,
    "BBH Score": 52.6972954461393,
    "Math Score": 34.894259818731115,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.54126933910858
  },
  {
    "Model Name": "prithivMLmods/Porpoise-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9288978684249287,
    "Overall Score": 41.769424398512,
    "MMLU Score": 48.84936465721041,
    "BBH Score": 49.94661296400096,
    "Math Score": 40.40785498489426,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.6545546979216
  },
  {
    "Model Name": "prithivMLmods/Primal-Opus-14B-Optimus-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.978810658535159,
    "Overall Score": 36.0644115881976,
    "MMLU Score": 47.325650118203306,
    "BBH Score": 48.27170322245717,
    "Math Score": 33.8368580060423,
    "Date Submitted": "2025-02-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.064118572929301
  },
  {
    "Model Name": "prithivMLmods/Primal-Opus-14B-Optimus-v2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9402900939156489,
    "Overall Score": 40.91271332337514,
    "MMLU Score": 49.13563829787233,
    "BBH Score": 50.1813442955816,
    "Math Score": 42.06948640483384,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.085874453345404
  },
  {
    "Model Name": "prithivMLmods/QwQ-LCoT-14B-Conversational",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.908904000886237,
    "Overall Score": 35.68306678902542,
    "MMLU Score": 47.538046690307326,
    "BBH Score": 45.62626030965493,
    "Math Score": 46.52567975830816,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.128662863282203
  },
  {
    "Model Name": "prithivMLmods/QwQ-LCoT-3B-Instruct",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.530787238010945,
    "Overall Score": 24.021306557737763,
    "MMLU Score": 28.690159574468087,
    "BBH Score": 26.621187622268376,
    "Math Score": 28.24773413897281,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.692126221897606
  },
  {
    "Model Name": "prithivMLmods/QwQ-LCoT-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3006094039639229,
    "Overall Score": 30.863799774866248,
    "MMLU Score": 37.04750295508275,
    "BBH Score": 34.780933423406445,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.730260353955096
  },
  {
    "Model Name": "prithivMLmods/QwQ-LCoT1-Merged",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3107590394812034,
    "Overall Score": 30.445290905975668,
    "MMLU Score": 37.30607269503546,
    "BBH Score": 35.166254489441975,
    "Math Score": 37.31117824773414,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 23.227221776800313
  },
  {
    "Model Name": "prithivMLmods/QwQ-LCoT2-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.051162302795652,
    "Overall Score": 30.32393037570108,
    "MMLU Score": 37.1306146572104,
    "BBH Score": 34.366736926024,
    "Math Score": 32.703927492447136,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.78377909654969
  },
  {
    "Model Name": "prithivMLmods/QwQ-MathOct-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3290464565624656,
    "Overall Score": 28.497758657229426,
    "MMLU Score": 37.00132978723404,
    "BBH Score": 35.254667256728304,
    "Math Score": 29.531722054380666,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.44225923519478
  },
  {
    "Model Name": "prithivMLmods/QwQ-R1-Distill-1.5B-CoT",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1748323105540768,
    "Overall Score": 13.93165110675273,
    "MMLU Score": 10.14701536643026,
    "BBH Score": 11.476456072950835,
    "Math Score": 33.45921450151057,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.858416713260343
  },
  {
    "Model Name": "prithivMLmods/QwQ-R1-Distill-7B-CoT",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3422405283085903,
    "Overall Score": 22.192243475184284,
    "MMLU Score": 20.04654255319149,
    "BBH Score": 20.95383106545541,
    "Math Score": 46.82779456193353,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.533730733901766
  },
  {
    "Model Name": "prithivMLmods/Qwen-7B-Distill-Reasoner",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3208078435703543,
    "Overall Score": 21.484736250167103,
    "MMLU Score": 20.203531323877066,
    "BBH Score": 22.175998122509004,
    "Math Score": 39.50151057401813,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.266360284544067
  },
  {
    "Model Name": "prithivMLmods/Qwen2.5-1.5B-DeepSeek-R1-Instruct",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2216157349184231,
    "Overall Score": 4.0677302519478,
    "MMLU Score": 1.3648788416075646,
    "BBH Score": 1.3610670095980737,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.3297952340303096
  },
  {
    "Model Name": "prithivMLmods/Qwen2.5-14B-DeepSeek-R1-1M",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.192776144696271,
    "Overall Score": 34.33386526785314,
    "MMLU Score": 43.32705378250591,
    "BBH Score": 40.75990957906041,
    "Math Score": 51.283987915407856,
    "Date Submitted": "2025-02-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.544179938953222
  },
  {
    "Model Name": "prithivMLmods/Qwen2.5-7B-DeepSeek-R1-1M",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3227817770235382,
    "Overall Score": 5.383076380804261,
    "MMLU Score": 2.23293439716312,
    "BBH Score": 4.665734765589359,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.069512049763044
  },
  {
    "Model Name": "prithivMLmods/SmolLM2-CoT-360M",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7755030844116371,
    "Overall Score": 5.950748387139655,
    "MMLU Score": 0.9493203309692664,
    "BBH Score": 4.801205481265894,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.673403893234547
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Elite5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.575029306614382,
    "Overall Score": 42.32332845547639,
    "MMLU Score": 46.669991134751776,
    "BBH Score": 50.17464726204971,
    "Math Score": 53.54984894259819,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.87145456769492
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Elite6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.495364629769308,
    "Overall Score": 41.88084511903062,
    "MMLU Score": 48.77548758865248,
    "BBH Score": 49.59519138828582,
    "Math Score": 40.78549848942598,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.981824374584555
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Sm1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.814819480880796,
    "Overall Score": 39.22381959796,
    "MMLU Score": 45.829639479905445,
    "BBH Score": 47.03125392036906,
    "Math Score": 56.64652567975831,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.613069515279445
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Sm2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7291170921733865,
    "Overall Score": 38.980475230049855,
    "MMLU Score": 48.27681737588653,
    "BBH Score": 51.25185799428797,
    "Math Score": 48.6404833836858,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.543571749125423
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Sm4",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7262493749468515,
    "Overall Score": 39.38545109416284,
    "MMLU Score": 47.778147163120565,
    "BBH Score": 51.15996014172698,
    "Math Score": 48.79154078549849,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.815620770536388
  },
  {
    "Model Name": "prithivMLmods/Sombrero-Opus-14B-Sm5",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9383475014210545,
    "Overall Score": 41.113179800786455,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 50.59600634041891,
    "Math Score": 40.93655589123867,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.210427836414926
  },
  {
    "Model Name": "prithivMLmods/Sqweeks-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0052051096519468,
    "Overall Score": 23.92065941810032,
    "MMLU Score": 23.703457446808507,
    "BBH Score": 24.982149693508465,
    "Math Score": 51.43504531722054,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 11.92928309575889
  },
  {
    "Model Name": "prithivMLmods/Tadpole-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0833767582436806,
    "Overall Score": 36.8786925782139,
    "MMLU Score": 48.02748226950354,
    "BBH Score": 47.77876442051519,
    "Math Score": 31.344410876132933,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.701403470250487
  },
  {
    "Model Name": "prithivMLmods/Taurus-Opus-7B",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3636199514034044,
    "Overall Score": 25.88865048007519,
    "MMLU Score": 32.790336879432616,
    "BBH Score": 34.23401639666226,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.98523885150787
  },
  {
    "Model Name": "prithivMLmods/Triangulum-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7188278372236376,
    "Overall Score": 28.30066565051636,
    "MMLU Score": 35.311391843971634,
    "BBH Score": 42.24074650996805,
    "Math Score": 35.49848942598187,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.465096176374146
  },
  {
    "Model Name": "prithivMLmods/Triangulum-5B",
    "Parameters (B)": 5.413,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9848582640288246,
    "Overall Score": 4.0117920459317,
    "MMLU Score": 2.482269503546098,
    "BBH Score": 4.293501650120951,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.073471475499833
  },
  {
    "Model Name": "prithivMLmods/Triangulum-v2-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.815262165506309,
    "Overall Score": 32.83383929882561,
    "MMLU Score": 38.5158096926714,
    "BBH Score": 42.75472604416384,
    "Math Score": 24.47129909365559,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.08765693613609
  },
  {
    "Model Name": "prithivMLmods/Tucana-Opus-14B-r999",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.99542266892318,
    "Overall Score": 39.75066582236797,
    "MMLU Score": 48.71084515366431,
    "BBH Score": 50.5867616437716,
    "Math Score": 40.6344410876133,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.92092524628841
  },
  {
    "Model Name": "prithivMLmods/Tulu-MathLingo-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.683147873413241,
    "Overall Score": 21.79779228784994,
    "MMLU Score": 22.715351654846337,
    "BBH Score": 24.70335071867501,
    "Math Score": 14.501510574018129,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.950610360601523
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-7B-Elite14",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6799435661327026,
    "Overall Score": 3.487135883248206,
    "MMLU Score": 0.9862588652482256,
    "BBH Score": 1.788971578530402,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.128566629554124
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-Hybrid-v1.2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9555707185530744,
    "Overall Score": 38.82547529143809,
    "MMLU Score": 47.140957446808514,
    "BBH Score": 48.286401555658045,
    "Math Score": 33.30815709969788,
    "Date Submitted": "2025-02-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.85378228620903
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-Hybrid-v1.3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7981105929281844,
    "Overall Score": 40.41199336479261,
    "MMLU Score": 45.524896572104026,
    "BBH Score": 49.614467306055566,
    "Math Score": 45.16616314199396,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.474698454994666
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-HybridMini-v1.3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6595156291478043,
    "Overall Score": 33.800748621674735,
    "MMLU Score": 37.24143026004728,
    "BBH Score": 33.666954037290026,
    "Math Score": 46.299093655589125,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 51.250868255162516
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-v0.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.3489197291447272,
    "Overall Score": 31.99646602214953,
    "MMLU Score": 32.5317671394799,
    "BBH Score": 44.62725748233725,
    "Math Score": 32.703927492447136,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.55426484059713
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-v1.1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8163804285158245,
    "Overall Score": 40.26026084781071,
    "MMLU Score": 47.02090721040189,
    "BBH Score": 49.268009957854,
    "Math Score": 54.607250755287005,
    "Date Submitted": "2025-02-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.165103860267653
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-v1.6-r999",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7538858337264824,
    "Overall Score": 40.588383013145055,
    "MMLU Score": 47.02090721040189,
    "BBH Score": 49.268009957854,
    "Math Score": 56.57099697885196,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.14197551097547
  },
  {
    "Model Name": "prithivMLmods/Viper-Coder-v1.7-Vsm6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.631943501432983,
    "Overall Score": 38.68288111891892,
    "MMLU Score": 47.63962765957447,
    "BBH Score": 49.533250464441856,
    "Math Score": 46.45015105740181,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.70356638263035
  },
  {
    "Model Name": "prithivMLmods/Viper-OneCoder-UIGEN",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.964400686121954,
    "Overall Score": 31.347294081128084,
    "MMLU Score": 32.263962765957444,
    "BBH Score": 42.73215347452439,
    "Math Score": 38.670694864048336,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.957688419979496
  },
  {
    "Model Name": "prithivMLmods/Volans-Opus-14B-Exp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.064902332390804,
    "Overall Score": 39.70707475125064,
    "MMLU Score": 48.72007978723404,
    "BBH Score": 49.91426652749493,
    "Math Score": 42.522658610271904,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.229517119716085
  },
  {
    "Model Name": "prithivMLmods/WebMind-7B-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2121225411059522,
    "Overall Score": 30.8050473229056,
    "MMLU Score": 36.4380171394799,
    "BBH Score": 35.064291045796445,
    "Math Score": 36.48036253776435,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 25.41413617702281
  },
  {
    "Model Name": "pszemraj/Llama-3-6.3b-v0.1",
    "Parameters (B)": 6.3,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.6289265744595216,
    "Overall Score": 10.384306670382523,
    "MMLU Score": 20.44363179669031,
    "BBH Score": 18.67999639960586,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.37493846143927
  },
  {
    "Model Name": "pszemraj/Mistral-v0.3-6B",
    "Parameters (B)": 5.939,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.061078907867203,
    "Overall Score": 10.122379227914848,
    "MMLU Score": 12.695774231678486,
    "BBH Score": 13.51509134454944,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.539704495927737
  },
  {
    "Model Name": "qingy2019/LLaMa_3.2_3B_Catalysts",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.299667653455569,
    "Overall Score": 19.930930685006384,
    "MMLU Score": 22.30902777777777,
    "BBH Score": 21.345400954820075,
    "Math Score": 12.915407854984895,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.335405656987641
  },
  {
    "Model Name": "qingy2019/OpenMath2-Llama3.1-8B",
    "Parameters (B)": 8.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.385612947044763,
    "Overall Score": 12.751664730325508,
    "MMLU Score": 6.148419030732861,
    "BBH Score": 16.294369976218587,
    "Math Score": 26.73716012084592,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.202905297270984
  },
  {
    "Model Name": "qingy2019/Oracle-14B",
    "Parameters (B)": 13.668,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3930241047147078,
    "Overall Score": 13.340250056368255,
    "MMLU Score": 15.355348699763594,
    "BBH Score": 23.18463030799016,
    "Math Score": 6.419939577039275,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.57646749343246
  },
  {
    "Model Name": "qingy2019/Oracle-14B",
    "Parameters (B)": 13.668,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7377749955379205,
    "Overall Score": 13.593017488054064,
    "MMLU Score": 15.318410165484634,
    "BBH Score": 23.30194605898976,
    "Math Score": 7.250755287009064,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.964987082652239
  },
  {
    "Model Name": "qingy2019/Qwen2.5-Math-14B-Instruct",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.865654563281181,
    "Overall Score": 38.15392351928652,
    "MMLU Score": 48.119828605200944,
    "BBH Score": 47.0170855041099,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.869977488858016
  },
  {
    "Model Name": "qingy2019/Qwen2.5-Math-14B-Instruct",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9718926104780867,
    "Overall Score": 36.380504031909005,
    "MMLU Score": 48.21217494089834,
    "BBH Score": 47.06557227198695,
    "Math Score": 27.64350453172205,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.4495361657086
  },
  {
    "Model Name": "qingy2019/Qwen2.5-Math-14B-Instruct-Alpha",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.7862834271963415,
    "Overall Score": 36.84070516730529,
    "MMLU Score": 48.119828605200944,
    "BBH Score": 47.750107640063504,
    "Math Score": 31.41993957703928,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.730044217684203
  },
  {
    "Model Name": "qingy2019/Qwen2.5-Math-14B-Instruct-Pro",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.3191387960289416,
    "Overall Score": 20.249049077126084,
    "MMLU Score": 28.422355200945624,
    "BBH Score": 33.03690414223814,
    "Math Score": 28.3987915407855,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.100693680346328
  },
  {
    "Model Name": "qingy2019/Qwen2.5-Ultimate-14B-Instruct",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.90417879428474,
    "Overall Score": 29.44018136092509,
    "MMLU Score": 43.65950059101655,
    "BBH Score": 40.58060064469629,
    "Math Score": 28.92749244712991,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.540684715572469
  },
  {
    "Model Name": "qingy2024/Benchmaxx-Llama-3.2-1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3138860847843751,
    "Overall Score": 25.69666706814397,
    "MMLU Score": 1.2540632387706852,
    "BBH Score": 76.69996850001888,
    "Math Score": 48.036253776435046,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 81.86621935087173
  },
  {
    "Model Name": "qingy2024/Eyas-17B-Instruct",
    "Parameters (B)": 17.431,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.571521797678892,
    "Overall Score": 32.566804942732524,
    "MMLU Score": 37.13984929078014,
    "BBH Score": 43.85006553278257,
    "Math Score": 24.69788519637462,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.123843302960457
  },
  {
    "Model Name": "qingy2024/Falcon3-2x10B-MoE-Instruct",
    "Parameters (B)": 18.799,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 4.386573555253281,
    "Overall Score": 35.53368391277467,
    "MMLU Score": 38.03560874704491,
    "BBH Score": 45.07385265905592,
    "Math Score": 27.94561933534744,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.100555813140344
  },
  {
    "Model Name": "qingy2024/Fusion-14B-Instruct",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.247361919434426,
    "Overall Score": 38.09742253326738,
    "MMLU Score": 44.93388002364066,
    "BBH Score": 48.57983591380125,
    "Math Score": 33.68580060422961,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.731806764520593
  },
  {
    "Model Name": "qingy2024/Fusion2-14B-Instruct",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.337331892077327,
    "Overall Score": 35.25779713463195,
    "MMLU Score": 45.00775709219858,
    "BBH Score": 44.76704383085473,
    "Math Score": 31.268882175226587,
    "Date Submitted": "2024-12-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.56466610897536
  },
  {
    "Model Name": "qingy2024/Fusion4-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.645661080723154,
    "Overall Score": 39.55218065222402,
    "MMLU Score": 46.596114066193856,
    "BBH Score": 50.69585563958964,
    "Math Score": 38.82175226586103,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.849110703504682
  },
  {
    "Model Name": "qingy2024/OwO-14B-Instruct",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.629522484161071,
    "Overall Score": 29.28644722085275,
    "MMLU Score": 46.45759456264776,
    "BBH Score": 44.94845230112603,
    "Math Score": 41.616314199395774,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.202296873891447
  },
  {
    "Model Name": "qingy2024/QwEnlarge-16B-Instruct",
    "Parameters (B)": 15.871,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7987979471737134,
    "Overall Score": 37.70013676666704,
    "MMLU Score": 38.617390661938536,
    "BBH Score": 42.5954533547226,
    "Math Score": 45.99697885196375,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.95851667270458
  },
  {
    "Model Name": "qingy2024/QwQ-14B-Math-v0.2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.822342589515159,
    "Overall Score": 28.93541522580025,
    "MMLU Score": 42.21889775413712,
    "BBH Score": 39.09921374295183,
    "Math Score": 48.11178247734139,
    "Date Submitted": "2024-12-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.241272678136879
  },
  {
    "Model Name": "qingy2024/Qwarkstar-4B",
    "Parameters (B)": 4.473,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.234656387692985,
    "Overall Score": 14.167330731742462,
    "MMLU Score": 15.83554964539007,
    "BBH Score": 16.574205111821954,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2025-01-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.339825133638794
  },
  {
    "Model Name": "qingy2024/Qwarkstar-4B-Instruct-Preview",
    "Parameters (B)": 4.473,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.934410461398533,
    "Overall Score": 18.87300966250048,
    "MMLU Score": 16.694370567375884,
    "BBH Score": 20.23401722066339,
    "Math Score": 12.83987915407855,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.756465878940574
  },
  {
    "Model Name": "qingy2024/Qwen2.5-4B",
    "Parameters (B)": 4.168,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.919529501444422,
    "Overall Score": 14.27535656814343,
    "MMLU Score": 16.943705673758867,
    "BBH Score": 19.977752146023,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.436903969124414
  },
  {
    "Model Name": "qingy2024/Qwen2.5-Coder-Draft-1.5B-Instruct",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1199516994910768,
    "Overall Score": 14.636502505800076,
    "MMLU Score": 13.82239952718676,
    "BBH Score": 13.001065842415562,
    "Math Score": 15.78549848942598,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.068869409681799
  },
  {
    "Model Name": "qingy2024/Qwen2.5-Math-14B-Instruct-Alpha",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.138693243209943,
    "Overall Score": 39.35285681111407,
    "MMLU Score": 44.065824468085104,
    "BBH Score": 50.1795027462589,
    "Math Score": 42.90030211480362,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.537974807269757
  },
  {
    "Model Name": "qingy2024/Qwen2.5-Math-14B-Instruct-Preview",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.237960654243049,
    "Overall Score": 39.91810674601417,
    "MMLU Score": 44.37056737588653,
    "BBH Score": 47.050807568284256,
    "Math Score": 47.583081570996974,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.328163003989925
  },
  {
    "Model Name": "qingy2024/Qwen2.6-14B-Instruct",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5785724883461816,
    "Overall Score": 36.25438494517895,
    "MMLU Score": 47.611923758865245,
    "BBH Score": 48.04794799002712,
    "Math Score": 30.513595166163142,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.130962852713855
  },
  {
    "Model Name": "qingy2024/Qwen2.6-Math-14B-Instruct",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.112143161139537,
    "Overall Score": 35.19645398109978,
    "MMLU Score": 47.12248817966904,
    "BBH Score": 47.02211721984639,
    "Math Score": 42.90030211480362,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.309394252998409
  },
  {
    "Model Name": "qq8933/OpenLongCoT-Base-Gemma2-2B",
    "Parameters (B)": 3.204,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.316973334195197,
    "Overall Score": 5.473141918546371,
    "MMLU Score": 3.507313829787232,
    "BBH Score": 3.546298466806123,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.6500409762487072
  },
  {
    "Model Name": "raphgg/test-2.5-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 44.86470543487947,
    "Overall Score": 46.73987796559809,
    "MMLU Score": 53.74372044917257,
    "BBH Score": 62.1541268705062,
    "Math Score": 41.08761329305136,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.0417961627640777
  },
  {
    "Model Name": "rasyosef/Mistral-NeMo-Minitron-8B-Chat",
    "Parameters (B)": 8.414,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9527959021153043,
    "Overall Score": 17.54564856271941,
    "MMLU Score": 15.595449172576831,
    "BBH Score": 26.036695387358723,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-08-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.9420458251619
  },
  {
    "Model Name": "rasyosef/Phi-1_5-Instruct-v0.1",
    "Parameters (B)": 1.415,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5900438699202877,
    "Overall Score": 6.864747864349624,
    "MMLU Score": 6.240765366430259,
    "BBH Score": 4.820243721122045,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-07-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.634300794069807
  },
  {
    "Model Name": "rasyosef/phi-2-instruct-apo",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9901298108291215,
    "Overall Score": 12.547052522669906,
    "MMLU Score": 12.834293735224584,
    "BBH Score": 21.672437586715603,
    "Math Score": 3.0211480362537766,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.672128831433902
  },
  {
    "Model Name": "rasyosef/phi-2-instruct-v0.1",
    "Parameters (B)": 2.775,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.4927260763011659,
    "Overall Score": 14.218631101919176,
    "MMLU Score": 13.85010342789598,
    "BBH Score": 26.35880186790661,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 28.857070461252412
  },
  {
    "Model Name": "realtreetune/rho-1b-sft-MATH",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5562682251492022,
    "Overall Score": 5.569175419988618,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 4.19762318329166,
    "Math Score": 3.474320241691843,
    "Date Submitted": "2024-10-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.011672729455029
  },
  {
    "Model Name": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.114373144767299,
    "Overall Score": 29.873991757144,
    "MMLU Score": 35.63460401891253,
    "BBH Score": 42.25120987807252,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 14.129006429672485
  },
  {
    "Model Name": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.939655062300775,
    "Overall Score": 23.910552802690432,
    "MMLU Score": 35.13593380614657,
    "BBH Score": 42.70379763449792,
    "Math Score": 10.045317220543806,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.0255793563588655
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.849617432472951,
    "Overall Score": 32.72459862019961,
    "MMLU Score": 35.09899527186761,
    "BBH Score": 42.32186103147748,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.50074044868861
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.2",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9140857936630225,
    "Overall Score": 30.048864030373213,
    "MMLU Score": 35.145168439716315,
    "BBH Score": 43.02796904930725,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.698807299994703
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.2",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.893568841337357,
    "Overall Score": 23.76285134105471,
    "MMLU Score": 34.692671394799056,
    "BBH Score": 43.56058143461737,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.03199690726994
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.3",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.876637213669096,
    "Overall Score": 30.2074720895527,
    "MMLU Score": 34.13859338061466,
    "BBH Score": 42.026279212829245,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.09659654488719
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.3",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.110699417105108,
    "Overall Score": 30.37598877443187,
    "MMLU Score": 33.76920803782505,
    "BBH Score": 43.326868296283614,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-09-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.9436069890484715
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.4",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.837820484416759,
    "Overall Score": 24.138127567307112,
    "MMLU Score": 37.84168144208039,
    "BBH Score": 42.44248167542507,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.134784142770482
  },
  {
    "Model Name": "recoilme/recoilme-gemma-2-9B-v0.5",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 5.791466966555618,
    "Overall Score": 33.229967443633754,
    "MMLU Score": 35.551492316784866,
    "BBH Score": 42.353355406534206,
    "Math Score": 21.148036253776432,
    "Date Submitted": "2024-11-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.737746176491919
  },
  {
    "Model Name": "redrix/AngelSlayer-12B-Unslop-Mell-RPMax-DARKNESS",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.191696575712337,
    "Overall Score": 22.776537692077188,
    "MMLU Score": 24.220596926713945,
    "BBH Score": 29.96593231071532,
    "Math Score": 11.329305135951662,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.392194770242977
  },
  {
    "Model Name": "redrix/patricide-12B-Unslop-Mell",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.05910982261042,
    "Overall Score": 23.021830606105613,
    "MMLU Score": 28.56087470449172,
    "BBH Score": 33.98944760745952,
    "Math Score": 13.141993957703926,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.18047728844296
  },
  {
    "Model Name": "refuelai/Llama-3-Refueled",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.751971666755731,
    "Overall Score": 23.18144830627433,
    "MMLU Score": 23.278664302600472,
    "BBH Score": 41.72197100339103,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.231634247374165
  },
  {
    "Model Name": "rhplus0831/maid-yuzu-v7",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 8.20857064636299,
    "Overall Score": 24.595223175883827,
    "MMLU Score": 28.219193262411352,
    "BBH Score": 26.8198371046094,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2024-09-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.9962857402928424
  },
  {
    "Model Name": "rhymes-ai/Aria",
    "Parameters (B)": 25.307,
    "Architecture": "AriaForConditionalGeneration",
    "Model Type": "游꺚 multimodal",
    "Training CO2 (kg)": 15.501419246428505,
    "Overall Score": 28.87016399525205,
    "MMLU Score": 37.83244680851063,
    "BBH Score": 39.28149335481041,
    "Math Score": 19.335347432024168,
    "Date Submitted": "2024-10-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.8624206942795691
  },
  {
    "Model Name": "rhysjones/phi-2-orange-v2",
    "Parameters (B)": 2.78,
    "Architecture": "PhiForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9418986908083168,
    "Overall Score": 15.324185096371076,
    "MMLU Score": 17.026817375886523,
    "BBH Score": 25.60654883732465,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.269462146953614
  },
  {
    "Model Name": "riaz/FineLlama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.842183161030028,
    "Overall Score": 17.660648060300424,
    "MMLU Score": 21.81959219858156,
    "BBH Score": 24.14877809167861,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.58680354586769
  },
  {
    "Model Name": "riaz/FineLlama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9019979013274062,
    "Overall Score": 17.14751095671923,
    "MMLU Score": 21.976580969267136,
    "BBH Score": 23.77338959053972,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-10-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 19.01058852962347
  },
  {
    "Model Name": "rmdhirr/Gluon-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8061565768916727,
    "Overall Score": 23.97696294457469,
    "MMLU Score": 31.201979905437344,
    "BBH Score": 30.34224724618852,
    "Math Score": 14.425981873111782,
    "Date Submitted": "2024-09-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.275129770774436
  },
  {
    "Model Name": "rombodawg/Rombos-Coder-V2.5-Qwen-14b",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.702802751219327,
    "Overall Score": 32.44560837708102,
    "MMLU Score": 32.661052009456256,
    "BBH Score": 44.51949885999458,
    "Math Score": 33.00604229607251,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.004430720089987
  },
  {
    "Model Name": "rombodawg/Rombos-Coder-V2.5-Qwen-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.243923486028219,
    "Overall Score": 27.40541476830636,
    "MMLU Score": 26.640070921985814,
    "BBH Score": 30.221720429768265,
    "Math Score": 33.383685800604226,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.031431254514203
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-0.5b",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.291413623978558,
    "Overall Score": 9.38591999487923,
    "MMLU Score": 9.620641252955084,
    "BBH Score": 8.412218566269734,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.267942524845989
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-1.5b",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4807159923900013,
    "Overall Score": 16.35438589717866,
    "MMLU Score": 21.35786052009456,
    "BBH Score": 18.711343783972325,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.044917446175004
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-14b",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.365399723221313,
    "Overall Score": 39.50095591766085,
    "MMLU Score": 48.6184988179669,
    "BBH Score": 49.38690027144481,
    "Math Score": 45.54380664652568,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.04864581072368
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-32b",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 35.82537944703887,
    "Overall Score": 45.83301184834238,
    "MMLU Score": 54.62101063829788,
    "BBH Score": 58.26189408678741,
    "Math Score": 49.546827794561935,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.279344770544522
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-3b",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.011588954205996,
    "Overall Score": 25.92178205181336,
    "MMLU Score": 30.67560579196217,
    "BBH Score": 27.21359695112569,
    "Math Score": 27.94561933534744,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.88622210696373
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-72b",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 32.06789125179346,
    "Overall Score": 46.50088713558663,
    "MMLU Score": 54.83340721040189,
    "BBH Score": 61.26714504573664,
    "Math Score": 54.229607250755286,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 1.450076238891635
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5-Qwen-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.634168110912232,
    "Overall Score": 32.74880353587022,
    "MMLU Score": 38.54351359338061,
    "BBH Score": 36.37235041430064,
    "Math Score": 38.14199395770393,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 12.432313412422667
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9292438685729816,
    "Overall Score": 13.357124972053429,
    "MMLU Score": 19.104609929078016,
    "BBH Score": 14.88140918445136,
    "Math Score": 9.138972809667676,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.374186824138704
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b",
    "Parameters (B)": 3.397,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.593723107934581,
    "Overall Score": 13.608595258365549,
    "MMLU Score": 19.34471040189125,
    "BBH Score": 15.057744482096084,
    "Math Score": 12.084592145015106,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.246741726877033
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.6-Nemotron-70b",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 23.901548933707826,
    "Overall Score": 41.94623049260674,
    "MMLU Score": 48.10135933806146,
    "BBH Score": 55.80557342514651,
    "Math Score": 33.30815709969788,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.7549586685342764
  },
  {
    "Model Name": "rombodawg/Rombos-LLM-V2.6-Qwen-14b",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.251570998218114,
    "Overall Score": 42.19934519573359,
    "MMLU Score": 44.01041666666667,
    "BBH Score": 49.27851764033085,
    "Math Score": 52.11480362537765,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.035565968745745
  },
  {
    "Model Name": "rombodawg/rombos_Replete-Coder-Instruct-8b-Merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9282563866341127,
    "Overall Score": 16.433823987631932,
    "MMLU Score": 8.983451536643026,
    "BBH Score": 21.937706578272657,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.522634283254291
  },
  {
    "Model Name": "rombodawg/rombos_Replete-Coder-Llama3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.411204186683609,
    "Overall Score": 11.971032787867795,
    "MMLU Score": 3.719710401891251,
    "BBH Score": 7.087845117845117,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.964752821009678
  },
  {
    "Model Name": "rootxhacker/Apollo-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 15.70960535007151,
    "Overall Score": 43.15901797697317,
    "MMLU Score": 47.54728132387708,
    "BBH Score": 53.528405173016914,
    "Math Score": 56.11782477341389,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 2.747301222100828
  },
  {
    "Model Name": "rootxhacker/Apollo_v2-32B",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 62.07832901657737,
    "Overall Score": 39.81170120905305,
    "MMLU Score": 54.10387115839244,
    "BBH Score": 58.27495148079832,
    "Math Score": 42.74924471299094,
    "Date Submitted": "2025-03-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 0.6413139953947817
  },
  {
    "Model Name": "rootxhacker/apollo-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4688116118963463,
    "Overall Score": 10.721175786000847,
    "MMLU Score": 8.309323286052008,
    "BBH Score": 11.072693643924143,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2025-03-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.299217747985395
  },
  {
    "Model Name": "rsh345/mistral-ft-optimized-1218-NeuralHermes-2.5-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9523481336611324,
    "Overall Score": 21.02740291549346,
    "MMLU Score": 22.81693262411348,
    "BBH Score": 32.78974404613455,
    "Math Score": 7.326283987915408,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 22.079533914407293
  },
  {
    "Model Name": "rubenroy/Geneva-12B-GCv2-5m",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8862036586829911,
    "Overall Score": 16.956630719456832,
    "MMLU Score": 24.9963061465721,
    "BBH Score": 32.64683054938012,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.134011187289044
  },
  {
    "Model Name": "rubenroy/Gilgamesh-72B",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 51.29178285770202,
    "Overall Score": 46.793671661266096,
    "MMLU Score": 53.3558658392435,
    "BBH Score": 61.83602130504769,
    "Math Score": 43.80664652567976,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 0.9123034734644542
  },
  {
    "Model Name": "rubenroy/Zurich-14B-GCv2-5m",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9337617528412068,
    "Overall Score": 37.06368897687889,
    "MMLU Score": 47.030141843971634,
    "BBH Score": 46.7337399544949,
    "Math Score": 30.74018126888218,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.166626355300775
  },
  {
    "Model Name": "ruizhe1217/sft-s1-qwen-0.5b",
    "Parameters (B)": 0.494,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.5358550528471566,
    "Overall Score": 9.240285567836873,
    "MMLU Score": 9.90691489361702,
    "BBH Score": 8.27626354194646,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2025-02-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.244001934367322
  },
  {
    "Model Name": "rwitz/go-bruins-v2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2756394415625334,
    "Overall Score": 15.433967198473246,
    "MMLU Score": 19.56634160756501,
    "BBH Score": 12.69326018768569,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.09900438604199
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-CPO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9544175459260744,
    "Overall Score": 7.303190047047342,
    "MMLU Score": 6.730200945626476,
    "BBH Score": 8.656016246266047,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.651986364061479
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-DPO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8351197963436573,
    "Overall Score": 7.558004575587002,
    "MMLU Score": 6.951832151300234,
    "BBH Score": 9.362230727907605,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.050204064946909
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-IPO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8523306948320086,
    "Overall Score": 7.804715247914783,
    "MMLU Score": 6.859485815602836,
    "BBH Score": 9.019805379879918,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.156909747868538
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-KTO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2560579107691543,
    "Overall Score": 7.882716013659315,
    "MMLU Score": 7.071882387706856,
    "BBH Score": 9.514963942405524,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.275758423297767
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-SPO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8157692025792285,
    "Overall Score": 7.352632078107196,
    "MMLU Score": 8.41090425531915,
    "BBH Score": 7.766130774573562,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.013127799946702
  },
  {
    "Model Name": "sabersaleh/Llama2-7B-SimPO",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9476039241157408,
    "Overall Score": 7.610783251808889,
    "MMLU Score": 7.127290189125294,
    "BBH Score": 8.98121133440231,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.03160799372049
  },
  {
    "Model Name": "sabersaleh/Llama3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3932662824351283,
    "Overall Score": 17.458608830485915,
    "MMLU Score": 24.017434988179662,
    "BBH Score": 26.70679448256402,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-11-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 12.530705042235027
  },
  {
    "Model Name": "sabersalehk/Llama3-001-300",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.399065934688029,
    "Overall Score": 17.12107684025811,
    "MMLU Score": 23.98049645390071,
    "BBH Score": 25.70681935525005,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.237505335354946
  },
  {
    "Model Name": "sabersalehk/Llama3-SimPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4053791547614594,
    "Overall Score": 18.71609771417637,
    "MMLU Score": 23.96202718676123,
    "BBH Score": 27.44856194235693,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-12-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 13.317472121858197
  },
  {
    "Model Name": "sabersalehk/Llama3_001_200",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4521678393056572,
    "Overall Score": 17.287940552816096,
    "MMLU Score": 24.257535460992905,
    "BBH Score": 25.62556750692528,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.904919035448541
  },
  {
    "Model Name": "sabersalehk/Llama3_01_300",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4485430669659736,
    "Overall Score": 16.69882386756007,
    "MMLU Score": 23.60187647754137,
    "BBH Score": 25.1552501785412,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-12-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.528013386951875
  },
  {
    "Model Name": "saishf/Fimbulvetr-Kuro-Lotus-10.7B",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6183371562566071,
    "Overall Score": 20.67786715826612,
    "MMLU Score": 26.547724586288417,
    "BBH Score": 19.90882095261725,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-07-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.777230676762262
  },
  {
    "Model Name": "saishf/Neural-SOVLish-Devil-8B-L3",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3797564443562462,
    "Overall Score": 21.691330731173803,
    "MMLU Score": 31.19274527186761,
    "BBH Score": 30.100237081099607,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.721130218235247
  },
  {
    "Model Name": "saishshinde15/TethysAI_Base_Reasoning",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7359453000675985,
    "Overall Score": 26.35483902520761,
    "MMLU Score": 24.848552009456267,
    "BBH Score": 23.59750296433112,
    "Math Score": 31.41993957703928,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 35.81086668097051
  },
  {
    "Model Name": "saishshinde15/TethysAI_Vortex",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7435275277874127,
    "Overall Score": 24.80337280546497,
    "MMLU Score": 24.894725177304963,
    "BBH Score": 26.91431404565564,
    "Math Score": 31.49546827794562,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 33.359051115800355
  },
  {
    "Model Name": "saishshinde15/TethysAI_Vortex_Reasoning",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7884395573169932,
    "Overall Score": 21.791497955306028,
    "MMLU Score": 26.455378250591018,
    "BBH Score": 25.73813775767069,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.638767934806605
  },
  {
    "Model Name": "sakaltcommunity/novablast-preview",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 11.262021345541967,
    "Overall Score": 41.51641804260023,
    "MMLU Score": 54.61177600472813,
    "BBH Score": 58.18215998102389,
    "Math Score": 48.94259818731118,
    "Date Submitted": "2024-12-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.6864091062155873
  },
  {
    "Model Name": "sakaltcommunity/sakaltum-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9443037628768556,
    "Overall Score": 13.528323522415516,
    "MMLU Score": 19.65868794326241,
    "BBH Score": 23.75264450329209,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.326241252286222
  },
  {
    "Model Name": "sakhan10/quantized_open_llama_3b_v2",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7854007472075212,
    "Overall Score": 5.142500028294101,
    "MMLU Score": 1.0601359338061456,
    "BBH Score": 2.805733273363854,
    "Math Score": 0.0,
    "Date Submitted": "2024-08-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 6.547612854428992
  },
  {
    "Model Name": "saltlux/luxia-21.4b-alignment-v1.0",
    "Parameters (B)": 21.421,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.4880949208019976,
    "Overall Score": 23.45457393678268,
    "MMLU Score": 26.70471335697399,
    "BBH Score": 48.02111296160791,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.724178805142695
  },
  {
    "Model Name": "saltlux/luxia-21.4b-alignment-v1.2",
    "Parameters (B)": 21.421,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.091851552468708,
    "Overall Score": 24.58071047593133,
    "MMLU Score": 27.480422576832154,
    "BBH Score": 47.76916471884749,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-07-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.0072341727796115
  },
  {
    "Model Name": "sam-paech/Darkest-muse-v1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.413894532223269,
    "Overall Score": 33.447324199858144,
    "MMLU Score": 35.37603427895981,
    "BBH Score": 42.61173126837064,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.577735253001345
  },
  {
    "Model Name": "sam-paech/Delirium-v1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.791002491828395,
    "Overall Score": 33.09183474861921,
    "MMLU Score": 35.44067671394799,
    "BBH Score": 42.31507908993327,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.907079427543847
  },
  {
    "Model Name": "sam-paech/Quill-v1",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.626938213438511,
    "Overall Score": 33.06394735308967,
    "MMLU Score": 35.237514775413715,
    "BBH Score": 42.59766913903588,
    "Math Score": 21.22356495468278,
    "Date Submitted": "2024-10-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.145966906810752
  },
  {
    "Model Name": "sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "Parameters (B)": 6.87,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.036453945253264,
    "Overall Score": 6.3386943375795655,
    "MMLU Score": 6.03760342789598,
    "BBH Score": 7.645606515056556,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.1157510824377885
  },
  {
    "Model Name": "schnapss/testmerge-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9403094349551654,
    "Overall Score": 20.91344608482232,
    "MMLU Score": 22.89080969267139,
    "BBH Score": 32.63816624149671,
    "Math Score": 6.873111782477341,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 22.241025461814584
  },
  {
    "Model Name": "sci-m-wang/Mistral-7B-Instruct-sa-v0.1",
    "Parameters (B)": 14.483,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5301646187834628,
    "Overall Score": 12.263004871086814,
    "MMLU Score": 15.133717494089836,
    "BBH Score": 5.743646077429951,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.014173586653934
  },
  {
    "Model Name": "sci-m-wang/Phi-3-mini-4k-instruct-sa-v0.1",
    "Parameters (B)": 7.642,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.5610053501203294,
    "Overall Score": 25.82414451642259,
    "MMLU Score": 33.16895685579196,
    "BBH Score": 36.605419148768114,
    "Math Score": 14.803625377643504,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.083596473240181
  },
  {
    "Model Name": "sci-m-wang/deepseek-llm-7b-chat-sa-v0.1",
    "Parameters (B)": 7.0,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9831480049623813,
    "Overall Score": 13.208049800984782,
    "MMLU Score": 13.434544917257682,
    "BBH Score": 12.05197465522808,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.660143251000234
  },
  {
    "Model Name": "securin/Securin-LLM-V2.5-Qwen-1.5B",
    "Parameters (B)": 1.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.20957081758515,
    "Overall Score": 5.2256798816861005,
    "MMLU Score": 6.831781914893617,
    "BBH Score": 4.863456136709561,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-12-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.320276089430562
  },
  {
    "Model Name": "senseable/WestLake-7B-v2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2620225825867748,
    "Overall Score": 16.257065193895503,
    "MMLU Score": 19.60328014184397,
    "BBH Score": 17.858141685089326,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 12.881754588395166
  },
  {
    "Model Name": "sequelbox/Llama3.1-70B-PlumChat",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 65.54413523224211,
    "Overall Score": 37.409205844366646,
    "MMLU Score": 46.26366725768322,
    "BBH Score": 52.81275213512472,
    "Math Score": 30.28700906344411,
    "Date Submitted": "2024-11-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 0.5707483318196944
  },
  {
    "Model Name": "sequelbox/Llama3.1-8B-MOTH",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9292739771594416,
    "Overall Score": 20.83650360825358,
    "MMLU Score": 25.98441193853428,
    "BBH Score": 27.91633224536528,
    "Math Score": 12.16012084592145,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.113197253218025
  },
  {
    "Model Name": "sequelbox/Llama3.1-8B-PlumChat",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.9785137872324547,
    "Overall Score": 13.214730095703656,
    "MMLU Score": 12.520316193853429,
    "BBH Score": 13.935991387298124,
    "Math Score": 3.625377643504532,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.679119539615855
  },
  {
    "Model Name": "sequelbox/Llama3.1-8B-PlumCode",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7813524957950064,
    "Overall Score": 9.82399989942098,
    "MMLU Score": 14.838209219858156,
    "BBH Score": 8.502927271642019,
    "Math Score": 2.719033232628399,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.51491067748306
  },
  {
    "Model Name": "sequelbox/Llama3.1-8B-PlumMath",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7375443764930234,
    "Overall Score": 13.936685074512214,
    "MMLU Score": 21.94887706855792,
    "BBH Score": 16.44658382894578,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.020908854507276
  },
  {
    "Model Name": "sequelbox/gemma-2-9B-MOTH",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 6.0558978861492285,
    "Overall Score": 4.729557867247653,
    "MMLU Score": 1.5588061465721037,
    "BBH Score": 3.2122172300496232,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-09-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.7809837543768499
  },
  {
    "Model Name": "sethuiyer/Llama-3.1-8B-Experimental-1206-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.370784422238238,
    "Overall Score": 25.684511231135144,
    "MMLU Score": 28.09914302600473,
    "BBH Score": 30.055034247108825,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.737090102904055
  },
  {
    "Model Name": "sethuiyer/Llama-3.1-8B-Experimental-1208-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5135607022091058,
    "Overall Score": 23.509819826801674,
    "MMLU Score": 27.89598108747045,
    "BBH Score": 29.491580809437377,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2025-01-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 15.53278952901466
  },
  {
    "Model Name": "sethuiyer/LlamaZero-3.1-8B-Experimental-1208",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.7465946737584666,
    "Overall Score": 21.958507942267545,
    "MMLU Score": 22.21668144208038,
    "BBH Score": 28.61268788658586,
    "Math Score": 10.80060422960725,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.57218304405762
  },
  {
    "Model Name": "sethuiyer/Llamaverse-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4322133247968185,
    "Overall Score": 26.19209991300966,
    "MMLU Score": 28.034500591016545,
    "BBH Score": 34.78211812089758,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.28784822730609
  },
  {
    "Model Name": "sethuiyer/Llamazing-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.620574710742619,
    "Overall Score": 23.606046468554243,
    "MMLU Score": 28.95796394799054,
    "BBH Score": 32.850609039112555,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.007965455739576
  },
  {
    "Model Name": "sethuiyer/Qwen2.5-7B-Anvita",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.1602466244661174,
    "Overall Score": 29.89836212098824,
    "MMLU Score": 35.172872340425535,
    "BBH Score": 35.482447523885746,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.8402540628329
  },
  {
    "Model Name": "shadowml/BeagSake-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.078669899162654,
    "Overall Score": 19.000757229169064,
    "MMLU Score": 17.608599290780138,
    "BBH Score": 25.19294464311316,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.658567057135439
  },
  {
    "Model Name": "shadowml/Mixolar-4x7b",
    "Parameters (B)": 36.099,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.709455400650262,
    "Overall Score": 20.2526965254598,
    "MMLU Score": 25.615026595744684,
    "BBH Score": 32.728963576299655,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 4.300432810694713
  },
  {
    "Model Name": "shastraai/Shastra-LLAMA2-Math-Commonsense-SFT",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5280844722045834,
    "Overall Score": 10.49075907778522,
    "MMLU Score": 11.079713356973992,
    "BBH Score": 13.659523241343653,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.865300491307325
  },
  {
    "Model Name": "shivam9980/NEPALI-LLM",
    "Parameters (B)": 10.273,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 14.370848641479697,
    "Overall Score": 6.93055339969496,
    "MMLU Score": 11.827718676122933,
    "BBH Score": 13.12524427731519,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 0.48226472719855706
  },
  {
    "Model Name": "shivam9980/mistral-7b-news-cnn-merged",
    "Parameters (B)": 7.723,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.188185330941949,
    "Overall Score": 17.196276123590845,
    "MMLU Score": 20.305112293144205,
    "BBH Score": 11.146535574656042,
    "Math Score": 1.8882175226586104,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.393750468863179
  },
  {
    "Model Name": "shivank21/mistral_dpo_self",
    "Parameters (B)": 7.913,
    "Architecture": null,
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.2630629848127213,
    "Overall Score": 9.824435617463962,
    "MMLU Score": 13.48995271867612,
    "BBH Score": 5.548411533266127,
    "Math Score": 2.190332326283988,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.3412117485881545
  },
  {
    "Model Name": "shuttleai/shuttle-3",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 47.04132341607627,
    "Overall Score": 46.70460730741495,
    "MMLU Score": 52.40469858156028,
    "BBH Score": 64.05301565117443,
    "Math Score": 45.99697885196375,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 0.9928421208373946
  },
  {
    "Model Name": "shyamieee/Padma-v7.0",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.1797979554990508,
    "Overall Score": 19.75621841010717,
    "MMLU Score": 22.549128250591018,
    "BBH Score": 31.65752076487425,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.745425195918695
  },
  {
    "Model Name": "silma-ai/SILMA-9B-Instruct-v1.0",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.4919978285857622,
    "Overall Score": 26.308011915634108,
    "MMLU Score": 32.439420803782504,
    "BBH Score": 30.71300262979214,
    "Math Score": 11.63141993957704,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.556996323935085
  },
  {
    "Model Name": "silma-ai/SILMA-Kashif-2B-Instruct-v1.0",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.3874880242826424,
    "Overall Score": 8.452456221236272,
    "MMLU Score": 13.979388297872342,
    "BBH Score": 12.844188209052897,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.540313557709234
  },
  {
    "Model Name": "siqi00/Mistral-7B-DFT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8755216987960303,
    "Overall Score": 20.75522180931725,
    "MMLU Score": 21.81035756501182,
    "BBH Score": 25.36449938722728,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.70611926335886
  },
  {
    "Model Name": "siqi00/Mistral-7B-DFT2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4011048354206313,
    "Overall Score": 19.8755968493133,
    "MMLU Score": 20.582151300236408,
    "BBH Score": 15.39381048021219,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 49.55212476675861
  },
  {
    "Model Name": "skumar9/Llama-medx_v2",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.019959966821536,
    "Overall Score": 19.88386236667153,
    "MMLU Score": 27.369606973995275,
    "BBH Score": 27.423041996880624,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.843691307387319
  },
  {
    "Model Name": "skymizer/Llama2-7b-sft-chat-custom-template-dpo",
    "Parameters (B)": 6.738,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2329408833483786,
    "Overall Score": 10.140548181946365,
    "MMLU Score": 10.51640070921986,
    "BBH Score": 11.238865074478818,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-07-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 8.224683209795923
  },
  {
    "Model Name": "someon98/qwen-CoMa-0.5b",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0183575110985603,
    "Overall Score": 5.858059919414088,
    "MMLU Score": 1.0970744680851066,
    "BBH Score": 2.126793919588037,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.752459087864599
  },
  {
    "Model Name": "sometimesanotion/ChocoTrio-14B-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8457620800763928,
    "Overall Score": 41.158305672336745,
    "MMLU Score": 48.55385638297872,
    "BBH Score": 50.01329228044157,
    "Math Score": 39.72809667673716,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.298814195290692
  },
  {
    "Model Name": "sometimesanotion/IF-reasoning-experiment-40",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.809917598536154,
    "Overall Score": 38.780695768343925,
    "MMLU Score": 44.72148345153664,
    "BBH Score": 44.30640768056546,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.178880452229265
  },
  {
    "Model Name": "sometimesanotion/IF-reasoning-experiment-80",
    "Parameters (B)": 7.383,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.773964867048081,
    "Overall Score": 22.64532031474884,
    "MMLU Score": 26.30762411347517,
    "BBH Score": 17.482339572802207,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 6.000405703951757
  },
  {
    "Model Name": "sometimesanotion/KytheraMix-7B-v0.2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.381778506653468,
    "Overall Score": 32.38407922772431,
    "MMLU Score": 38.949837470449175,
    "BBH Score": 37.50149964913648,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.43651972569422
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.1-experimental",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.789386756229194,
    "Overall Score": 37.55216413847084,
    "MMLU Score": 48.97864952718677,
    "BBH Score": 50.79490766919466,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.909826194631787
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.590061110558608,
    "Overall Score": 36.853034263826295,
    "MMLU Score": 49.00635342789597,
    "BBH Score": 51.27430858821048,
    "Math Score": 34.06344410876133,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.842836227941373
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.4-Qwenvergence",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4825269957712743,
    "Overall Score": 36.62014600012022,
    "MMLU Score": 48.96018026004729,
    "BBH Score": 50.20804499847927,
    "Math Score": 33.987915407854985,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.515394724746411
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.6",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.84476948734033,
    "Overall Score": 41.16744391023699,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 49.29789462939962,
    "Math Score": 40.40785498489426,
    "Date Submitted": "2025-01-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.707389362558407
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.6-002-model_stock",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.775851332590963,
    "Overall Score": 39.457579354747615,
    "MMLU Score": 45.04469562647754,
    "BBH Score": 45.00658355961355,
    "Math Score": 37.764350453172206,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.449982236899167
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.6-model_stock",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.723278579007773,
    "Overall Score": 40.67608193287934,
    "MMLU Score": 46.64228723404256,
    "BBH Score": 46.491326082885486,
    "Math Score": 42.44712990936556,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.924802178976151
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.7-Fusion",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.515341471959302,
    "Overall Score": 41.68165196521005,
    "MMLU Score": 48.78472222222222,
    "BBH Score": 50.42650008400056,
    "Math Score": 40.40785498489426,
    "Date Submitted": "2025-02-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.557401872055406
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.7-rc1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8975613656159886,
    "Overall Score": 41.14125262846636,
    "MMLU Score": 49.06176122931441,
    "BBH Score": 49.50816072696898,
    "Math Score": 38.51963746223565,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.555639480474019
  },
  {
    "Model Name": "sometimesanotion/Lamarck-14B-v0.7-rc4",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8324623578695967,
    "Overall Score": 41.79013452973212,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 49.854949919143934,
    "Math Score": 40.25679758308157,
    "Date Submitted": "2025-01-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.90425179099804
  },
  {
    "Model Name": "sometimesanotion/LamarckInfusion-14B-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.981689278019317,
    "Overall Score": 42.05767311482166,
    "MMLU Score": 48.62773345153664,
    "BBH Score": 50.34764346772722,
    "Math Score": 41.69184290030212,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 21.22314208454414
  },
  {
    "Model Name": "sometimesanotion/LamarckInfusion-14B-v2",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8852153316741096,
    "Overall Score": 42.11094293951407,
    "MMLU Score": 49.07099586288417,
    "BBH Score": 50.84149099483824,
    "Math Score": 43.8821752265861,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.337471073990628
  },
  {
    "Model Name": "sometimesanotion/LamarckInfusion-14B-v2-hi",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9025659110395232,
    "Overall Score": 41.509609454034056,
    "MMLU Score": 48.94171099290781,
    "BBH Score": 50.65842470890095,
    "Math Score": 42.296072507552864,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.817698516081396
  },
  {
    "Model Name": "sometimesanotion/LamarckInfusion-14B-v2-lo",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8154785258852453,
    "Overall Score": 41.58407798423975,
    "MMLU Score": 48.85859929078014,
    "BBH Score": 50.25299157009956,
    "Math Score": 42.37160120845921,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.90529873602495
  },
  {
    "Model Name": "sometimesanotion/LamarckInfusion-14B-v3",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.948833045177632,
    "Overall Score": 41.58315666578661,
    "MMLU Score": 48.96941489361702,
    "BBH Score": 50.091807278816894,
    "Math Score": 41.23867069486405,
    "Date Submitted": "2025-03-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.337464883758884
  },
  {
    "Model Name": "sometimesanotion/Qwen-14B-ProseStock-v4",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6889640300489233,
    "Overall Score": 37.376459859146784,
    "MMLU Score": 48.73854905437352,
    "BBH Score": 49.54129977932439,
    "Math Score": 36.40483383685801,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.131966469364325
  },
  {
    "Model Name": "sometimesanotion/Qwen-2.5-14B-Virmarckeoso",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.790309427252899,
    "Overall Score": 36.63616421583777,
    "MMLU Score": 48.63696808510639,
    "BBH Score": 50.65229487013111,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2024-12-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.64797447267358
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.135318380945588,
    "Overall Score": 36.05694131448308,
    "MMLU Score": 48.10135933806146,
    "BBH Score": 49.17895641544632,
    "Math Score": 33.8368580060423,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.500248757387308
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v2",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.1650812295035533,
    "Overall Score": 36.185823403667726,
    "MMLU Score": 48.6646719858156,
    "BBH Score": 50.41962540780512,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.432826136137907
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.857249308247871,
    "Overall Score": 41.02652166075893,
    "MMLU Score": 48.25834810874704,
    "BBH Score": 48.58158725626311,
    "Math Score": 40.03021148036254,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.636212072948675
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-IF-Variant",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.934752419774387,
    "Overall Score": 34.41237931041414,
    "MMLU Score": 39.873300827423165,
    "BBH Score": 35.653096662329,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.745754659803296
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-Prose01",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7879159156412014,
    "Overall Score": 40.27916996114231,
    "MMLU Score": 47.50110815602837,
    "BBH Score": 47.70662461639211,
    "Math Score": 39.95468277945619,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.63359664210604
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-model_stock",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.769904533407341,
    "Overall Score": 41.224844265866444,
    "MMLU Score": 47.95360520094562,
    "BBH Score": 48.76100556664132,
    "Math Score": 42.44712990936556,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.935248863876753
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3864242985911932,
    "Overall Score": 32.15683651529989,
    "MMLU Score": 36.6688829787234,
    "BBH Score": 36.01177427952259,
    "Math Score": 29.154078549848943,
    "Date Submitted": "2025-02-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 23.194080302816293
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1-Prose",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6469028935169414,
    "Overall Score": 30.518790394446103,
    "MMLU Score": 39.17146867612293,
    "BBH Score": 37.44132686992394,
    "Math Score": 28.92749244712991,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 47.17677212499106
  },
  {
    "Model Name": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1-Reason",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6705605680412755,
    "Overall Score": 29.020681749258376,
    "MMLU Score": 36.74276004728132,
    "BBH Score": 36.259832032643125,
    "Math Score": 26.20845921450152,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 43.27824082174788
  },
  {
    "Model Name": "sometimesanotion/Qwentessential-14B-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9578394364648848,
    "Overall Score": 40.27876153100695,
    "MMLU Score": 48.68314125295508,
    "BBH Score": 50.365974711716206,
    "Math Score": 40.70996978851964,
    "Date Submitted": "2025-02-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 20.573066810695728
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v013",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.847378348005329,
    "Overall Score": 38.63606262403764,
    "MMLU Score": 44.3428634751773,
    "BBH Score": 43.96523461481209,
    "Math Score": 37.08459214501511,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.042179148840011
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v1",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8363009330752975,
    "Overall Score": 37.151308752643104,
    "MMLU Score": 48.99711879432624,
    "BBH Score": 50.73749377731295,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.684148715325485
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v2",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.006593147681782,
    "Overall Score": 37.91575826840247,
    "MMLU Score": 48.9878841607565,
    "BBH Score": 50.53548026965414,
    "Math Score": 37.53776435045317,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.463341265469033
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v3",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.826016412766472,
    "Overall Score": 39.159303783541326,
    "MMLU Score": 49.03405732860521,
    "BBH Score": 50.03761140499875,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.235006743012496
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v5",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.767575484919844,
    "Overall Score": 39.35077790070098,
    "MMLU Score": 49.08946513002365,
    "BBH Score": 50.28397367122805,
    "Math Score": 34.44108761329305,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.444589115256486
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v6",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.807936642717539,
    "Overall Score": 39.59946867765128,
    "MMLU Score": 48.88630319148937,
    "BBH Score": 50.2319102421481,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.399193157108588
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v6-Prose",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.927070295037354,
    "Overall Score": 38.69645443942003,
    "MMLU Score": 48.8031914893617,
    "BBH Score": 50.14060102445929,
    "Math Score": 37.00906344410876,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.853771776970941
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v7",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.795123715981153,
    "Overall Score": 39.15035648193577,
    "MMLU Score": 48.99711879432624,
    "BBH Score": 50.34706507410996,
    "Math Score": 35.725075528700906,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.315963170600945
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v8",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.955932580216315,
    "Overall Score": 38.48492951696213,
    "MMLU Score": 49.02482269503546,
    "BBH Score": 50.11142993537886,
    "Math Score": 39.12386706948641,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.728408848377727
  },
  {
    "Model Name": "sometimesanotion/Qwentinuum-14B-v9",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.805381923005296,
    "Overall Score": 37.21744200410536,
    "MMLU Score": 49.1264036643026,
    "BBH Score": 50.80134720526892,
    "Math Score": 34.818731117824775,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.780212014754337
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-qv256",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.927284904836732,
    "Overall Score": 40.12038665513343,
    "MMLU Score": 46.42065602836879,
    "BBH Score": 47.07821800122079,
    "Math Score": 38.97280966767372,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.21580751773886
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v0.6-004-model_stock",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.819502496328202,
    "Overall Score": 40.603760450568224,
    "MMLU Score": 46.58687943262411,
    "BBH Score": 46.366653802814,
    "Math Score": 40.93655589123867,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.630641160622828
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v10",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.020614495063573,
    "Overall Score": 41.47601045691917,
    "MMLU Score": 47.10401891252955,
    "BBH Score": 46.74625368312197,
    "Math Score": 47.88519637462236,
    "Date Submitted": "2025-01-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.315838662931387
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v11",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.710329520646223,
    "Overall Score": 41.51678135973019,
    "MMLU Score": 48.082890070921984,
    "BBH Score": 47.54895322758622,
    "Math Score": 46.45015105740181,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 11.189513257167324
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v12-Prose",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5109968121064616,
    "Overall Score": 38.05247832908145,
    "MMLU Score": 48.68314125295508,
    "BBH Score": 49.67252940065303,
    "Math Score": 35.34743202416919,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.838083987393723
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v12-Prose-DS",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3611769809371155,
    "Overall Score": 41.20324803823761,
    "MMLU Score": 48.54462174940899,
    "BBH Score": 49.86582018521094,
    "Math Score": 43.05135951661632,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.25857735903865
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v13-Prose-DS",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.834947059251281,
    "Overall Score": 41.0787757849406,
    "MMLU Score": 48.32299054373522,
    "BBH Score": 48.43969044109607,
    "Math Score": 38.59516616314199,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.040128276709966
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v15-Prose-MS",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.945423542855048,
    "Overall Score": 37.71173844405559,
    "MMLU Score": 48.81242612293145,
    "BBH Score": 50.27819609278966,
    "Math Score": 36.329305135951664,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.384847367844085
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v2-Prose",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.3695775044675425,
    "Overall Score": 36.95506362229142,
    "MMLU Score": 48.5723256501182,
    "BBH Score": 49.93347199164365,
    "Math Score": 35.57401812688822,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.967269212028713
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v3",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8056301463694058,
    "Overall Score": 37.51730006937248,
    "MMLU Score": 48.73854905437352,
    "BBH Score": 50.35268751505373,
    "Math Score": 36.933534743202415,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.858367373183706
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v3-Prose",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.422682705037116,
    "Overall Score": 37.52186681948957,
    "MMLU Score": 48.55385638297872,
    "BBH Score": 49.79836668099142,
    "Math Score": 36.48036253776435,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.962706757558667
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v3-Reason",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.791207955566846,
    "Overall Score": 37.613265274956085,
    "MMLU Score": 48.83089539007093,
    "BBH Score": 50.69444798867054,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.921182302787265
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v3-Reason",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.926171913330613,
    "Overall Score": 36.71404812686041,
    "MMLU Score": 48.84936465721041,
    "BBH Score": 50.635776137274746,
    "Math Score": 31.19335347432024,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 19.06062894634199
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v6-Prose",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.87052828006981,
    "Overall Score": 38.9508473949213,
    "MMLU Score": 48.56309101654846,
    "BBH Score": 50.11997604002554,
    "Math Score": 35.64954682779456,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.063444722904535
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v6-Prose-model_stock",
    "Parameters (B)": 14.0,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.9661217268137188,
    "Overall Score": 37.16067561259897,
    "MMLU Score": 48.74778368794326,
    "BBH Score": 49.91412568099364,
    "Math Score": 36.027190332326285,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 18.900495887821386
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v8",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.021208808906965,
    "Overall Score": 39.212221774327226,
    "MMLU Score": 49.27415780141844,
    "BBH Score": 49.83459258547442,
    "Math Score": 40.48338368580061,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.751351804331144
  },
  {
    "Model Name": "sometimesanotion/Qwenvergence-14B-v9",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.830780939917615,
    "Overall Score": 39.81487420685213,
    "MMLU Score": 45.67265070921986,
    "BBH Score": 44.84335580801756,
    "Math Score": 41.389728096676734,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.393409289466808
  },
  {
    "Model Name": "sometimesanotion/lamarck-14b-prose-model_stock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.11503897196628,
    "Overall Score": 35.677974423595586,
    "MMLU Score": 48.37839834515367,
    "BBH Score": 49.383875963762,
    "Math Score": 34.13897280966767,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 11.453460051279832
  },
  {
    "Model Name": "sometimesanotion/lamarck-14b-reason-model_stock",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.97910462331388,
    "Overall Score": 36.96126205505086,
    "MMLU Score": 48.91400709219858,
    "BBH Score": 50.71540412568496,
    "Math Score": 35.80060422960725,
    "Date Submitted": "2024-12-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.7038655721375426
  },
  {
    "Model Name": "sonthenguyen/ft-unsloth-zephyr-sft-bnb-4bit-20241014-161415",
    "Parameters (B)": 7.723,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.255423129392052,
    "Overall Score": 8.889814609614424,
    "MMLU Score": 4.4584810874704495,
    "BBH Score": 12.789212309485556,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.730770857204848
  },
  {
    "Model Name": "sonthenguyen/ft-unsloth-zephyr-sft-bnb-4bit-20241014-164205",
    "Parameters (B)": 7.723,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.177996296525118,
    "Overall Score": 12.93210443469452,
    "MMLU Score": 12.492612293144209,
    "BBH Score": 16.710725154148115,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.069263532130207
  },
  {
    "Model Name": "sonthenguyen/ft-unsloth-zephyr-sft-bnb-4bit-20241014-170522",
    "Parameters (B)": 7.723,
    "Architecture": "?",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.229396078207106,
    "Overall Score": 13.424509088727826,
    "MMLU Score": 11.726137706855791,
    "BBH Score": 14.138281987896178,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.156972004555365
  },
  {
    "Model Name": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbc-213steps",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3976205387596683,
    "Overall Score": 15.85379263495726,
    "MMLU Score": 18.98455969267139,
    "BBH Score": 19.669907319611504,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.343417040097922
  },
  {
    "Model Name": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbo-180steps",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3513696384081009,
    "Overall Score": 15.602364526823637,
    "MMLU Score": 19.418587470449168,
    "BBH Score": 21.35140303187909,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 11.545593510005935
  },
  {
    "Model Name": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbr-180steps",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3684496812307692,
    "Overall Score": 16.475407146329456,
    "MMLU Score": 19.01226359338061,
    "BBH Score": 21.21356840671135,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.039468730418827
  },
  {
    "Model Name": "sophosympatheia/Midnight-Miqu-70B-v1.5",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 12.90593416636188,
    "Overall Score": 25.99019477918401,
    "MMLU Score": 31.386672576832154,
    "BBH Score": 38.54146159014599,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 2.0138173993576567
  },
  {
    "Model Name": "speakleash/Bielik-11B-v2",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 1.837466067264166,
    "Overall Score": 15.989069166924798,
    "MMLU Score": 23.749630614657207,
    "BBH Score": 27.81790653786216,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.701694932919871
  },
  {
    "Model Name": "speakleash/Bielik-11B-v2.0-Instruct",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7768492123292696,
    "Overall Score": 24.661167243528865,
    "MMLU Score": 26.12293144208038,
    "BBH Score": 33.774676263963016,
    "Math Score": 11.858006042296072,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.879155908339891
  },
  {
    "Model Name": "speakleash/Bielik-11B-v2.1-Instruct",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.6112462322667813,
    "Overall Score": 27.19716415968224,
    "MMLU Score": 27.184914302600472,
    "BBH Score": 36.29005304442506,
    "Math Score": 26.66163141993957,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.415396228670788
  },
  {
    "Model Name": "speakleash/Bielik-11B-v2.2-Instruct",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.921850536723809,
    "Overall Score": 27.9792775947469,
    "MMLU Score": 27.628176713947987,
    "BBH Score": 36.95804119871526,
    "Math Score": 26.812688821752268,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.575875714066914
  },
  {
    "Model Name": "speakleash/Bielik-11B-v2.3-Instruct",
    "Parameters (B)": 11.169,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8122839514567144,
    "Overall Score": 28.331123935725586,
    "MMLU Score": 27.15721040189125,
    "BBH Score": 38.062787893588194,
    "Math Score": 20.84592145015106,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.632828350630716
  },
  {
    "Model Name": "spmurrayzzz/Mistral-Syndicate-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1597182125585273,
    "Overall Score": 14.012817664482595,
    "MMLU Score": 18.125738770685576,
    "BBH Score": 20.50625197041595,
    "Math Score": 3.3987915407854987,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.082950420833727
  },
  {
    "Model Name": "spow12/ChatWaifu_12B_v2.0",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.1788552099315455,
    "Overall Score": 21.979985555353448,
    "MMLU Score": 26.529255319148938,
    "BBH Score": 31.16523957802424,
    "Math Score": 7.099697885196375,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.244178426383151
  },
  {
    "Model Name": "spow12/ChatWaifu_22B_v2.0_preview",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9884076630530747,
    "Overall Score": 29.54596932234328,
    "MMLU Score": 33.19666075650118,
    "BBH Score": 45.48829424136917,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.886860379737467
  },
  {
    "Model Name": "spow12/ChatWaifu_v1.4",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.88428537598844,
    "Overall Score": 25.70673411510532,
    "MMLU Score": 27.498891843971627,
    "BBH Score": 31.63055380047582,
    "Math Score": 10.574018126888216,
    "Date Submitted": "2024-09-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.912687464670746
  },
  {
    "Model Name": "spow12/ChatWaifu_v2.0_22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7398346907612154,
    "Overall Score": 28.83809762383144,
    "MMLU Score": 31.506722813238763,
    "BBH Score": 42.28622796334265,
    "Math Score": 18.580060422960727,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.525488169441083
  },
  {
    "Model Name": "spow12/ChatWaifu_v2.0_22B",
    "Parameters (B)": 22.247,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.791720231086567,
    "Overall Score": 29.03230470609974,
    "MMLU Score": 31.24815307328605,
    "BBH Score": 42.01979809251511,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.399431999960848
  },
  {
    "Model Name": "ssmits/Qwen2.5-95B-Instruct",
    "Parameters (B)": 94.648,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 38.4669896056288,
    "Overall Score": 45.257345532181205,
    "MMLU Score": 46.85468380614657,
    "BBH Score": 58.530351322851054,
    "Math Score": 53.02114803625378,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 1.1765242353552614
  },
  {
    "Model Name": "stabilityai/StableBeluga2",
    "Parameters (B)": 68.977,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 12.509347312088028,
    "Overall Score": 22.808722961321305,
    "MMLU Score": 25.845892434988176,
    "BBH Score": 41.26326112722379,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.823334374870285
  },
  {
    "Model Name": "stabilityai/stablelm-2-12b",
    "Parameters (B)": 12.143,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.946558448523118,
    "Overall Score": 13.998663061157224,
    "MMLU Score": 23.02009456264776,
    "BBH Score": 22.685797482043984,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.750851987400308
  },
  {
    "Model Name": "stabilityai/stablelm-2-12b-chat",
    "Parameters (B)": 12.143,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.1761933718736635,
    "Overall Score": 16.778178021081665,
    "MMLU Score": 19.27083333333333,
    "BBH Score": 25.25369709081264,
    "Math Score": 5.362537764350453,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.709874608539936
  },
  {
    "Model Name": "stabilityai/stablelm-2-1_6b",
    "Parameters (B)": 1.645,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.0997436553514433,
    "Overall Score": 5.316831473392678,
    "MMLU Score": 5.1510786052009445,
    "BBH Score": 8.632695204968835,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.834609817952154
  },
  {
    "Model Name": "stabilityai/stablelm-2-1_6b-chat",
    "Parameters (B)": 1.645,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9908530170377292,
    "Overall Score": 8.867360692101089,
    "MMLU Score": 6.905658983451536,
    "BBH Score": 7.493378297410634,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.9492190462427
  },
  {
    "Model Name": "stabilityai/stablelm-2-zephyr-1_6b",
    "Parameters (B)": 1.645,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9461773254818848,
    "Overall Score": 9.458167591621253,
    "MMLU Score": 7.930703309692672,
    "BBH Score": 6.708710147938231,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.996189231024154
  },
  {
    "Model Name": "stabilityai/stablelm-3b-4e1t",
    "Parameters (B)": 2.795,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8685302527863359,
    "Overall Score": 7.3261912916856,
    "MMLU Score": 7.432033096926712,
    "BBH Score": 9.01307034954628,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-08-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 8.435159590794232
  },
  {
    "Model Name": "stabilityai/stablelm-zephyr-3b",
    "Parameters (B)": 2.795,
    "Architecture": "StableLmForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7680472629918603,
    "Overall Score": 12.369206962303688,
    "MMLU Score": 8.530954491725769,
    "BBH Score": 14.7591192080273,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.10474714032641
  },
  {
    "Model Name": "sthenno/tempesthenno-0120",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.683677828224274,
    "Overall Score": 36.46706051009951,
    "MMLU Score": 47.667331560283685,
    "BBH Score": 47.90901771207657,
    "Math Score": 33.53474320241692,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 6.41610267369654
  },
  {
    "Model Name": "sthenno/tempesthenno-fusion-0309",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6217801348510528,
    "Overall Score": 42.138889973963565,
    "MMLU Score": 47.31641548463357,
    "BBH Score": 50.97985614656526,
    "Math Score": 47.65861027190332,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 25.983108972927255
  },
  {
    "Model Name": "sthenno/tempesthenno-kto-0205-ckpt80",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.002422600889499,
    "Overall Score": 41.7909439445551,
    "MMLU Score": 47.62115839243499,
    "BBH Score": 50.64379713470144,
    "Math Score": 45.9214501510574,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.3541410390086
  },
  {
    "Model Name": "sthenno/tempesthenno-nuslerp-001",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9542203017547903,
    "Overall Score": 42.58615155936238,
    "MMLU Score": 47.29794621749409,
    "BBH Score": 51.04491084341287,
    "Math Score": 47.583081570996974,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.415360809099592
  },
  {
    "Model Name": "sthenno/tempesthenno-nuslerp-0124",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.399205437411366,
    "Overall Score": 41.287889272020685,
    "MMLU Score": 48.35992907801419,
    "BBH Score": 49.276795334077576,
    "Math Score": 41.1631419939577,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.647030614159414
  },
  {
    "Model Name": "sthenno/tempesthenno-ppo-ckpt40",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.8322570455957,
    "Overall Score": 42.73562035742862,
    "MMLU Score": 47.685800827423165,
    "BBH Score": 50.57317166167434,
    "Math Score": 47.35649546827795,
    "Date Submitted": "2025-01-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 7.3274583104496305
  },
  {
    "Model Name": "sthenno/tempesthenno-sft-0309-ckpt10",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.550085406181084,
    "Overall Score": 42.192396685999725,
    "MMLU Score": 47.30718085106383,
    "BBH Score": 50.60090254912357,
    "Math Score": 47.205438066465256,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.21940127799044
  },
  {
    "Model Name": "sthenno/tempesthenno-sft-0314-stage1-ckpt50",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5142965828921595,
    "Overall Score": 41.88689161687085,
    "MMLU Score": 47.796616430260045,
    "BBH Score": 51.25931343801958,
    "Math Score": 46.82779456193353,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 27.66095630809055
  },
  {
    "Model Name": "sthenno/tempestissimo-14b-0309",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5719156377988648,
    "Overall Score": 41.88723985978792,
    "MMLU Score": 47.56575059101655,
    "BBH Score": 50.92276703756472,
    "Math Score": 47.9607250755287,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.647256921778663
  },
  {
    "Model Name": "sthenno-com/miscii-14b-0130",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.8863293871608944,
    "Overall Score": 41.08592583319626,
    "MMLU Score": 48.4799793144208,
    "BBH Score": 49.8388387063664,
    "Math Score": 43.202416918429,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 10.571910340109135
  },
  {
    "Model Name": "sthenno-com/miscii-14b-0218",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5469423212307571,
    "Overall Score": 42.89726019720522,
    "MMLU Score": 47.75044326241135,
    "BBH Score": 50.6445656375432,
    "Math Score": 51.43504531722054,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 27.730355300562135
  },
  {
    "Model Name": "sthenno-com/miscii-14b-1028",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.067456578018677,
    "Overall Score": 42.38069997703781,
    "MMLU Score": 46.1436170212766,
    "BBH Score": 49.26266765557472,
    "Math Score": 50.30211480362537,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 13.816234687961657
  },
  {
    "Model Name": "sthenno-com/miscii-14b-1225",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.896994492005911,
    "Overall Score": 42.34951191764194,
    "MMLU Score": 47.464169621749406,
    "BBH Score": 50.91280572690238,
    "Math Score": 45.16616314199396,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 14.618430250558976
  },
  {
    "Model Name": "streamerbtw1002/Nexuim-R1-7B-Instruct",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.670074015460606,
    "Overall Score": 30.443047255620304,
    "MMLU Score": 34.86812943262411,
    "BBH Score": 31.4442193637187,
    "Math Score": 44.5619335347432,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 45.43236501223508
  },
  {
    "Model Name": "stupidity-ai/Llama-3-8B-Instruct-MultiMoose",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.7775533202619482,
    "Overall Score": 4.768701692265338,
    "MMLU Score": 1.041666666666666,
    "BBH Score": 1.2076926870097695,
    "Math Score": 0.0,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.13295778951702
  },
  {
    "Model Name": "suayptalha/Clarus-7B-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6465909529861601,
    "Overall Score": 36.705259716178944,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 36.03116366747631,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 56.76735739444316
  },
  {
    "Model Name": "suayptalha/Clarus-7B-v0.2",
    "Parameters (B)": 7.613,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6742416859737426,
    "Overall Score": 36.86064291856668,
    "MMLU Score": 37.77703900709219,
    "BBH Score": 36.01880357725931,
    "Math Score": 48.56495468277945,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 54.66977744832314
  },
  {
    "Model Name": "suayptalha/Clarus-7B-v0.3",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.6434001187386952,
    "Overall Score": 36.77615414123522,
    "MMLU Score": 37.61081560283688,
    "BBH Score": 36.45786933549141,
    "Math Score": 48.79154078549849,
    "Date Submitted": "2025-02-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 57.1590726674565
  },
  {
    "Model Name": "suayptalha/DeepSeek-R1-Distill-Llama-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2163133549070893,
    "Overall Score": 23.27368245692195,
    "MMLU Score": 21.976580969267136,
    "BBH Score": 21.44875568223163,
    "Math Score": 20.921450151057403,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.134610635513216
  },
  {
    "Model Name": "suayptalha/Falcon3-Jessi-v0.4-7B-Slerp",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4557438278499164,
    "Overall Score": 36.07723171541437,
    "MMLU Score": 34.00007387706855,
    "BBH Score": 37.28589655286154,
    "Math Score": 39.65256797583081,
    "Date Submitted": "2025-01-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.78267881011675
  },
  {
    "Model Name": "suayptalha/HomerCreativeAnvita-Mix-Qw7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2997613805312176,
    "Overall Score": 35.464381527434064,
    "MMLU Score": 38.27570921985816,
    "BBH Score": 36.98416750362379,
    "Math Score": 36.102719033232624,
    "Date Submitted": "2024-11-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 27.285301793579706
  },
  {
    "Model Name": "suayptalha/Komodo-Llama-3.2-3B-v2-fp16",
    "Parameters (B)": 3.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1961295271944847,
    "Overall Score": 20.317372826484497,
    "MMLU Score": 20.582151300236408,
    "BBH Score": 20.20432897355036,
    "Math Score": 10.649546827794564,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.98593033995138
  },
  {
    "Model Name": "suayptalha/Lamarckvergence-14B",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.161000268078386,
    "Overall Score": 43.32033313654279,
    "MMLU Score": 47.593454491725765,
    "BBH Score": 50.32923622182769,
    "Math Score": 54.003021148036254,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 13.704628112188614
  },
  {
    "Model Name": "suayptalha/Lix-14B-v0.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.61743506178036,
    "Overall Score": 43.31763225045196,
    "MMLU Score": 47.93513593380615,
    "BBH Score": 51.473725053502925,
    "Math Score": 52.94561933534743,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.781682476186045
  },
  {
    "Model Name": "suayptalha/Luminis-phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.838788559017852,
    "Overall Score": 41.75746608595973,
    "MMLU Score": 49.15410756501182,
    "BBH Score": 55.80283046446502,
    "Math Score": 46.37462235649547,
    "Date Submitted": "2025-02-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 22.709226616171435
  },
  {
    "Model Name": "suayptalha/Maestro-10B",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8131166227010425,
    "Overall Score": 32.83184082460664,
    "MMLU Score": 35.754654255319146,
    "BBH Score": 39.54498059710542,
    "Math Score": 19.10876132930513,
    "Date Submitted": "2025-01-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 18.10795864619909
  },
  {
    "Model Name": "suayptalha/Rombos-2.5-T.E-8.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3720311227158388,
    "Overall Score": 35.40416180893529,
    "MMLU Score": 38.2849438534279,
    "BBH Score": 36.49986120588039,
    "Math Score": 49.24471299093656,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 25.80419731212456
  },
  {
    "Model Name": "sumink/Qmerft",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2209124695691955,
    "Overall Score": 3.9704632098131207,
    "MMLU Score": 1.7434988179669018,
    "BBH Score": 1.949013632691756,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.2520457516615555
  },
  {
    "Model Name": "sumink/Qwenftmodel",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0288285053678234,
    "Overall Score": 10.104913951155991,
    "MMLU Score": 14.875147754137116,
    "BBH Score": 14.041351651308329,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-12-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 4.980664420093007
  },
  {
    "Model Name": "sumink/Qwenmplus",
    "Parameters (B)": 1.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.1917080289432085,
    "Overall Score": 9.390911516269796,
    "MMLU Score": 11.024305555555555,
    "BBH Score": 12.70658883354089,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.284745683391907
  },
  {
    "Model Name": "sumink/Qwensci",
    "Parameters (B)": 1.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.085459346450348,
    "Overall Score": 5.562539636892597,
    "MMLU Score": 2.8885933806146578,
    "BBH Score": 6.319843194764268,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.6672970855848006
  },
  {
    "Model Name": "sumink/bbhqwen",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7892143760544216,
    "Overall Score": 7.833827413484496,
    "MMLU Score": 6.850251182033097,
    "BBH Score": 6.631749430919456,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.926108356830415
  },
  {
    "Model Name": "sumink/bbhqwen2",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7929371277340248,
    "Overall Score": 6.258601237356344,
    "MMLU Score": 1.6603871158392434,
    "BBH Score": 3.8643035117477176,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.892935036654847
  },
  {
    "Model Name": "sumink/bbhqwen3",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7695893917829426,
    "Overall Score": 4.947842576914937,
    "MMLU Score": 1.8450797872340408,
    "BBH Score": 2.187659932659932,
    "Math Score": 0.0,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.429197997976617
  },
  {
    "Model Name": "sumink/bbhqwen4",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7885846459457425,
    "Overall Score": 5.656083792655539,
    "MMLU Score": 5.658983451536641,
    "BBH Score": 4.8923014124501245,
    "Math Score": 0.6042296072507553,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.172449808317341
  },
  {
    "Model Name": "sumink/bbhqwen5",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.763493256291797,
    "Overall Score": 5.199436501746352,
    "MMLU Score": 1.457225177304964,
    "BBH Score": 2.81326456924998,
    "Math Score": 0.2265861027190332,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.810062117639972
  },
  {
    "Model Name": "sumink/bbhqwen6",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7747034439706267,
    "Overall Score": 4.366128533965068,
    "MMLU Score": 1.6973256501182026,
    "BBH Score": 2.129703501956035,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-02-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.635870819919335
  },
  {
    "Model Name": "sumink/flflmillama",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1867441515549952,
    "Overall Score": 9.04335499884608,
    "MMLU Score": 12.178634751773048,
    "BBH Score": 13.745933922898066,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 7.620307196792619
  },
  {
    "Model Name": "sumink/ftgpt",
    "Parameters (B)": 0.124,
    "Architecture": "GPT2LMHeadModel",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1056350390792806,
    "Overall Score": 3.951784139825086,
    "MMLU Score": 1.9097222222222217,
    "BBH Score": 1.9312767142279632,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 37.409785373006926
  },
  {
    "Model Name": "sumink/llamaft",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.1911480280954392,
    "Overall Score": 8.156199769325905,
    "MMLU Score": 12.381796690307327,
    "BBH Score": 12.950582368134748,
    "Math Score": 1.6616314199395772,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.847343551722188
  },
  {
    "Model Name": "sumink/llamamerge",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.8166414393378985,
    "Overall Score": 14.736806871689032,
    "MMLU Score": 17.664007092198577,
    "BBH Score": 24.376393916804787,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.112116432321436
  },
  {
    "Model Name": "sumink/llftfl7",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2173806002200136,
    "Overall Score": 7.811247007957387,
    "MMLU Score": 8.253915484633568,
    "BBH Score": 13.272908076195748,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 6.416437888484245
  },
  {
    "Model Name": "sumink/llmer",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4185286218364976,
    "Overall Score": 17.983709841194923,
    "MMLU Score": 28.09914302600473,
    "BBH Score": 26.830896875618176,
    "Math Score": 6.495468277945619,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.677720818852649
  },
  {
    "Model Name": "sumink/qwft",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3540079479977694,
    "Overall Score": 3.1061410184104887,
    "MMLU Score": 1.4387559101654843,
    "BBH Score": 2.872788366329503,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.2940345534925957
  },
  {
    "Model Name": "sumink/qwmer",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.353406247419345,
    "Overall Score": 11.672277450870531,
    "MMLU Score": 13.499187352245862,
    "BBH Score": 20.382371995631058,
    "Math Score": 0.0755287009063444,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.62437089612011
  },
  {
    "Model Name": "sumink/solarmer3",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.419555202086502,
    "Overall Score": 20.50211421532019,
    "MMLU Score": 25.80895390070922,
    "BBH Score": 33.44249367336016,
    "Math Score": 5.81570996978852,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 14.442632583210296
  },
  {
    "Model Name": "sumink/somer",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.439342359392516,
    "Overall Score": 19.64702871989658,
    "MMLU Score": 27.19414893617021,
    "BBH Score": 31.718258352659863,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.650003831047352
  },
  {
    "Model Name": "sumink/somer2",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5175328638862864,
    "Overall Score": 20.03735671593734,
    "MMLU Score": 27.02792553191489,
    "BBH Score": 31.37584098110337,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2025-01-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.203902988053379
  },
  {
    "Model Name": "sumink/somerft",
    "Parameters (B)": 1.543,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2931926679579668,
    "Overall Score": 4.941854251868015,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 3.616794951113687,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2025-01-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 3.8214369554627274
  },
  {
    "Model Name": "sunbaby/BrainCog-8B-0.1-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.669108790177119,
    "Overall Score": 18.380632683786093,
    "MMLU Score": 20.646793735224584,
    "BBH Score": 24.283467839476657,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-08-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 11.012243654792336
  },
  {
    "Model Name": "swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6332776227685777,
    "Overall Score": 21.82755308278925,
    "MMLU Score": 30.26004728132387,
    "BBH Score": 27.990827697552746,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.36426384498506
  },
  {
    "Model Name": "synergetic/FrankenQwen2.5-14B",
    "Parameters (B)": 16.972,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.517963472170647,
    "Overall Score": 18.126546386620493,
    "MMLU Score": 37.57387706855792,
    "BBH Score": 44.273555426330965,
    "Math Score": 0.0,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.012105564437339
  },
  {
    "Model Name": "talha2001/Beast-Soul-new",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.285765955666773,
    "Overall Score": 21.79227783258031,
    "MMLU Score": 23.352541371158388,
    "BBH Score": 33.07275916855207,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.948868288614207
  },
  {
    "Model Name": "tangledgroup/tangled-llama-pints-1.5b-v0.1-instruct",
    "Parameters (B)": 1.5,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5908680116894098,
    "Overall Score": 4.366498008182751,
    "MMLU Score": 1.2078900709219855,
    "BBH Score": 3.8421954101765152,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 7.389971908782234
  },
  {
    "Model Name": "tangledgroup/tangled-llama-pints-1.5b-v0.2-instruct",
    "Parameters (B)": 1.5,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5956229144427482,
    "Overall Score": 4.745857038769314,
    "MMLU Score": 1.300236406619384,
    "BBH Score": 4.080205486997016,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-09-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.967888614912397
  },
  {
    "Model Name": "tanliboy/lambda-gemma-2-9b-dpo",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 4.4831744963862326,
    "Overall Score": 22.91040441700333,
    "MMLU Score": 31.017287234042552,
    "BBH Score": 35.554545346782085,
    "Math Score": 9.441087613293051,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.110308428875744
  },
  {
    "Model Name": "tanliboy/lambda-gemma-2-9b-dpo",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.9035758929213187,
    "Overall Score": 16.97010860262216,
    "MMLU Score": 31.165041371158388,
    "BBH Score": 35.73966330720827,
    "Math Score": 0.0,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.844554862159416
  },
  {
    "Model Name": "tanliboy/lambda-qwen2.5-14b-dpo-test",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.6014865819313373,
    "Overall Score": 42.61740082662664,
    "MMLU Score": 42.75450650118203,
    "BBH Score": 48.45443982860533,
    "Math Score": 54.607250755287005,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.833280468248361
  },
  {
    "Model Name": "tanliboy/lambda-qwen2.5-32b-dpo-test",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 10.99860689314531,
    "Overall Score": 45.92459258818872,
    "MMLU Score": 51.739804964539005,
    "BBH Score": 54.40796058706255,
    "Math Score": 61.027190332326285,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.175491772218027
  },
  {
    "Model Name": "tannedbum/Ellaria-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7142266237103225,
    "Overall Score": 33.04997199099277,
    "MMLU Score": 35.61613475177305,
    "BBH Score": 41.72156106008432,
    "Math Score": 20.77039274924472,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.898210943837762
  },
  {
    "Model Name": "tannedbum/L3-Nymeria-Maid-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9115967213637292,
    "Overall Score": 26.04317593533049,
    "MMLU Score": 30.5186170212766,
    "BBH Score": 31.240944775904463,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 28.568746820820564
  },
  {
    "Model Name": "tannedbum/L3-Nymeria-v2-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9849768481433716,
    "Overall Score": 25.70941805244105,
    "MMLU Score": 30.59249408983452,
    "BBH Score": 32.262543662000034,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 26.10154553470157
  },
  {
    "Model Name": "tannedbum/L3-Rhaenys-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.095765884407275,
    "Overall Score": 26.45482324033988,
    "MMLU Score": 31.10039893617021,
    "BBH Score": 33.137944169076256,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.14276956126436
  },
  {
    "Model Name": "teknium/CollectiveCognition-v1.1-Mistral-7B",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.8586361225619709,
    "Overall Score": 14.256397052482129,
    "MMLU Score": 20.40669326241135,
    "BBH Score": 23.47613361696592,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 16.60353749146303
  },
  {
    "Model Name": "teknium/OpenHermes-13B",
    "Parameters (B)": 13.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 62.23823339896335,
    "Overall Score": 12.182264325006637,
    "MMLU Score": 15.438460401891252,
    "BBH Score": 18.21332824040884,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.19573602365791998
  },
  {
    "Model Name": "teknium/OpenHermes-2-Mistral-7B",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9500596701618964,
    "Overall Score": 21.44047612236278,
    "MMLU Score": 21.4594414893617,
    "BBH Score": 29.25183921122332,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 22.567504753369
  },
  {
    "Model Name": "teknium/OpenHermes-2.5-Mistral-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9455666006211318,
    "Overall Score": 21.317189027423066,
    "MMLU Score": 22.826167257683213,
    "BBH Score": 27.77002636780757,
    "Math Score": 5.060422960725076,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 22.544354901516243
  },
  {
    "Model Name": "teknium/OpenHermes-7B",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.966179505229206,
    "Overall Score": 9.569248719177576,
    "MMLU Score": 10.368646572104018,
    "BBH Score": 12.08139546207365,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.9268833736479936
  },
  {
    "Model Name": "tensopolis/falcon3-10b-tensopolis-v1",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 10.0902986546538,
    "Overall Score": 35.588967109820835,
    "MMLU Score": 37.99867021276595,
    "BBH Score": 45.05928024956778,
    "Math Score": 27.492447129909365,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 3.5270479425707246
  },
  {
    "Model Name": "tensopolis/falcon3-10b-tensopolis-v2",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.8575561467328316,
    "Overall Score": 35.190439950096184,
    "MMLU Score": 38.04484338061466,
    "BBH Score": 45.0469273083913,
    "Math Score": 26.66163141993957,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 41.03572702984733
  },
  {
    "Model Name": "tensopolis/lamarckvergence-14b-tensopolis-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.1100675280897367,
    "Overall Score": 42.91732437905944,
    "MMLU Score": 47.224069148936174,
    "BBH Score": 50.983494714854295,
    "Math Score": 51.66163141993958,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 13.799483127435526
  },
  {
    "Model Name": "tensopolis/mistral-small-2501-tensopolis-v1",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3811453118741102,
    "Overall Score": 39.24515046605988,
    "MMLU Score": 38.49734042553191,
    "BBH Score": 48.693238200527865,
    "Math Score": 44.41087613293052,
    "Date Submitted": "2025-02-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 28.414932251268457
  },
  {
    "Model Name": "tensopolis/mistral-small-r1-tensopolis",
    "Parameters (B)": 23.572,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4434002419959506,
    "Overall Score": 25.876977987240537,
    "MMLU Score": 33.72303486997636,
    "BBH Score": 34.60228302469567,
    "Math Score": 29.0785498489426,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 17.927791082712826
  },
  {
    "Model Name": "tensopolis/phi-4-tensopolis-v1",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.7062156886278963,
    "Overall Score": 40.45533321662008,
    "MMLU Score": 48.71084515366431,
    "BBH Score": 55.03657465495981,
    "Math Score": 49.39577039274924,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 14.949042453128236
  },
  {
    "Model Name": "tensopolis/qwen2.5-14b-tensopolis-v1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 11.845475420900796,
    "Overall Score": 41.14159022263494,
    "MMLU Score": 43.456338652482266,
    "BBH Score": 47.96504993841635,
    "Math Score": 52.94561933534743,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 3.4731902908719476
  },
  {
    "Model Name": "tensopolis/qwen2.5-3b-or1-tensopolis",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5197455737492314,
    "Overall Score": 18.28025106583868,
    "MMLU Score": 24.414524231678485,
    "BBH Score": 22.10898759328048,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 12.028494362211612
  },
  {
    "Model Name": "tensopolis/qwen2.5-7b-tensopolis-v1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 8.295151060589886,
    "Overall Score": 35.49167672948769,
    "MMLU Score": 36.31796690307328,
    "BBH Score": 34.78352811189759,
    "Math Score": 45.61933534743202,
    "Date Submitted": "2025-03-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 4.278605232170878
  },
  {
    "Model Name": "tensopolis/qwen2.5-7b-tensopolis-v2",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.501444779713065,
    "Overall Score": 35.37814971872235,
    "MMLU Score": 36.03169326241135,
    "BBH Score": 35.224120159606855,
    "Math Score": 48.18731117824773,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 7.859287728722833
  },
  {
    "Model Name": "tensopolis/virtuoso-lite-tensopolis-v1",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.852792974488292,
    "Overall Score": 36.38947458816892,
    "MMLU Score": 38.16489361702128,
    "BBH Score": 43.94133513211286,
    "Math Score": 25.45317220543807,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 5.310166923711303
  },
  {
    "Model Name": "tensopolis/virtuoso-lite-tensopolis-v2",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.034670836864486,
    "Overall Score": 36.25617876736285,
    "MMLU Score": 38.22030141843972,
    "BBH Score": 43.93077957655731,
    "Math Score": 25.0,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 6.007979514952459
  },
  {
    "Model Name": "tensopolis/virtuoso-small-tensopolis-v1",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.667430653436983,
    "Overall Score": 38.413589685550576,
    "MMLU Score": 44.09352836879432,
    "BBH Score": 48.17122576570145,
    "Math Score": 35.27190332326284,
    "Date Submitted": "2025-01-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.230136136519508
  },
  {
    "Model Name": "tensopolis/virtuoso-small-tensopolis-v2",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.714171092623901,
    "Overall Score": 40.113839873543775,
    "MMLU Score": 46.15285165484633,
    "BBH Score": 50.22972026624839,
    "Math Score": 38.74622356495468,
    "Date Submitted": "2025-02-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.509203226906317
  },
  {
    "Model Name": "tensopolis/virtuoso-small-v2-tensopolis-v1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 28.93224667890828,
    "Overall Score": 42.6978958480128,
    "MMLU Score": 46.39295212765958,
    "BBH Score": 50.96603012167689,
    "Math Score": 45.2416918429003,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 1.4757891539456467
  },
  {
    "Model Name": "tensoropera/Fox-1-1.6B",
    "Parameters (B)": 1.665,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.6856405963989034,
    "Overall Score": 7.764365648440015,
    "MMLU Score": 4.12603427895981,
    "BBH Score": 7.399760932518088,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-06-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.891066533195479
  },
  {
    "Model Name": "tenyx/Llama3-TenyxChat-70B",
    "Parameters (B)": 70.554,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 18.734013036098165,
    "Overall Score": 36.69601460825378,
    "MMLU Score": 46.780806737588655,
    "BBH Score": 49.61562001611543,
    "Math Score": 23.56495468277945,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 1.9587909188247614
  },
  {
    "Model Name": "theo77186/Qwen2.5-Coder-7B-Instruct-20241106",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.324064898427438,
    "Overall Score": 28.33079885828984,
    "MMLU Score": 26.14140070921986,
    "BBH Score": 28.938504045379137,
    "Math Score": 38.82175226586103,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.396835526670703
  },
  {
    "Model Name": "theprint/Boptruth-Agatha-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.776210317612061,
    "Overall Score": 17.51238060668224,
    "MMLU Score": 20.674497635933804,
    "BBH Score": 29.286422282807493,
    "Math Score": 5.5135951661631415,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 22.561386017848168
  },
  {
    "Model Name": "theprint/CleverBoi-7B-v2",
    "Parameters (B)": 7.736,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.0447950669431973,
    "Overall Score": 15.095914857389625,
    "MMLU Score": 18.98455969267139,
    "BBH Score": 23.44418148733149,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.957941183393033
  },
  {
    "Model Name": "theprint/CleverBoi-7B-v3",
    "Parameters (B)": 7.736,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.205779635795906,
    "Overall Score": 13.690467425790892,
    "MMLU Score": 20.75760933806146,
    "BBH Score": 21.93674717909172,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.270557861470703
  },
  {
    "Model Name": "theprint/CleverBoi-Llama-3.1-8B-Instruct",
    "Parameters (B)": 16.061,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.740445190281058,
    "Overall Score": 13.970394725475051,
    "MMLU Score": 23.05703309692672,
    "BBH Score": 24.04860308113929,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.7349550694593425
  },
  {
    "Model Name": "theprint/CleverBoi-Llama-3.1-8B-v2",
    "Parameters (B)": 9.3,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.042758552185006,
    "Overall Score": 14.145587569893708,
    "MMLU Score": 24.31294326241135,
    "BBH Score": 24.132844977310707,
    "Math Score": 5.287009063444108,
    "Date Submitted": "2024-09-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.805128864193683
  },
  {
    "Model Name": "theprint/CleverBoi-Nemo-12B-v2",
    "Parameters (B)": 13.933,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.011026557852458,
    "Overall Score": 17.858393307746045,
    "MMLU Score": 24.756205673758867,
    "BBH Score": 31.65269522562221,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 2.5471866580999283
  },
  {
    "Model Name": "theprint/Code-Llama-Bagel-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6360934056784031,
    "Overall Score": 14.665251333761097,
    "MMLU Score": 20.240469858156025,
    "BBH Score": 25.33815455229531,
    "Math Score": 6.117824773413897,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.963578291350778
  },
  {
    "Model Name": "theprint/Conversely-Mistral-7B",
    "Parameters (B)": 14.496,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0739591416532064,
    "Overall Score": 15.03265572351316,
    "MMLU Score": 20.286643026004725,
    "BBH Score": 25.70696557300103,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.24828923656145
  },
  {
    "Model Name": "theprint/Llama-3.2-3B-VanRossum",
    "Parameters (B)": 3.696,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.709176750592317,
    "Overall Score": 17.58480896190996,
    "MMLU Score": 19.66792257683215,
    "BBH Score": 19.366361887076,
    "Math Score": 9.743202416918429,
    "Date Submitted": "2024-11-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 4.740892695151788
  },
  {
    "Model Name": "theprint/ReWiz-7B",
    "Parameters (B)": 7.736,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8908113661516803,
    "Overall Score": 17.7870406487212,
    "MMLU Score": 18.559766548463354,
    "BBH Score": 23.50442985462492,
    "Math Score": 4.078549848942599,
    "Date Submitted": "2024-10-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 6.152957905516937
  },
  {
    "Model Name": "theprint/ReWiz-Llama-3.1-8B-v2",
    "Parameters (B)": 9.3,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.70618045737013,
    "Overall Score": 15.893327785890378,
    "MMLU Score": 25.67043439716312,
    "BBH Score": 23.7732870894326,
    "Math Score": 5.740181268882175,
    "Date Submitted": "2024-11-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 3.3771182235480532
  },
  {
    "Model Name": "theprint/ReWiz-Llama-3.2-3B",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.96389515102324,
    "Overall Score": 18.18625421313072,
    "MMLU Score": 20.970005910165483,
    "BBH Score": 19.293728122396512,
    "Math Score": 10.95166163141994,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 9.26029793579113
  },
  {
    "Model Name": "theprint/ReWiz-Nemo-12B-Instruct",
    "Parameters (B)": 12.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.350104550430264,
    "Overall Score": 16.173142405102812,
    "MMLU Score": 25.99364657210401,
    "BBH Score": 29.92638936582184,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2024-11-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.881882085689246
  },
  {
    "Model Name": "theprint/ReWiz-Qwen-2.5-14B",
    "Parameters (B)": 16.743,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 11.856532712090589,
    "Overall Score": 30.03173400795292,
    "MMLU Score": 45.46948877068559,
    "BBH Score": 44.86187336352475,
    "Math Score": 29.229607250755286,
    "Date Submitted": "2024-11-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.532927183452911
  },
  {
    "Model Name": "theprint/ReWiz-Worldbuilder-7B",
    "Parameters (B)": 7.248,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2217343468651976,
    "Overall Score": 15.790699918990596,
    "MMLU Score": 21.90270390070922,
    "BBH Score": 25.07634729001636,
    "Math Score": 3.700906344410876,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 12.924822781243208
  },
  {
    "Model Name": "theprint/RuDolph-Hermes-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0041344395875431,
    "Overall Score": 19.03701308822906,
    "MMLU Score": 23.029329196217496,
    "BBH Score": 30.709648163100884,
    "Math Score": 5.13595166163142,
    "Date Submitted": "2024-11-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 18.958629778746236
  },
  {
    "Model Name": "theprint/WorldBuilder-12B",
    "Parameters (B)": 13.933,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.662550205199193,
    "Overall Score": 14.516406576626444,
    "MMLU Score": 24.35911643026005,
    "BBH Score": 29.277996282041656,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.5635810810644806
  },
  {
    "Model Name": "theprint/phi-3-mini-4k-python",
    "Parameters (B)": 4.132,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.751101854174533,
    "Overall Score": 17.728138144118287,
    "MMLU Score": 28.63475177304965,
    "BBH Score": 28.44601616578647,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-09-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 6.444013738429036
  },
  {
    "Model Name": "thinkcoder/llama3-8b-instruct-lora-8-sft",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7149804779098244,
    "Overall Score": 22.36364436394473,
    "MMLU Score": 27.50812647754137,
    "BBH Score": 27.203772889314084,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 31.278678306466016
  },
  {
    "Model Name": "thirdeyeai/elevate360m",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7375654899500736,
    "Overall Score": 1.918188276637857,
    "MMLU Score": 0.8569739952718666,
    "BBH Score": 2.339846843629065,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.600702314268663
  },
  {
    "Model Name": "thomas-yanxin/XinYuan-Qwen2-1_5B",
    "Parameters (B)": 1.777,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.704728139077506,
    "Overall Score": 11.515091263493494,
    "MMLU Score": 15.078309692671397,
    "BBH Score": 12.12557956003766,
    "Math Score": 6.722054380664652,
    "Date Submitted": "2024-09-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.257393228223267
  },
  {
    "Model Name": "thomas-yanxin/XinYuan-Qwen2-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.905125785403986,
    "Overall Score": 22.431711657583364,
    "MMLU Score": 32.494828605200944,
    "BBH Score": 28.40148852275863,
    "Math Score": 14.577039274924472,
    "Date Submitted": "2024-09-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.573116498731314
  },
  {
    "Model Name": "thomas-yanxin/XinYuan-Qwen2-7B-0917",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.9711289872712614,
    "Overall Score": 24.546893470710334,
    "MMLU Score": 36.059397163120565,
    "BBH Score": 32.61993813582105,
    "Math Score": 19.78851963746224,
    "Date Submitted": "2024-09-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 8.261806732684011
  },
  {
    "Model Name": "thomas-yanxin/XinYuan-Qwen2.5-7B-0917",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9424504667015177,
    "Overall Score": 21.39759488657262,
    "MMLU Score": 32.023862293144205,
    "BBH Score": 33.43966927024198,
    "Math Score": 19.335347432024168,
    "Date Submitted": "2024-09-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.015773762770875
  },
  {
    "Model Name": "tianyil1/MistralForCausalLM_Cal_DPO",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.3582537551579863,
    "Overall Score": 18.088644447193257,
    "MMLU Score": 19.59404550827423,
    "BBH Score": 21.78360838715177,
    "Math Score": 2.8700906344410875,
    "Date Submitted": "2025-01-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 13.317573670237534
  },
  {
    "Model Name": "tiiuae/Falcon3-10B-Base",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.620778879963983,
    "Overall Score": 27.61785087949368,
    "MMLU Score": 36.003989361702125,
    "BBH Score": 41.37546218651794,
    "Math Score": 24.924471299093657,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 17.039863500755516
  },
  {
    "Model Name": "tiiuae/Falcon3-10B-Instruct",
    "Parameters (B)": 10.306,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.680822286122655,
    "Overall Score": 35.47541146366702,
    "MMLU Score": 38.1002511820331,
    "BBH Score": 44.82153982483132,
    "Math Score": 27.64350453172205,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 21.105985895452523
  },
  {
    "Model Name": "tiiuae/Falcon3-1B-Base",
    "Parameters (B)": 1.669,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.8027389735646433,
    "Overall Score": 9.8880961034972,
    "MMLU Score": 6.757904846335696,
    "BBH Score": 11.343173265854867,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 12.317946965485072
  },
  {
    "Model Name": "tiiuae/Falcon3-1B-Instruct",
    "Parameters (B)": 1.669,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7940407279002907,
    "Overall Score": 16.164597322515025,
    "MMLU Score": 9.315898345153665,
    "BBH Score": 12.961374062508185,
    "Math Score": 6.3444108761329305,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.357390691104257
  },
  {
    "Model Name": "tiiuae/Falcon3-3B-Base",
    "Parameters (B)": 3.228,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.9624329512252896,
    "Overall Score": 15.738743193619,
    "MMLU Score": 20.877659574468087,
    "BBH Score": 21.584784293773264,
    "Math Score": 11.782477341389727,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.353080153356906
  },
  {
    "Model Name": "tiiuae/Falcon3-3B-Instruct",
    "Parameters (B)": 3.228,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.9609272919904578,
    "Overall Score": 26.60234489991349,
    "MMLU Score": 22.281323877068555,
    "BBH Score": 26.28722946843269,
    "Math Score": 25.0,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 27.68403512071094
  },
  {
    "Model Name": "tiiuae/Falcon3-7B-Base",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.2187440946071069,
    "Overall Score": 24.745725360383613,
    "MMLU Score": 32.337839834515364,
    "BBH Score": 31.55991854750336,
    "Math Score": 19.410876132930515,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 20.304283294485234
  },
  {
    "Model Name": "tiiuae/Falcon3-7B-Instruct",
    "Parameters (B)": 7.456,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.237521337225013,
    "Overall Score": 36.404684964282325,
    "MMLU Score": 34.30481678486997,
    "BBH Score": 37.91581245917148,
    "Math Score": 40.86102719033233,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 29.417420022765253
  },
  {
    "Model Name": "tiiuae/Falcon3-Mamba-7B-Base",
    "Parameters (B)": 7.273,
    "Architecture": "FalconMambaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.6726362873383394,
    "Overall Score": 18.138791975781,
    "MMLU Score": 22.64147458628841,
    "BBH Score": 25.53404880295316,
    "Math Score": 19.410876132930515,
    "Date Submitted": "2024-12-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 10.844432894999068
  },
  {
    "Model Name": "tiiuae/Falcon3-Mamba-7B-Instruct",
    "Parameters (B)": 7.273,
    "Architecture": "FalconMambaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6569950132433542,
    "Overall Score": 28.109654708582763,
    "MMLU Score": 26.32609338061465,
    "BBH Score": 25.20350517239808,
    "Math Score": 30.06042296072508,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 16.96423615274601
  },
  {
    "Model Name": "tiiuae/falcon-11B",
    "Parameters (B)": 11.103,
    "Architecture": "FalconForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.165741982835327,
    "Overall Score": 13.851902586180216,
    "MMLU Score": 15.438460401891252,
    "BBH Score": 21.937999462890275,
    "Math Score": 2.794561933534743,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.395915439587917
  },
  {
    "Model Name": "tiiuae/falcon-40b",
    "Parameters (B)": 40.0,
    "Architecture": "FalconForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 43.58716780286837,
    "Overall Score": 11.40130446230009,
    "MMLU Score": 16.722074468085104,
    "BBH Score": 16.583304730312175,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.26157479453275684
  },
  {
    "Model Name": "tiiuae/falcon-40b-instruct",
    "Parameters (B)": 40.0,
    "Architecture": "FalconForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 39.466490974353526,
    "Overall Score": 10.484506782098748,
    "MMLU Score": 14.016326832151298,
    "BBH Score": 17.220114203264526,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.265655915265228
  },
  {
    "Model Name": "tiiuae/falcon-7b",
    "Parameters (B)": 7.0,
    "Architecture": "FalconForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.57168247484153,
    "Overall Score": 5.17344472031948,
    "MMLU Score": 1.392582742316784,
    "BBH Score": 5.963936911876051,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.291660245076608
  },
  {
    "Model Name": "tiiuae/falcon-7b-instruct",
    "Parameters (B)": 7.0,
    "Architecture": "FalconForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.532429051211775,
    "Overall Score": 5.1165739086852,
    "MMLU Score": 1.725029550827422,
    "BBH Score": 4.823178460674432,
    "Math Score": 1.2084592145015105,
    "Date Submitted": "2024-06-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.3388651204695226
  },
  {
    "Model Name": "tiiuae/falcon-mamba-7b",
    "Parameters (B)": 7.0,
    "Architecture": "FalconMambaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 7.220815834996586,
    "Overall Score": 15.179238027611218,
    "MMLU Score": 14.468823877068557,
    "BBH Score": 19.87687780354344,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-07-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 2.1021500027799
  },
  {
    "Model Name": "tinycompany/BiBo-v0.3",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.3977961314488438,
    "Overall Score": 19.54353096107359,
    "MMLU Score": 22.16127364066194,
    "BBH Score": 24.34266236145128,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 49.129514884653595
  },
  {
    "Model Name": "tinycompany/BiBo-v0.7",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7902558830661202,
    "Overall Score": 15.965356863831778,
    "MMLU Score": 18.3381353427896,
    "BBH Score": 19.67472884227719,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.20276875622572
  },
  {
    "Model Name": "tinycompany/ShawtyIsBad-bgem3",
    "Parameters (B)": 1.436,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.611048879853014,
    "Overall Score": 12.610397878155718,
    "MMLU Score": 17.59013002364066,
    "BBH Score": 13.857811570359898,
    "Math Score": 4.833836858006042,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.637298085202467
  },
  {
    "Model Name": "tinycompany/ShawtyIsBad-e5-large",
    "Parameters (B)": 1.436,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6184516264754303,
    "Overall Score": 12.316339936795012,
    "MMLU Score": 17.433141252955085,
    "BBH Score": 14.177224162496438,
    "Math Score": 4.531722054380665,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.914799168669198
  },
  {
    "Model Name": "tinycompany/ShawtyIsBad-ib",
    "Parameters (B)": 1.436,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6104909575072485,
    "Overall Score": 12.35455968391428,
    "MMLU Score": 17.56242612293144,
    "BBH Score": 14.236689579644496,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.237088743067243
  },
  {
    "Model Name": "tinycompany/ShawtyIsBad-nomic-moe",
    "Parameters (B)": 1.436,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6057768623498688,
    "Overall Score": 12.741407000136505,
    "MMLU Score": 17.47007978723404,
    "BBH Score": 14.318942650237616,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 21.033168798675007
  },
  {
    "Model Name": "tinycompany/ShawtyIsBad-nomic1.5",
    "Parameters (B)": 1.436,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.6106685886710093,
    "Overall Score": 12.504999335501656,
    "MMLU Score": 17.414671985815602,
    "BBH Score": 14.217971903055156,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.47755454839447
  },
  {
    "Model Name": "tinycompany/SigmaBoi-base",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7619494892522348,
    "Overall Score": 15.2508076506235,
    "MMLU Score": 20.18506205673759,
    "BBH Score": 20.769956753887325,
    "Math Score": 7.779456193353475,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.015510038060924
  },
  {
    "Model Name": "tinycompany/SigmaBoi-bge-m3",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7659973634243759,
    "Overall Score": 15.455458242923893,
    "MMLU Score": 20.212765957446805,
    "BBH Score": 21.20631466545509,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 20.176907886249865
  },
  {
    "Model Name": "tinycompany/SigmaBoi-bgem3",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7750909044876523,
    "Overall Score": 15.455458242923893,
    "MMLU Score": 20.212765957446805,
    "BBH Score": 21.20631466545509,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.940187858532802
  },
  {
    "Model Name": "tinycompany/SigmaBoi-ib",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7716704676927227,
    "Overall Score": 14.968209771816907,
    "MMLU Score": 20.268173758865245,
    "BBH Score": 21.07657916936113,
    "Math Score": 7.401812688821751,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.397152539181025
  },
  {
    "Model Name": "tinycompany/SigmaBoi-nomic-moe",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5675806835217012,
    "Overall Score": 15.186432252407451,
    "MMLU Score": 20.40669326241135,
    "BBH Score": 20.96864244921853,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 9.687815378210619
  },
  {
    "Model Name": "tinycompany/SigmaBoi-nomic1.5",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7843821506214192,
    "Overall Score": 15.473023890881102,
    "MMLU Score": 20.45286643026005,
    "BBH Score": 21.43784511243409,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.726384490803042
  },
  {
    "Model Name": "tinycompany/SigmaBoi-nomic1.5-fp32",
    "Parameters (B)": 2.943,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.7882026155759113,
    "Overall Score": 15.498419470905068,
    "MMLU Score": 20.45286643026005,
    "BBH Score": 21.43784511243409,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 19.662989140908813
  },
  {
    "Model Name": "tinycompany/Tamed-Shawty",
    "Parameters (B)": 1.562,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6145020115350416,
    "Overall Score": 13.533997252162251,
    "MMLU Score": 17.793291962174944,
    "BBH Score": 14.653983733918906,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 22.024333522284138
  },
  {
    "Model Name": "tklohj/WindyFloLLM",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.197024186099759,
    "Overall Score": 14.243655403588258,
    "MMLU Score": 17.57166075650118,
    "BBH Score": 24.39876319785054,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-07-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.483158216329943
  },
  {
    "Model Name": "togethercomputer/GPT-JT-6B-v1",
    "Parameters (B)": 6.0,
    "Architecture": "GPTJForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 75.91762136171212,
    "Overall Score": 6.877706827738106,
    "MMLU Score": 6.951832151300234,
    "BBH Score": 7.318523965141613,
    "Math Score": 1.0574018126888218,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.09059434034384502
  },
  {
    "Model Name": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "Parameters (B)": 20.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.967175975443749,
    "Overall Score": 5.140295456712411,
    "MMLU Score": 1.6142139479905429,
    "BBH Score": 6.830794983137852,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 0.8614285011646825
  },
  {
    "Model Name": "togethercomputer/LLaMA-2-7B-32K",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.169145546277345,
    "Overall Score": 6.8377158675946506,
    "MMLU Score": 8.530954491725769,
    "BBH Score": 8.089984229889549,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.84847274949342
  },
  {
    "Model Name": "togethercomputer/Llama-2-7B-32K-Instruct",
    "Parameters (B)": 7.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.179818726519121,
    "Overall Score": 8.25854218578891,
    "MMLU Score": 8.678708628841607,
    "BBH Score": 8.563469919446954,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.999839890789415
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-7B-Base",
    "Parameters (B)": 7.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.441214326653394,
    "Overall Score": 5.56181429403527,
    "MMLU Score": 2.186761229314421,
    "BBH Score": 5.087242272916432,
    "Math Score": 1.5861027190332326,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.2782982359684234
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "Parameters (B)": 7.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.438672213362967,
    "Overall Score": 4.050900591245242,
    "MMLU Score": 1.3464095744680846,
    "BBH Score": 4.502173664381199,
    "Math Score": 0.6797583081570997,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 1.661109094140613
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "Parameters (B)": 7.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.362237340653382,
    "Overall Score": 6.456725492718323,
    "MMLU Score": 3.027112884160755,
    "BBH Score": 7.9054164937041635,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 2.733309384963167
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "Parameters (B)": 3.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 1.5522036912990087,
    "Overall Score": 5.521090384654182,
    "MMLU Score": 1.2355939716312052,
    "BBH Score": 3.518607767474259,
    "Math Score": 1.4350453172205435,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.5569367703498314
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "Parameters (B)": 3.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5498179167454655,
    "Overall Score": 4.848823926757166,
    "MMLU Score": 1.4110520094562635,
    "BBH Score": 5.164727927050627,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-06-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.1286410321926303
  },
  {
    "Model Name": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "Parameters (B)": 3.0,
    "Architecture": "GPTNeoXForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5213420694196813,
    "Overall Score": 5.777231560126986,
    "MMLU Score": 1.2171247044917255,
    "BBH Score": 4.510786368926982,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.7974573084215844
  },
  {
    "Model Name": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.7162203415060449,
    "Overall Score": 22.34514981791089,
    "MMLU Score": 23.19555260047281,
    "BBH Score": 29.267966131617708,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2024-09-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.01997725904019
  },
  {
    "Model Name": "tomasmcm/sky-t1-coder-32b-flash",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 50.04717672288697,
    "Overall Score": 44.868558910231286,
    "MMLU Score": 53.13423463356975,
    "BBH Score": 55.46594372212499,
    "Math Score": 54.229607250755286,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 0.8965252757147546
  },
  {
    "Model Name": "trthminh1112/autotrain-llama32-1b-finetune",
    "Parameters (B)": 1.1,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.1744157173870496,
    "Overall Score": 4.586088234847661,
    "MMLU Score": 1.0970744680851066,
    "BBH Score": 2.852986635695443,
    "Math Score": 1.5105740181268883,
    "Date Submitted": "2025-03-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 26.294007808198703
  },
  {
    "Model Name": "tugstugi/Qwen2.5-7B-Instruct-QwQ-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6264384026419691,
    "Overall Score": 28.42790067536457,
    "MMLU Score": 34.23093971631205,
    "BBH Score": 30.49889389653247,
    "Math Score": 38.14199395770393,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 17.478621157239395
  },
  {
    "Model Name": "universalml/NepaliGPT-2.0",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.4203635608706261,
    "Overall Score": 12.586353879208668,
    "MMLU Score": 25.550384160756494,
    "BBH Score": 24.216690252212945,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2025-03-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 29.941591162518314
  },
  {
    "Model Name": "unsloth/Llama-3.2-1B-Instruct",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.722639371510048,
    "Overall Score": 14.532450983938604,
    "MMLU Score": 8.244680851063828,
    "BBH Score": 8.31684951238064,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.110239708599295
  },
  {
    "Model Name": "unsloth/Llama-3.2-1B-Instruct-no-system-message",
    "Parameters (B)": 1.236,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.7138739509390423,
    "Overall Score": 14.363515028823208,
    "MMLU Score": 7.432033096926712,
    "BBH Score": 9.386371925607728,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2025-01-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.120519890001855
  },
  {
    "Model Name": "unsloth/Phi-3-mini-4k-instruct",
    "Parameters (B)": 3.821,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.9390662160488384,
    "Overall Score": 27.342019856110284,
    "MMLU Score": 33.67686170212765,
    "BBH Score": 36.73247326561403,
    "Math Score": 16.389728096676738,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 29.116178804890893
  },
  {
    "Model Name": "unsloth/phi-4",
    "Parameters (B)": 14.66,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.886538526666603,
    "Overall Score": 40.728304291060965,
    "MMLU Score": 48.64620271867612,
    "BBH Score": 55.25314499847013,
    "Math Score": 50.0,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 21.588906728040886
  },
  {
    "Model Name": "unsloth/phi-4-bnb-4bit",
    "Parameters (B)": 8.058,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.0477431372705746,
    "Overall Score": 39.06049481375357,
    "MMLU Score": 47.288711583924346,
    "BBH Score": 53.53519912141298,
    "Math Score": 46.07250755287009,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.816203024489276
  },
  {
    "Model Name": "unsloth/phi-4-unsloth-bnb-4bit",
    "Parameters (B)": 8.483,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.037535966214848,
    "Overall Score": 39.21645140571378,
    "MMLU Score": 47.62115839243499,
    "BBH Score": 53.84008105932037,
    "Math Score": 45.61933534743202,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 12.910613023812987
  },
  {
    "Model Name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.565551571277175,
    "Overall Score": 20.57236409322395,
    "MMLU Score": 23.758865248226947,
    "BBH Score": 31.87240188800212,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.140649257846576
  },
  {
    "Model Name": "upstage/SOLAR-10.7B-v1.0",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 2.16660205245516,
    "Overall Score": 16.8549748598855,
    "MMLU Score": 26.66777482269504,
    "BBH Score": 29.78935808901913,
    "Math Score": 2.643504531722054,
    "Date Submitted": "2024-06-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 7.779451164456205
  },
  {
    "Model Name": "upstage/solar-pro-preview-instruct",
    "Parameters (B)": 22.14,
    "Architecture": "SolarForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.483526305840195,
    "Overall Score": 39.93865486453309,
    "MMLU Score": 47.48263888888889,
    "BBH Score": 54.82235099983529,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-09-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.465007397123776
  },
  {
    "Model Name": "utkmst/chimera-beta-test2-lora-merged",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4398028314543256,
    "Overall Score": 22.38980642084878,
    "MMLU Score": 22.13356973995272,
    "BBH Score": 25.61316406168906,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2025-03-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 15.550605910555918
  },
  {
    "Model Name": "uukuguy/speechless-code-mistral-7b-v1.0",
    "Parameters (B)": 7.0,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.292796678606731,
    "Overall Score": 18.19259169032542,
    "MMLU Score": 23.841976950354614,
    "BBH Score": 24.091412067845624,
    "Math Score": 5.211480362537765,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.072276013218012
  },
  {
    "Model Name": "uukuguy/speechless-codellama-34b-v2.0",
    "Parameters (B)": 34.0,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.991254192277104,
    "Overall Score": 17.209357596769955,
    "MMLU Score": 17.137632978723403,
    "BBH Score": 25.99329326784064,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 8.642471495359489
  },
  {
    "Model Name": "uukuguy/speechless-coder-ds-6.7b",
    "Parameters (B)": 6.7,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.5772070117938326,
    "Overall Score": 9.714852002598894,
    "MMLU Score": 7.986111111111111,
    "BBH Score": 15.897457343156352,
    "Math Score": 2.114803625377644,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.159528793591737
  },
  {
    "Model Name": "uukuguy/speechless-instruct-mistral-7b-v0.2",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2352409646090443,
    "Overall Score": 18.10671348498029,
    "MMLU Score": 21.1362293144208,
    "BBH Score": 24.558747365322688,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.65844641147494
  },
  {
    "Model Name": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "Parameters (B)": 13.016,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.959048665788608,
    "Overall Score": 18.701595895131856,
    "MMLU Score": 17.322325650118206,
    "BBH Score": 26.79172729423422,
    "Math Score": 2.0392749244713,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.54626407282414
  },
  {
    "Model Name": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.311437449926933,
    "Overall Score": 18.34008948586425,
    "MMLU Score": 22.11510047281324,
    "BBH Score": 29.65312947574292,
    "Math Score": 2.9456193353474323,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.984723012817785
  },
  {
    "Model Name": "uukuguy/speechless-zephyr-code-functionary-7b",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2679992531547388,
    "Overall Score": 16.460834340340238,
    "MMLU Score": 23.26942966903073,
    "BBH Score": 25.983622785908505,
    "Math Score": 4.229607250755287,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.981738198493607
  },
  {
    "Model Name": "v000000/L3-8B-Stheno-v3.2-abliterated",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.0007103084614668,
    "Overall Score": 24.620611328256683,
    "MMLU Score": 28.93026004728133,
    "BBH Score": 30.74630496568445,
    "Math Score": 6.948640483383686,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 24.603135512923238
  },
  {
    "Model Name": "v000000/L3.1-Niitorm-8B-DPO-t0.0001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7562181593962325,
    "Overall Score": 28.113230470994733,
    "MMLU Score": 31.848404255319146,
    "BBH Score": 30.51317301580421,
    "Math Score": 16.238670694864048,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.007823584206495
  },
  {
    "Model Name": "v000000/L3.1-Storniitova-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6270799995011005,
    "Overall Score": 28.28170680403471,
    "MMLU Score": 30.841829196217496,
    "BBH Score": 30.810993185589904,
    "Math Score": 14.652567975830816,
    "Date Submitted": "2024-09-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.381878464922757
  },
  {
    "Model Name": "v000000/Qwen2.5-14B-Gutenberg-1e-Delta",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.604773014380301,
    "Overall Score": 40.87901381911441,
    "MMLU Score": 43.668735224586285,
    "BBH Score": 48.6166718794722,
    "Math Score": 52.64350453172205,
    "Date Submitted": "2024-09-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.340246294576179
  },
  {
    "Model Name": "v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 5.344519821833167,
    "Overall Score": 41.36227864094851,
    "MMLU Score": 43.59485815602837,
    "BBH Score": 48.45212383388064,
    "Math Score": 53.24773413897282,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 7.7391945431612745
  },
  {
    "Model Name": "v000000/Qwen2.5-Lumen-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.673385087937254,
    "Overall Score": 41.13785114892261,
    "MMLU Score": 43.36399231678487,
    "BBH Score": 48.50786084405761,
    "Math Score": 53.625377643504535,
    "Date Submitted": "2024-09-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.198894252609676
  },
  {
    "Model Name": "vhab10/Llama-3.1-8B-Base-Instruct-SLERP",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6134415622278524,
    "Overall Score": 19.27479354795199,
    "MMLU Score": 29.12418735224587,
    "BBH Score": 29.92604162309261,
    "Math Score": 12.009063444108762,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.946384671867017
  },
  {
    "Model Name": "vhab10/Llama-3.2-Instruct-3B-TIES",
    "Parameters (B)": 1.848,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.245852928376529,
    "Overall Score": 17.33432617767801,
    "MMLU Score": 21.28398345153665,
    "BBH Score": 19.183159360187968,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.718371028956273
  },
  {
    "Model Name": "vhab10/llama-3-8b-merged-linear",
    "Parameters (B)": 4.65,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.609886668917451,
    "Overall Score": 23.91136833689406,
    "MMLU Score": 30.04765070921986,
    "BBH Score": 27.8160513277408,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2024-09-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.16184163154188
  },
  {
    "Model Name": "vicgalle/CarbonBeagle-11B",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8307574022339383,
    "Overall Score": 22.470185912589034,
    "MMLU Score": 25.29181442080378,
    "BBH Score": 33.06060419684841,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.273710260666062
  },
  {
    "Model Name": "vicgalle/CarbonBeagle-11B-truthy",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.814546619696793,
    "Overall Score": 21.31996250525653,
    "MMLU Score": 26.18757387706856,
    "BBH Score": 33.98837559181831,
    "Math Score": 4.909365558912387,
    "Date Submitted": "2024-07-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 11.749470790019743
  },
  {
    "Model Name": "vicgalle/Configurable-Hermes-2-Pro-Llama-3-8B",
    "Parameters (B)": 8.031,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4978545713733988,
    "Overall Score": 22.56595247127864,
    "MMLU Score": 23.30636820330969,
    "BBH Score": 30.50962474895478,
    "Math Score": 7.628398791540786,
    "Date Submitted": "2024-07-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 15.06551630749284
  },
  {
    "Model Name": "vicgalle/Configurable-Llama-3.1-8B-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.593219107942026,
    "Overall Score": 28.01011138792457,
    "MMLU Score": 28.800975177304966,
    "BBH Score": 29.661397892084384,
    "Math Score": 17.29607250755287,
    "Date Submitted": "2024-08-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.58082817880929
  },
  {
    "Model Name": "vicgalle/Configurable-Yi-1.5-9B-Chat",
    "Parameters (B)": 8.829,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.8838176236566784,
    "Overall Score": 26.162899498605693,
    "MMLU Score": 33.5014036643026,
    "BBH Score": 35.33444508462291,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.888233749411945
  },
  {
    "Model Name": "vicgalle/ConfigurableBeagle-11B",
    "Parameters (B)": 10.732,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7597130454120933,
    "Overall Score": 22.622956003400244,
    "MMLU Score": 26.38150118203309,
    "BBH Score": 32.392022902811185,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 12.856048355373959
  },
  {
    "Model Name": "vicgalle/ConfigurableHermes-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2345637627211006,
    "Overall Score": 19.53629541490737,
    "MMLU Score": 22.50295508274231,
    "BBH Score": 23.158164380406475,
    "Math Score": 4.758308157099698,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 15.824452332739336
  },
  {
    "Model Name": "vicgalle/ConfigurableSOLAR-10.7B",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3553626295511634,
    "Overall Score": 20.153450201779847,
    "MMLU Score": 24.146719858156025,
    "BBH Score": 27.45095014166692,
    "Math Score": 6.646525679758309,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 14.86941558101966
  },
  {
    "Model Name": "vicgalle/Humanish-RP-Llama-3.1-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5069010760109964,
    "Overall Score": 25.423199454688373,
    "MMLU Score": 27.51736111111111,
    "BBH Score": 29.95856031523668,
    "Math Score": 15.181268882175228,
    "Date Submitted": "2024-08-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 16.87118010558966
  },
  {
    "Model Name": "vicgalle/Merge-Mistral-Prometheus-7B",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2607111502563213,
    "Overall Score": 16.58664234759141,
    "MMLU Score": 19.0769060283688,
    "BBH Score": 18.41040626692948,
    "Math Score": 1.812688821752266,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 13.156576226218908
  },
  {
    "Model Name": "vicgalle/Merge-Mixtral-Prometheus-8x7B",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.348018298275145,
    "Overall Score": 24.76898152616297,
    "MMLU Score": 29.81678486997636,
    "BBH Score": 34.65142126614313,
    "Math Score": 9.290030211480364,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.370838302345706
  },
  {
    "Model Name": "vicgalle/Roleplay-Llama-3-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.252317027783774,
    "Overall Score": 24.020182936148974,
    "MMLU Score": 30.093823877068555,
    "BBH Score": 28.554603909240623,
    "Math Score": 9.138972809667674,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 10.664654504603314
  },
  {
    "Model Name": "viettelsecurity-ai/security-llama3.2-3b",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.606916288481658,
    "Overall Score": 19.977384437548874,
    "MMLU Score": 20.41592789598109,
    "BBH Score": 20.597405725871987,
    "Math Score": 12.613293051359516,
    "Date Submitted": "2025-03-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 32.916210714210585
  },
  {
    "Model Name": "vihangd/smart-dan-sft-v0.1",
    "Parameters (B)": 0.379,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7220493353549226,
    "Overall Score": 3.871212537831616,
    "MMLU Score": 1.5772754137115832,
    "BBH Score": 3.1255992643495936,
    "Math Score": 0.9818731117824772,
    "Date Submitted": "2024-08-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.361423864380023
  },
  {
    "Model Name": "voidful/smol-360m-ft",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7634589764630502,
    "Overall Score": 4.78993024096286,
    "MMLU Score": 0.967789598108746,
    "BBH Score": 3.0227064431492727,
    "Math Score": 0.8308157099697886,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 6.273985097606201
  },
  {
    "Model Name": "vonjack/MobileLLM-125M-HF",
    "Parameters (B)": 0.125,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游릭 pretrained",
    "Training CO2 (kg)": 0.343622716808116,
    "Overall Score": 5.565351724961825,
    "MMLU Score": 1.8173758865248213,
    "BBH Score": 3.146583712799116,
    "Math Score": 0.906344410876133,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 16.196111178730945
  },
  {
    "Model Name": "vonjack/Phi-3-mini-4k-instruct-LLaMAfied",
    "Parameters (B)": 3.821,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9022300106035944,
    "Overall Score": 26.96808014137996,
    "MMLU Score": 32.06080082742317,
    "BBH Score": 40.20185213345416,
    "Math Score": 13.821752265861026,
    "Date Submitted": "2025-01-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 29.890471192970224
  },
  {
    "Model Name": "vonjack/Phi-3.5-mini-instruct-hermes-fc-json",
    "Parameters (B)": 4.132,
    "Architecture": "?",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.5703771540987903,
    "Overall Score": 4.642406244437133,
    "MMLU Score": 1.540336879432624,
    "BBH Score": 2.390836087243887,
    "Math Score": 0.7552870090634441,
    "Date Submitted": "2024-11-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.8061187001425962
  },
  {
    "Model Name": "vonjack/Qwen2.5-Coder-0.5B-Merged",
    "Parameters (B)": 0.63,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.9935574479094093,
    "Overall Score": 6.979693269720411,
    "MMLU Score": 2.24216903073286,
    "BBH Score": 3.588738438643756,
    "Math Score": 3.776435045317221,
    "Date Submitted": "2024-11-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 7.0249518881939945
  },
  {
    "Model Name": "vonjack/SmolLM2-1.7B-Merged",
    "Parameters (B)": 1.711,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6226545348609049,
    "Overall Score": 12.23422955589429,
    "MMLU Score": 11.643026004728132,
    "BBH Score": 10.766530256983184,
    "Math Score": 6.268882175226587,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 19.64850309590582
  },
  {
    "Model Name": "vonjack/SmolLM2-135M-Merged",
    "Parameters (B)": 0.135,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6910205312158826,
    "Overall Score": 5.872429779192967,
    "MMLU Score": 1.2448286052009452,
    "BBH Score": 4.587041236226676,
    "Math Score": 1.1329305135951662,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.498198698756687
  },
  {
    "Model Name": "vonjack/SmolLM2-360M-Merged",
    "Parameters (B)": 0.362,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7714837221663239,
    "Overall Score": 7.294376590792457,
    "MMLU Score": 1.087839834515365,
    "BBH Score": 4.741734006734007,
    "Math Score": 1.7371601208459215,
    "Date Submitted": "2024-11-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.454997404624262
  },
  {
    "Model Name": "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored",
    "Parameters (B)": 10.732,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6039422180157412,
    "Overall Score": 21.621994458789136,
    "MMLU Score": 26.03981973995272,
    "BBH Score": 33.858639234912964,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 13.480532039076818
  },
  {
    "Model Name": "wanlige/li-14b-v0.4",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.999544646290045,
    "Overall Score": 43.65996249118637,
    "MMLU Score": 46.30060579196218,
    "BBH Score": 50.384177102490106,
    "Math Score": 55.740181268882175,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 8.732787799701843
  },
  {
    "Model Name": "wanlige/li-14b-v0.4-slerp",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.988583231107894,
    "Overall Score": 37.79262489578497,
    "MMLU Score": 48.58156028368795,
    "BBH Score": 51.046628177994485,
    "Math Score": 41.918429003021146,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 19.00479914774785
  },
  {
    "Model Name": "wanlige/li-14b-v0.4-slerp0.1",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.5949348623708084,
    "Overall Score": 42.906109293180656,
    "MMLU Score": 47.71350472813239,
    "BBH Score": 50.88127296750732,
    "Math Score": 53.32326283987915,
    "Date Submitted": "2025-02-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 26.901480621849597
  },
  {
    "Model Name": "wannaphong/KhanomTanLLM-Instruct",
    "Parameters (B)": 3.447,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 0.8034612656682864,
    "Overall Score": 4.8192843205392455,
    "MMLU Score": 1.3187056737588652,
    "BBH Score": 3.944866059804924,
    "Math Score": 1.3595166163141994,
    "Date Submitted": "2024-08-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 5.998153895484633
  },
  {
    "Model Name": "waqasali1707/Beast-Soul-new",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.2737761309085094,
    "Overall Score": 22.10838822353402,
    "MMLU Score": 23.41718380614657,
    "BBH Score": 33.044262388969805,
    "Math Score": 7.02416918429003,
    "Date Submitted": "2024-08-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 17.356572860071896
  },
  {
    "Model Name": "wave-on-discord/qwent-7b",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.646991877058367,
    "Overall Score": 8.797033099146908,
    "MMLU Score": 6.702497044917257,
    "BBH Score": 18.066398100675865,
    "Math Score": 0.3776435045317221,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 3.3234076671678925
  },
  {
    "Model Name": "weathermanj/Menda-3B-500",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7291662157880165,
    "Overall Score": 27.910059821789428,
    "MMLU Score": 27.498891843971627,
    "BBH Score": 26.596424541570496,
    "Math Score": 37.235649546827794,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.276677138184155
  },
  {
    "Model Name": "weathermanj/Menda-3b-750",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7407846285793263,
    "Overall Score": 27.833449062404902,
    "MMLU Score": 27.840573286052013,
    "BBH Score": 26.375984192530563,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2025-03-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 37.57293009141372
  },
  {
    "Model Name": "weathermanj/Menda-3b-Optim-100",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7290687191951919,
    "Overall Score": 27.957516413922587,
    "MMLU Score": 27.34190307328605,
    "BBH Score": 26.024032164105297,
    "Math Score": 37.160120845921455,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 38.3468878554884
  },
  {
    "Model Name": "weathermanj/Menda-3b-Optim-200",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.694796800217475,
    "Overall Score": 27.967747014863694,
    "MMLU Score": 27.60047281323877,
    "BBH Score": 26.07213126581908,
    "Math Score": 37.31117824773414,
    "Date Submitted": "2025-03-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 40.25313157186338
  },
  {
    "Model Name": "win10/ArliAI-RPMax-v1.3-merge-13.3B",
    "Parameters (B)": 13.265,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.902610378028072,
    "Overall Score": 16.531629526309775,
    "MMLU Score": 24.442228132387704,
    "BBH Score": 23.029799582073213,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.695435271454091
  },
  {
    "Model Name": "win10/Breeze-13B-32k-Instruct-v1_0",
    "Parameters (B)": 12.726,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.897622042858872,
    "Overall Score": 15.461558427858105,
    "MMLU Score": 17.423906619385342,
    "BBH Score": 25.258698638977545,
    "Math Score": 1.283987915407855,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 5.335947269576716
  },
  {
    "Model Name": "win10/EVA-Norns-Qwen2.5-v0.1",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.313321814515779,
    "Overall Score": 26.432796717883942,
    "MMLU Score": 26.94481382978724,
    "BBH Score": 30.06094150146785,
    "Math Score": 26.132930513595166,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.126671487315313
  },
  {
    "Model Name": "win10/Llama-3.2-3B-Instruct-24-9-29",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.4272112484883923,
    "Overall Score": 24.00469809006401,
    "MMLU Score": 24.756205673758867,
    "BBH Score": 24.196425775209622,
    "Math Score": 17.069486404833835,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.81930275948161
  },
  {
    "Model Name": "win10/Norns-Qwen2.5-12B",
    "Parameters (B)": 12.277,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.2459439428137693,
    "Overall Score": 17.708127562863925,
    "MMLU Score": 18.44895094562648,
    "BBH Score": 23.76925747689573,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-11-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.455463148730015
  },
  {
    "Model Name": "win10/Norns-Qwen2.5-7B",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.299827184284067,
    "Overall Score": 26.380789509358355,
    "MMLU Score": 26.81552895981087,
    "BBH Score": 30.250415044309648,
    "Math Score": 26.28398791540785,
    "Date Submitted": "2024-11-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 20.295613007885088
  },
  {
    "Model Name": "win10/Qwen2.5-2B-Instruct",
    "Parameters (B)": 2.9,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.052183070259754,
    "Overall Score": 10.57067746533664,
    "MMLU Score": 10.37788120567376,
    "BBH Score": 12.07194568570475,
    "Math Score": 2.2658610271903323,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 5.150942729489851
  },
  {
    "Model Name": "win10/llama3-13.45b-Instruct",
    "Parameters (B)": 13.265,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.273069289198686,
    "Overall Score": 17.340222099927356,
    "MMLU Score": 26.0582890070922,
    "BBH Score": 26.67569043948038,
    "Math Score": 2.416918429003021,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 4.05802502284701
  },
  {
    "Model Name": "win10/miscii-14b-1M-0128",
    "Parameters (B)": 14.766,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.776966322179807,
    "Overall Score": 35.33959615681345,
    "MMLU Score": 38.79284869976359,
    "BBH Score": 37.27434361892823,
    "Math Score": 47.73413897280967,
    "Date Submitted": "2025-01-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.356608754832065
  },
  {
    "Model Name": "winglian/Llama-3-8b-64k-PoSE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.8220424320327848,
    "Overall Score": 11.143207450567283,
    "MMLU Score": 16.297281323877066,
    "BBH Score": 13.30731679540503,
    "Math Score": 4.154078549848943,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.11577823582035
  },
  {
    "Model Name": "winglian/llama-3-8b-256k-PoSE",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.101445621651442,
    "Overall Score": 6.633243929125161,
    "MMLU Score": 1.291001773049644,
    "BBH Score": 5.502848923020156,
    "Math Score": 1.9637462235649543,
    "Date Submitted": "2024-06-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 3.156514668179879
  },
  {
    "Model Name": "wzhouad/gemma-2-9b-it-WPO-HB",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 5.179894574744527,
    "Overall Score": 24.97756909058171,
    "MMLU Score": 26.22451241134752,
    "BBH Score": 36.66169583479774,
    "Math Score": 15.332326283987916,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.8220226744312855
  },
  {
    "Model Name": "x0000001/Deepseek-Lumen-R1-Qwen2.5-14B",
    "Parameters (B)": 14.77,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 4.47491141011125,
    "Overall Score": 26.028524707214856,
    "MMLU Score": 37.54617316784869,
    "BBH Score": 22.725259750809624,
    "Math Score": 27.794561933534744,
    "Date Submitted": "2025-01-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.816545250125468
  },
  {
    "Model Name": "xMaulana/FinMatcha-3B-Instruct",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.3131482898189555,
    "Overall Score": 24.14212432324268,
    "MMLU Score": 24.23906619385342,
    "BBH Score": 23.19102296943548,
    "Math Score": 14.350453172205436,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.301194419488565
  },
  {
    "Model Name": "xinchen9/Llama3.1_8B_Instruct_CoT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8041996739094426,
    "Overall Score": 16.316624597778073,
    "MMLU Score": 20.877659574468087,
    "BBH Score": 21.14286611806116,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-09-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.818638647450679
  },
  {
    "Model Name": "xinchen9/Llama3.1_CoT",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.900197688328748,
    "Overall Score": 13.741515006547855,
    "MMLU Score": 19.317006501182032,
    "BBH Score": 19.899123541883053,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-09-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 7.231623894161097
  },
  {
    "Model Name": "xinchen9/Llama3.1_CoT_V1",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.8211828454337167,
    "Overall Score": 14.734826092960333,
    "MMLU Score": 20.05577718676123,
    "BBH Score": 20.166003338515427,
    "Math Score": 3.3232628398791544,
    "Date Submitted": "2024-09-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 5.222924886562985
  },
  {
    "Model Name": "xinchen9/Mistral-7B-CoT",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.515921799473043,
    "Overall Score": 11.26567589705759,
    "MMLU Score": 14.265661938534278,
    "BBH Score": 14.80619341451162,
    "Math Score": 2.492447129909366,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 4.477752805916771
  },
  {
    "Model Name": "xinchen9/llama3-b8-ft-dis",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.12465356085566,
    "Overall Score": 13.97349198756153,
    "MMLU Score": 24.931663711583923,
    "BBH Score": 24.72745698442778,
    "Math Score": 3.927492447129909,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.5768331576532395
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2484614630480797,
    "Overall Score": 22.823848851733704,
    "MMLU Score": 29.84448877068557,
    "BBH Score": 27.42282120153998,
    "Math Score": 9.214501510574015,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.281580591210233
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5005271922689942,
    "Overall Score": 24.502405108853072,
    "MMLU Score": 29.9645390070922,
    "BBH Score": 29.398353220629613,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 16.329197654727082
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3434827058247885,
    "Overall Score": 22.639173242532337,
    "MMLU Score": 30.019946808510632,
    "BBH Score": 27.69519951055004,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.851108796844347
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.438456591582074,
    "Overall Score": 23.07373460043833,
    "MMLU Score": 28.88408687943262,
    "BBH Score": 28.508587310114308,
    "Math Score": 8.610271903323262,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.040619324536504
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2300050028863556,
    "Overall Score": 22.42453458288846,
    "MMLU Score": 30.093823877068555,
    "BBH Score": 27.61371406788812,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 18.23125477560382
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.6829369566351955,
    "Overall Score": 24.203175690452312,
    "MMLU Score": 29.604388297872337,
    "BBH Score": 28.574878539626724,
    "Math Score": 8.534743202416918,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 14.381510605627964
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.359682794746034,
    "Overall Score": 21.79108884286481,
    "MMLU Score": 30.04765070921986,
    "BBH Score": 26.943904089240508,
    "Math Score": 10.725075528700906,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.026597473372473
  },
  {
    "Model Name": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.5382385227104545,
    "Overall Score": 23.12157632033239,
    "MMLU Score": 28.10837765957446,
    "BBH Score": 28.046977965255564,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-10-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 15.031203535060998
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9728607299994527,
    "Overall Score": 21.35765886697308,
    "MMLU Score": 29.539745862884164,
    "BBH Score": 26.866404089240515,
    "Math Score": 9.969788519637463,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.825730646977297
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1803061762843057,
    "Overall Score": 24.132871091204738,
    "MMLU Score": 29.918365839243503,
    "BBH Score": 29.73123940180749,
    "Math Score": 9.667673716012084,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 20.446280444940875
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3310428701238797,
    "Overall Score": 22.08358104722241,
    "MMLU Score": 29.53051122931442,
    "BBH Score": 27.892403263090213,
    "Math Score": 10.42296072507553,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.59118691283557
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1768382510919406,
    "Overall Score": 23.235948102250973,
    "MMLU Score": 29.050310283687946,
    "BBH Score": 28.43982384277912,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.744385501313605
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1728857969296893,
    "Overall Score": 20.90534117256461,
    "MMLU Score": 29.161125886524825,
    "BBH Score": 27.145373836403248,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.823850563532588
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.7389475842988935,
    "Overall Score": 23.550849013748405,
    "MMLU Score": 29.12418735224587,
    "BBH Score": 29.740550305634912,
    "Math Score": 7.175226586102719,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 13.543162097806187
  },
  {
    "Model Name": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3501876436837452,
    "Overall Score": 20.7748680596979,
    "MMLU Score": 29.678265366430256,
    "BBH Score": 26.839803365680336,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 15.386652482626337
  },
  {
    "Model Name": "xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.067883125987604,
    "Overall Score": 23.68496106862757,
    "MMLU Score": 30.17693557919622,
    "BBH Score": 28.11988708608538,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 11.453723264614302
  },
  {
    "Model Name": "xwen-team/Xwen-7B-Chat",
    "Parameters (B)": 7.616,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.0556345468545887,
    "Overall Score": 31.576751501854343,
    "MMLU Score": 36.55806737588653,
    "BBH Score": 30.9216327073333,
    "Math Score": 45.090634441087616,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 15.361072594431358
  },
  {
    "Model Name": "xxx777xxxASD/L3.1-ClaudeMaid-4x8B",
    "Parameters (B)": 24.942,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.752369138298316,
    "Overall Score": 26.404880965062542,
    "MMLU Score": 28.671690307328607,
    "BBH Score": 29.437347820739543,
    "Math Score": 14.123867069486405,
    "Date Submitted": "2024-07-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 5.556151089415869
  },
  {
    "Model Name": "yam-peleg/Hebrew-Gemma-11B-Instruct",
    "Parameters (B)": 10.475,
    "Architecture": "GemmaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 3.874534345261228,
    "Overall Score": 14.058232008864843,
    "MMLU Score": 17.266917848699762,
    "BBH Score": 16.86274051283721,
    "Math Score": 6.570996978851963,
    "Date Submitted": "2024-07-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 3.6283668580867907
  },
  {
    "Model Name": "yam-peleg/Hebrew-Mistral-7B",
    "Parameters (B)": 7.504,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.0942131773492205,
    "Overall Score": 13.302117179699644,
    "MMLU Score": 19.778738179669027,
    "BBH Score": 20.176940422218426,
    "Math Score": 4.984894259818732,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 6.351844847302978
  },
  {
    "Model Name": "yam-peleg/Hebrew-Mistral-7B-200K",
    "Parameters (B)": 7.504,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7353117338467755,
    "Overall Score": 10.64429135893812,
    "MMLU Score": 17.47931442080378,
    "BBH Score": 17.49360317518456,
    "Math Score": 2.3413897280966767,
    "Date Submitted": "2024-07-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-07",
    "Carbon_Efficiency": 14.475889434339123
  },
  {
    "Model Name": "yam-peleg/Hebrew-Mistral-7B-200K",
    "Parameters (B)": 7.504,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游릴 continuously pretrained",
    "Training CO2 (kg)": 2.6696632132469658,
    "Overall Score": 8.386669075864491,
    "MMLU Score": 16.989878841607567,
    "BBH Score": 7.671323719331375,
    "Math Score": 3.096676737160121,
    "Date Submitted": "2024-08-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.1414708170864154
  },
  {
    "Model Name": "yanng1242/Marcoro14-7B-slerp",
    "Parameters (B)": 7.242,
    "Architecture": "MistralForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 0.846102654796972,
    "Overall Score": 21.933478090702422,
    "MMLU Score": 24.09131205673759,
    "BBH Score": 32.97528227053496,
    "Math Score": 7.477341389728097,
    "Date Submitted": "2025-01-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 25.9229515075396
  },
  {
    "Model Name": "yasserrmd/Coder-GRPO-3B",
    "Parameters (B)": 3.086,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7510040579702157,
    "Overall Score": 25.914051108530288,
    "MMLU Score": 24.414524231678485,
    "BBH Score": 22.91231134222773,
    "Math Score": 32.02416918429003,
    "Date Submitted": "2025-03-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 34.505873614810774
  },
  {
    "Model Name": "yasserrmd/Text2SQL-1.5B",
    "Parameters (B)": 1.544,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.5655182145088332,
    "Overall Score": 13.233972018030462,
    "MMLU Score": 15.142952127659573,
    "BBH Score": 13.675719585052784,
    "Math Score": 6.797583081570997,
    "Date Submitted": "2025-03-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 23.40149561676718
  },
  {
    "Model Name": "ycros/BagelMIsteryTour-v2-8x7B",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.64913185802464,
    "Overall Score": 24.258614269254902,
    "MMLU Score": 27.480422576832154,
    "BBH Score": 31.69928662894613,
    "Math Score": 7.854984894259818,
    "Date Submitted": "2024-06-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 6.64777684476073
  },
  {
    "Model Name": "ycros/BagelMIsteryTour-v2-8x7B",
    "Parameters (B)": 46.703,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 7.238673064292047,
    "Overall Score": 24.82550730859936,
    "MMLU Score": 27.56353427895981,
    "BBH Score": 31.36612301591548,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-08-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-08",
    "Carbon_Efficiency": 3.4295660389833245
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2365060445940472,
    "Overall Score": 23.61656457033402,
    "MMLU Score": 30.17693557919622,
    "BBH Score": 28.170106538118223,
    "Math Score": 11.178247734138973,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.099433175910992
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2813256734746974,
    "Overall Score": 24.97848128342916,
    "MMLU Score": 30.53708628841608,
    "BBH Score": 29.30812792849256,
    "Math Score": 10.347432024169184,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.49424865240743
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.3591089095296276,
    "Overall Score": 23.457640244691195,
    "MMLU Score": 30.1954048463357,
    "BBH Score": 27.469588233937547,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.259573592825333
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2963682534332266,
    "Overall Score": 24.08979336766512,
    "MMLU Score": 29.807550236406616,
    "BBH Score": 28.60442422478885,
    "Math Score": 9.894259818731117,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 18.582523371632334
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.1644703259402496,
    "Overall Score": 23.246034978048385,
    "MMLU Score": 30.223108747044915,
    "BBH Score": 28.09919885125768,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.9627542756647
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2120430270932958,
    "Overall Score": 24.470596545324664,
    "MMLU Score": 30.38009751773049,
    "BBH Score": 28.78591054243753,
    "Math Score": 8.761329305135952,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 20.189544428971054
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2981844362850772,
    "Overall Score": 22.724716099715508,
    "MMLU Score": 30.029181442080382,
    "BBH Score": 27.82525272195498,
    "Math Score": 9.365558912386708,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 17.504998107006447
  },
  {
    "Model Name": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.2153799016409517,
    "Overall Score": 23.749108318905765,
    "MMLU Score": 29.659796099290777,
    "BBH Score": 28.12061516996449,
    "Math Score": 8.685800604229607,
    "Date Submitted": "2024-09-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 19.54048136458467
  },
  {
    "Model Name": "yifAI/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.344031359009474,
    "Overall Score": 22.73807535003498,
    "MMLU Score": 27.997562056737586,
    "BBH Score": 27.28106392287093,
    "Math Score": 7.552870090634441,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 16.917816089345205
  },
  {
    "Model Name": "ylalain/ECE-PRYMMAL-YL-1B-SLERP-V8",
    "Parameters (B)": 1.357,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.0968554918483069,
    "Overall Score": 9.679667500944214,
    "MMLU Score": 15.373817966903072,
    "BBH Score": 15.175392374828268,
    "Math Score": 0.4531722054380665,
    "Date Submitted": "2024-11-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.824925045169847
  },
  {
    "Model Name": "ymcki/Llama-3.1-8B-GRPO-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.6567906669597681,
    "Overall Score": 28.168375624484387,
    "MMLU Score": 30.4262706855792,
    "BBH Score": 30.353176522305507,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2025-02-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 42.88790484017315
  },
  {
    "Model Name": "ymcki/Llama-3.1-8B-SFT-GRPO-Instruct",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 0.7521236769130275,
    "Overall Score": 7.65915538651705,
    "MMLU Score": 1.087839834515365,
    "BBH Score": 4.467782695872583,
    "Math Score": 4.003021148036254,
    "Date Submitted": "2025-03-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-03",
    "Carbon_Efficiency": 10.183372258606244
  },
  {
    "Model Name": "ymcki/gemma-2-2b-ORPO-jpn-it-abliterated-18",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 7.227142161386585,
    "Overall Score": 15.288362728327092,
    "MMLU Score": 14.939790189125294,
    "BBH Score": 16.30199203988385,
    "Math Score": 4.305135951661631,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 2.1154091599318834
  },
  {
    "Model Name": "ymcki/gemma-2-2b-ORPO-jpn-it-abliterated-18-merge",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.7865524740093672,
    "Overall Score": 16.505537805625195,
    "MMLU Score": 16.232638888888886,
    "BBH Score": 17.34833699622109,
    "Math Score": 5.438066465256798,
    "Date Submitted": "2024-11-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.9232826080165575
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-17",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.98891218827434,
    "Overall Score": 15.64497618709844,
    "MMLU Score": 16.16799645390071,
    "BBH Score": 16.23474918432881,
    "Math Score": 3.8519637462235647,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.86609699479626
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-17-18-24",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4097172171633234,
    "Overall Score": 14.44776069045957,
    "MMLU Score": 14.247192671394798,
    "BBH Score": 13.114728218255616,
    "Math Score": 2.56797583081571,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 10.248694216512302
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-17-ORPO",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 11.290834446830782,
    "Overall Score": 14.844141845651569,
    "MMLU Score": 13.231382978723405,
    "BBH Score": 14.389413087436518,
    "Math Score": 6.193353474320242,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 1.3147072446729713
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-17-ORPO-alpaca",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.369332753800096,
    "Overall Score": 12.53043213387293,
    "MMLU Score": 13.8778073286052,
    "BBH Score": 16.922412033306475,
    "Math Score": 3.2477341389728096,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.288591108098166
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-18",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.906288848838165,
    "Overall Score": 16.245944384743186,
    "MMLU Score": 16.722074468085104,
    "BBH Score": 17.143414938177205,
    "Math Score": 4.45619335347432,
    "Date Submitted": "2024-10-18",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.522288946213308
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-18-ORPO",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 3.220754256066701,
    "Overall Score": 15.132293957042885,
    "MMLU Score": 13.166740543735225,
    "BBH Score": 16.538078577820993,
    "Math Score": 4.682779456193353,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.698369622127886
  },
  {
    "Model Name": "ymcki/gemma-2-2b-jpn-it-abliterated-24",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.6208845800460434,
    "Overall Score": 16.334186539569448,
    "MMLU Score": 16.37115839243499,
    "BBH Score": 16.772590130572933,
    "Math Score": 4.380664652567976,
    "Date Submitted": "2024-10-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 10.07732860232741
  },
  {
    "Model Name": "yuchenxie/ArlowGPT-3B-Multilingual",
    "Parameters (B)": 3.213,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.2236435031470276,
    "Overall Score": 20.501174920235083,
    "MMLU Score": 20.18506205673759,
    "BBH Score": 19.503170070297383,
    "Math Score": 11.253776435045316,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": 1287.0,
    "Reported CO2 (t)": 502.0,
    "Cloud Provider": "Microsoft (Azure)",
    "Water Use (Million Liters)": 4879.0,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 16.754205671430555
  },
  {
    "Model Name": "yuchenxie/ArlowGPT-8B",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.4335595564415415,
    "Overall Score": 28.9735720267936,
    "MMLU Score": 30.961879432624112,
    "BBH Score": 29.842908708676827,
    "Math Score": 20.39274924471299,
    "Date Submitted": "2025-01-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 20.21093012606561
  },
  {
    "Model Name": "yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 1.9440590206951107,
    "Overall Score": 18.088167586242665,
    "MMLU Score": 18.162677304964536,
    "BBH Score": 21.238562899271304,
    "Math Score": 5.664652567975831,
    "Date Submitted": "2024-09-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 9.304330472320293
  },
  {
    "Model Name": "yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.828288143464655,
    "Overall Score": 19.17256512798472,
    "MMLU Score": 28.59781323877068,
    "BBH Score": 23.492187889680057,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.486621157894835
  },
  {
    "Model Name": "yuvraj17/Llama3-8B-abliterated-Spectrum-slerp",
    "Parameters (B)": 8.03,
    "Architecture": "LlamaForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.6533204310572152,
    "Overall Score": 17.72531595014861,
    "MMLU Score": 25.07941784869976,
    "BBH Score": 28.54692976096071,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-09-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-09",
    "Carbon_Efficiency": 10.72104089272892
  },
  {
    "Model Name": "zake7749/gemma-2-2b-it-chinese-kyara-dpo",
    "Parameters (B)": 2.614,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 2.558618143456469,
    "Overall Score": 19.62411186744714,
    "MMLU Score": 17.47931442080378,
    "BBH Score": 19.061804188812648,
    "Math Score": 8.38368580060423,
    "Date Submitted": "2024-10-17",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 7.66980876674965
  },
  {
    "Model Name": "zake7749/gemma-2-9b-it-chinese-kyara",
    "Parameters (B)": 9.242,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游눫 chat models (RLHF, DPO, IFT, ...)",
    "Training CO2 (kg)": 2.0677900362682515,
    "Overall Score": 21.38318153545784,
    "MMLU Score": 35.32062647754137,
    "BBH Score": 41.100635505919165,
    "Math Score": 10.498489425981871,
    "Date Submitted": "2025-02-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.341079684303029
  },
  {
    "Model Name": "zelk12/Gemma-2-TM-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.935785345901056,
    "Overall Score": 33.52554437747302,
    "MMLU Score": 34.314051418439725,
    "BBH Score": 42.04949103777593,
    "Math Score": 20.241691842900305,
    "Date Submitted": "2024-11-06",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.518133340881603
  },
  {
    "Model Name": "zelk12/MT-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.725492826278124,
    "Overall Score": 34.51416587215041,
    "MMLU Score": 37.56464243498817,
    "BBH Score": 44.01124668886745,
    "Math Score": 22.20543806646526,
    "Date Submitted": "2024-10-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.13184189823164
  },
  {
    "Model Name": "zelk12/MT-Gen2-GI-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.737011711006484,
    "Overall Score": 34.7634808902102,
    "MMLU Score": 37.28760342789598,
    "BBH Score": 44.00259101447648,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.30248112089737
  },
  {
    "Model Name": "zelk12/MT-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.97889524950865,
    "Overall Score": 34.81518978196506,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 44.10778153097642,
    "Math Score": 21.90332326283988,
    "Date Submitted": "2024-11-10",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.749963896703326
  },
  {
    "Model Name": "zelk12/MT-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6264962573562407,
    "Overall Score": 34.862851201023894,
    "MMLU Score": 37.28760342789598,
    "BBH Score": 43.95064827244946,
    "Math Score": 22.9607250755287,
    "Date Submitted": "2024-11-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.613370241401912
  },
  {
    "Model Name": "zelk12/MT-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5633668079338543,
    "Overall Score": 34.69186259861687,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 43.96040416470536,
    "Math Score": 22.356495468277945,
    "Date Submitted": "2024-12-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.735697857816731
  },
  {
    "Model Name": "zelk12/MT-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5748551883605884,
    "Overall Score": 34.56384281127872,
    "MMLU Score": 37.80474290780142,
    "BBH Score": 44.39824361895261,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-12-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.66859942294041
  },
  {
    "Model Name": "zelk12/MT-Gen6-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.016062111190977,
    "Overall Score": 19.816468872767587,
    "MMLU Score": 35.172872340425535,
    "BBH Score": 39.39691509660613,
    "Math Score": 8.23262839879154,
    "Date Submitted": "2025-01-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 4.934303385783778
  },
  {
    "Model Name": "zelk12/MT-Gen6fix-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8012175211404218,
    "Overall Score": 20.06441030320394,
    "MMLU Score": 34.66496749408983,
    "BBH Score": 40.78635026219728,
    "Math Score": 8.157099697885197,
    "Date Submitted": "2025-02-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.278416768210707
  },
  {
    "Model Name": "zelk12/MT-Gen7-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.058312500916082,
    "Overall Score": 20.39180070971448,
    "MMLU Score": 34.692671394799056,
    "BBH Score": 40.93907104389604,
    "Math Score": 8.91238670694864,
    "Date Submitted": "2025-02-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.907047982577385
  },
  {
    "Model Name": "zelk12/MT-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.69223875048688,
    "Overall Score": 34.703708309941995,
    "MMLU Score": 37.73086583924351,
    "BBH Score": 44.5016839041576,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2025-01-02",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.39909649812482
  },
  {
    "Model Name": "zelk12/MT-Merge-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.438111674016961,
    "Overall Score": 34.87860604484159,
    "MMLU Score": 37.35224586288417,
    "BBH Score": 44.32084182103274,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-10-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.417521132105437
  },
  {
    "Model Name": "zelk12/MT-Merge1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.05468073156111,
    "Overall Score": 34.85532711993079,
    "MMLU Score": 37.49076536643025,
    "BBH Score": 44.05824559954283,
    "Math Score": 22.88519637462236,
    "Date Submitted": "2024-11-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 5.7567572371307945
  },
  {
    "Model Name": "zelk12/MT-Merge2-MU-gemma-2-MTg2MT1g2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6897704411880734,
    "Overall Score": 34.891868837941765,
    "MMLU Score": 37.47229609929077,
    "BBH Score": 43.84019994693836,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2024-11-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.456379304373986
  },
  {
    "Model Name": "zelk12/MT-Merge2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.701582383026738,
    "Overall Score": 34.82072732965434,
    "MMLU Score": 37.57387706855792,
    "BBH Score": 44.15719687702352,
    "Math Score": 23.48942598187311,
    "Date Submitted": "2024-11-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.406984291183562
  },
  {
    "Model Name": "zelk12/MT-Merge3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7620410574299785,
    "Overall Score": 34.63973964338121,
    "MMLU Score": 37.48153073286053,
    "BBH Score": 44.06607310905077,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.207698457986845
  },
  {
    "Model Name": "zelk12/MT-Merge4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.74677027237328,
    "Overall Score": 34.59930867791183,
    "MMLU Score": 37.66622340425532,
    "BBH Score": 44.05349239999947,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2024-12-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.23443557055766
  },
  {
    "Model Name": "zelk12/MT-Merge5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.601579747299585,
    "Overall Score": 34.6922400282852,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 44.240598262546506,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2024-12-30",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.632506417301176
  },
  {
    "Model Name": "zelk12/MT-Merge6-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.0751509617498924,
    "Overall Score": 20.20346619991928,
    "MMLU Score": 34.6095596926714,
    "BBH Score": 41.32196105730412,
    "Math Score": 8.006042296072508,
    "Date Submitted": "2025-02-13",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 9.73590190415954
  },
  {
    "Model Name": "zelk12/MT-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.046797818737478,
    "Overall Score": 33.61322699458912,
    "MMLU Score": 35.819296690307326,
    "BBH Score": 43.32424255563143,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.558847509409086
  },
  {
    "Model Name": "zelk12/MT1-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.724969438917603,
    "Overall Score": 34.93165507194035,
    "MMLU Score": 37.50923463356973,
    "BBH Score": 44.27328174531427,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-10-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.19432175703131
  },
  {
    "Model Name": "zelk12/MT1-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.991990303629385,
    "Overall Score": 35.005439602301884,
    "MMLU Score": 37.27836879432624,
    "BBH Score": 43.91919055805058,
    "Math Score": 22.507552870090635,
    "Date Submitted": "2024-11-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.768918995238064
  },
  {
    "Model Name": "zelk12/MT1-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.889753245978531,
    "Overall Score": 34.739851169246734,
    "MMLU Score": 37.21372635933806,
    "BBH Score": 43.99030612548967,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-12-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.931119526711097
  },
  {
    "Model Name": "zelk12/MT1-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.484124550367983,
    "Overall Score": 34.28920938772912,
    "MMLU Score": 36.51189420803782,
    "BBH Score": 43.14536816106877,
    "Math Score": 21.6012084592145,
    "Date Submitted": "2024-12-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.841556721646933
  },
  {
    "Model Name": "zelk12/MT1-Gen5-IF-gemma-2-S2DMv1-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.4142540478852608,
    "Overall Score": 33.781043838460555,
    "MMLU Score": 35.754654255319146,
    "BBH Score": 42.20102785338743,
    "Math Score": 20.31722054380665,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.89412134090726
  },
  {
    "Model Name": "zelk12/MT1-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.510460673126224,
    "Overall Score": 33.556617199966034,
    "MMLU Score": 35.80082742316785,
    "BBH Score": 42.49676419899819,
    "Math Score": 20.77039274924472,
    "Date Submitted": "2024-12-24",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.559035216333118
  },
  {
    "Model Name": "zelk12/MT1-Gen6-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.846159834892288,
    "Overall Score": 19.919694219754245,
    "MMLU Score": 34.81272163120568,
    "BBH Score": 41.26198928071469,
    "Math Score": 8.08157099697885,
    "Date Submitted": "2025-02-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.1791124328851765
  },
  {
    "Model Name": "zelk12/MT1-Gen7-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.130285589661694,
    "Overall Score": 20.19902054572098,
    "MMLU Score": 34.94200650118203,
    "BBH Score": 41.18207626381973,
    "Math Score": 8.308157099697885,
    "Date Submitted": "2025-02-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 4.890465830324206
  },
  {
    "Model Name": "zelk12/MT1-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.755959661882613,
    "Overall Score": 34.87300068519695,
    "MMLU Score": 37.57387706855792,
    "BBH Score": 44.2263771296489,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.284711185560878
  },
  {
    "Model Name": "zelk12/MT1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.6914387804832085,
    "Overall Score": 34.86746462523027,
    "MMLU Score": 37.30607269503546,
    "BBH Score": 44.16152621661877,
    "Math Score": 22.356495468277945,
    "Date Submitted": "2024-10-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.210757472208748
  },
  {
    "Model Name": "zelk12/MT2-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.766419553650529,
    "Overall Score": 34.46173377708927,
    "MMLU Score": 37.51846926713948,
    "BBH Score": 44.141103157274806,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2024-10-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.0930530546981725
  },
  {
    "Model Name": "zelk12/MT2-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.074882610785808,
    "Overall Score": 34.64186698980044,
    "MMLU Score": 37.64775413711584,
    "BBH Score": 44.04450256220759,
    "Math Score": 21.827794561933533,
    "Date Submitted": "2024-11-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.501316552802496
  },
  {
    "Model Name": "zelk12/MT2-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.848753509583258,
    "Overall Score": 34.26447113111225,
    "MMLU Score": 37.49076536643025,
    "BBH Score": 44.007274058843926,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-12-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.902745017521893
  },
  {
    "Model Name": "zelk12/MT2-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.572871445220205,
    "Overall Score": 34.202321593914604,
    "MMLU Score": 36.89974881796691,
    "BBH Score": 43.778361681045226,
    "Math Score": 22.356495468277945,
    "Date Submitted": "2024-12-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.572782597501666
  },
  {
    "Model Name": "zelk12/MT2-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5242714236898025,
    "Overall Score": 34.04923355550058,
    "MMLU Score": 36.68735224586289,
    "BBH Score": 43.12428137338583,
    "Math Score": 21.07250755287009,
    "Date Submitted": "2024-12-25",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.661353925984534
  },
  {
    "Model Name": "zelk12/MT2-Gen6-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8988147594218,
    "Overall Score": 20.837841635914646,
    "MMLU Score": 35.662307919621746,
    "BBH Score": 41.771094311913785,
    "Math Score": 8.459214501510575,
    "Date Submitted": "2025-02-05",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 5.344660601163039
  },
  {
    "Model Name": "zelk12/MT2-Gen7-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.033677209952117,
    "Overall Score": 22.28290945432224,
    "MMLU Score": 36.788933215130015,
    "BBH Score": 43.57419892144867,
    "Math Score": 10.196374622356496,
    "Date Submitted": "2025-02-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.956954891994336
  },
  {
    "Model Name": "zelk12/MT2-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6579498577309617,
    "Overall Score": 34.675340724715895,
    "MMLU Score": 37.67545803782505,
    "BBH Score": 44.04081717896338,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2025-01-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.479446704670009
  },
  {
    "Model Name": "zelk12/MT2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.3882197422474745,
    "Overall Score": 34.516135363494435,
    "MMLU Score": 37.42612293144209,
    "BBH Score": 44.16748136989228,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2024-10-15",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.403091433318655
  },
  {
    "Model Name": "zelk12/MT3-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.227331803428212,
    "Overall Score": 34.08858123026874,
    "MMLU Score": 36.96439125295508,
    "BBH Score": 44.11949468740284,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-10-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.47402680735634
  },
  {
    "Model Name": "zelk12/MT3-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8382167971966807,
    "Overall Score": 34.34982932139744,
    "MMLU Score": 37.02903368794326,
    "BBH Score": 43.94022574925496,
    "Math Score": 22.356495468277945,
    "Date Submitted": "2024-11-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.949423947726334
  },
  {
    "Model Name": "zelk12/MT3-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8089251355109486,
    "Overall Score": 34.43703358555928,
    "MMLU Score": 36.696586879432616,
    "BBH Score": 43.78374025194924,
    "Math Score": 21.52567975830816,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.041142149132767
  },
  {
    "Model Name": "zelk12/MT3-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.6417066861965695,
    "Overall Score": 34.517532467321914,
    "MMLU Score": 37.63851950354609,
    "BBH Score": 43.77959090180507,
    "Math Score": 20.619335347432024,
    "Date Submitted": "2024-12-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.478394456686003
  },
  {
    "Model Name": "zelk12/MT3-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8812542327353103,
    "Overall Score": 34.7576818343369,
    "MMLU Score": 36.8535756501182,
    "BBH Score": 43.9511986459128,
    "Math Score": 22.658610271903324,
    "Date Submitted": "2024-12-26",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.955270577532216
  },
  {
    "Model Name": "zelk12/MT3-Gen5-gemma-2-9B_v1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.8563037332700265,
    "Overall Score": 34.734556510838615,
    "MMLU Score": 37.32454196217494,
    "BBH Score": 44.15960180869316,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2024-12-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.00721491701194
  },
  {
    "Model Name": "zelk12/MT3-Gen6-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 2.047318577948042,
    "Overall Score": 21.10285538804693,
    "MMLU Score": 34.47104018912529,
    "BBH Score": 42.63936302517612,
    "Math Score": 8.836858006042297,
    "Date Submitted": "2025-02-12",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-02",
    "Carbon_Efficiency": 10.307558196046658
  },
  {
    "Model Name": "zelk12/MT3-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.892564060112597,
    "Overall Score": 22.46770825046867,
    "MMLU Score": 37.65698877068557,
    "BBH Score": 44.20651979334247,
    "Math Score": 10.120845921450153,
    "Date Submitted": "2025-01-09",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.771955940480725
  },
  {
    "Model Name": "zelk12/MT3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.273305775537166,
    "Overall Score": 34.21556543403697,
    "MMLU Score": 36.96439125295508,
    "BBH Score": 44.24846451595969,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2024-10-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.454152349381883
  },
  {
    "Model Name": "zelk12/MT4-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.2071216016304085,
    "Overall Score": 34.703100960707964,
    "MMLU Score": 37.65698877068557,
    "BBH Score": 44.0095244503664,
    "Math Score": 21.978851963746223,
    "Date Submitted": "2024-10-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.248656503596019
  },
  {
    "Model Name": "zelk12/MT4-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.954094529653287,
    "Overall Score": 35.05354383653148,
    "MMLU Score": 37.41688829787233,
    "BBH Score": 44.17665766133724,
    "Math Score": 23.26283987915408,
    "Date Submitted": "2024-11-22",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 8.865125396889573
  },
  {
    "Model Name": "zelk12/MT4-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.917402531237976,
    "Overall Score": 34.3726822248935,
    "MMLU Score": 37.56464243498817,
    "BBH Score": 43.894390102514826,
    "Math Score": 21.90332326283988,
    "Date Submitted": "2024-12-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.774355443639095
  },
  {
    "Model Name": "zelk12/MT4-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.587482458465672,
    "Overall Score": 34.381140380385126,
    "MMLU Score": 36.92745271867612,
    "BBH Score": 43.475810110859705,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-12-19",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.583639997807703
  },
  {
    "Model Name": "zelk12/MT4-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.69472341738416,
    "Overall Score": 34.72051149657049,
    "MMLU Score": 37.60158096926713,
    "BBH Score": 43.94789156904174,
    "Math Score": 22.658610271903324,
    "Date Submitted": "2024-12-28",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.397323581301354
  },
  {
    "Model Name": "zelk12/MT4-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.916799717428739,
    "Overall Score": 22.332038216896635,
    "MMLU Score": 37.67545803782505,
    "BBH Score": 44.17398166698081,
    "Math Score": 9.516616314199396,
    "Date Submitted": "2025-01-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.701603305761303
  },
  {
    "Model Name": "zelk12/MT4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.310517143448776,
    "Overall Score": 34.02640198293455,
    "MMLU Score": 37.39841903073286,
    "BBH Score": 43.55382749958519,
    "Math Score": 20.84592145015106,
    "Date Submitted": "2024-10-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.392014823738946
  },
  {
    "Model Name": "zelk12/MT5-Gen1-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.03450573615006,
    "Overall Score": 34.44043157912841,
    "MMLU Score": 37.42612293144209,
    "BBH Score": 44.18333461079421,
    "Math Score": 22.12990936555892,
    "Date Submitted": "2024-10-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 8.536468611392605
  },
  {
    "Model Name": "zelk12/MT5-Gen2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.71676143663356,
    "Overall Score": 34.55154984197392,
    "MMLU Score": 37.54617316784869,
    "BBH Score": 44.11321466977781,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-11-23",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 9.296144084315735
  },
  {
    "Model Name": "zelk12/MT5-Gen3-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.874666248807024,
    "Overall Score": 34.48864530182997,
    "MMLU Score": 37.5,
    "BBH Score": 43.88591333925529,
    "Math Score": 21.676737160120847,
    "Date Submitted": "2024-12-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.901062204376629
  },
  {
    "Model Name": "zelk12/MT5-Gen4-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.643440535396216,
    "Overall Score": 34.658891352635635,
    "MMLU Score": 37.74010047281324,
    "BBH Score": 44.32321082390572,
    "Math Score": 22.432024169184288,
    "Date Submitted": "2024-12-20",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.512682042130972
  },
  {
    "Model Name": "zelk12/MT5-Gen5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.783290823904248,
    "Overall Score": 34.634253143757086,
    "MMLU Score": 36.99209515366431,
    "BBH Score": 44.1150811115254,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-12-29",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.15453100378245
  },
  {
    "Model Name": "zelk12/MT5-Max-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 4.124418721495757,
    "Overall Score": 22.353756658265933,
    "MMLU Score": 37.66622340425532,
    "BBH Score": 44.27440650358212,
    "Math Score": 9.818731117824774,
    "Date Submitted": "2025-01-14",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.4198562676873765
  },
  {
    "Model Name": "zelk12/MT5-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.539660404219592,
    "Overall Score": 34.77304917830787,
    "MMLU Score": 37.4076536643026,
    "BBH Score": 44.27125659181852,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-10-21",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.317256100312369
  },
  {
    "Model Name": "zelk12/MTM-Merge-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.586691793579361,
    "Overall Score": 34.61498534418492,
    "MMLU Score": 37.64775413711584,
    "BBH Score": 44.38067726918037,
    "Math Score": 21.75226586102719,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 9.65095060750695
  },
  {
    "Model Name": "zelk12/MTMaMe-Merge_02012025163610-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.795679355233992,
    "Overall Score": 22.38549709465176,
    "MMLU Score": 37.57387706855792,
    "BBH Score": 44.16046314846229,
    "Math Score": 9.59214501510574,
    "Date Submitted": "2025-01-16",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 5.897625958257943
  },
  {
    "Model Name": "zelk12/Rv0.4DMv1t0.25-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.837289337494063,
    "Overall Score": 34.11401781690754,
    "MMLU Score": 37.786273640661946,
    "BBH Score": 43.66476423073275,
    "Math Score": 22.58308157099698,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.890134367398435
  },
  {
    "Model Name": "zelk12/Rv0.4DMv1t0.25Tt0.25-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.825165974191258,
    "Overall Score": 33.87751505283704,
    "MMLU Score": 37.186022458628834,
    "BBH Score": 43.91481856092577,
    "Math Score": 20.694864048338367,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 8.856482380480143
  },
  {
    "Model Name": "zelk12/Rv0.4MT4g2-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.706506822326515,
    "Overall Score": 33.255961795847774,
    "MMLU Score": 37.97096631205674,
    "BBH Score": 43.19904579899195,
    "Math Score": 19.486404833836858,
    "Date Submitted": "2025-01-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 8.972319056726716
  },
  {
    "Model Name": "zelk12/T31122024203920-gemma-2-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.7327384775668433,
    "Overall Score": 34.20907135232025,
    "MMLU Score": 37.47229609929077,
    "BBH Score": 43.72899711113373,
    "Math Score": 20.54380664652568,
    "Date Submitted": "2024-12-31",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.164604366984523
  },
  {
    "Model Name": "zelk12/Test01012025155054",
    "Parameters (B)": 3.817,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.4009482075272095,
    "Overall Score": 3.591417057729718,
    "MMLU Score": 1.0047281323877066,
    "BBH Score": 1.2805465682883084,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.5635616209316323
  },
  {
    "Model Name": "zelk12/Test01012025155054t0.5_gemma-2",
    "Parameters (B)": 3.817,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 1.3959284921606303,
    "Overall Score": 3.591417057729718,
    "MMLU Score": 1.0047281323877066,
    "BBH Score": 1.2805465682883084,
    "Math Score": 0.0,
    "Date Submitted": "2025-01-01",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2025-01",
    "Carbon_Efficiency": 2.5727801086507602
  },
  {
    "Model Name": "zelk12/gemma-2-S2MTM-9B",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 3.5302052373960766,
    "Overall Score": 33.89283041556518,
    "MMLU Score": 36.63194444444445,
    "BBH Score": 43.11572752288462,
    "Math Score": 20.46827794561933,
    "Date Submitted": "2024-12-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 9.600810189881468
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.886382695851784,
    "Overall Score": 33.91991864588516,
    "MMLU Score": 36.89974881796691,
    "BBH Score": 43.70651609013871,
    "Math Score": 22.80966767371601,
    "Date Submitted": "2024-10-03",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.925651121062125
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.389981437107325,
    "Overall Score": 34.28211941982605,
    "MMLU Score": 37.77703900709219,
    "BBH Score": 43.85035014659934,
    "Math Score": 21.45015105740181,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.364979500683056
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 7.50290559085358,
    "Overall Score": 31.782789348821325,
    "MMLU Score": 34.895833333333336,
    "BBH Score": 42.48715312806591,
    "Math Score": 20.166163141993955,
    "Date Submitted": "2024-10-04",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.236064143945266
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.8273508762924,
    "Overall Score": 33.62606373114868,
    "MMLU Score": 36.91821808510639,
    "BBH Score": 43.63358839796041,
    "Math Score": 22.2809667673716,
    "Date Submitted": "2024-10-11",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 4.925199296247295
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.698969799762018,
    "Overall Score": 33.904825121052134,
    "MMLU Score": 36.83510638297872,
    "BBH Score": 43.94125829423596,
    "Math Score": 20.996978851963743,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.4957140625269347
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-Ifable-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 9.808855629370424,
    "Overall Score": 34.40699088269145,
    "MMLU Score": 36.92745271867612,
    "BBH Score": 43.39057008013784,
    "Math Score": 22.05438066465257,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 3.5077477111262008
  },
  {
    "Model Name": "zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1",
    "Parameters (B)": 10.159,
    "Architecture": "Gemma2ForCausalLM",
    "Model Type": "游뱋 base merges and moerges",
    "Training CO2 (kg)": 6.264440877177395,
    "Overall Score": 32.586530614782504,
    "MMLU Score": 35.33909574468085,
    "BBH Score": 42.1326829485998,
    "Math Score": 18.882175226586103,
    "Date Submitted": "2024-10-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-10",
    "Carbon_Efficiency": 5.201825869807746
  },
  {
    "Model Name": "zetasepic/Qwen2.5-32B-Instruct-abliterated-v2",
    "Parameters (B)": 32.764,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 13.4895781101849,
    "Overall Score": 46.88867299768722,
    "MMLU Score": 51.35195035460993,
    "BBH Score": 56.53381848053764,
    "Math Score": 59.5166163141994,
    "Date Submitted": "2024-12-07",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-12",
    "Carbon_Efficiency": 3.4759184175141358
  },
  {
    "Model Name": "zetasepic/Qwen2.5-72B-Instruct-abliterated",
    "Parameters (B)": 72.706,
    "Architecture": "Qwen2ForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 37.618363240455366,
    "Overall Score": 46.33795303791254,
    "MMLU Score": 54.13157505910166,
    "BBH Score": 59.912975835046495,
    "Math Score": 52.41691842900303,
    "Date Submitted": "2024-11-08",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-11",
    "Carbon_Efficiency": 1.2317907810534403
  },
  {
    "Model Name": "zhengr/MixTAO-7Bx2-MoE-v8.1",
    "Parameters (B)": 12.879,
    "Architecture": "MixtralForCausalLM",
    "Model Type": "游댰 fine-tuned on domain-specific datasets",
    "Training CO2 (kg)": 1.854780175643176,
    "Overall Score": 17.067606418207944,
    "MMLU Score": 20.517508865248228,
    "BBH Score": 19.17690717348315,
    "Math Score": 6.042296072507553,
    "Date Submitted": "2024-06-27",
    "Training Energy (MWh)": NaN,
    "Reported CO2 (t)": NaN,
    "Cloud Provider": null,
    "Water Use (Million Liters)": NaN,
    "Year_Month": "2024-06",
    "Carbon_Efficiency": 9.20195645949767
  }
]